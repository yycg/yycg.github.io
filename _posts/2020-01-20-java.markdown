---
layout:     post
title:      "Java整理"
subtitle:   ""
date:       2020-01-20 12:00:00
author:     "盈盈冲哥"
header-img: "img/fleabag.jpg"
mathjax: true
catalog: true
tags:
    - 学习
---

## 目录

- [基础](#基础)
- [容器](#容器)
- [并发](#并发)
- [JVM](#jvm)
- [Java 8](#java\ 8)
- [网络](#网络)
- [操作系统](#操作系统)
- [数据库](#数据库)
- [系统设计](#系统设计)
- [工具](#工具)

## 基础

- 面对对象语言的特点：**封装**、**继承**、**多态**（指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。（发送消息就是函数调用））（引用变量指向哪个类的实例对象，引用对象发出的方法调用哪个类中的实现的方法，在程序运行期间才能确定）。

- JVM、JDK、JRE

  - **Java虚拟机(JVM)**实现**平台无关性**，是运行**Java字节码**（.class文件）的虚拟机。
  - .java源代码（通过JDK中的javac编译）.class字节码（通过JVM）机器码。
  - **JDK包括JRE**、javac、jdb等，能够创建和**编译程序**；**JRE**是**Java运行环境**，用于运行已编译的Java程序，包括JVM等。

- Java与C++的区别

  - Java**没有指针来直接访问内存**，访问内存更安全。
  - 有**自动内存管理机制**，不需要手动释放内存。
  - Java的类是**单继承**的，接口可以多继承，C++支持多继承。
  - Java字符串没有\0，因为Java里**一切都是对象**，可以确定长度。

- Java的接口和C++的虚类的相同和不同处

  - 由于Java不支持多继承，而有可能某个类或对象要使用分别在几个类或对象里面的方法或属性，现有的单继承机制就不能满足要求。
  - 与继承相比，接口有更高的灵活性，因为接口中没有任何实现代码。当一个类实现了接口以后，该类要实现接口里面所有的方法和属性。

  > [https://blog.csdn.net/chwshuang/article/details/46943711](<https://blog.csdn.net/chwshuang/article/details/46943711>)

  - C++虚类相当于java中的抽象类，一个子类只能继承一个抽象类（虚类），但能实现多个接口
  - 一个抽象类可以有构造方法，接口没有构造方法
  - 一个抽象类中的方法不一定是抽象方法，即其中的方法可以有实现（有方法体），接口中的方法都是抽象方法，不能有方法体，只有声明
  - 一个抽象类可以是public、private、protected、default，接口只有public
  - 一个抽象类中的方法可以是public、private、protected、default，接口中的方法只能是public和default
  - 相同之处是：都不能实例化。

- **构造器（private方法）**不能**重写**（override），但是可以**重载**（overload），一个类中可以有多个构造器。

- **重写**（override）和**重载**（overload）的区别

  - 方法的重写和重载都是实现多态的方式，区别在于前者实现的是运行的多态性，而后者实现的是编译时的多态性。

  - 重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，不能比父类被重写方法声明更多的异常（里氏代换原则）

  - 重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载。

  - 重载是否区分返回值类型？重载不根据返回类型进行区分。

  - Overloaded的方法是否可以改变返回值的类型？

    > [https://blog.csdn.net/singit/article/details/47722047](https://blog.csdn.net/singit/article/details/47722047)

    这个题目很模糊。如果几个Overloaded的方法的参数列表不一样，它们的返回者类型当然也可以不一样。但我估计你想问的问题是：如果两个方法的参数列表完全一样，是否可以让它们的返回值不同来实现重载Overload。这是不行的。

    我们可以用反证法来说明这个问题，因为我们有时候调用一个方法时也可以不定义返回结果变量，即不要关心其返回结果，例如，我们调用map.remove(key)方法时，虽然remove方法有返回值，但是我们通常都不会定义接收返回结果的变量，这时候假设该类中有两个名称和参数列表完全相同的方法，仅仅是返回类型不同，java就无法确定编程者倒底是想调用哪个方法了，因为它无法通过返回结果类型来判断。

- String、Stringbuffer、StringBuilder

  - **String**类中使用**final**关键字修饰字符数组来保存字符串，对象**不可变**，**线程安全**。
  - StringBuffer和StringBuilder构造方法调用父类AbstractStringBuffer实现，是**可变**的。
  - **StringBuffer**对方法加了**同步锁**，是**线程安全**的；**StringBuilder**没有加同步锁，非线程安全。
  - 底层实现上的话，StringBuffer其实就是比StringBuilder多了Synchronized修饰符。

- **装箱**：基本类型用对应的引用类型包装起来。

  **拆箱**：包装类型转换为基本数据类型。

- 静态方法内不能调用非静态成员，因为静态方法可以不通过对象进行调用。

- 不做事且没有参数的构造方法的作用：子类中没有用super()方法来调用父类特定的构造方法，**会调用父类中没有参数的构造方法**。

- **接口**和**抽象类**的区别

  - **方法在接口中不能有实现**，而抽象类可以有非抽象方法。
  - 接口中除了static、final变量，不能有其他变量。
  - **一个类可以实现多个接口，但只能实现一个抽象类**。接口可以通过extends关键字扩展多个接口。
  - 接口方法默认是public，抽象方法可以有public、protected、default（不能使用private）。
  - 抽象类是对类的抽象，接口是对行为的抽象。

- **成员变量**和**局部变量**的区别

  - 成员变量属于类，局部变量是在方法中定义的变量或方法的参数；成员变量可以被public、private、static等修饰符修饰，局部变量不能被访问控制符及static所修饰；成员变量和局部变量都能被final修饰。
  - 成员变量如果使用static修饰属于类，否则属于实例。对象存在堆中，局部变量存在栈中，**静态变量存在方法区**。
  - 成员变量是对象的一部分，随着对象的创建而存在；局部变量随着方法的调用而自动消失。
  - 成员变量如果没有赋初值会自动赋默认值，局部变量不会自动赋值。

- 构造方法

  - 名字于类名相同。
  - 没有返回值，不能用void声明构造函数。
  - 生成类的对象时自动执行，无需调用。如果没有声明构造方法，会有默认的不带参数的构造函数。
  - 作用时完成堆类对象的初始化工作。

- **静态方法**和**实例方法**的区别

  - 在外部调用静态方法：类名.方法名、对象名.方法名；实例方法：对象名.方法名。
  - 静态方法在访问本类成员时，只允许访问静态成员（静态成员变量、静态方法），不允许访问实例成员变量和实例方法。

- **==**和**equals()**的区别

  - ==：判断两个对象的地址是不是相等。
  - equals()
    - 情况1：类没有覆盖equals()方法时，等价于==。
    - 情况2：覆盖类equals()方法，来比较两个对象的内容是否相等。

- **hashCode()**和**equals()**的区别

  - hashCode()的作用：获取散列码，实际上是一个int整数。
  - 为什么要有散列码？以“HashSet”如何检查重复为例：**当把对象加入HashSet时，HashSet会先计算散列码，如果没有相符的散列码，HashSet会假设对象没有重复出现，如果发现有相同散列码的对象，会调用equals()方法来检查对象是否真的相同。如果两者相同，HashSet就不会让它加入，否则就会重新散列到其他位置。这样就大大减少equals()的次数，提高执行速度。**
  - 相关规定
    - **如果两个对象相等，则散列码相同。**
    - 如果两个对象相等，则两个对象分别调用equals()方法都返回true。
    - 两个对象有相同的散列码，它们也不一定是相等的。
    - **equals()方法被覆盖过，则hashCode()方法也必须被覆盖**。
    - hashCode()的默认行为是对堆上的对象产生独特值，如果没有重写hashcode()，则同一个类的两个对象无论如何不会相等。

- 重写equals()是否需要重写hashcode()，不重写会有什么后果

  > [https://blog.csdn.net/xyh269/article/details/69171545](https://blog.csdn.net/xyh269/article/details/69171545)
  
  需要，不重写有可能两个对象相等但是hashcode不相等，HashMap中存在重复的键。

- 为什么**Java中只有值传递**

  - 例1

    ```java
    public static void main(String[] args) {
    	int[] arr = { 1, 2, 3, 4, 5 };
    	System.out.println(arr[0]);
    	change(arr);
    	System.out.println(arr[0]);
    }
    
    public static void change(int[] array) {
    	// 将数组的第一个元素变为0
    	array[0] = 0;
    }
    ```

    结果

    ```
    1
    0
    ```

    解析：**方法得到的是对象引用的拷贝，对象引用及对象引用的拷贝同时引用同一个对象**。

    ![example 2](https://camo.githubusercontent.com/b7bad9506150c29bb8d7debd3905bd7a71cd6611/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d32372f333832353230342e6a7067)

  - 例2

    ```java
    public class Test {
    
    	public static void main(String[] args) {
    		// TODO Auto-generated method stub
    		Student s1 = new Student("小张");
    		Student s2 = new Student("小李");
    		Test.swap(s1, s2);
    		System.out.println("s1:" + s1.getName());
    		System.out.println("s2:" + s2.getName());
    	}
    
    	public static void swap(Student x, Student y) {
    		Student temp = x;
    		x = y;
    		y = temp;
    		System.out.println("x:" + x.getName());
    		System.out.println("y:" + y.getName());
    	}
    }
    ```

    结果

    ```
    x:小李
    y:小张
    s1:小张
    s2:小李
    ```

    解析

    交换之前：

    ![img](https://camo.githubusercontent.com/9d6dd0313695d309280675cd3251b47432a28814/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d32372f38383732393831382e6a7067)

    交换之后：

    ![img](https://camo.githubusercontent.com/6bea9b0ed65609d699207ab787f631f7ba0a9246/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d32372f33343338343431342e6a7067)

    方法并没有改变存储在变量s1和s2中的对象引用。

  - 总结

    **Java中对对象采用的不是引用调用，对象引用是按值传递的**，因此一个方法不能让对象参数引用一个新的对象。

- HashMap的key可以是可变的对象吗

  > [https://www.cnblogs.com/0201zcr/p/4810813.html](https://www.cnblogs.com/0201zcr/p/4810813.html)

  运行时可能会出现找不到key的问题。

- Java中的异常处理

  - 异常类层次结构

    ![Java异常类层次结构图](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-2/Exception.png)

    **Throwable类**分为两个子类：**Exception（异常）**和**Error（错误）**。

    **Error是程序无法处理的错误**。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题。例如，Java虚拟机运行错误（Virtual MachineError），当 JVM 不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。

    **Exception是程序本身可以处理的异常**。Exception 类有一个重要的子类 **RuntimeException**。RuntimeException 异常由Java虚拟机抛出。**NullPointerException**（要访问的变量没有引用任何对象时，抛出该异常）、**ArithmeticException**（算术运算异常，一个整数除以0时，抛出该异常）和 **ArrayIndexOutOfBoundsException** （下标越界异常）。

  - 异常处理总结

    - **try 块：** 用于捕获异常。其后可接零个或多个catch块，如果没有catch块，则必须跟一个finally块。

    - **catch 块：** 用于处理try捕获到的异常。

    - **finally 块：** 无论是否捕获或处理异常，finally块里的语句都会被执行。当在try块或catch块中遇到return 语句时，finally语句块将在方法返回之前被执行。

    - **注意：** 当try语句和finally语句中都有return语句时，在方法返回之前，finally语句的内容将被执行，并且finally语句的返回值将会覆盖原始的返回值。以下代码如果调用 `f(2)`，返回值将是0，因为finally语句的返回值覆盖了try语句块的返回值。

      ```java
      public static int f(int value) {
          try {
              return value * value;
          } finally {
              if (value == 2) {
                  return 0;
              }
          }
      }
      ```

  - 请说明JAVA语言如何进行异常处理，关键字：throws,throw,try,catch,finally分别代表什么意义？在try块中可以抛出异常吗？

    - throw：用来明确地抛出一个“异常”。

    - throws：标明一个成员函数可能抛出的各种“异常”。
    - 可以在try里手动抛出异常，不过比较少见；也可以在try里嵌套try。

- transient关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复。transient只能修饰变量，不能修饰类和方法。

- 获取用键盘输入的方法

  - 通过 Scanner

    ```java
    Scanner input = new Scanner(System.in);
    String s  = input.nextLine();
    input.close();
    ```

  - 通过 BufferedReader

    ```java
    BufferedReader input = new BufferedReader(new InputStreamReader(System.in)); 
    String s = input.readLine(); 
    ```

- Java中的I/O流

  - Java中的I/O流的40多个类都是由以下4个抽象类积累中派生出来的。

    - InputStream/Reader: 字节输入流/字符输入流。
    - OutputStream/Writer: 字节输出流/字符输出流。

  - 信息的最小存储单元都是字节，那为什么 I/O 流操作要分为字节流操作和字符流操作呢？

    如果我们不知道编码类型就很容易出现乱码问题。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。

  - BIO、NIO、AIO

    - **BIO (Blocking I/O):** 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。
    - **NIO (New I/O):** NIO是一种同步非阻塞的I/O模型。NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。
    - **AIO (Asynchronous I/O):** AIO 也就是 NIO 2，是异步非阻塞的IO模型。

    > [https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/BIO-NIO-AIO.md](https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/BIO-NIO-AIO.md)

    **同步与异步**

    同步： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。

    异步： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。

    同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。

    **阻塞和非阻塞**

    阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。

    非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。

    举个生活中简单的例子，你妈妈让你烧水，小时候你比较笨啊，在那里傻等着水开（同步阻塞）。等你稍微再长大一点，你知道每次烧水的空隙可以去干点其他事，然后只需要时不时来看看水开了没有（同步非阻塞）。后来，你们家用上了水开了会发出声音的壶，这样你就只需要听到响声后就知道水开了，在这期间你可以随便干自己的事情，你需要去倒水了（异步非阻塞）。

- select、poll、eopll的区别

  > [https://www.cnblogs.com/anker/p/3265058.html](https://www.cnblogs.com/anker/p/3265058.html)
  >
  > [https://segmentfault.com/a/1190000003063859](https://segmentfault.com/a/1190000003063859)

  select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

  **select**
  
  select的几大缺点：

  （1）每次调用select，**都需要把fd集合从用户态拷贝到内核态**，这个开销在fd很多时会很大

  （2）同时每次调用select**都需要在内核遍历传递进来的所有fd**，这个开销在fd很多时也很大

  （3）select支持的文件描述符数量太小了，默认是1024

  **poll**
  
  poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构。

  **epoll**
  
  epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。

  对于第一个缺点，epoll的解决方案**在epoll_ctl函数中**。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），**会把所有的fd拷贝进内核**，而不是在epoll_wait的时候重复拷贝。**epoll保证了每个fd在整个过程中只会拷贝一次。**

  对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，**当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表**）。**epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd**（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。

  对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。

  **总结**
  
  （1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。

  （2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而**epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次**（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。

- static、final

  - **final**关键字
    - **对于一个final变量，如果是基本数据类型的变量，其数值在初始化后不能更改；如果是引用类型的变量，在对其初始化之后不能再让它指向另一个对象。**
    - **用final修饰一个类时，表示这个类不能被继承。final类的所有成员方法都会被隐式指定final方法。**
    - 使用final方法有两个原因。
      - 把方法锁定，以防任何继承类修改它的含义。
      - 效率。在早期的Java实现版本中，会将final方法转为内嵌调用。类中的所有private方法都隐式地指定为final。
  - **static**关键字
    - **修饰成员变量和成员方法:** 被 static 修饰的成员属于类，不属于单个这个类的某个对象，被类中所有对象共享，可以并且建议通过类名调用。被static 声明的成员变量属于静态成员变量，**静态变量 存放在 Java 内存区域的方法区**。调用格式：`类名.静态变量名` `类名.静态方法名()`
    - **静态代码块:** 静态代码块定义在类中方法外, 静态代码块在非静态代码块之前执行(静态代码块—>非静态代码块—>构造方法)。 该类不管创建多少对象，静态代码块只执行一次.
    - **静态内部类（static修饰类的话只能修饰内部类）：** 静态内部类与非静态内部类之间存在一个最大的区别: 非静态内部类在编译完成之后会隐含地保存着一个引用，该引用是指向创建它的外围类，但是静态内部类却没有。没有这个引用就意味着：1. 它的创建是不需要依赖外围类的创建。2. 它不能使用任何外围类的非static成员变量和方法。
    - **静态导包(用来导入类中的静态资源，1.5之后的新特性):** 格式为：`import static` 这两个关键字连用可以指定导入某个类中的指定静态资源，并且不需要使用类名调用类中静态成员，可以直接使用类中静态成员变量和成员方法。

- 深拷贝、浅拷贝

  - **浅拷贝**：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝。
  - **深拷贝**：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容。

- Java和PHP/JavaScript、Python的区别

  > [https://www.zhihu.com/question/20377398](<https://www.zhihu.com/question/20377398>)
  >
  > [https://www.zhihu.com/question/19913979](<https://www.zhihu.com/question/19913979>)
  >
  > [https://www.zhihu.com/question/19918532](<https://www.zhihu.com/question/19918532>)
  >
  > [https://www.zhihu.com/question/20491745](<https://www.zhihu.com/question/20491745>)

  - Java 属于**强类型**（所有程序都是well behaved），是**静态类型**语言（在编译时拒绝ill behaved）。

  - PHP/JavaScript属于弱类型（不需要定义变量的类型），是动态类型语言（在运行时拒绝ill behaved）。
  - PHP/JavaScript数组的功能强大，可以当作map和list来用。
  - PHP主要用于服务器端，JavaScript主要用于网页端。
  - Java和Python的区别是静态类型和动态类型，**静态类型必须先声明再使用，动态则不需要声明**。
  - Python也是强类型。**强弱类型不是指是否需要定义，而是是一旦类型决定了，是否能随便转换。**

- 如何跳出多重循环

  - loop and a half
  - break

- 内部类可以引用他包含类的成员吗，如果可以，有没有什么限制吗？

  - 一个内部类对象可以访问创建它的外部类对象的内容。内部类如果不是static的，那么它可以访问创建它的外部类对象的所有属性内部类；如果是satic的，即为nested class，那么它只可以访问创建它的外部类对象的所有static属性

  - 完全可以。如果不是静态内部类，那没有什么限制！
    如果你把静态嵌套类当作内部类的一种特例，那在这种情况下不可以访问外部类的普通成员变量，而只能访问外部类中的静态成员。

- Static Nested Class 和 Inner Class的不同

  > [https://blog.csdn.net/zzy7075/article/details/50378366](<https://blog.csdn.net/zzy7075/article/details/50378366>)

  Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。而通常的内部类需要在外部类实例化后才能实例化。

- final, finally, finalize的区别

  - final 用于声明属性，方法和类，分别表示属性不可变，方法不可覆盖，类不可继承。
  - finally是异常处理语句结构的一部分，表示总是执行。
  - finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。

- extends 和super 泛型限定符

  > [https://blog.csdn.net/qq_40395278/article/details/88603655](<https://blog.csdn.net/qq_40395278/article/details/88603655>)

  - 在java泛型中，**？ 表示通配符，代表未知类型，< ? extends Object>表示上边界限定通配符，< ? super Object>表示下边界限定通配符。**

  - 通配符 与 T 的区别

    - **T：作用于模板上，用于将数据类型进行参数化**，不能用于实例化对象。 
    - **?：在实例化对象的时候，不确定泛型参数的具体类型时，可以使用通配符进行对象定义。**
    - < T > 等同于 < T extends Object>
    - < ? > 等同于 < ? extends Object>

  - 例一：**定义泛型类**，将key，value的数据类型进行< K, V >参数化，而不可以使用通配符。

    ```java
    public class Container<K, V> {
    	private K key;
    	private V value;
    
    	public Container(K k, V v) {
    		key = k;
    		value = v;
    	}
    }
    ```

  - 例二：**实例化泛型对象**，我们不能够确定eList存储的数据类型是Integer还是Long，因此我们使用List<? extends Number>定义变量的类型。

    ```java
    List<? extends Number> eList = null;
    eList = new ArrayList<Integer>();
    eList = new ArrayList<Long>();
    ```

    上界类型通配符（? extends）

    ```java
    List<? extends Number> eList = null;
    eList = new ArrayList<Integer>();
    Number numObject = eList.get(0); //语句1，正确
     
    //Type mismatch: cannot convert from capture#3-of ? extends Number to Integer
    Integer intObject = eList.get(0); //语句2，错误
     
    //The method add(capture#3-of ? extends Number) in the type List<capture#3-of ? extends Number> is not applicable for the arguments (Integer)
    eList.add(new Integer(1)); //语句3，错误
    ```

- 泛型

  泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。

- Object类的方法

  > [https://fangjian0423.github.io/2016/03/12/java-Object-method/](<https://fangjian0423.github.io/2016/03/12/java-Object-method/>)

  - getClass()
  - **hashCode()**
  - **equals()**
  - clone()
  - **toString()**
  - **notify()**: 唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果所有的线程都在此对象上等待，那么只会选择一个线程。
  - notifyAll(): 跟notify一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。
  - **wait**(long timeout) throws InterruptedException: wait方法会让当前线程等待直到另外一个线程调用对象的notify或notifyAll方法，或者超过参数设置的timeout超时时间。
  - wait(long timeout, int nanos) throws InterruptedException: 跟wait(long timeout)方法类似，多了一个nanos参数，这个参数表示额外时间（以毫微秒为单位，范围是 0-999999）。 所以超时的时间还需要加上nanos毫秒。
  - wait() throws InterruptedException: 跟之前的2个wait方法一样，只不过该方法一直等待，没有超时时间这个概念。
  - finalize()的作用是实例被垃圾回收器回收的时候触发的操作，就好比 “死前的最后一波挣扎”。

- Query接口的list方法和iterate方法有什么区别？

  > [https://www.nowcoder.com/questionTerminal/e0f929dfaf6e46e4900b538b9c2134ea?orderByHotValue=1&page=1&onlyReference=false](<https://www.nowcoder.com/questionTerminal/e0f929dfaf6e46e4900b538b9c2134ea?orderByHotValue=1&page=1&onlyReference=false>)

  1. 返回的类型不一样，list返回List，iterate返回iterator

  1. 查询策略不同。获取数据的方式不一样，list会直接查询数据库，iterate会先到数据库中把id取出来，然后真正要遍历某个对象的时候先到缓存中找，如果找不到，以id为条件再发一条sql到数据库，这样如果缓存中没有数据，则查询数据库的次数为n+1 

  1. iterate会查询2级缓存，list只会缓存，但不会使用缓存（除非结合查询缓存）。  

  1. list中返回的list中每个对象都是原本的对象，iterate中返回的对象中仅包含了主键值

- 汉字能用char类型来表示吗，一个汉字占多少字节？

  char固定占用2个字节，用来储存Unicode字符。范围在065536。unicode编码字符集中包含了汉字，所以，char型变量中可以存储汉字。不过，如果某个特殊的汉字没有被包含在unicode编码字符集中，那么，这个char型变量中就不能存储这个特殊汉字。

  > [https://www.cnblogs.com/kingcat/archive/2012/10/16/2726334.html](https://www.cnblogs.com/kingcat/archive/2012/10/16/2726334.html)

  UTF-8 与UTF-16的区别

  UTF-16比较好理解,就是任何字符对应的数字都用两个字节来保存.我们通常对Unicode的误解就是把Unicode与UTF-16等同了.但是很显然如果都是英文字母这做有点浪费.明明用一个字节能表示一个字符为啥整两个啊.

  于是又有个UTF-8,这里的8非常容易误导人,8不是指一个字节,难道一个字节表示一个字符?实际上不是.当用UTF-8时表示一个字符是可变的,有可能是用一个字节表示一个字符,也可能是两个,三个.当然最多不能超过3个字节了.反正是根据字符对应的数字大小来确定.

## 容器

- Collections、Arrays工具类

  - Collections

    - 排序

      ```java
      void reverse(List list)//反转
      void shuffle(List list)//随机排序
      void sort(List list)//按自然排序的升序排序
      void sort(List list, Comparator c)//定制排序，由Comparator控制排序逻辑
      void swap(List list, int i , int j)//交换两个索引位置的元素
      void rotate(List list, int distance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面。
      ```

      实例代码

      ```java
      ArrayList<Integer> arrayList = new ArrayList<Integer>();
      arrayList.add(-1);
      arrayList.add(3);
      arrayList.add(3);
      arrayList.add(-5);
      arrayList.add(7);
      arrayList.add(4);
      arrayList.add(-9);
      arrayList.add(-7);
      System.out.println("原始数组:");
      System.out.println(arrayList);
      // void reverse(List list)：反转
      Collections.reverse(arrayList);
      System.out.println("Collections.reverse(arrayList):");
      System.out.println(arrayList);
      
      
      Collections.rotate(arrayList, 4);
      System.out.println("Collections.rotate(arrayList, 4):");
      System.out.println(arrayList);
      
      // void sort(List list),按自然排序的升序排序
      Collections.sort(arrayList);
      System.out.println("Collections.sort(arrayList):");
      System.out.println(arrayList);
      
      // void shuffle(List list),随机排序
      Collections.shuffle(arrayList);
      System.out.println("Collections.shuffle(arrayList):");
      System.out.println(arrayList);
      
      // void swap(List list, int i , int j),交换两个索引位置的元素
      Collections.swap(arrayList, 2, 5);
      System.out.println("Collections.swap(arrayList, 2, 5):");
      System.out.println(arrayList);
      
      // 定制排序的用法
      Collections.sort(arrayList, new Comparator<Integer>() {
      
          @Override
          public int compare(Integer o1, Integer o2) {
              return o2.compareTo(o1);
          }
      });
      System.out.println("定制排序后：");
      System.out.println(arrayList);
      ```

    - 查找、替换

      ```java
      int binarySearch(List list, Object key)//对List进行二分查找，返回索引，注意List必须是有序的
      int max(Collection coll)//根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll)
      int max(Collection coll, Comparator c)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)
      void fill(List list, Object obj)//用指定的元素代替指定list中的所有元素。
      int frequency(Collection c, Object o)//统计元素出现次数
      int indexOfSubList(List list, List target)//统计target在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target).
      boolean replaceAll(List list, Object oldVal, Object newVal), 用新元素替换旧元素
      ```

      示例代码

      ```java
      ArrayList<Integer> arrayList = new ArrayList<Integer>();
      arrayList.add(-1);
      arrayList.add(3);
      arrayList.add(3);
      arrayList.add(-5);
      arrayList.add(7);
      arrayList.add(4);
      arrayList.add(-9);
      arrayList.add(-7);
      ArrayList<Integer> arrayList2 = new ArrayList<Integer>();
      arrayList2.add(-3);
      arrayList2.add(-5);
      arrayList2.add(7);
      System.out.println("原始数组:");
      System.out.println(arrayList);
      
      System.out.println("Collections.max(arrayList):");
      System.out.println(Collections.max(arrayList));
      
      System.out.println("Collections.min(arrayList):");
      System.out.println(Collections.min(arrayList));
      
      System.out.println("Collections.replaceAll(arrayList, 3, -3):");
      Collections.replaceAll(arrayList, 3, -3);
      System.out.println(arrayList);
      
      System.out.println("Collections.frequency(arrayList, -3):");
      System.out.println(Collections.frequency(arrayList, -3));
      
      System.out.println("Collections.indexOfSubList(arrayList, arrayList2):");
      System.out.println(Collections.indexOfSubList(arrayList, arrayList2));
      
      System.out.println("Collections.binarySearch(arrayList, 7):");
      // 对List进行二分查找，返回索引，List必须是有序的
      Collections.sort(arrayList);
      System.out.println(Collections.binarySearch(arrayList, 7));
      ```

    - 同步控制

      **效率非常低**

  - Arrays

    - 排序 : `sort()`
    - 查找 : `binarySearch()`
    - 比较: `equals()`
    - 填充 : `fill()`
    - 转列表: `asList()`
    - 转字符串 : `toString()`
    - 复制: `copyOf()`

- Comparable和Comparator接口的作用以及它们的区别

  - Java提供了只包含一个compareTo()方法的Comparable接口。这个方法可以个给两个对象排序。具体来说，它返回负数，0，正数来表明输入对象小于，等于，大于已经存在的对象。

  - Java提供了包含compare()和equals()两个方法的Comparator接口。compare()方法用来给两个输入参数排序，返回负数，0，正数表明第一个参数是小于，等于，大于第二个参数。equals()方法需要一个对象作为参数，它用来决定输入参数是否和comparator相等。只有当输入参数也是一个comparator并且输入参数和当前comparator的排序结果是相同的时候，这个方法才返回true。

  > [https://www.jianshu.com/p/fa1a1089d44d](<https://www.jianshu.com/p/fa1a1089d44d>)

  - Comparable接口的实现是在类的内部（如 String、Integer已经实现了Comparable接口，自己就可以完成比较大小操作），Comparator接口的实现是在类的外部（可以理解为一个是自已完成比较，一个是外部程序实现比较）

  - **实现Comparable接口要重写compareTo方法, 在compareTo方法里面实现比较**

    ```java
    public class Student implements Comparable {
         String name;
         int age
         public int compareTo(Student another) {
              int i = 0;
              i = name.compareTo(another.name); 
              if(i == 0) { 
                   return age - another.age;
              } else {
                   return i; 
              }
         }
    }
    ```

    这时我们可以直接用 Collections.sort( StudentList ) 对其排序了(**只需传入要排序的列表**）

  - **实现Comparator需要重写 compare 方法**

    ```java
    public class Student{
         String name;
         int age
    }
    class StudentComparator implements Comparator { 
         public int compare(Student one, Student another) {
              int i = 0;
              i = one.name.compareTo(another.name); 
              if(i == 0) { 
                   return one.age - another.age;
              } else {
                   return i;
              }
         }
    }
    ```

    Collections.sort( StudentList , new StudentComparator()) 可以对其排序（**不仅要传入待排序的列表，还要传入实现了Comparator的类的对象**）

- List、Set、Map的区别

  - List：有序的多个对象。
    - **Arraylist：** Object数组
    - **Vector：** Object数组
    - **LinkedList：** 双向链表
  - Set：不允许重复的集合。
    - **HashSet（无序，唯一）:** 基于 HashMap 实现的，底层采用 HashMap 来保存元素
    - **LinkedHashSet：** LinkedHashSet 继承于 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 HashMap 实现一样，不过还是有一点点区别的
    - **TreeSet（有序，唯一）：** 红黑树(自平衡的排序二叉树)
  - Map：使用键值对存储。
  - Set和Map容器都有基于哈希存储和排序树的两种实现版本，基于哈希存储的版本理论存取时间复杂度为O(1)，而基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。

- Array和ArrayList的区别

  - Array可以包含基本类型和对象类型，ArrayList只能包含对象类型。
  - Array大小是固定的，ArrayList的大小是动态变化的。
  - ArrayList提供了更多的方法和特性，比如：addAll()，removeAll()，iterator()等等。

- ArrayList和LinkedList的区别

  - 都不保证线程安全。
  - 底层数据结构：**ArrayList底层使用的Object数组，LinkedList底层使用的是双向链表结构。**
  - 时间复杂度：ArrayList插入删除元素的时间复杂度为**O(n)**，取第 i 元素的时间复杂度为**O(1)**；LinkedList插入和删除的时间复杂度为**O(1)**，如果是要在指定位置i插入和删除元素的话，时间复杂度近似为**O(n)**因为需要先移动到指定位置再插入。
  - 是否支持快速随机访问：LinkedList不支持高效的随机元素访问，而 ArrayList 支持。
  - 内存空间占用： ArrayList的空 间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。

- ArrayList和Vector的区别

  - Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。
  - Arraylist不是同步的，所以在不需要保证线程安全时建议使用Arraylist。

- ArrayList如何扩容和缩容

  1、扩容：直接是采用底层的System.copyOf()，创建一个新的大数组，将原来的数组内容copy到新数组中，然后返回新数组的引用

  2、缩容：trimToSize（）。如果实际size<数组长度，在内存紧张的情况下，会将数组缩小，采用的依然是System.copyOf()，

- 如何用LinkedHashMap实现LRU？

  > [https://www.jianshu.com/p/d76a78086c3a](https://www.jianshu.com/p/d76a78086c3a)

  LinkedHashMap重写removeEldestEntry()方法，当前size()大于了cacheSize便删掉头部的元素
  
- 如何用TreeMap实现一致性hash？

  > 什么是一致性hash
  >
  > [https://zhuanlan.zhihu.com/p/34985026](https://zhuanlan.zhihu.com/p/34985026)

  > 自己实现一个一致性 Hash 算法
  >
  > [https://juejin.im/post/5abf8f3851882555731c42d1](https://juejin.im/post/5abf8f3851882555731c42d1)

  - 内部没有使用数组，而是使用了有序 Map。
  - put 方法中，对象如果没有落到缓存节点上，就找比他小的节点且离他最近的。这里我们使用了 TreeMap 的 tailMap 方法，具体 API 可以看文档。
  - get 方法中，和 put 步骤相同，否则是取不到对象的。

- Map的分类

  - Map有4个实现类，HashMap、HashTable、LinkedHashMap、TreeMap。
  - Hashmap 是一个最常用的Map，它根据键的HashCode值存储数据,根据键可以直接获取它的值，具有**很快的访问速度**，遍历时，取得数据的顺序是完全随机的。 **HashMap最多只允许一条记录的键为Null；允许多条记录的值为 Null；HashMap不支持线程的同步**，即任一时刻可以有多个线程同时写HashMap；可能会导致数据的不一致。
  - **Hashtable**与 HashMap类似，它继承自Dictionary类，不同的是：**它不允许记录的键或者值为空；它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了 Hashtable在写入时会比较慢。**
  - LinkedHashMap 是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的.也可以在构造时用带参数，按照应用次数排序。
  - TreeMap实现SortMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。
  - 一般情况下，我们用的最多的是HashJDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）Map，在Map 中插入、删除和定位元素，HashMap 是最好的选择。但如果您要按**自然顺序**或自定义顺序遍历键，那么**TreeMap**会更好。如果需要**输出的顺序和输入的相同**，那么用**LinkedHashMap**可以实现,它还可以按读取顺序来排列.

- HashMap和HashSet的区别

  - HashSet 底层就是基于 HashMap 实现的。

  - | HashMap                          | HashSet                                                      |
    | -------------------------------- | ------------------------------------------------------------ |
    | 实现了Map接口                    | 实现Set接口                                                  |
    | 存储键值对                       | 仅存储对象                                                   |
    | 调用 `put()`向map中添加元素      | 调用 `add()`方法向Set中添加元素                              |
    | HashMap使用键（Key）计算Hashcode | HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性 |

- HashMap源码学习

  JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间。

  ```java
  public V put(K key, V value) {
      return putVal(hash(key), key, value, false, true);
  }

  final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                    boolean evict) {
      Node<K,V>[] tab; Node<K,V> p; int n, i;
      // table未初始化或者长度为0，进行扩容
      if ((tab = table) == null || (n = tab.length) == 0)
          n = (tab = resize()).length;
      // (n - 1) & hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)
      if ((p = tab[i = (n - 1) & hash]) == null)
          tab[i] = newNode(hash, key, value, null);
      // 桶中已经存在元素
      else {
          Node<K,V> e; K k;
          // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等
          if (p.hash == hash &&
              ((k = p.key) == key || (key != null && key.equals(k))))
                  // 将第一个元素赋值给e，用e来记录
                  e = p;
          // hash值不相等，即key不相等；为红黑树结点
          else if (p instanceof TreeNode)
              // 放入树中
              e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
          // 为链表结点
          else {
              // 在链表最末插入结点
              for (int binCount = 0; ; ++binCount) {
                  // 到达链表的尾部
                  if ((e = p.next) == null) {
                      // 在尾部插入新结点
                      p.next = newNode(hash, key, value, null);
                      // 结点数量达到阈值，转化为红黑树
                      if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                          treeifyBin(tab, hash);
                      // 跳出循环
                      break;
                  }
                  // 判断链表中结点的key值与插入的元素的key值是否相等
                  if (e.hash == hash &&
                      ((k = e.key) == key || (key != null && key.equals(k))))
                      // 相等，跳出循环
                      break;
                  // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表
                  p = e;
              }
          }
          // 表示在桶中找到key值、hash值与插入元素相等的结点
          if (e != null) { 
              // 记录e的value
              V oldValue = e.value;
              // onlyIfAbsent为false或者旧值为null
              if (!onlyIfAbsent || oldValue == null)
                  //用新值替换旧值
                  e.value = value;
              // 访问后回调
              afterNodeAccess(e);
              // 返回旧值
              return oldValue;
          }
      }
      // 结构性修改
      ++modCount;
      // 实际大小大于阈值则扩容
      if (++size > threshold)
          resize();
      // 插入后回调
      afterNodeInsertion(evict);
      return null;
  } 
  ```

  ```java
  public V get(Object key) {
      Node<K,V> e;
      return (e = getNode(hash(key), key)) == null ? null : e.value;
  }

  final Node<K,V> getNode(int hash, Object key) {
      Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
      if ((tab = table) != null && (n = tab.length) > 0 &&
          (first = tab[(n - 1) & hash]) != null) {
          // 数组元素相等
          if (first.hash == hash && // always check first node
              ((k = first.key) == key || (key != null && key.equals(k))))
              return first;
          // 桶中不止一个节点
          if ((e = first.next) != null) {
              // 在树中get
              if (first instanceof TreeNode)
                  return ((TreeNode<K,V>)first).getTreeNode(hash, key);
              // 在链表中get
              do {
                  if (e.hash == hash &&
                      ((k = e.key) == key || (key != null && key.equals(k))))
                      return e;
              } while ((e = e.next) != null);
          }
      }
      return null;
  }
  ```

  ```java
  final Node<K,V>[] resize() {
      Node<K,V>[] oldTab = table;
      int oldCap = (oldTab == null) ? 0 : oldTab.length;
      int oldThr = threshold;
      int newCap, newThr = 0;
      if (oldCap > 0) {
          // 超过最大值就不再扩充了，就只好随你碰撞去吧
          if (oldCap >= MAXIMUM_CAPACITY) {
              threshold = Integer.MAX_VALUE;
              return oldTab;
          }
          // 没超过最大值，就扩充为原来的2倍
          else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY && oldCap >= DEFAULT_INITIAL_CAPACITY)
              newThr = oldThr << 1; // double threshold
      }
      else if (oldThr > 0) // initial capacity was placed in threshold
          newCap = oldThr;
      else { 
          // signifies using defaults
          newCap = DEFAULT_INITIAL_CAPACITY;
          newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
      }
      // 计算新的resize上限
      if (newThr == 0) {
          float ft = (float)newCap * loadFactor;
          newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);
      }
      threshold = newThr;
      @SuppressWarnings({"rawtypes","unchecked"})
          Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
      table = newTab;
      if (oldTab != null) {
          // 把每个bucket都移动到新的buckets中
          for (int j = 0; j < oldCap; ++j) {
              Node<K,V> e;
              if ((e = oldTab[j]) != null) {
                  oldTab[j] = null;
                  if (e.next == null)
                      newTab[e.hash & (newCap - 1)] = e;
                  else if (e instanceof TreeNode)
                      ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                  else { 
                      Node<K,V> loHead = null, loTail = null;
                      Node<K,V> hiHead = null, hiTail = null;
                      Node<K,V> next;
                      do {
                          next = e.next;
                          // 原索引
                          if ((e.hash & oldCap) == 0) {
                              if (loTail == null)
                                  loHead = e;
                              else
                                  loTail.next = e;
                              loTail = e;
                          }
                          // 原索引+oldCap
                          else {
                              if (hiTail == null)
                                  hiHead = e;
                              else
                                  hiTail.next = e;
                              hiTail = e;
                          }
                      } while ((e = next) != null);
                      // 原索引放到bucket里
                      if (loTail != null) {
                          loTail.next = null;
                          newTab[j] = loHead;
                      }
                      // 原索引+oldCap放到bucket里
                      if (hiTail != null) {
                          hiTail.next = null;
                          newTab[j + oldCap] = hiHead;
                      }
                  }
              }
          }
      }
      return newTab;
  }
  ```

- hashmap hash算法的具体实现，巧妙之处

  1. hashmap规定长度必定为2的n次方、如果指定的capacity不为2的n次方，会将其转换为>capacity的最小的2的次方数

  2. hash算法 hash = h ^ (h >>> 16)，保证了capacity较小时，能够将高16位和低16位的变化都反应到低位上，在计算下标时，高位和地位同时参与，使hash更加均匀分散，降低hash碰撞的概率

  3. put的时候会put到table[(n-1)&hash]，因为n为2的n次方，所以n-1导致低位全是1，便可以保证hash与上n-1得到的数组下标一定在0~n-1之间

  4. get的时候依然是直接用table[(n-1)&hash]

  所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。

  ```java
  static final int hash(Object key) {
      int h;
      // key.hashCode()：返回散列值也就是hashcode
      // ^ ：按位异或
      // >>>:无符号右移，忽略符号位，空位都以0补齐
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
  ```

- hashmap扩容resize怎么实现

  1、首先建立新数组newTable、为原数组的两倍

  2、将原数组hash到新数组中，hash & (newLength-1) ，

  3、如果原数组节点只有一个头节点，则hash到新数组直接放入

  4、如果原数组e是树节点，则将其split（保持顺序分裂成两个树节点TreeNode list、list过长则转化成树，不然则彻底转成node list）
  
  5、如果是链表，则保持原数组中链表的顺序，hash到新数组中

  > [https://segmentfault.com/a/1190000015812438?utm_source=tag-newest](https://segmentfault.com/a/1190000015812438?utm_source=tag-newest)

- hashmap扩容时每个entry需要再计算一次hash吗？

  > [https://blog.csdn.net/qq_27093465/article/details/52270519](https://blog.csdn.net/qq_27093465/article/details/52270519)

  还是原来的hash，`hash & oldCap`如果是0的话就是原索引，如果是1的话是原索引+oldCap

- jdk1.8之前并发操作hashmap时为什么会有死循环的问题

  > [https://juejin.im/post/5a66a08d5188253dc3321da0](https://juejin.im/post/5a66a08d5188253dc3321da0)

  在并发的情况，发生扩容时，可能会产生循环链表，在执行get的时候，会触发死循环，引起CPU的100%问题，所以一定要避免在并发环境下使用HashMap。

- hashmap一个写，多个读并发会有线程安全问题吗，引申出fail-fast和iterator

  1、会导致数据读写不一致的问题、因为JMM(java内存模型)里线程只能先与自己的工作内存交互，之后才能与共享内存交互

  2、会导致fail-fast问题（这是java集合的一个错误检测机制）

  fail-fast：如果在集合迭代的过程中，iterator（迭代器）不知道集合发生了修改（add/remove）操作，就会报错

  如何实现遍历集合的同时进行修改：让iterator知道，即用iterator自带的remove方法：iterator.remove();

  modCount是集合通用的属性，只要集合发生了修改操作，modCount就会++，在获取迭代器的时候会将modCount赋值给ExpectedModCount，此时两者肯定相等，但是如果执行了修改操作，modCound就会++，两者不等，就会报错。

  1. 场景1：写线程唯一、读线程不确定，没有迭代操作。使用hashmap不会存在程序不安全，最多就是发生数据不一致性的问题。
  2. 场景2：写线程唯一、读线程不确定，有迭代操作，此时不能使用hashmap，会存在fastfail问题
  3. 场景3: 读写线程是同一个，且唯一，有迭代操作，此时注意不能通过集合方法remove或者add更改，只能通过iterator内方法来更新。不然会存在fastfail问题。

- 并发容器

  **JDK 提供的并发容器总结**

  - ConcurrentHashMap: 线程安全的 HashMap
  - CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector.
  - ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。
  - BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。
  - ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。

  **CopyOnWriteArrayList**

  在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问 List 的内部数据，毕竟读取操作是安全的。

  这和我们之前在多线程章节讲过 ReentrantReadWriteLock 读写锁的思想非常类似，也就是读读共享、写写互斥、读写互斥、写读互斥。JDK 中提供了 CopyOnWriteArrayList 类比相比于在读写锁的思想又更进一步。为了将读取的性能发挥到极致，CopyOnWriteArrayList 读取是完全不用加锁的，并且更厉害的是：写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待。这样一来，读操作的性能就会大幅度提升。那它是怎么做的呢？

  CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。**当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。**

  从 CopyOnWriteArrayList 的名字就能看出CopyOnWriteArrayList 是满足CopyOnWrite 的 ArrayList，所谓CopyOnWrite 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。

  **读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。**

  CopyOnWriteArrayList **写入操作 add() 方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。**

  **ConcurrentLinkedQueue**

  Java 提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。

  从名字可以看出，ConcurrentLinkedQueue这个队列使用链表作为其数据结构．ConcurrentLinkedQueue 应该算是在高并发环境中性能最好的队列了。它之所有能有很好的性能，是因为其内部复杂的实现。

  ConcurrentLinkedQueue 内部代码我们就不分析了，大家知道 **ConcurrentLinkedQueue 主要使用 CAS 非阻塞算法**来实现线程安全就好了。

  ConcurrentLinkedQueue 适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 ConcurrentLinkedQueue 来替代。

  **BlockingQueue**

  上面我们己经提到了 ConcurrentLinkedQueue 作为高性能的非阻塞队列。下面我们要讲到的是阻塞队列——BlockingQueue。阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是 BlockingQueue 提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。

  BlockingQueue 是一个接口，继承自 Queue，所以其实现类也可以作为 Queue 的实现来使用，而 Queue 又继承自 Collection 接口。

  下面主要介绍一下:ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue，这三个 BlockingQueue 的实现类。

  - ArrayBlockingQueue

    ArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。ArrayBlockingQueue 一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。

    ArrayBlockingQueue 默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 ArrayBlockingQueue。而非公平性则是指访问 ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当 ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到 ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。

  - LinkedBlockingQueue

    LinkedBlockingQueue 底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE。

  - PriorityBlockingQueue

    PriorityBlockingQueue 是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 compareTo() 方法来指定元素排序规则，或者初始化时通过构造器参数 Comparator 来指定排序规则。

    PriorityBlockingQueue 并发控制采用的是 ReentrantLock，队列为无界队列（ArrayBlockingQueue 是有界队列，LinkedBlockingQueue 也可以通过在构造函数中传入 capacity 指定队列最大的容量，但是 PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。

    简单地说，它就是 PriorityQueue 的线程安全版本。不可以插入 null 值，同时，插入队列的对象必须是可比较大小的（comparable），否则报 ClassCastException 异常。它的插入操作 put 方法不会 block，因为它是无界队列（take 方法在队列为空的时候会阻塞）。
  
  **ConcurrentSkipListMap**

  使用跳表实现 Map 和使用哈希算法实现 Map 的另外一个不同之处是：哈希并不会保存元素的顺序，而跳表内所有的元素都是排序的。因此在对跳表进行遍历时，你会得到一个有序的结果。所以，如果你的应用需要有序性，那么跳表就是你不二的选择。JDK 中实现这一数据结构的类是 ConcurrentSkipListMap。

- 如何线程安全地遍历List：Vector、CopyOnWriteArrayList

  > [https://blog.csdn.net/xiao__gui/article/details/51050793](https://blog.csdn.net/xiao__gui/article/details/51050793)

  **Vector**

  Vector和ArrayList类似，是长度可变的数组，与ArrayList不同的是，Vector是线程安全的，它给几乎所有的public方法都加上了synchronized关键字。由于加锁导致性能降低，在不需要并发访问同一对象时，这种强制性的同步机制就显得多余，所以现在Vector已被弃用。

  **HashTable**
  
  HashTable和HashMap类似，不同点是HashTable是线程安全的，它给几乎所有public方法都加上了synchronized关键字，还有一个不同点是HashTable的K，V都不能是null，但HashMap可以，它现在也因为性能原因被弃用了。

  **Collections包装方法**
  
  Vector和HashTable被弃用后，它们被ArrayList和HashMap代替，但它们不是线程安全的，所以Collections工具类中提供了相应的包装方法把它们包装成线程安全的集合。

  ```java
  List<E> synArrayList = Collections.synchronizedList(new ArrayList<E>());

  Set<E> synHashSet = Collections.synchronizedSet(new HashSet<E>());

  Map<K,V> synHashMap = Collections.synchronizedMap(new HashMap<K,V>());
  ```

  Collections针对每种集合都声明了一个线程安全的包装类，在原集合的基础上添加了锁对象，集合中的每个方法都通过这个锁对象实现同步。

  **ConcurrentHashMap**
  
  ConcurrentHashMap和HashTable都是线程安全的集合，它们的不同主要是加锁粒度上的不同。HashTable的加锁方法是给每个方法加上synchronized关键字，这样锁住的是整个Table对象。而ConcurrentHashMap是更细粒度的加锁。

  在JDK1.8之前，ConcurrentHashMap加的是分段锁，也就是Segment锁，每个Segment含有整个table的一部分，这样不同分段之间的并发操作就互不影响。

  JDK1.8对此做了进一步的改进，它取消了Segment字段，直接在table元素上加锁，实现对每一行进行加锁，进一步减小了并发冲突的概率。

  **CopyOnWriteArrayList和CopyOnWriteArraySet**

  它们是加了写锁的ArrayList和ArraySet，锁住的是整个对象，但读操作可以并发执行

  除此之外还有ConcurrentSkipListMap、ConcurrentSkipListSet、ConcurrentLinkedQueue、ConcurrentLinkedDeque等，至于为什么没有ConcurrentArrayList，原因是无法设计一个通用的而且可以规避ArrayList的并发瓶颈的线程安全的集合类，只能锁住整个list，这用Collections里的包装类就能办到。

- 为什么java.util.concurrent 包里没有并发的ArrayList实现？

  > [http://ifeve.com/why-is-there-not-concurrent-arraylist-in-java-util-concurrent-package/](http://ifeve.com/why-is-there-not-concurrent-arraylist-in-java-util-concurrent-package/)

  在java.util.concurrent包中没有加入并发的ArrayList实现的主要原因是：很难去开发一个通用并且没有并发瓶颈的线程安全的List。

  像ConcurrentHashMap这样的类的真正价值（The real point / value of classes）并不是它们保证了线程安全。而在于它们在保证线程安全的同时不存在并发瓶颈。举个例子，ConcurrentHashMap采用了锁分段技术和弱一致性的Map迭代器去规避并发瓶颈。

  所以问题在于，像“Array List”这样的数据结构，你不知道如何去规避并发的瓶颈。拿contains() 这样一个操作来说，当你进行搜索的时候如何避免锁住整个list？

  另一方面，Queue 和Deque (基于Linked List)有并发的实现是因为他们的接口相比List的接口有更多的限制，这些限制使得实现并发成为可能。

  CopyOnWriteArrayList是一个有趣的例子，它规避了只读操作（如get/contains）并发的瓶颈，但是它为了做到这点，在修改操作中做了很多工作和修改可见性规则。 此外，修改操作还会锁住整个List，因此这也是一个并发瓶颈。所以从理论上来说，CopyOnWriteArrayList并不算是一个通用的并发List。

- ConcurrentHashMap和HashTable的区别

  - **底层数据结构：** JDK1.7的 ConcurrentHashMap 底层采用 **分段的数组+链表** 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。HasTable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 **数组+链表** 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；

  - **实现线程安全的方式（重要）：** 

    ① **在JDK1.7的时候，ConcurrentHashMap（分段锁）** 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 

    >  ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。HashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。
    >
    >  在ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。 

    **到了 JDK1.8 的时候已经摒弃了Segment的概念，则是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化）** 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；

    ② **HashTable(同一把锁)** :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。

  - HashTable

    ![HashTable全表锁](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/HashTable%E5%85%A8%E8%A1%A8%E9%94%81.png)

  - JDK1.7的ConcurrentHashMap

    ![JDK1.7的ConcurrentHashMap](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ConcurrentHashMap%E5%88%86%E6%AE%B5%E9%94%81.jpg)

  - JDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）

    ![JDK1.8的ConcurrentHashMap](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JDK1.8-ConcurrentHashMap-Structure.jpg)

- ConcurrentHashmap读操作加锁吗，不加锁volatile修饰共享变量，为什么volatile能实现读操作线程安全

  不加锁，volatile能够保证内存可见性。

  当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。

  当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，线程接下来将从主内存中读取共享变量。

- ConcurrentHashMap如何做到get操作不加锁？

  get方法中将要使用的共享变量都定义成volatile类型，定义成volatile的变量，只能被单线程写，但能被多个线程同时读，在线程之间保持可见性，保证不会读到过期的值。在get操作中只需要读不需要写共享变量get和value，所以可以不用加锁，之所以不会读到过期的值，是因为JMM的happen before规则，对volatile字段的写先于读。

- ConcurrentHashMap如何在resize中并发的插入、删除和查找

  利用CAS+synchronized实现node节点粒度的并发

  resize的时候单线程构建一个nextTable（2倍原容量）、多线程扩容
  
  put的时候如果检测到需要插入的位置被forward节点占有，就帮助扩容、如果检测到的节点非空且不是forward节点，对节点加syn锁，进行节点插入
  
  get的时候不加锁，可多线程查找
  
  remove的时候如果检测到需要删除的位置被forward节点占有，就帮助扩容、如果不是，则对节点加syn锁，进行节点删除

- concurrentHashmap的size实现

  > [https://juejin.im/post/5ae75584f265da0b873a4810](https://juejin.im/post/5ae75584f265da0b873a4810)
  
  JDK 8 推荐使用mappingCount 方法，因为这个方法的返回值是 long 类型，不会因为 size 方法是 int 类型限制最大值（size 方法是接口定义的，不能修改）。

  在没有并发的情况下，使用一个 baseCount volatile 变量就足够了，当并发的时候，CAS 修改 baseCount 失败后，就会使用 CounterCell 类了，会创建一个这个对象，通常对象的 volatile value 属性是 1。在计算 size 的时候，会将 baseCount 和 CounterCell 数组中的元素的 value 累加，得到总的大小，但这个数字仍旧可能是不准确的。

- List、Set、Map是否继承自Collection接口？

  List、Set 是，Map 不是。Map是键值对映射容器，与List和Set有明显的区别，而Set存储的零散的元素且不允许有重复元素（数学中的集合也是如此），List是线性结构的容器，适用于按数值索引访问元素的情形。

- 常用集合类以及主要方法

  > [https://blog.csdn.net/zhj870975587/article/details/50996811](<https://blog.csdn.net/zhj870975587/article/details/50996811>)

  > 若要检查Collection中的元素，可以使用foreach进行遍历，也可以使用迭代器，Collection支持iterator()方法，通过该方法可以访问Collection中的每一个元素。Set和List是由Collection派生的两个接口。

  - **Collection接口**
    - **List接口**：LinkedList类、ArrayList类
    - Vector类
    - Stack类
    - **Set接口**：HashSet类、TreeSet类
    - Queue类

  - **Map接口**：HashTable类、HashMap类、TreeMap类、LinkedHashMap类

- Collection 和 Collections的区别

  - Collection是集合类的上级接口，继承与他的接口主要有Set 和List.
  - Collections是针对集合类的一个帮助类，他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。

- 快速失败(fail-fast)和安全失败(fail-safe)的区别

  > [https://blog.csdn.net/qq_31780525/article/details/77431970](<https://blog.csdn.net/qq_31780525/article/details/77431970>)

  - **在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。**

    - 原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。

    - 注意：这里异常的抛出条件是检测到 modCount!=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。

    - 场景：**java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。**

  - **采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。**

    - 原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。

    - 缺点：**基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。**

    - 场景：**java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。**

  - 快速失败和安全失败是对迭代器而言的。 

    - 快速失败：当在迭代一个集合的时候，如果有另外一个线程在修改这个集合，就会抛出ConcurrentModification异常，java.util下都是快速失败。
    - 安全失败：在迭代时候会在集合二层做一个拷贝，所以在修改集合上层元素不会影响下层。在java.util.concurrent下都是安全失败

- Iterator和ListIterator的区别

  - Iterator可用来遍历Set和List集合，但是ListIterator只能用来遍历List。Iterator对集合只能是前向遍历，ListIterator既可以前向也可以后向。
  - ListIterator实现了Iterator接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引，等等。

- 什么是迭代器？

  - Iterator提供了统一遍历操作集合元素的统一接口，Collection接口实现Iterable接口，每个集合都通过实现Iterable接口中iterator()方法返回Iterator接口的实例，然后对集合的元素进行迭代操作.
  - 有一点需要注意的是：在迭代元素的时候不能通过集合的方法删除元素，否则会抛出ConcurrentModificationException 异常. 但是可以通过Iterator接口中的remove()方法进行删除.

- 为什么集合类没有实现Cloneable和Serializable接口？

  - 克隆(cloning)或者是序列化(serialization)的语义和含义是跟具体的实现相关的。因此，应该由集合类的具体实现来决定如何被克隆或者是序列化。
  - 实现Serializable序列化的作用：将对象的状态保存在存储媒体中以便可以在以后重写创建出完全相同的副本；按值将对象从一个从一个应用程序域发向另一个应用程序域。
    实现 Serializable接口的作用就是可以把对象存到字节流，然后可以恢复。所以你想如果你的对象没有序列化，怎么才能进行网络传输呢？要网络传输就得转为字节流，所以在分布式应用中，你就得实现序列化。如果你不需要分布式应用，那就没必要实现实现序列化。

- TreeMap的底层实现

  - TreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树，这样就可以保证当需要快速检索指定节点。

    红黑树的插入、删除、遍历时间复杂度都为O(lgN)，所以性能上低于哈希表。但是哈希表无法提供键值对的有序输出，红黑树因为是排序插入的，可以按照键的值的大小有序输出。

  - 红黑树性质：

    性质1：每个节点要么是红色，要么是黑色。

    性质2：根节点永远是黑色的。

    性质3：所有的叶节点都是空节点（即 null），并且是黑色的。

    性质4：每个红色节点的两个子节点都是黑色。（从每个叶子到根的路径上不会有两个连续的红色节点）

    性质5：从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点。

- HashMap的容量为什么是2的n次幂？

  > [https://blog.csdn.net/sybnfkn040601/article/details/73194613](https://blog.csdn.net/sybnfkn040601/article/details/73194613)

  用`h & (length - 1)`取代` h % length`，位运算取低位速度快。

- 如果hashMap的key是一个自定义的类，怎么办？

  使用HashMap，如果key是自定义的类，就必须重写hashcode()和equals()。

- 红黑树和平衡二叉树的区别、java中哪种数据结构实现了红黑树

  BST：二叉搜索树、不确保平衡、性能无法确保

  AVL：平衡二叉树，**严格平衡（每个节点的左右子树的高度差不超过1）**，搜索性能可以一直确保最佳，但是一旦有插入删除操作，就必须
  要进行旋转，来维持树的严格平衡，而旋转操作是非常耗时的。所以AVL使用于搜索操作多，而插入删除操作少的场景
  
  RBT：红黑树，**弱平衡（红黑树确保没有一条路径会比其他路径长出两倍）**，这样子的话一旦有插入删除操作，用于维持RBT规则的旋转操作次数就会很少。用非严格的平衡来换取增删节点时候旋转次数的降低。所以RBT适用于插入删除操作多的场景

  所以简单说，搜索的次数远远大于插入和删除，那么选择AVL树，如果搜索，插入删除次数几乎差不多，应该选择RB树

  java的TreeMap实现了红黑树

## 并发

- 使用线程池的好处

  池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。

  线程池提供了一种限制和管理资源（包括执行一个任务）。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。

  这里借用《Java 并发编程的艺术》提到的来说一下使用线程池的好处：

  - **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
  - **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
  - **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

- Executors 返回线程池对象的弊端如下：

  - FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。
  - CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。

- 核心线程池ThreadPoolExecutor内部参数

  ThreadPoolExecutor 3 个最重要的参数：

  - **corePoolSize : 核心线程数定义了最小可以同时运行的线程数量。**
  - **maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。**
  - **workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，信任就会被存放在队列中。**

  ThreadPoolExecutor其他常见参数:

  - keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；
  - unit : keepAliveTime 参数的时间单位。
  - threadFactory :executor 创建新线程的时候会用到。
  - handler :饱和策略。

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%90%84%E4%B8%AA%E5%8F%82%E6%95%B0%E7%9A%84%E5%85%B3%E7%B3%BB.jpg)

  ThreadPoolExecutor 饱和策略定义:

  如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了时，ThreadPoolTaskExecutor 定义一些策略:

  - ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。
  - ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。
  - ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。
  - ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。

  > [https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md](https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md)

  1. corePoolSize：指定了线程池中的线程数量
  2. maximumPoolSize：指定了线程池中的最大线程数量
  3. keepAliveTime：线程池维护线程所允许的空闲时间
  4. unit: keepAliveTime 的单位。
  5. workQueue：任务队列，被提交但尚未被执行的任务。
  6. threadFactory：线程工厂，用于创建线程，一般用默认的即可。
  7. handler：拒绝策略。当任务太多来不及处理，如何拒绝任务。

- 线程池的运行流程，使用参数以及方法策略

  ![img](/img/post/线程池.jpg)

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png)

  > [https://blog.csdn.net/u011240877/article/details/73440993](https://blog.csdn.net/u011240877/article/details/73440993)

  1. 当前池中线程比核心数少，新建一个线程执行任务

  2. 核心池已满，但任务队列未满，添加到队列中

  3. 核心池已满，队列已满，试着创建一个新线程

- 实现Runnable接口和Callable接口的区别

  Runnable自Java 1.0以来一直存在，但Callable仅在Java 1.5中引入,目的就是为了来处理Runnable不支持的用例。Runnable 接口不会返回结果或抛出检查异常，但是Callable 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口，这样代码看起来会更加简洁。

  工具类 Executors 可以实现 Runnable 对象和 Callable 对象之间的相互转换。（Executors.callable（Runnable task）或 Executors.callable（Runnable task，Object resule））。

- 执行execute()方法和submit()方法的区别是什么呢？

  1. **execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否**；
  2. **submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功**，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

- 介绍一下Atomic 原子类

  Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

  所以，所谓原子类说简单点就是具有原子/原子操作特征的类。

- JUC 包中的原子类是哪4类?

  基本类型

  使用原子的方式更新基本类型

  - AtomicInteger：整形原子类
  - AtomicLong：长整型原子类
  - AtomicBoolean：布尔型原子类
  
  数组类型

  使用原子的方式更新数组里的某个元素

  - AtomicIntegerArray：整形数组原子类
  - AtomicLongArray：长整形数组原子类
  - AtomicReferenceArray：引用类型数组原子类
  
  引用类型

  - AtomicReference：引用类型原子类
  - AtomicStampedReference：原子更新引用类型里的字段原子类
  - AtomicMarkableReference ：原子更新带有标记位的引用类型
  
  对象的属性修改类型

  - AtomicIntegerFieldUpdater：原子更新整形字段的更新器
  - AtomicLongFieldUpdater：原子更新长整形字段的更新器
  - AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

- 能不能给我简单介绍一下 AtomicInteger 类的原理

  AtomicInteger 线程安全原理简单分析

  AtomicInteger 类的部分源码：

  ```java
  // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）
  private static final Unsafe unsafe = Unsafe.getUnsafe();
  private static final long valueOffset;

  static {
      try {
          valueOffset = unsafe.objectFieldOffset
              (AtomicInteger.class.getDeclaredField("value"));
      } catch (Exception ex) { throw new Error(ex); }
  }

  private volatile int value;
  ```
  
  AtomicInteger 类主要利用 **CAS (compare and swap) + volatile** 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

  CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 **value 是一个volatile变量**，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。

- 悲观锁和乐观锁

  > [https://snailclimb.gitee.io/javaguide/#/docs/essential-content-for-interview/%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E4%B9%8B%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81?id=2-cas%e7%ae%97%e6%b3%95](https://snailclimb.gitee.io/javaguide/#/docs/essential-content-for-interview/%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E4%B9%8B%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81?id=2-cas%e7%ae%97%e6%b3%95)

  **悲观锁**

  总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

  **乐观锁**

  总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用**版本号机制和CAS算法**实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.**atomic**包下面的**原子变量类**就是使用了乐观锁的一种实现方式**CAS**实现的。

  **两种锁的使用场景**

  从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，**像乐观锁适用于写比较少的情况下（多读场景）**，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以**一般多写的场景下用悲观锁就比较合适**。

  **乐观锁常见的两种实现方式**

  > 乐观锁一般会使用版本号机制或CAS算法实现。

  1. 版本号机制

      一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

      举一个简单的例子： 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。

      1. 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。
      2. 在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。
      3. 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
      4. 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。

      这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。

  2. CAS算法

      即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数

      - 需要读写的内存值 V
      - 进行比较的值 A
      - 拟写入的新值 B
      
      当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。

      > [自旋锁](https://blog.csdn.net/qq_34337272/article/details/81252853)
      
      自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。

      ```java
      public class SpinLock {
          private AtomicReference<Thread> cas = new AtomicReference<Thread>();
          public void lock() {
              Thread current = Thread.currentThread();
              // 利用CAS
              while (!cas.compareAndSet(null, current)) {
                  // DO nothing
              }
          }
          public void unlock() {
              Thread current = Thread.currentThread();
              cas.compareAndSet(current, null);
          }
      }
      ```

      > [https://blog.csdn.net/bohu83/article/details/51124065](https://blog.csdn.net/bohu83/article/details/51124065)

      ```java
      /** 
      * Atomically sets the value to the given updated value 
      * if the current value {@code ==} the expected value. 
      * 
      * @param expect the expected value 
      * @param update the new value 
      * @return true if successful. False return indicates that 
      * the actual value was not equal to the expected value. 
      */  
      public final boolean compareAndSet(int expect, int update) {  
          return unsafe.compareAndSwapInt(this, valueOffset, expect, update);  
      } 
      ```

  **乐观锁的缺点**

  > ABA 问题是乐观锁一个常见的问题

  1. **ABA 问题**

      如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。

      JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

  2. **循环时间长开销大**

      **自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。** 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

  3. 只能保证一个共享变量的原子操作

      CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。
  
  **CAS与synchronized的使用情景**

  > **简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多）**

  1. 对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。
  2. 对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。

  补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。

- AQS

  **AQS介绍**
  
  AQS 的全称为（AbstractQueuedSynchronizer），这个类在 java.util.concurrent.locks 包下面。

  AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask(jdk1.7) 等等皆是基于 AQS 的。当然，我们自己也能利用 AQS 非常轻松容易地构造出符合我们自己需求的同步器。

  **AQS原理**

  AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/Java%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%EF%BC%9A%E5%B9%B6%E5%8F%91%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93/CLH.png)

  **AQS 定义两种资源共享方式**

  1)Exclusive（独占）

  只有一个线程能执行，如 ReentrantLock。又可分为公平锁和非公平锁,ReentrantLock 同时支持两种锁,下面以 ReentrantLock 对这两种锁的定义做介绍：

  - **公平锁：按照线程在队列中的排队顺序，先到者先拿到锁**
  - **非公平锁：当线程要获取锁时，先通过两次 CAS 操作去抢锁，如果没抢到，当前线程再加入到队列中等待唤醒。**

  公平锁和非公平锁只有两处不同：

  1. 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。
  2. 非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。

  公平锁和非公平锁就这两点区别，如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。

  相对来说，非公平锁会有更好的性能，因为它的吞吐量比较大。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。

  2)Share（共享）

  多个线程可同时执行，如 Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。

  ReentrantReadWriteLock 可以看成是组合式，因为 ReentrantReadWriteLock 也就是读写锁允许多个线程同时对某一资源进行读。

  不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS 已经在上层已经帮我们实现好了。

  **Semaphore(信号量)-允许多个线程同时访问**

  synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。

  执行 acquire 方法阻塞，直到有一个许可证可以获得然后拿走一个许可证；每个 release 方法增加一个许可证，这可能会释放一个阻塞的 acquire 方法。然而，其实并没有实际的许可证这个对象，Semaphore 只是维持了一个可获得许可证的数量。 Semaphore 经常用于限制获取某种资源的线程数量。

  Semaphore 有两种模式，公平模式和非公平模式。

  - 公平模式： 调用 acquire 的顺序就是获取许可证的顺序，遵循 FIFO；
  - 非公平模式： 抢占式的。

  **CountDownLatch （倒计时器）**

  CountDownLatch 是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。在 Java 并发中，countdownlatch 的概念是一个常见的面试题，所以一定要确保你很好的理解了它。

  - CountDownLatch 的三种典型用法

    ① 某一线程在开始运行前等待 n 个线程执行完毕。将 CountDownLatch 的计数器初始化为 n ：new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减 1 countdownlatch.countDown()，当计数器的值变为 0 时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。

    ② 实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 ：new CountDownLatch(1)，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。

    ③ 死锁检测：一个非常方便的使用场景是，你可以使用 n 个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。
  
  - CountDownLatch 的不足

    CountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。
  
  **CyclicBarrier(循环栅栏)**

  CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。

  CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。

  - CyclicBarrier 的应用场景

  CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个 Excel 保存了用户所有银行流水，每个 Sheet 保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个 sheet 里的银行流水，都执行完之后，得到每个 sheet 的日均银行流水，最后，再用 barrierAction 用这些线程的计算结果，计算出整个 Excel 的日均银行流水。

  **CyclicBarrier 和 CountDownLatch 的区别**

  下面这个是国外一个大佬的回答：

  CountDownLatch 是计数器，只能使用一次，而 CyclicBarrier 的计数器提供 reset 功能，可以多次使用。但是我不那么认为它们之间的区别仅仅就是这么简单的一点。我们来从 jdk 作者设计的目的来看，javadoc 是这么描述它们的：

  > CountDownLatch: A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.(**CountDownLatch: 一个或者多个线程，等待其他多个线程完成某件事情之后才能执行；**) CyclicBarrier : A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.(**CyclicBarrier : 多个线程互相等待，直到到达同一个同步点，再继续一起执行。**)

  对于 CountDownLatch 来说，重点是“一个线程（多个线程）等待”，而其他的 N 个线程在完成“某件事情”之后，可以终止，也可以等待。而对于 CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。

  CountDownLatch 是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而 CyclicBarrier 更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。

  **ReentrantLock 和 ReentrantReadWriteLock**

  ReentrantLock 和 synchronized 的区别在上面已经讲过了这里就不多做讲解。另外，需要注意的是：读写锁 ReentrantReadWriteLock 可以保证多个线程可以同时读，所以在读操作远大于写操作的时候，读写锁就非常有用了。

- 什么是线程和进程?

  **何为进程?**

  进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

  在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。

  **何为线程?**
  
  线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

- 程序计数器为什么是私有的?

  程序计数器主要有下面两个作用：

  字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。

  在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

  需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。

  所以，程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。

- 虚拟机栈和本地方法栈为什么是私有的?

  虚拟机栈： 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。

  本地方法栈： 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

  所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。

- 为什么要使用多线程呢?

  先从总体上来说：

  从计算机底层来说： 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。

  从当代互联网发展趋势来说： 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。

  再深入到计算机底层来探讨：

  单核时代： 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。

  多核时代: 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。

- 线程、程序、进程

  - **线程**是比进程更小的执行单位，一个进程在执行过程中可以产生多个线程。同类的多个线程共享同一块内存空间和一组系统资源，所以各个线程之间切换工作负担比进程小得多。
  - **程序**是含有指令和数据的文件，程序是静态的代码。
  - **进程**是程序的一次执行过程，进程是动态的。

- 线程的基本状态

  - 就绪、运行、阻塞、新建、终止（王道操作系统P28）

  - Java线程的状态：新建New（线程被构建）、可运行Runnable（运行中Running、就绪Ready）、阻塞Blocked（线程阻塞于锁）、等待Waiting（当前线程需要等待其他线程的消息）、超时等待TimeWaiting（在等待状态的基础上增加了超时限制，在指定时间自动回到Runnable）、终止Terminated

    比操作系统多了等待、超时等待两个状态

    ![Java线程的状态](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png)

  - Java线程状态变迁

    ![Java线程状态变迁](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%20%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E8%BF%81.png)

- 什么是上下文切换?

  多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。

  概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换。**

  上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。

  Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。

- 说说 sleep() 方法和 wait() 方法区别和共同点?

  两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。

  两者都可以暂停线程的执行。

  Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。

  wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。

- 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

  这是另一个非常经典的 java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！

  new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

  总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。

- 说一说自己对于 synchronized 关键字的了解

  synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

  另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

- 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗

  synchronized关键字最主要的三种使用方式：

  **修饰实例方法**: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁

  **修饰静态方法**: 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，**因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。**

  **修饰代码块**: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

  总结： **synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。**尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！

- 讲一下 synchronized 关键字的底层原理

  synchronized 关键字底层原理属于 JVM 层面。

  ① synchronized 同步语句块的情况

  ```java
  public class SynchronizedDemo {
      public void method() {
          synchronized (this) {
              System.out.println("synchronized 代码块");
          }
      }
  }
  ```

  synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

  ② synchronized 修饰方法的的情况

  ```java
  public class SynchronizedDemo2 {
      public synchronized void method() {
          System.out.println("synchronized 方法");
      }
  }
  ```

  synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

- 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗

  JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。

  锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

- 谈谈 synchronized和ReentrantLock 的区别

  ① 两者都是可重入锁

  两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

  ② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API

  synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。

  ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。

  ③ ReentrantLock 比 synchronized 增加了一些高级功能

  相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）

  ReentrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。

  ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 

  ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。

  synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，**比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。** 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。

  如果你想使用上述功能，那么选择ReentrantLock是一个不错的选择。

  ④ 性能已不是选择标准

- synchronized与java.util.concurrent.locks.Lock的相同之处和不同之处

  synchronized是jvm层面的锁，lock是juc包下面的

  **synchronized书写方便但是不够灵活，lock书写复杂但是灵活**

  **synchronized是悲观锁，lock是乐观锁，底层用volatile和cas操作实现的**

  **synchronized与lock性能差不多**，因为synchronized在jdk1.6~1.7的时候做了许多性能优化，比如自旋锁、偏向锁等

  所以尽可能要使用synchronized而不是lock，毕竟synchronized是亲生的，而lock是领养的

  > [https://blog.csdn.net/qq838642798/article/details/65441415](<https://blog.csdn.net/qq838642798/article/details/65441415>)

  ReenTrantLock可重入锁（和synchronized的区别）总结

  **可重入性：**

  从名字上理解，ReenTrantLock的字面意思就是再进入的锁，其实synchronized关键字所使用的锁也是可重入的，两者关于这个的区别不大。两者都是同一个线程每进入一次，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

  **锁的实现：**

  Synchronized是依赖于JVM实现的，而ReenTrantLock是JDK实现的，有什么区别，说白了就类似于操作系统来控制实现和用户自己敲代码实现的区别。前者的实现是比较难见到的，后者有直接的源码可供阅读。

  **性能的区别：**

  在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。

  **功能区别：**

  便利性：很明显**Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放，而ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。**

  锁的细粒度和灵活度：很明显ReenTrantLock优于Synchronized

  **ReenTrantLock独有的能力：**

  1. **ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。**

  1. **ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的诸线程，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。**

  1. ReenTrantLock提供了一种能够**中断等待锁**的线程的机制，通过lock.lockInterruptibly()来实现这个机制。

  **ReenTrantLock实现的原理：**

  在网上看到相关的源码分析，本来这块应该是本文的核心，但是感觉比较复杂就不一一详解了，简单来说，ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。**想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。**

  **什么情况下使用ReenTrantLock：**

  答案是，如果你需要实现ReenTrantLock的三个独有功能时。

- volatile关键字

  **讲一下Java内存模型**

  在 JDK1.2 之前，Java的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4.png)

  要解决这个问题，就需要把变量声明为volatile，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。

  说白了， volatile 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%8F%AF%E8%A7%81%E6%80%A7.png)

  **说说 synchronized 关键字和 volatile 关键字的区别**

  synchronized关键字和volatile关键字比较

  volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。

  多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞。

  volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。

  volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。

- ThreadLocal

  **ThreadLocal简介**

  通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK中提供的ThreadLocal类正是为了解决这样的问题。 ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。

  如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get() 和 set() 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。

  再举个简单的例子：

  比如有两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来避免这两个线程竞争的。

  **ThreadLocal原理**

  最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。 ThrealLocal 类中可以通过Thread.currentThread()获取到当前线程对象后，直接通过getMap(Thread t)可以访问到该线程的ThreadLocalMap对象。

  每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为key的键值对。 比如我们在同一个线程中声明了两个 ThreadLocal 对象的话，会使用 Thread内部都是使用仅有那个ThreadLocalMap 存放数据的，**ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值。**

  **ThreadLocal 内存泄露问题**

  ThreadLocalMap 中使用的 **key 为 ThreadLocal 的弱引用,而 value 是强引用**。所以，**如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉**。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法。

  **弱引用介绍**

  如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。

  弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。

- 如何保证线程安全？

  **通过合理的时间调度，避开共享资源的存取冲突。**另外，在并行任务设计上可以通过适当的策略，保证任务与任务之间不存在共享资源，设计一个规则来保证一个客户的计算工作和数据访问只会被一个线程或一台工作机完成，而不是把一个客户的计算工作分配给多个线程去完成。

- 什么是线程池(thread pool)？

  在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在Java中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。**所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。**

  Java 5+中的Executor接口定义一个执行线程的工具。它的子类型即线程池接口是ExecutorService。要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，因此在工具类Executors面提供了一些静态工厂方法，生成一些常用的线程池，如下所示：

  - newSingleThreadExecutor：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。
  - newFixedThreadPool：创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。
  - newCachedThreadPool：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。
  - newScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。

  > [https://blog.csdn.net/paul342/article/details/52442932](<https://blog.csdn.net/paul342/article/details/52442932>)

  Java通过Executors提供四种线程池，分别为：

  - **newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。**
  - **newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数**，超出的线程会在队列中等待。
  - **newScheduledThreadPool** 创建一个定长线程池，**支持定时及周期性任务执行。**
  - **newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务**，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

  > [https://blog.csdn.net/dakaniu/article/details/80778801?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task](https://blog.csdn.net/dakaniu/article/details/80778801?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

  1. newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。Executors.newCachedThreadPool(); 缺点：**大家一般不用是因为newCachedThreadPool 可以无限的新建线程，容易造成堆外内存溢出，因为它的最大值是在初始化的时候设置为 Integer.MAX_VALUE，一般来说机器都没那么大内存给它不断使用。**当然知道可能出问题的点，就可以去重写一个方法限制一下这个最大值

  2. newFixedThreadPool  Executors.newFixedThreadPool(3);创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。定长线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors()。可参考PreloadDataCache。其实newFixedThreadPool()在严格上说并不会复用线程，每运行一个Runnable都会通过ThreadFactory创建一个线程
  
  3. newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。Executors.newScheduledThreadPool(5);与Timer 对比：Timer 的优点在于简单易用，但由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务（比如：一个任务出错，以后的任务都无法继续）。

      ScheduledThreadPoolExecutor的设计思想是，每一个被调度的任务都会由线程池中一个线程去执行，因此任务是并发执行的，相互之间不会受到干扰。需要注意的是，只有当任务的执行时间到来时，ScheduedExecutor 才会真正启动一个线程，其余时间 ScheduledExecutor 都是在轮询任务的状态。

      通过对比可以发现ScheduledExecutorService比Timer更安全，功能更强大，在以后的开发中尽可能使用ScheduledExecutorService(JDK1.5以后)替代Timer

  4. newSingleThreadExecutor

      Executors.newSingleThreadExecutor()　创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。现行大多数GUI程序都是单线程的。Android中单线程可用于数据库操作，文件操作，应用批量安装，应用批量删除等不适合并发但可能IO阻塞性及影响UI线程响应的操作。

- 同步和异步

  如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就必须进行同步存取（数据库操作中的排他锁就是最好的例子）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的**同步就是指阻塞式操作，而异步就是非阻塞式操作。**

- 当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？

  不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的synchronized修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。

- 线程同步和线程调度的相关方法

  - wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；
  - sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理InterruptedException异常；
  - notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关；
  - notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；
  - 通过Lock接口提供了显式的锁机制（explicit lock），增强了灵活性以及对线程的协调。Lock接口中定义了加锁（lock()）和解锁（unlock()）的方法，同时还提供了newCondition()方法来产生用于线程之间通信的Condition对象；此外，Java 5还提供了信号量机制（semaphore），信号量可以用来限制对某个共享资源进行访问的线程的数量。在对资源进行访问之前，线程必须得到信号量的许可（调用Semaphore对象的acquire()方法）；在完成对资源的访问后，线程必须向信号量归还许可（调用Semaphore对象的release()方法）。

- 线程的sleep()方法和yield()方法有什么区别？

  ① sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会；

  ② 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态；

  ③ sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常；

  ④ sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性。

  > [https://www.jianshu.com/p/25e959037eed](<https://www.jianshu.com/p/25e959037eed>)

  Java中wait、sleep的区别或者Java中sleep、yield的区别是Java面试或者多线程面试中最常问的问题之一。在这3个在Java中能够用来暂停线程的方法中，sleep()和yield()方法是定义在Thread类中，而wait()方法是定义在Object类中的， 这也是面试中常问的一个问题。

  wait()和sleep()的关键的区别在于，**wait()是用于线程间通信的，而sleep()是用于短时间暂停当前线程。**更加明显的一个区别在于，**当一个线程调用wait()方法的时候，会释放它锁持有的对象的管程和锁，但是调用sleep()方法的时候，不会释放他所持有的管程。**

  回到**yield()方法**上来，与wait()和sleep()方法有一些区别，它**仅仅释放线程所占有的CPU资源，从而让其他线程有机会运行，但是并不能保证某个特定的线程能够获得CPU资源。谁能获得CPU完全取决于调度器，在有些情况下调用yield方法的线程甚至会再次得到CPU资源。所以，依赖于yield方法是不可靠的，它只能尽力而为。**

  - Java中wait和sleep的区别

    wait和sleep的主要区别是调用wait方法时，线程在等待的时候会释放掉它所获得的monitor，但是调用Thread.sleep()方法时，线程在等待的时候仍然会持有monitor或者锁。另外，Java中的wait方法应在同步代码块中调用，但是sleep方法不需要。
    **另一个区别是Thread.sleep()方法是一个静态方法，作用在当前线程上；但是wait方法是一个实例方法，并且只能在其他线程调用本实例的notify()方法时被唤醒。**另外，使用sleep方法时，被暂停的线程在被唤醒之后会立即进入就绪态（Runnable state)，但是使用wait方法的时候，被暂停的线程会首先获得锁（译者注：阻塞态），然后再进入就绪态。所以，根据你的需求，如果你需要暂定你的线程一段特定的时间就使用sleep()方法，如果你想要实现线程间通信就使用wait()方法。
    下面列出Java中wait和sleep方法的区别：

    1. wait只能在同步（synchronize）环境中被调用，而sleep不需要。详见[Why to wait and notify needs to call from synchronized method](https://link.jianshu.com/?t=http%3A%2F%2Fjavarevisited.blogspot.com%2F2011%2F05%2Fwait-notify-and-notifyall-in-java.html)
    2. 进入wait状态的线程能够被notify和notifyAll线程唤醒，但是进入sleeping状态的线程不能被notify方法唤醒。
    3. wait通常有条件地执行，线程会一直处于wait状态，直到某个条件变为真。但是sleep仅仅让你的线程进入睡眠状态。
    4. wait方法在进入wait状态的时候会释放对象的锁，但是sleep方法不会。
    5. wait方法是针对一个被同步代码块加锁的对象，而sleep是针对一个线程。更详细的讲解可以参考《Java核心技术卷1》，里面介绍了如何使用wait和notify方法。

  - yield和sleep的区别

    yield和sleep的区别主要是，**yield方法会临时暂停当前正在执行的线程，来让有同样优先级的正在等待的线程有机会执行。如果没有正在等待的线程，或者所有正在等待的线程的优先级都比较低，那么该线程会继续运行。**执行了yield方法的线程什么时候会继续运行由线程调度器来决定，不同的厂商可能有不同的行为。**yield方法不保证当前的线程会暂停或者停止，但是可以保证当前线程在调用yield方法时会放弃CPU。**
    在Java中Sleep方法有两个， 一个只有一个毫秒参数，另一个有毫秒和纳秒两个参数。

    ```java
    sleep(long millis)
    ```

    or

    ```java
    sleep(long millis, int nanos)
    ```

    会让当前执行的线程sleep指定的时间。

    下面这张图很好地展示了在调用wait、sleep、yield方法的时候，线程状态如何转换。

    ![img](https://upload-images.jianshu.io/upload_images/66827-780462c52b8f5a83.png?imageMogr2/auto-orient/strip\|imageView2/2/w/1100/format/webp)

    Java中sleep方法的几个注意点：

    1. Thread.sleep()方法用来暂停线程的执行，将CPU放给线程调度器。
    2. Thread.sleep()方法是一个静态方法，它暂停的是当前执行的线程。
    3. Java有两种sleep方法，一个只有一个毫秒参数，另一个有毫秒和纳秒两个参数。
    4. 与wait方法不同，sleep方法不会释放锁
    5. 如果其他的线程中断了一个休眠的线程，sleep方法会抛出Interrupted Exception。
    6. 休眠的线程在唤醒之后不保证能获取到CPU，它会先进入就绪态，与其他线程竞争CPU。
    7. 有一个易错的地方，当调用t.sleep()的时候，会暂停线程t。这是不对的，因为Thread.sleep是一个静态方法，它会使当前线程而不是线程t进入休眠状态。

    这就是java中的sleep方法。我们已经看到了java中sleep、wait以及yield方法的区别。总之，记住sleep和yield作用于当前线程。

- 第一个 问题：Java中有几种方法可以实现一个线程？

  第二个问题：用什么关键字修饰同步方法?  

  第三个问题：stop()和suspend()方法为何不推荐使用，请说明原因？

  > [https://blog.csdn.net/Amen_Wu/article/details/54025804](<https://blog.csdn.net/Amen_Wu/article/details/54025804>)

  - **多线程有两种实现方法，分别是继承Thread类与实现Runnable接口。**

  - **用synchronized关键字修饰同步方法。（同步的实现方面有两种，分别是synchronized, wait与notify.）**

  - **反对使用stop()，是因为它不安全。它会解除由线程获取的所有锁定**，而且如果对象处于一种不连贯状态，那么其他线程能在那种状态下检查和修改它们。结果很难检查出真正的问题所在。

    **suspend()方法容易发生死锁。调用suspend()的时候，目标线程会停下来，但却仍然持有在这之前获得的锁定。**此时，其他任何线程都不能访问锁定的资源，除非被”挂起”的线程恢复运行。对任何线程来说，如果它们想恢复目标线程，同时又试图使用任何一个锁定的资源，就会造成死锁。

    所以不应该使用suspend()，而应在自己的Thread类中置入一个标志，指出线程应该活动还是挂起。若标志指出线程应该挂起，便用 wait()命其进入等待状态。若标志指出线程应当恢复，则用一个notify()重新启动线程。

- 启动一个线程是用run()还是start()?

  > [https://blog.csdn.net/wang_xing1993/article/details/70257475](<https://blog.csdn.net/wang_xing1993/article/details/70257475>)

  启动线程肯定要用start()方法。当用start()开始一个线程后，线程就进入就绪状态，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM调度并执行。这并不意味着线程就会立即运行。当cpu分配给它时间时，才开始执行run()方法(如果有的话)。start()是方法,它调用run()方法.而run()方法是你必须重写的. run()方法中包含的是线程的主体。

  继承Thread类的启动方式：

  ```java
  public class ThreadStartTest {
    public static void main(String[] args) {
      ThreadTest tt = new ThreadTest();// 创建一个线程实例
      tt.start();  // 启动线程
    }
  }
  ```

  实现Runnable接口的启动方式：

  ```java
  public class RunnableStartTest {
  	public static void main(String[] args) {
  		Thread t = new Thread(new RunnableTest());    // 创建一个线程实例
  		t.start();  // 启动线程
  	}
  }
  ```

  实际上这两种启动线程的方式原理是一样的。首先都是调用本地方法启动一个线程，其次是在这个线程里执行目标对象的run()方法。那么这个目标对象是什么呢？为了弄明白这个问题，我们来看看Thread类的run()方法的实现：

  ```java
  public void run() {
     if (target != null) {
         target.run();
      }
  }
  ```

  当我们采用实现Runnable接口的方式来实现线程的情况下，在调用new Thread(Runnable target)构造器时，将实现Runnable接口的类的实例设置成了线程要执行的主体所属的目标对象target，当线程启动时，这个实例的 run()方法就被执行了。当我们采用继承Thread的方式实现线程时，线程的这个run()方法被重写了，所以当线程启动时，执行的是这个对象自身的 run()方法。总结起来就一句话，如果我们采用的是继承Thread类的方式，那么这个target就是线程对象自身，如果我们采用的是实现Runnable接口的方式，那么这个target就是实现了Runnable接口的类的实例。

- 使用内部类实现线程设计4个线程，其中两个线程每次对j增加1，另外两个线程对j每次减少1

  > [https://www.nowcoder.com/questionTerminal/8db05d0b47044b3f9605860451d63d25](<https://www.nowcoder.com/questionTerminal/8db05d0b47044b3f9605860451d63d25>)

  ```java
  public class Main{
      private int j=0;//定义变量j
      
      public synchronized add() {
          j++;//定义同步方法每次只有一个线程对j进行j++操作
      }
      
      public synchronized dec() {
  		j--;//定义同步方法每次只有一个线程对j进行j--操作
      }
      
  	public static void main(String[] args){
  		
          for(int i=0;i<2;i++) {
  			
              new Thead(new Runnable(){//使用匿名内部类进行线程的创建，重写run()方法，调用add()方法
                  public void run() {
  					while(true){
                   		add();
             			}
           		}
           	}).start();
              
           	new Thead(new Runnable() {//使用匿名内部类进行线程的创建，重写run()方法，调用dec()方法
             		public void run(){
                      while(true){
                          dec();
                      }
  				}
              }).start();
          }
      }
  }
  ```

  > [https://blog.csdn.net/zuoyixiao/article/details/39525625](<https://blog.csdn.net/zuoyixiao/article/details/39525625>)

  ```java
  public class MultiThread {
  	private int j;
   
  	public static void main(String[] args) {
  		MultiThread mt = new MultiThread();
  		Inc inc = mt.new Inc();
  		Dec dec = mt.new Dec();
  		// 4个线程（0、1、2、3）
  		for (int i = 0; i < 2; i++) {
  			Thread t = new Thread(inc);
  			t.start();
  			t = new Thread(dec);
  			t.start();
  		}
  		// System.exit(0);// 如果报错加上此句
  	}
   
  	// 对j增加1的方法
  	private synchronized void inc() {
  		j++;
  		System.out.println(Thread.currentThread().getName() + "-inc:" + j);
  	}
   
  	// 对j减少1的方法
  	private synchronized void dec() {
  		j--;
  		System.out.println(Thread.currentThread().getName() + "-dec:" + j);
  	}
   
  	// 内部类实现线程
  	class Inc implements Runnable {
  		public void run() {
  			for (int i = 0; i < 100; i++) {
  				inc();
  			}
  		}
  	}
   
  	class Dec implements Runnable {
  		public void run() {
  			for (int i = 0; i < 100; i++) {
  				dec();
  			}
  		}
  	}
  }
  ```

- 在监视器(Monitor)内部，是如何做到线程同步的？在程序又应该做哪种级别的同步呢？

  > [https://www.nowcoder.com/questionTerminal/26fc16a2a85e49a5bd5fc2b5759dbbc2](https://www.nowcoder.com/questionTerminal/26fc16a2a85e49a5bd5fc2b5759dbbc2)

  在 java 虚拟机中, 每个对象( Object 和 class )通过某种逻辑关联监视器,每个监视器和一个对象引用相关联, 为了实现监视器的互斥功能, 每个对象都关联着一把锁。
 
  一旦方法或者代码块被 synchronized 修饰, 那么这个部分就放入了监视器的监视区域, 确保一次只能有一个线程执行该部分的代码, 线程在获取锁之前不允许执行该部分的代码。
  
  另外 java 还提供了显式监视器( Lock )和隐式监视器( synchronized )两种锁方案。

- 同步方法和同步代码块的区别是什么？

  同步方法默认用this或者当前类class对象作为锁；
  同步代码块可以选择以什么来加锁，比同步方法要更细颗粒度，我们可以选择只同步会发生同步问题的部分代码而不是整个方法。

- 创建线程有几种不同的方式？你喜欢哪一种？为什么？

  > [https://blog.csdn.net/u012973218/article/details/51280044](<https://blog.csdn.net/u012973218/article/details/51280044>)

  1. 继承Thread类创建线程类

     ```java
     public class FirstThreadTest extends Thread {  
         int i = 0;  
         //重写run方法，run方法的方法体就是现场执行体  
         public void run() {  
             for(;i<100;i++) {  
                 System.out.println(getName()+"  "+i);  
             }  
         }  
         public static void main(String[] args) {  
             for(int i = 0;i< 100;i++) {  
                 System.out.println(Thread.currentThread().getName()+"  : "+i);  
                 if(i==20) {  
                     new FirstThreadTest().run();  
                     new FirstThreadTest().run();  
                 }  
             }  
         }   
     }
     ```

  2. 通过Runable接口创建线程类

     ```java
     public class RunnableThreadTest implements Runnable {  
         private int i;  
         public void run() {  
             for(i = 0;i <100;i++) {  
                 System.out.println(Thread.currentThread().getName()+" "+i);  
             }  
         }  
         public static void main(String[] args) {  
             for(int i = 0;i < 100;i++) {  
                 System.out.println(Thread.currentThread().getName()+" "+i);  
                 if(i==20) {  
                     RunnableThreadTest rtt = new RunnableThreadTest();  
                     new Thread(rtt,"新线程1").start();  
                     new Thread(rtt,"新线程2").start();  
                 }  
             }  
         }  
     }
     ```

  3. 通过Callable接口和FutureTask对象创建线程

     a. 创建Callable接口的实现类，并实现call()方法；

     b. 创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callback对象的call()方法的返回值；

     c. 使用FutureTask对象作为Thread对象的target创建并启动新线程；

     d. 调用FutureTask对象的get()方法来获得子线程执行结束后的返回值。

     ```java
     import java.util.concurrent.Callable;  
     import java.util.concurrent.ExecutionException;  
     import java.util.concurrent.FutureTask;  
       
     public class CallableThreadTest implements Callable<Integer> {  
       
         public static void main(String[] args) {  
             CallableThreadTest ctt = new CallableThreadTest();  
             FutureTask<Integer> ft = new FutureTask<Integer>(ctt);  
     //        Thread thread = new Thread(ft,"有返回值的线程");
     //        thread.start();
             for(int i = 0;i < 100;i++) {  
                 System.out.println(Thread.currentThread().getName()+" 的循环变量i的值"+i);  
                 if(i==20) {  
                     new Thread(ft,"有返回值的线程").start();  
                 }  
             }  
             try {  
                 System.out.println("子线程的返回值："+ft.get());  
             } catch (InterruptedException e) {  
                 e.printStackTrace();  
             } catch (ExecutionException e) {  
                 e.printStackTrace();  
             }  
         }  
       
         @Override  
         public Integer call() throws Exception {  
             int i = 0;  
             for(;i<100;i++) {  
                 System.out.println(Thread.currentThread().getName()+" "+i);  
             }  
             return i;  
         }  
     } 
     ```

  4. 通过线程池创建线程

     ```java
     import java.util.concurrent.ExecutorService;
     import java.util.concurrent.Executors;
     
     public class ThreadPool {
     	/* POOL_NUM */
     	private static int POOL_NUM = 10;
     	
     	/**
     	 * Main function
     	 */
     	public static void main(String[] args) {
     		ExecutorService executorService = Executors.newFixedThreadPool(5);
     		for(int i = 0; i<POOL_NUM; i++) {
     			RunnableThread thread = new RunnableThread();
     			executorService.execute(thread);
     		}
     	}
     }
      
     class RunnableThread implements Runnable {
     	private int THREAD_NUM = 10;
     	public void run() {
     		for(int i = 0; i<THREAD_NUM; i++) {
     			System.out.println("线程" + Thread.currentThread() + " " + i);
     		} 
     	}
     }
     ```

- Java多线程回调是什么意思？

  > [https://blog.csdn.net/wenzhi20102321/article/details/52512536](<https://blog.csdn.net/wenzhi20102321/article/details/52512536>)

  所谓回调，就是客户程序C调用服务程序S中的某个方法A，然后S又在某个时候反过来调用C中的某个方法B，对于C来说，这个B便叫做回调方法。

  - 回答者(S)

  ```java
  package com.xykj.thread;
  public class XiaoZhang extends Thread {
      // 回答1+1，很简单的问题不需要线程
      public int add(int num1, int num2) {
         return num1 + num2;
      }
   
      // 重写run方法
      @Override
      public void run() {
         // 回答地球为什么是圆的
         askquestion();
         super.run();
      }
   
      // 回调接口的创建，里面要有一个回调方法
      //回调接口什么时候用呢？这个思路是最重要的   
      public static interface CallPhone {
         public void call(String question);
      }
   
      // 回调接口的对象
      CallPhone callPhone;
   
      // 回答地球为什么是圆的
      private void askquestion() {
         System.err.println("开始查找资料！");
         try {
             sleep(3000);// 思考3天
         } catch (InterruptedException e) {
             e.printStackTrace();
         }
         // 把答案返回到回调接口的call方法里面
         if (callPhone!=null) {//提问者实例化callPhone对象，相当于提问者已经告诉我，我到时用什么方式回复答案
             //这个接口的方法实现是在提问者的类里面
             callPhone.call("知道了，！！！~~~~百度有啊");
         }     
      }
  }
  ```

  - 提问者(C)

  ```java
  package com.xykj.thread;
  import com.xykj.thread.XiaoZhang.CallPhone;
  public class MainClass {
      /**
       * java回调方法的使用
       * 实际操作时的步骤：（以本实例解释）
       * 1.在回答者的类内创建回调的接口
       * 2.在回答者的类内创建回调接口的对象，
       * 3.在提问者类里面实例化接口对象，重写接口方法
       * 2.-3.这个点很重要，回调对象的实例化，要在提问者的类内实例化，然后重写接口的方法
       * 相当于提问者先把一个联络方式给回答者，回答者找到答案后，通过固定的联络方式，来告诉提问者答案。
       * 4.调用开始新线程的start方法
       * 5.原来的提问者还可以做自己的事
       * */
      public static void main(String[] args) {
         // 小王问小张1+1=？，线程同步
         XiaoZhang xiaoZhang = new XiaoZhang();
         int i = xiaoZhang.add(1, 1);//回答1+1的答案
   
         // 问小张地球为什么是圆的？回调方法的使用
         //这相当于先定好一个返答案的方式，再来执行实际操作
        
         // 实例化回调接口的对象
         CallPhone phone = new CallPhone() {
             @Override
             public void call(String question) {
                //回答问题者，回答后，才能输出答案
                System.err.println(question);
             }
         };
        
         //把回调对象赋值给回答者的回调对象，回答问题者的回调对象才能回答问题
         xiaoZhang.callPhone = phone;
        
         System.out.println("交代完毕！");
         //相关交代完毕之后再执行查询操作
         xiaoZhang.start();
        
         //小王做自己的事！
         System.out.println("小王做自己的事！");
      }
   
  }
  ```

- CyclicBarrier和CountDownLatch区别

  > [https://blog.csdn.net/tolcf/article/details/50925145](<https://blog.csdn.net/tolcf/article/details/50925145>)

  | CountDownLatch                                               | CyclicBarrier                                                |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | 减计数方式                                                   | 加计数方式                                                   |
  | 计算为0时释放所有等待的线程                                  | 计数达到指定值时释放所有等待线程                             |
  | 计数为0时，无法重置                                          | 计数达到指定值时，计数置为0重新开始                          |
  | **调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响** | **调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞** |
  | 不可重复利用                                                 | 可重复利用                                                   |

- 如何让多个执行速度不同的线程跑到一个点上（同步）

  **CyclicBarrier**

  **用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行**
  
  和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。

  CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它
  才叫做循环屏障。

  **CountDownLatch**

  **用来控制一个线程等待多个线程。**

  维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。

  **Semaphore**

  Semaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。

- 线程池的优势

  第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。

  第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能执行。

  第三：提高线程的可管理性，线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。

- 内存足够的情况下，线程池里的线程越多越好吗

  也不是线程越多，程序的性能就越好，因为线程之间的调度和切换也会浪费CPU时间。

- 什么是生产者消费者模式？

  ![img](https://uploadfiles.nowcoder.com/images/20180925/308572_1537880635592_7142B8354CA8A352B2B805F997C71549)

  生产者消费者问题是线程模型中的经典问题：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者取走数据。

- 线程安全有哪些实现方式

  1、同步方案：互斥同步（阻塞同步）：synchronized和lock

  非阻塞同步（乐观锁）：CAS

  2、无同步方案：不可变对象（本身就是线程安全的，因为不能修改。比如final、String、enum（枚举））

  栈封闭（多线程访问一个方法的局部变量，不会有问题，因为虚拟机栈是线程私有的）

  线程本地存储（ThreadLocal，线程局部变量）

  可重入代码（纯代码，可以在代码执行的任何时刻中断，转而去执行其他代码，返回之后，不会出现程序错误）

  （特征：不依赖堆等共享资源，用到的状态变量全部由参数传入，不调用不可重入的代码）

- 实现多线程同步的方法

  > [https://www.cnblogs.com/xhjt/p/3897440.html](<https://www.cnblogs.com/xhjt/p/3897440.html>)

  1. **同步方法**

     即有synchronized关键字修饰的方法。由于java的每个对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

     代码如：

     ```java
     public synchronized void save(){}
     ```

     注： synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类

  2. **同步代码块**

     即有synchronized关键字修饰的语句块。被该关键字修饰的语句块会自动被加上内置锁，从而实现同步。

     代码如：

     ```java
     synchronized(object){}
     ```

     注：同步是一种高开销的操作，因此应该尽量减少同步的内容。通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可。

     代码实例：

     ```java
     package com.xhj.thread;
     
     /**
       * 线程同步的运用
       */
     public class SynchronizedThread {
     
         class Bank {
     
             private int account = 100;
     
             public int getAccount() {
                 return account;
             }
     
             /**
               * 用同步方法实现
               * 
               * @param money
               */
             public synchronized void save(int money) {
                 account += money;
             }
     
             /**
               * 用同步代码块实现
               * 
               * @param money
               */
             public void save1(int money) {
                 synchronized (this) {
                     account += money;
                 }
             }
         }
     
         class NewThread implements Runnable {
             private Bank bank;
     
             public NewThread(Bank bank) {
                 this.bank = bank;
             }
     
             @Override
             public void run() {
                 for (int i = 0; i < 10; i++) {
                     // bank.save1(10);
                     bank.save(10);
                     System.out.println(i + "账户余额为：" + bank.getAccount());
                 }
             }
     
         }
     
         /**
           * 建立线程，调用内部类
           */
         public void useThread() {
             Bank bank = new Bank();
             NewThread new_thread = new NewThread(bank);
             System.out.println("线程1");
             Thread thread1 = new Thread(new_thread);
             thread1.start();
             System.out.println("线程2");
             Thread thread2 = new Thread(new_thread);
             thread2.start();
         }
     
         public static void main(String[] args) {
             SynchronizedThread st = new SynchronizedThread();
             st.useThread();
         }
     
     }
     ```

  3. 使用特殊域变量(**volatile**)实现线程同步

     a.volatile关键字为域变量的访问提供了一种免锁机制，

     b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新，

     c.因此每次使用该域就要重新计算，而不是使用寄存器中的值

     d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量

     例如：在上面的例子当中，只需在account前面加上volatile修饰，即可实现线程同步。

     代码实例：

     ```java
     //只给出要修改的代码，其余代码与上同
     class Bank {
         //需要同步的变量加上volatile
         private volatile int account = 100;
     
         public int getAccount() {
             return account;
         }
         //这里不再需要synchronized 
         public void save(int money) {
             account += money;
         }
     }
     ```

     注：多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法。用final域，有锁保护的域和volatile域可以避免非同步的问题。

  4. 使用**重入锁**实现线程同步

     在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。ReentrantLock类是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。

     **ReentrantLock类**的常用方法有：

     - ReentrantLock() : 创建一个ReentrantLock实例
     - lock() : 获得锁
     - unlock() : 释放锁

     注：ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用。

     例如：在上面例子基础上，修改后的代码为：

     代码实例：

     ```java
     //只给出要修改的代码，其余代码与上同
     class Bank {
     
         private int account = 100;
         //需要声明这个锁
         private Lock lock = new ReentrantLock();
         public int getAccount() {
             return account;
         }
         //这里不再需要synchronized 
         public void save(int money) {
             lock.lock();
             try{
                 account += money;
             }finally{
                 lock.unlock();
             }
         }
     }
     ```

     注：关于Lock对象和synchronized关键字的选择：

     a.最好两个都不用，使用一种java.util.concurrent包提供的机制，能够帮助用户处理所有与锁相关的代码。

     b.如果synchronized关键字能满足用户的需求，就用synchronized，因为它能简化代码

     c.如果需要更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally代码释放锁

  5. 使用局部变量实现线程同步

     **如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。**

     **ThreadLocal 类**的常用方法

     - ThreadLocal() : 创建一个线程本地变量
     - get() : 返回此线程局部变量的当前线程副本中的值
     - initialValue() : 返回此线程局部变量的当前线程的"初始值"
     - set(T value) : 将此线程局部变量的当前线程副本中的值设置为value

     例如：在上面例子基础上，修改后的代码为：

     代码实例：

     ```java
     //只改Bank类，其余代码与上同
     public class Bank{
         //使用ThreadLocal类管理共享变量account
         private static ThreadLocal<Integer> account = new ThreadLocal<Integer>(){
             @Override
             protected Integer initialValue(){
                 return 100;
             }
         };
         public void save(int money){
             account.set(account.get()+money);
         }
         public int getAccount(){
             return account.get();
         }
     }
     ```

     注：ThreadLocal与同步机制

     a.**ThreadLocal**与**同步机制**都是为了解决多线程中相同变量的访问冲突问题。

     b.前者采用以"**空间换时间**"的方法，后者采用以"**时间换空间**"的方式

  6. 使用**阻塞队列**实现线程同步

     前面5种同步方式都是在底层实现的线程同步，但是我们在实际开发当中，应当尽量远离底层结构。 
     使用javaSE5.0版本中新增的java.util.concurrent包将有助于简化开发。 

     本小节主要是使用**LinkedBlockingQueue<E>**来实现线程的同步 。LinkedBlockingQueue<E>是一个基于已连接节点的，范围任意的blocking queue。 队列是先进先出的顺序（FIFO），关于队列以后会详细讲解~ 

     **LinkedBlockingQueue 类常用方法** 

     - LinkedBlockingQueue() : 创建一个容量为Integer.MAX_VALUE的LinkedBlockingQueue 
     - put(E e) : 在队尾添加一个元素，如果队列满则阻塞 
     - size() : 返回队列中的元素个数 
     - take() : 移除并返回队头元素，如果队列空则阻塞 

     **代码实例：** 实现商家生产商品和买卖商品的同步

     ```java
     package com.xhj.thread;
     
     import java.util.Random;
     import java.util.concurrent.LinkedBlockingQueue;
     
     /**
      * 用阻塞队列实现线程同步 LinkedBlockingQueue的使用
      */
     public class BlockingSynchronizedThread {
         /**
          * 定义一个阻塞队列用来存储生产出来的商品
          */
         private LinkedBlockingQueue<Integer> queue = new LinkedBlockingQueue<Integer>();
         /**
          * 定义生产商品个数
          */
         private static final int size = 10;
         /**
          * 定义启动线程的标志，为0时，启动生产商品的线程；为1时，启动消费商品的线程
          */
         private int flag = 0;
     
         private class LinkBlockThread implements Runnable {
             @Override
             public void run() {
                 int new_flag = flag++;
                 System.out.println("启动线程 " + new_flag);
                 if (new_flag == 0) {
                     for (int i = 0; i < size; i++) {
                         int b = new Random().nextInt(255);
                         System.out.println("生产商品：" + b + "号");
                         try {
                             queue.put(b);
                         } catch (InterruptedException e) {
                             // TODO Auto-generated catch block
                             e.printStackTrace();
                         }
                         System.out.println("仓库中还有商品：" + queue.size() + "个");
                         try {
                             Thread.sleep(100);
                         } catch (InterruptedException e) {
                             // TODO Auto-generated catch block
                             e.printStackTrace();
                         }
                     }
                 } else {
                     for (int i = 0; i < size / 2; i++) {
                         try {
                             int n = queue.take();
                             System.out.println("消费者买去了" + n + "号商品");
                         } catch (InterruptedException e) {
                             // TODO Auto-generated catch block
                             e.printStackTrace();
                         }
                         System.out.println("仓库中还有商品：" + queue.size() + "个");
                         try {
                             Thread.sleep(100);
                         } catch (Exception e) {
                             // TODO: handle exception
                         }
                     }
                 }
             }
         }
     
         public static void main(String[] args) {
             BlockingSynchronizedThread bst = new BlockingSynchronizedThread();
             LinkBlockThread lbt = bst.new LinkBlockThread();
             Thread thread1 = new Thread(lbt);
             Thread thread2 = new Thread(lbt);
             thread1.start();
             thread2.start();
         }
     }
     ```

     注：BlockingQueue<E>定义了阻塞队列的常用方法，尤其是三种添加元素的方法，我们要多加注意，当队列满时：add()方法会抛出异常，offer()方法返回false，put()方法会阻塞。

  7. 使用**原子变量**实现线程同步

     需要使用线程同步的根本原因在于对普通变量的操作不是原子的。那么什么是原子操作呢？原子操作就是指将读取变量值、修改变量值、保存变量值看成一个整体来操作，即-这几种行为要么同时完成，要么都不完成。在java的**util.concurrent.atomic包中提供了创建了原子类型变量的工具类**，使用该类可以简化线程同步。其中**AtomicInteger** 表可以用原子方式更新int的值，可用在应用程序中(如以原子方式增加的计数器)，但不能用于替换Integer；可扩展Number，允许那些处理机遇数字类的工具和实用工具进行统一访问。

     **AtomicInteger类常用方法：**

     - AtomicInteger(int initialValue) : 创建具有给定初始值的新的AtomicInteger
     - addAddGet(int dalta) : 以原子方式将给定值与当前值相加
     - get() : 获取当前值

     **代码实例：**只改Bank类，其余代码与上面第一个例子同

     ```java
     class Bank {
         private AtomicInteger account = new AtomicInteger(100);
     
         public AtomicInteger getAccount() {
             return account;
         }
     
         public void save(int money) {
             account.addAndGet(money);
         }
     }
     ```

     **补充--原子操作主要有：**

     对于引用变量和大多数原始变量(long和double除外)的读写操作；

     对于所有使用volatile修饰的变量(包括long和double)的读写操作。

- ThreadLocal原理

  1、每个线程都有一个ThreadLocalMap变量（和hashMap差不多）

  2、Map的键值对：<WeakReference<ThreadLocal> ，value>

  3、ThreadLocal是空间换时间，synchronized是时间换空间

  **为什么key要采用弱引用？**

  保证当threadLocal这个key没有强引用指向的时候，可以被gc回收掉

  如果没有弱引用的话，当threadLocal没有了强引用指向，但还是被key所强引用，将无法被gc回收，导致内存泄漏

  **采用了弱引用但还有内存泄漏？**

  弱引用在一定程度上完成了无用对象的回收，但是前提是threadLocal的强引用被开发者手动清理掉

  不然的话，threadLocalMap的key-value键值对一直在涨，最后导致内存泄漏

  所以，当某个threadLocal对象不用的时候，一定要手动remove掉

- 什么是线程安全

  如果一段代码可以保证多个线程访问的时候正确操作共享数据，那么它是线程安全的

- 多线程中的i++线程安全吗？请简述一下原因？

  不安全。i++不是原子性操作。i++分为读取i值，对i值加一，再赋值给i++，执行期中任何一步都是有可能被其他线程抢占的。

- synchronized的可重入怎么实现

  > 《Java并发编程实践》

  **“重入”意味这获取锁的操作的粒度是“线程”，而不是“调用”。**重入的一种**实现方法**是，为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程持有。当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1. 如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减。当计数值为0时，这个锁将被释放。

  > [https://www.jianshu.com/p/5379356c648f](<https://www.jianshu.com/p/5379356c648f>)

  若一个程序或子程序可以“**在任意时刻被中断然后操作系统调度执行另外一段代码，这段代码又调用了该子程序不会出错**”，则称其为可重入（reentrant或re-entrant）的。即**当该子程序正在运行时，执行线程可以再次进入并执行它**，仍然获得符合设计时预期的结果。与多线程并发执行的线程安全不同，可重入强调对单个线程执行时重新进入同一个子程序仍然是安全的。

- 《Java并发编程实战》摘录

  - 第二章 线程安全性

    - **安全性**的含义是“**永远不发生糟糕的事情**”，而**活跃性**则关注于另一个目标，即“**某件正确的事情最终会发生**”。

    - **当多个线程访问某个类时**，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，**这个类都能表现出正确的行为**，那么就称**这个类是线程安全的**。

    - 无状态对象一定是线程安全的。

    - 当某个计算的正确性取决于多个线程的交替执行时序时，就会发生**竞争条件**(race condition)。换句话说，就是正确的结果要取决于运气。最常见的竞争条件类型就是“**先检查后执行**(check-then-act)”操作，即通过一个可能失效的观测结果来决定下一步的动作。

    - 假定有两个操作A和B，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说时**原子的**。原子操作是指，对于访问同一个状态的所有操作（包括该操作本身）来说，这个操作是一个以原子方式执行的操作。

    - 在java.util.concurrent.atomic包中包含了一些原子变量类，用于实现在数值和对象引用上的原子状态转换。通过用AtomicLong来代替long类型的计数器，能够确保所有对计数器状态的访问操作都是原子的。

    - 要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。

    - **“重入”意味这获取锁的操作的粒度是“线程”，而不是“调用”。**重入的一种**实现方法**是，为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程持有。当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1. 如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减。当计数值为0时，这个锁将被释放。

      在以下代码中，子类改写了父类的synchronized方法，然后调用父类的方法，此时如果没有可重入的锁，那么这段代码将产生死锁。

      ```java
      public class Widget {
          public synchronized void doSomething() {
              ...
          }
      }
      
      public class LoggingWiget extends Widget {
          public synchronized void doSomething() {
              System.out.println(toString() + ": calling doSomething");
              super.doSomething();
          }
      }
      ```

    - 一种常见的错误是认为，只有在写入共享变量时才需要使用同步，然而事实并非如此。

    - 对于可能被多个线程同时访问的可变状态变量，在访问它时都需要持有同一个锁，在这种情况下，我们称状态是由这个锁保护的。**每个共享的和可变的变量都应该只由一个锁来保护，从而使维护人员知道是哪一个锁。对于包含多个变量的不变性条件，其中涉及的所有变量都需要由同一个锁来保护。**

    - Servlet中一个同步代码块负责保护判断是否只需返回缓存结果的“先检查后执行”操作序列，另一个同步代码块则负责确保对缓存的数值和引述分解结果进行同步更新。

      ```java
      @ThreadSafe
      public class CacheFactorizer implments Servlet {
          @GuardedBy("this") private BigInteger lastNumber;
          @GuardedBy("this") private BigInteger[] lastFactors;
          @GuardedBy("this") private long hits;
          @GuardedBy("this") private long cacheHits;
          
          public synchronized long getHits() { return hits; }
          public synchronized double getCacheHitRatio() {
              return (double) cacheHits / (double) hits;
          }
          
          public void service(ServletRequest req, ServletResponse resq) {
              BigInteger i = extractFromRequest(req);
              BigInteger[] factors = null;
              synchronized (this) {
                  ++hits;
                  if (i.equals(lastNumber)) {
                      ++cacheHits;
                      factors = lastFactors.clone();
                  }
              }
              if (factors == null) {
                  factors = factor(i);
                  synchronized (this) {
                      lastNumber = i;
                      lastFactors = factors.clone();
                  }
              }
              encodeIntResponse(resp, factors);
          }
      }
      ```

      在简单性与性能之间存在着相互制约因素。

      **当执行时间较长的计算或者可能无法快速完成的操作时（例如，网络I/O或控制台I/O），一定不要持有锁。**

  - 第三章 对象的共享

    - 在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意向不到的调整。在缺乏足够同步的多线程程序中，要想对内存操作的执行顺序进行判断，几乎无法得出正确的结论。在缺乏同步的程序中可能产生错误结果的一种情况是**失效数据**。仅对set方法进行同步是不够的，调用get的线程仍然会看到失效值。

    - 当线程在没有同步的情况下读取变量时，可能会得到一个失效值，但至少这个值是由之前某个线程设置的值，而不是一个随机值。这种安全性保证也被称为最低安全性(out-of-thin-air safety)。最低安全性适用于绝大多数变量，但是存在一个例外：非volatile类型的64位数值变量（double和long）。Java内存模型要求，变量的读取操作和写入操作都必须时原子操作，但对于非volatile类型的long和double变量，JVM允许将64位读操作或写操作分解为两个32位的操作。当读取一个非volatile类型的long时，如果对该变量的读操作和写操作在不同的线程中执行，那么很可能会读取到某个值的高32位和另一个值的低32位。

    - 在访问某个共享且可变的变量时要求所有线程在同一个锁上同步，就是为了确保某个线程写入该变量的值对于其他线程来说时可见的。**加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。**

    - **Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保变量的更新操作通知到其他线程。在读取volatile类型的变量时总会返回最新写入的值。在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。**

    - volatile变量对可见性的影响比volatile变量本身更为重要。当线程A首先写入一个volatile变量并且线程B随后读取该变量时，在写入volatile变量之前对A可见的所有变量的值，在B读取了volatile变量后，对B也是可见的。因此，从内存可见性的角度来看，写入volatile变量相当于退出同步代码块，而读取volatile变量就相当于进入同步代码块。

    - **加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。**虽然volatile变量很方便，但也存在一些局限性，在使用时要非常小心。例如，volatile的语义不足以确保递增操作(count++)的原子性，除非你能确保只有一个线程对变量执行写操作。

    - 当且仅当满足以下所有条件时，才应该使用volatile变量：

      - 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。
      - 该变量不会与其他状态一起纳入不变性条件中。
      - 在访问变量时不需要加锁。

    - volatile变量的典型用法：检查某个状态标记以判断是否退出循环。为了使这个示例能正确执行，asleep必须为volatile变量。否则，当asleep被另一个线程修改时，执行判断的线程却发现不了。

      ```java
      volatile boolean asleep;
      ...
          while (!asleep)
              countSomeSheep();
      ```

## JVM

- JVM加载class文件的原理

  > [https://www.cnblogs.com/Qian123/p/5707562.html](<https://www.cnblogs.com/Qian123/p/5707562.html>)

   Java中的所有类，都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，像是反射，就需要显式的加载所需要的类。

  类装载方式，有两种 

  1. 隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中，
  2. 显式装载， 通过class.forname()等方法，显式加载需要的类 

  隐式加载与显式加载的区别：两者本质是一样? 

  Java类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载。这当然就是为了节省内存开销。

  Java的类加载器有三个，对应Java的三种类:（java中的类大致分为三种：   1.系统类   2.扩展类 3.由程序员自定义的类 ）

  ```​
       Bootstrap Loader  // 负责加载**系统类** (指的是内置类，像是String，对应于C#中的System类和C/C++标准库中的类)
  ​            | 
  ​          \- - ExtClassLoader   // 负责加载**扩展类**(就是继承类和实现类)
  ​                          | 
  ​                      \- - AppClassLoader   // 负责加载**应用类**(程序员自定义的类)
  ```

  三个加载器各自完成自己的工作，但它们是如何协调工作呢？哪一个类该由哪个类加载器完成呢？为了解决这个问题，Java采用了**委托模型机制**。

  **委托模型机制的工作原理很简单：当类加载器需要加载类的时候，先请示其Parent(即上一层加载器)在其搜索路径载入，如果找不到，才在自己的搜索路径搜索该类。这样的顺序其实就是加载器层次上自顶而下的搜索，因为加载器必须保证基础类的加载。** 之所以是这种机制，还有一个安全上的考虑：如果某人将一个恶意的基础类加载到jvm，委托模型机制会搜索其父类加载器，显然是不可能找到的，自然就不会将该类加载进来。

  我们可以通过这样的代码来获取类加载器:

  ```java
  ClassLoader loader = ClassName.class.getClassLoader();
  ClassLoader ParentLoader = loader.getParent();
  ```

  注意一个很重要的问题，就是Java在逻辑上并不存在BootstrapLoader的实体！因为它是用C++编写的，所以打印其内容将会得到null。

  前面是对类加载器的简单介绍，它的原理机制非常简单，就是下面几个步骤:

  1. **加载**:查找和导入class文件;

  2. **连接**:

     (1)**验证**:检查载入的class文件数据的正确性;

     (2)**准备**:为类的静态变量分配存储空间;

     (3)**解析**:将符号引用转换成直接引用(这一步是可选的)

  3. **初始化**:初始化静态变量，静态代码块。

  这样的过程在程序调用类的静态成员的时候开始执行，所以静态方法main()才会成为一般程序的入口方法。类的构造器也会引发该动作。

  ![img](https://uploadfiles.nowcoder.com/images/20180926/308572_1537962641528_95106A90F455887E4A4B298735A4641B)

  > 《深入理解JVM》P191 双亲委派模型

  **双亲委派模型**的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载器请求最终都应该传送到顶层的启动类加载器中，只有当父加载器自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。

  > 《深入理解JVM》P194 破坏双亲委派模型

  双亲委派模型主要出现过三次较大规模的“被破坏”情况。

  第一次出现在双亲委派模型出现之前————即JDK1.2发布之前。由于双亲委派模型在JDK1.0时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协。为了向前兼容，JDK1.2之后的java.lang.ClassLoader添加了一个新的protected方法findClass()，在次之前，用户继承**java.lang.ClassLoader的唯一目的就是重写loadClass()方法**。

  **JDK1.2之后已不提倡用户再去覆盖loadClass()方法，而应该把自己的类加载逻辑写到findClass()方法中，在loadClass()方法的逻辑里如果父类加载失败，则会调用自己的findClass()方法来完成加载**，这样就可以保证新写出来的类加载器时符合双亲委派规则的。

  第二次是**由这个模型的自身的缺陷所导致**的，基础类之所以被称为“基础”，是因为它们总是作为被用户代码调用的API，但如果**基础类又要调用回用户的代码**，那该怎么办？

  **JNDI服务由启动类加载器去加载**，但启动类加载器不可能“认识”这些代码啊！为了解决这个困境，Java设计团队只好引入了一个不太优雅的设计：**线程上下文类加载器**。JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码，也就是**父类加载器请求子类加载器去完成类加载器**的动作，这种行为实际上就是打通了双亲委派模型的层次结构来你想使用类加载器。

  第三次是由于**用户对程序动态性的追求**而导致的，这里所说的“动态性”指的是当前一些非常“热”门的名词：代码热替换、模块热部署等，说白了就是希望应用程序能像我们的电脑外设那样，插上鼠标或U盘，不用重启机器就能立即使用，鼠标有问题或要升级就换个鼠标，不用停机也不用重启。

- 什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？

  > [https://www.nowcoder.com/questionTerminal/a90230b35b5f4a7287f779ecdd88841d](<https://www.nowcoder.com/questionTerminal/a90230b35b5f4a7287f779ecdd88841d>)

  java的跨平台不是java源程序的跨平台 ，如果是这样，那么所有语言都是跨平台的， java源程序先经过javac编译器编译成二进制的.class字节码文件（java的跨平台指的就是.class字节码文件的跨平台，.class字节码文件是与平台无关的），.class文件再运行在jvm上，java解释器（jvm的一部分）会将其解释成对应平台的机器码执行，所以java所谓的跨平台就是在不同平台上安装了不同的jvm，而在不同平台上生成的.class文件都是一样的，而.class文件再由对应平台的jvm解释成对应平台的机器码执行。 

  最后解释下机器码和字节码的区别: 

  一，机器码，完全依附硬件而存在～并且不同硬件由于内嵌指令集不同，即使相同的0 1代码 意思也可能是不同的～换句话说，根本不存在跨平台性～比如～不同型号的CPU,你给他个指令10001101，他们可能会解析为不同的结果～ 

  二，我们知道JAVA是跨平台的，为什么呢？因为他有一个jvm,不论哪种硬件，只要你装有jvm,那么他就认识这个JAVA字节码～～～～至于底层的机器码，咱不用管，有jvm搞定，他会把字节码再翻译成所在机器认识的机器码～～～

- JVM最大内存限制多少？

  > [https://blog.csdn.net/lengyuhong/article/details/6044894](<https://blog.csdn.net/lengyuhong/article/details/6044894>)

  没想到第一个实验的程序，跑了几个小时，就遇到了Out of Memory Exception了。看看自己的虚拟机设置，我设置的是-Xms512M -Xmx1024M。想都没想，直接改成-Xms512M -Xmx2048M，结果直接就Could not reserve enough space for object heap。程序都起不来了。这才发现原来最大内存还有限制。上网搜了一下，发现很多讨论这个问题的文章。最终在BEA的DEV2DEV论坛发现了最有用的一篇

  这里的版主YuLimin 做了[测试](http://softtest.chinaitlab.com/)，得出结论：

  　　公司 JVM版本                  最大内存(兆)client    最大内存(兆)server

  　　SUN 1.5.x                          1492                            1520

  　　SUN 1.5.5(Linux)             2634                            2660

  　　SUN 1.4.2                          1564                            1564

  　　SUN 1.4.2(Linux)             1900                            1260

  　　IBM 1.4.2(Linux)             2047                             N/A

  　　BEA JRockit 1.5 (U3)      1909                             1902

  >[https://www.nowcoder.com/questionTerminal/855006adab6b45afb9fe98e3c72b90d6](<https://www.nowcoder.com/questionTerminal/855006adab6b45afb9fe98e3c72b90d6>)

  首先JVM内存限制于实际的最大物理内存了 假设物理内存无限大的话 JVM内存的最大值跟操作系统有很大的关系 简单的说就32位处理器虽然可控内存空间有4GB,但是具体的操作系统会给一个限制，这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G Linux系统 下为2G-3G） 而64bit以上的处理器就不会有限制了

- JVM是如何实现线程的？

  > 《深入理解JVM》P333 Java与线程
  
  > [https://blog.csdn.net/qq_33938256/article/details/52615257](<https://blog.csdn.net/qq_33938256/article/details/52615257>)

  并发不一定要依赖多线程（如PHP中很常见的多进程并发），但是在Java里面谈论并发，大多数都与线程脱不开关系。

  - 线程的实现

    线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的**资源分配**和**执行调度**分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度（线程是CPU调度的最基本单位）。

    主流的操作系统都提供了线程实现，Java语言则提供了在不同硬件和操作系统平台下对线程操作的同一处理，每个java.lang.Thread类的实例就代表了一个线程。**Thread类的关键方法，都声明为Native**。这意味着这个方法无法或没有使用平台无关的手段来实现，也可能是为了执行效率。

    实现线程主要有三种方式：使用内核线程实现，使用用户线程实现，使用用户线程加轻量级进程混合实现。

    1. **使用内核线程实现**

       内核线程就是直接由操作系统内核支持的线程。

       - **由内核来完成线程切换**
       - 内核通过调度器Scheduler调度线程，并将线程的任务映射到各个CPU上
       - 程序使用**内核线程的高级接口**，**轻量级进程**(Light Weight Process,LWP)–>(!!!名字是进程，实际是线程)
       - **用户态和内核态切换消耗内核资源**
       - 轻量级进程与内核线程之间的1:1关系称为**一对一线程模型**

    2. **使用用户线程实现**

       - **系统内核不能感知线程存在的实现**
       - **用户线程的建立、同步、销毁和调度完全在用户态中完成**
       - 所有线程操作需要用户程序自己处理，复杂度高
       - 这种进程与线程之间1:N的关系称为**一对多的线程模型**

    3. **混合实现**

       - 轻量级进程作为用户线程和内核线程之间的桥梁
       - 混合模式中，用户线程与轻量级进程的数量比是不定的，是M:N的关系，称为**多对多关系**

    4. Java线程的实现

       对于Sun JDK来说，它的Windows版与Linux版都是使用一对一的线程模型来实现的，一条Java线程就映射到一条轻量级进程之中，因为Windows和Linux系统系统提供的线程模型就是一对一的。

  - Java线程调度

    线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同式线程调度和抢占式线程调度。

    - 协同式调度：线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上去。

      优点：实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。

      缺点：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。

    - 抢占式调度：每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定。

      在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。

    虽然说Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配一点执行时间，另外的一些线程则可以少分配一点——这项操作可以通过设置线程优先级来完成。Java语言一共设置了10个级别的线程优先级。

    不过，线程优先级并不是太靠谱，原因是Java的线程是被映射到系统原生线程上来实现的，所以线程调度最终还是有操作系统说了算，虽然现在很多操作系统都提供线程优先级的概念，但是并不见得能与Java线程的优先级一一对应。Windows只有7中优先级，比Java线程优先级少，不得不出现几个优先级相同的情况。还有其他情况让我们不能太依赖优先级：优先级可能会被系统自行改变。例如在Windows系统中存在一个名为“优先级推进器”的功能，它的大致作用就是当系统发现一个线程被执行得特别“勤奋努力”的话，可能会越过线程优先级去为它分配执行时间。

  > 王道操作系统 P34

  - 线程的实现方式

    线程的实现可以分为两类，**用户级线程**和**内核级线程**。

    **在用户级线程中，有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。**通常，应用程序从单线程起始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。

    **在内核级线程中，线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。**内核为进程及其内部的每个线程维护上下文信息，调度也是在内核基于线程架构的基础上完成。

    在一些系统中，使用**组合方式**的多线程实现。线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行，一个应用程序中的多个用户级线程被映射到一些内核级线程上。

  - 多线程模型

    有的系统同时支持用户线程和内核线程，由此产生了不同的多线程模型。

    1. **多对一模型**。**将多个用户级线程映射到一个内核级线程**，线程管理在用户空间完成。

       优点：线程管理是在用户空间进行的，因此效率比较高。

       缺点：当一个线程在使用内核服务被阻塞，那么整个进程都会被阻塞；多个线程不能并行地运行在多处理器上。

    2. **一对一模型**。将每个用户及线程映射到一个内核级线程。

       优点：当一个线程被阻塞后允许另一个线程继续执行，所以并发能力较强。

       缺点：每创建一个用户及线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。

    3. **多对多模型**。将$n$个用户及线程映射到$m$个内核级线程上，要求$m\le n$。

- 什么是Java内存模型？

  > 《深入理解JVM》P318

  Java虚拟机规范中试图定义一种Java内存模型(JMM)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现**让Java程序在各种平台下都能达到一致的并发效果。**

  Java内存模型规定了所有的变量都存储在主内存中。每个线程还有自己的工作内存，线程的工作内存中给保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读取主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。

  > [https://blog.csdn.net/suifeng3051/article/details/52611310](<https://blog.csdn.net/suifeng3051/article/details/52611310>)

  Java内存模型(简称JMM)。**JMM决定一个线程对共享变量的写入何时对另一个线程可见**。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：**线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本**。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。

  ![这里写图片描述](https://img-blog.csdn.net/20160921182337904)

  从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤：

  1. 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。
  2. 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。 

  下面通过示意图来说明这两个步骤：

  ![这里写图片描述](https://img-blog.csdn.net/20160921182748551)

  如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。

  从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。

- JVM运行时数据区域

  > [https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F?id=%e5%86%99%e5%9c%a8%e5%89%8d%e9%9d%a2-%e5%b8%b8%e8%a7%81%e9%9d%a2%e8%af%95%e9%a2%98](<https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F?id=%e5%86%99%e5%9c%a8%e5%89%8d%e9%9d%a2-%e5%b8%b8%e8%a7%81%e9%9d%a2%e8%af%95%e9%a2%98>)

  **线程私有的：**

  - 程序计数器
  - 虚拟机栈
  - 本地方法栈

  **线程共享的：**

  - 堆
  - 方法区
  - 直接内存 (非运行时数据区的一部分)

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F.png)

  > 《深入理解JVM》P25 运行时数据区域

  Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。

  - 程序计数器

    程序计数器是一块较小的内存空间，它的作用可以看作是当前线程所执行的字节码的行号指示器。**字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。**

    另外，**为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。**

    **注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。**

  - Java虚拟机栈

    **与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。**

    **Java 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。** （实际上，Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。）

    **局部变量表主要存放了编译器可知的各种数据类型**（boolean、byte、char、short、int、float、long、double）、**对象引用**（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。

    **Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。**

    - **StackOverFlowError：** 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。
    - **OutOfMemoryError：** 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 错误。

    Java 虚拟机栈也是线程私有的，每个线程都有各自的 Java 虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。

  - 本地方法栈

    和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。** 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

    本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。

    方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。

    > [https://blog.csdn.net/wike163/article/details/6635321](https://blog.csdn.net/wike163/article/details/6635321)

    > 一个Native Method是这样一个java的方法：该方法的实现由非java语言实现，比如C。

  - Java堆

    Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都是在这里分配内存。

    Java堆是垃圾收集器管理的主要区域，因此很多时候也被称作“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老生代，再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。

    根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。

  - 方法区

    方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 **Java 虚拟机规范把方法区描述为堆的一个逻辑部分**，但是它却有一个别名叫做 **Non-Heap（非堆）**，目的应该是与 Java 堆区分开来。

    《Java 虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 **方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。** 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法。

    根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。

  - 运行时常量池

    运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项时常量池信息，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。

    既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。

  - 直接内存

    **直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。**

    JDK1.4 中新加入的 **NIO(New Input/Output) 类**，引入了一种基于**通道（Channel）** 与**缓存区（Buffer）** 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为**避免了在 Java 堆和 Native 堆之间来回复制数据**。

    本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。
  
  - jdk1.8：**用元数据区替代永久代，实现方法区，并把字符串常量池和类静态变量迁移到堆中存放。**

    ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3Java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9FJDK1.8.png)

    元数据区直接存放在本地内存中，不在java虚拟机中，因此加载多少类的内存限制由系统实际的可用空间控制。

    为什么要用元数据区（metadata）代替永久代

    1、字符串存放在永久代，容易出现性能和内存溢出的问题

    2、类信息比较难确定其大小，永久代空间分配困难
    
    3、永久代为垃圾回收带来了不必要的复杂度，并且回收效率低

    > **整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。**

- 在JAVA虚拟机中，哪些对象可作为ROOT对象？

  > 《深入理解JVM》P46 根搜索算法
  >
  > [https://www.nowcoder.com/questionTerminal/b898ead0055e47fd8ae2ea896bfdd0c1](<https://www.nowcoder.com/questionTerminal/b898ead0055e47fd8ae2ea896bfdd0c1>)

  在主流的商用程序语言中，都是使用**根搜索算法**判断对象是否存活。这个算法的基本思路就是通过一系列的名为"GC Roots"的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（用图论的话来说就是从GC Roots到这个对象不可达）时，则证明此对象时不可用的。

  在Java语言中，可作为GC Roots的对象包括下面几种：

  1. **虚拟机栈**（栈帧中的本地变量表）中引用的对象
  2. **方法区中的类静态变量**引用的对象
  3. **方法区中的常量**引用的对象
  4. **本地方法栈中JNI**（即一般说的Native方法）的引用的变量

- GC中如何判断对象是否需要被回收？

  > 《深入理解JVM》P44 对象已死？
  >
  > [https://blog.csdn.net/u010126792/article/details/82855265](<https://blog.csdn.net/u010126792/article/details/82855265>) 判断一个对象是否可用（存活，可回收），GC回收对象的过程方式，finilized函数了解吗，调用了finilized函数的对象一定会被回收吗，可以主动调用finilized函数吗？

  - 判断对象是否需要被回收

    - 引用计数算法

      给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时候计数器都为0的对象就是不可能再被使用的。

      **Java语言中没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间的相互循环引用的问题。但是它们的引用计数可能都不为0，计数引用算法无法通知GC收集器回收它们。**

    - 根搜索算法

      在主流的商用程序语言中，都是使用**根搜索算法**判断对象是否存活。这个算法的基本思路就是通过一系列的名为"GC Roots"的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（用凸轮的话来说就是从GC Roots到这个对象不可达）时，则证明此对象时不可用的。

      在Java语言中，可作为GC Roots的对象包括下面几种：

      1. **虚拟机栈**（栈帧中的本地变量表）中引用的对象
      2. **方法区中的类静态变量**引用的对象
      3. **方法区中的常量**引用的对象
      4. **本地方法栈中JNI**（即一般说的Native方法）的引用的变量

  - Java的四种引用类型

    上面的分析可知，无论是通过引用计数还是可达性分析的判断都用到了引用，那么引用是否可以被回收就至关重要了，如果一个引用要么可以被回收，要么就不能被回收，那对于一些“可回收”的对象就无能无力了，jdk1.2之后扩充了引用的概念，将引用分为强引用（Strong Reference），软引用（Soft Reference），弱引用（Weak Reference），虚引用（Phantom Reference），四种引用引用的强度依次逐渐减弱。

    **强引用**：程序中的普通对象赋值就是强引用，只要引用还在垃圾回收器就永远不会回收被引用的对象。

    **软引用**：描述还有用但并非必须的对象，在系统将要发生内存溢出异常之前，将会把这些对象放入回收范围内进行二次回收，如果还没有足够内存，才抛出异常。

    **弱引用**：也是用来描述非必须对象，强度更弱，弱引用关联的对象只能生存到下一次垃圾收集发生之前，无论内存是否足够都会被回收掉。

    **虚引用**：一个对象是否有虚引用的存在，不会对其生存时间产生任何影响，也无法通过虚引用获取对象实例，虚引用的唯一一个目的就是能在对象被回收时收到一个系统通知。

  - finalize()方法

    在根搜索算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行根搜索后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。

    如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程区执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，**如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）复制给某个类变量或对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合**；如果对象这时候还没有逃脱，那它就真的离死不远了。

    并不鼓励使用finalize()方法来拯救对象，因为它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。finalize()能做的所有工作，使用try-finally或其他方式都可以做得更好。

- Eden区和Survivor区的含义以及工作原理？

  目前主流的虚拟机实现都采用了分代收集的思想，把整个堆区划分为新生代和老年代；新生代又被划分成Eden 空间、 From Survivor 和 To Survivor 三块区域。

  我们把Eden : From Survivor : To Survivor 空间大小设成 8 : 1 : 1 ，对象总是在 Eden 区出生， From Survivor 保存当前的幸存对象， To Survivor 为空。一次 gc 发生后： 1）Eden 区活着的对象 ＋ From Survivor 存储的对象被复制到 To Survivor ；2) 清空 Eden 和 From Survivor ； 3) 颠倒 From Survivor 和 To Survivor 的逻辑关系： From 变 To ， To 变 From 。可以看出，只有在 Eden 空间快满的时候才会触发 Minor GC 。而 Eden 空间占新生代的绝大部分，所以 Minor GC 的频率得以降低。当然，使用两个 Survivor 这种方式我们也付出了一定的代价，如 10% 的空间浪费、复制对象的开销等。

  > 《深入理解JVM》P51 垃圾收集算法

  - 标记-清除算法

    算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。

    它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量布莱纳许的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。

  - 复制算法

    为了解决效率问题，一种称为“复制”的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这块用完了，就将还活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样是的每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价时将内存缩小为原来的一半，未免太高了一点。

    现在的商业虚拟机都采用这种收集算法来回收新生代，新生代中的对象98%是朝生夕死的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地拷贝到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor的空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%(80%+10%)，只有10%的内存是会被“浪费”的。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够时，需要依赖其他内存（这里指老年代）进行分配担保。

  - 标记-整理算法

    根据老年代的特点，有人提出了另外一种“标记-整理”算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象对象进行清理，而是所有存活的对象都向一端移动，然后直接清理掉段边界以外的内存。

  - 分代收集算法

    当前商业虚拟机的垃圾收集都采用“分代收集”算法，这种算法并没有什么新的思想，只是根据对象的存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少了存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。

- JVM的回收算法以及它的回收器是什么？CMS采用哪种回收算法？使用CMS怎样解决内存碎片的问题呢？

  > 《深入理解JVM》P55 垃圾收集器
  >
  > [https://crowhawk.github.io/2017/08/15/jvm_3/](<https://crowhawk.github.io/2017/08/15/jvm_3/>)

  **如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。**Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。接下来讨论的收集器基于JDK1.7 Update 14 之后的HotSpot虚拟机（在此版本中正式提供了商用的G1收集器，之前G1仍处于实验状态），该虚拟机包含的所有收集器如下图所示：

  ![img](https://pic.yupoo.com/crowhawk/56a02e55/3b3c42d2.jpg)

  上图展示了7种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。Hotspot实现了如此多的收集器，正是因为目前并无完美的收集器出现，只是选择对具体应用最适合的收集器。

  - 相关概念

    - 并行和并发

      - **并行（Parallel）**：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。
      - **并发（Concurrent）**：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行。而垃圾收集程序运行在另一个CPU上。

    - 吞吐量（Throughput）

      吞吐量就是**CPU用于运行用户代码的时间**与**CPU总消耗时间**的比值，即

      **吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）。**

      假设虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。

    - Minor GC 和 Full GC
      - **新生代GC（Minor GC）**：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。具体原理见上一篇文章。
      - **老年代GC（Major GC / Full GC）**：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。

  - 新生代收集器

    - Serial收集器

      **Serial（串行）**收集器是最基本、发展历史最悠久的收集器，它是采用**复制算法**的**新生代收集器**，曾经（JDK 1.3.1之前）是虚拟机**新生代**收集的唯一选择。它是一个单线程收集器，只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是**它在进行垃圾收集时，必须暂停其他所有的工作线程，直至Serial收集器收集结束为止（“Stop The World”）**。这项工作是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说是难以接收的。

      下图展示了Serial 收集器（老年代采用Serial Old收集器）的运行过程：

      ![img](https://pic.yupoo.com/crowhawk/6b90388c/6c281cf0.png)

      为了消除或减少工作线程因内存回收而导致的停顿，HotSpot虚拟机开发团队在JDK 1.3之后的Java发展历程中研发出了各种其他的优秀收集器，这些将在稍后介绍。但是这些收集器的诞生并不意味着Serial收集器已经“老而无用”，实际上到现在为止，它依然是**HotSpot虚拟机运行在Client模式下的默认的新生代收集器**。它也有着优于其他收集器的地方：**简单而高效（与其他收集器的单线程相比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得更高的单线程收集效率。**

      在用户的桌面应用场景中，分配给虚拟机管理的内存一般不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本不会再大了），停顿时间完全可以控制在几十毫秒最多一百毫秒以内，只要不频繁发生，这点停顿时间可以接收。所以，Serial收集器对于运行在Client模式下的虚拟机来说是一个很好的选择。

    - ParNew 收集器

      **ParNew**收集器就是Serial收集器的多线程版本，它也是一个**新生代收集器**。除了使用多线程进行垃圾收集外，其余行为包括Serial收集器可用的所有控制参数、收集算法（复制算法）、Stop The World、对象分配规则、回收策略等与Serial收集器完全相同，两者共用了相当多的代码。

      ParNew收集器的工作过程如下图（老年代采用Serial Old收集器）：

      ![img](https://pic.yupoo.com/crowhawk/605f57b5/75122b84.png)

      ParNew收集器除了使用多线程收集外，其他与Serial收集器相比并无太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关的重要原因是，**除了Serial收集器外，目前只有它能和CMS收集器（Concurrent Mark Sweep）配合工作**，CMS收集器是JDK 1.5推出的一个具有划时代意义的收集器，具体内容将在稍后进行介绍。

      ParNew 收集器在**单CPU的环境**中绝对不会有比Serial收集器有更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越。在**多CPU环境**下，随着CPU的数量增加，它对于GC时系统资源的有效利用是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多的情况下可使用**-XX:ParallerGCThreads**参数设置。

    - Parallel Scavenge 收集器

      **Parallel Scavenge**收集器也是一个**并行**的**多线程新生代**收集器，它也使用**复制算法**。Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是**达到一个可控制的吞吐量（Throughput）**。

      **停顿时间越短就越适合需要与用户交互的程序**，良好的响应速度能提升用户体验。而**高吞吐量**则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合**在后台运算而不需要太多交互的任务**。

      Parallel Scavenge收集器除了会显而易见地提供可以精确控制吞吐量的参数，还提供了一个参数**-XX:+UseAdaptiveSizePolicy**，这是一个开关参数，打开参数后，就不需要手工指定新生代的大小（-Xmn）、Eden和Survivor区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为**GC自适应的调节策略（GC Ergonomics）**。自适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。

      另外值得注意的一点是，Parallel Scavenge收集器无法与CMS收集器配合使用，所以在JDK 1.6推出Parallel Old之前，如果新生代选择Parallel Scavenge收集器，老年代只有Serial Old收集器能与之配合使用。

  - 老年代收集器

    - Serial Old收集器

      Serial Old 是 Serial收集器的老年代版本，它同样是一个**单线程收集器**，使用**“标记-整理”（Mark-Compact）**算法。

      此收集器的主要意义也是在于给Client模式下的虚拟机使用。如果在Server模式下，它还有两大用途：

      - 在JDK1.5 以及之前版本（Parallel Old诞生以前）中与Parallel Scavenge收集器搭配使用。
      - 作为CMS收集器的后备预案，在并发收集发生**Concurrent Mode Failure**时使用。

      它的工作流程与Serial收集器相同，这里再次给出Serial/Serial Old配合使用的工作流程图：

      ![img](https://pic.yupoo.com/crowhawk/6b90388c/6c281cf0.png)

    - Parallel Old收集器

      Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用**多线程**和**“标记-整理”**算法。前面已经提到过，这个收集器是在JDK 1.6中才开始提供的，在此之前，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old以外别无选择，所以在Parallel Old诞生以后，**“吞吐量优先”收集器**终于有了比较名副其实的应用组合，在**注重吞吐量**以及**CPU资源敏感**的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。Parallel Old收集器的工作流程与Parallel Scavenge相同，这里给出Parallel Scavenge/Parallel Old收集器配合使用的流程图：

      ![img](https://pic.yupoo.com/crowhawk/9a6b1249/b1800d45.png)

    - CMS收集器

      **CMS（Concurrent Mark Sweep）**收集器是一种以**获取最短回收停顿时间**为目标的收集器，它非常符合那些集中在互联网站或者B/S系统的服务端上的Java应用，这些应用都非常重视服务的响应速度。从名字上（“Mark Sweep”）就可以看出它是基于**“标记-清除”**算法实现的。

      CMS收集器工作的整个流程分为以下4个步骤：

      - **初始标记（CMS initial mark）**：仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。
      - **并发标记（CMS concurrent mark）**：进行**GC Roots Tracing**的过程，在整个过程中耗时最长。
      - **重新标记（CMS remark）**：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要“Stop The World”。
      - **并发清除（CMS concurrent sweep）**

      由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。通过下图可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间：

      ![img](https://pic.yupoo.com/crowhawk/fffcf9a2/f60599b2.png)

      **优点**

      CMS是一款优秀的收集器，它的主要**优点**在名字上已经体现出来了：**并发收集**、**低停顿**，因此CMS收集器也被称为**并发低停顿收集器（Concurrent Low Pause Collector）**。

      **缺点**

      - **对CPU资源非常敏感** 其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。**CMS默认启动的回收线程数是（CPU数量+3）/4**，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是**当CPU不足4个时（比如2个），CMS对用户程序的影响就可能变得很大**，如果本来CPU负载就比较大，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。
      - **无法处理浮动垃圾（Floating Garbage）** 可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。**由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。**这一部分垃圾出现在标记过程之后，CMS无法再当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就被称为**“浮动垃圾”**。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。
      - **标记-清除算法导致的空间碎片** CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次Full GC。为了解决这个问题，CMS收集器提供了一个-XX:+UseCMSCompactAtFullCollection开关参数，用于在“享受”完Full GC服务之后额外免费附送一个碎片整理过程，内存整理的过程是无法并发的。空间碎片问题没有了，但停顿时间不得不变长了。虚拟机设计者还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction，这个参数用于设置在执行多少次不压缩的Full GC后，跟着来一次带压缩的。

    - G1收集器

      **G1（Garbage-First）**收集器是当今收集器技术发展最前沿的成果之一，它是一款**面向服务端应用**的垃圾收集器，HotSpot开发团队赋予它的使命是（在比较长期的）未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点：

      - **并行与并发** G1 能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。
      - **分代收集** 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。
      - **空间整合** G1从整体来看是基于**“标记-整理”**算法实现的收集器，从局部（两个Region之间）上来看是基于**“复制”**算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。
      - **可预测的停顿** 这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。

      **横跨整个堆内存**

      在G1之前的其他收集器进行收集的范围都是整个新生代或者老生代，而G1不再是这样。G1在使用时，Java堆的内存布局与其他收集器有很大区别，它**将整个Java堆划分为多个大小相等的独立区域（Region）**，虽然还保留新生代和老年代的概念，但**新生代和老年代不再是物理隔离的了，而都是一部分Region（不需要连续）的集合**。

      **建立可预测的时间模型**

      G1收集器之所以能建立可预测的停顿时间模型，是因为它可以**有计划地避免在整个Java堆中进行全区域的垃圾收集**。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），**在后台维护一个优先列表**，每次根据允许的收集时间，**优先回收价值最大的Region（这也就是Garbage-First名称的来由）**。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。

      **避免全堆扫描——Remembered Set**

      G1把Java堆分为多个Region，就是“化整为零”。但是Region不可能是孤立的，一个对象分配在某个Region中，可以与整个Java堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个Java堆才能保证准确性，这显然是对GC效率的极大伤害。

      为了避免全堆扫描的发生，虚拟机**为G1中每个Region维护了一个与之对应的Remembered Set**。虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable**把相关引用信息记录到被引用对象所属的Region的Remembered Set之中**。当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。

      ------

      如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤：

      - **初始标记（Initial Marking）** 仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改**TAMS（Nest Top Mark Start）**的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要**停顿线程**，但耗时很短。
      - **并发标记（Concurrent Marking）** 从GC Root 开始对堆中对象进行**可达性分析**，找到存活对象，此阶段耗时较长，但**可与用户程序并发执行**。
      - **最终标记（Final Marking）** 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在**线程的Remembered Set Logs**里面，最终标记阶段需要**把Remembered Set Logs的数据合并到Remembered Set中**，这阶段需要**停顿线程**，但是**可并行执行**。
      - **筛选回收（Live Data Counting and Evacuation）** 首先对各个Region中的回收价值和成本进行排序，根据用户所期望的GC 停顿是时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。

      通过下图可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段（Safepoint处）：

      ![img](https://pic.yupoo.com/crowhawk/53b7a589/0bce1667.png)

  - 总结

    **新生代的收集器有Serial、ParNew、Parallel Scavenge。Serial收集器是串行、单线程的收集器，在收集垃圾时需要暂停其他所有的工作，stop the world，使用复制算法。ParNew收集器是Serial的并行、多线程版本，可以配合CMS使用。Parallel Scavenge收集器目标是达到高吞吐量，可以配合Parallel Old使用。**

    **老年代的收集器有Serail Old、Parallel Old、CMS、G1算法。Serial Old收集器是Serial收集器的老年代版本，使用标记-整理算法。Parallel Old收集器是Parallel Scavenge的老年代版本，使用多线程和标记-整理算法。**
    
    **CMS收集器的目标是低停顿、高响应速度，基于标记-清除算法，步骤分为初始标记（标记GC Roots能关联到的对象，速度很快，需要stop the world）、并发标记（GC Root Tracing，耗时最长）、重新标记（修复并发标记期间改动的标记，需要stop the world）、并发清除。**

    **G1收集器使命是在未来替代CMS。G1将整个Java堆划分为多个大小相等的独立区域（Region），每个Region维护了一个与之对应的Remembered Set，把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。从整体来看基于标记-整理算法，从局部（两个Region之间）来看基于复制算法。步骤分为：初始标记、并发标记、最终标记（将变动合并到Remember Set中）、筛选回收（回收一部分Region）。**

    | 收集器                | 串行、并行or并发 | 新生代/老年代 | 算法               | 目标             | 适用场景                                  |
    | --------------------- | ---------------- | ------------- | ------------------ | ---------------- | ----------------------------------------- |
    | **Serial**            | **串行**         | 新生代        | 复制算法           | 响应速度优先     | 单CPU环境下的Client模式                   |
    | **ParNew**            | **并行**         | 新生代        | 复制算法           | 响应速度优先     | 多CPU环境时在Server模式下**与CMS配合**    |
    | **Parallel Scavenge** | 并行             | 新生代        | 复制算法           | **吞吐量优先**   | 在后台运算而不需要太多交互的任务          |
    | **Serial Old**        | 串行             | 老年代        | 标记-整理          | 响应速度优先     | 单CPU环境下的Client模式、CMS的后备预案    |
    | **Parallel Old**      | 并行             | 老年代        | 标记-整理          | 吞吐量优先       | 在后台运算而不需要太多交互的任务          |
    | **CMS**               | **并发**         | 老年代        | **标记-清除**      | **响应速度优先** | 集中在互联网站或B/S系统服务端上的Java应用 |
    | **G1**                | 并发             | both          | 标记-整理+复制算法 | 响应速度优先     | 面向服务端应用，将来替换CMS               |

- 假设一个场景，要求stop the world时间非常短，你会怎么设计垃圾回收机制？

  ParNew + CMS

- 垃圾回收器的基本原理是什么？垃圾回收器可以马上回收内存吗？并且有什么办法可以主动通知虚拟机进行垃圾回收呢？

  对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。通常，GC采用有向图的方式记录和管理堆(heap)中的所有对象。通过这种方式确定哪些对象是”可达的”，哪些对象是”不可达的”。当GC确定一些对象为”不可达”时，GC就有责任回收这些内存空间。可以。程序员可以手动执行System.gc()，通知GC运行，但是Java语言规范并不保证GC一定会执行。

- 在java中会存在内存泄漏吗？

  > [https://blog.csdn.net/m0_37204491/article/details/64500151](<https://blog.csdn.net/m0_37204491/article/details/64500151>)

  **内存泄露**就是指一个不再被程序使用的对象或变量一直被占据在内存中。java中有垃圾回收机制，它可以保证一对象不再被引用的时候，即对象变成了孤儿的时候，对象将自动被垃圾回收器从内存中清除掉。由于Java 使用有向图的方式进行垃圾回收管理，可以消除引用循环的问题，例如有两个对象，相互引用，只要它们和根进程不可达的，那么GC也是可以回收它们的。

  **java中的内存泄露的情况**：

  1. 长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄露的发生场景，通俗地说，就是**程序员可能创建了一个对象，以后一直不再使用这个对象，这个对象却一直被引用，即这个对象无用但是却无法被垃圾回收器回收的**，这就是java中可能出现内存泄露的情况，例如，缓存系统，我们加载了一个对象放在缓存中(例如放在一个全局map对象中)，然后一直不再使用它，这个对象一直被缓存引用，但却不再被使用。

     检查java中的内存泄露，一定要让程序将各种分支情况都完整执行到程序结束，然后看某个对象是否被使用过，如果没有，则才能判定这个对象属于内存泄露。

  2. 如果一个外部类的实例对象的方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持久外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄露。

  3. 当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄露。

- 垃圾回收的优点以及原理

  Java 语言中一个显著的特点就是引入了垃圾回收机制，使c++程序员最头疼的内存管理的问题迎刃而解，它使得Java程序员在编写程序的时候不再需要考虑内存管理。由于有个垃圾回收机制，Java中的对象不再有"作用域"的概念，只有对象的引用才有"作用域"。垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低级别的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清楚和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。回收机制有分代复制垃圾回收和标记垃圾回收，增量垃圾回收。

- 什么时候触发MinorGC?什么时候触发FullGC?

  > [https://www.cnblogs.com/williamjie/p/9516367.html](https://www.cnblogs.com/williamjie/p/9516367.html)

  **触发MinorGC(Young GC)**

  虚拟机在进行minorGC之前会判断老年代最大的可用连续空间是否大于新生代的所有对象总空间

  1、如果大于的话，直接执行minorGC

  2、如果小于，判断是否开启HandlerPromotionFailure，没有开启直接FullGC

  3、如果开启了HanlerPromotionFailure, JVM会判断老年代的最大连续内存空间是否大于历次晋升的大小，如果小于直接执行FullGC

  4、如果大于的话，执行minorGC

  **触发FullGC**

  - 老年代空间不足

    如果创建一个大对象，Eden区域当中放不下这个大对象，会直接保存在老年代当中，如果老年代空间也不足，就会触发Full GC。为了避免这种情况，最好就是不要创建太大的对象。

  - 持久代空间不足

    如果有持久代空间的话，系统当中需要加载的类，调用的方法很多，同时持久代当中没有足够的空间，就出触发一次Full GC
  
  - YGC出现promotion failure
  
    promotion failure发生在Young GC, 如果Survivor区当中存活对象的年龄达到了设定值，会就将Survivor区当中的对象拷贝到老年代，如果老年代的空间不足，就会发生promotion failure， 接下去就会发生Full GC.
  
  - 统计YGC发生时晋升到老年代的平均总大小大于老年代的空闲空间
  
    在发生YGC是会判断，是否安全，这里的安全指的是，当前老年代空间可以容纳YGC晋升的对象的平均大小，如果不安全，就不会执行YGC,转而执行Full GC。
  
  - 显示调用System.gc

- 什么原因会导致minor gc运行频繁？同样的，什么原因又会导致minor gc运行很慢？

  > [https://www.nowcoder.com/questionTerminal/b3cd86f89d6c4b1ab54252b49a6bff57](<https://www.nowcoder.com/questionTerminal/b3cd86f89d6c4b1ab54252b49a6bff57>)

  什么原因会导致minor gc运行频繁？

  1. **产生了太多朝生夕灭的对象导致需要频繁minor gc**

  2. **新生代空间设置的比较小**

  什么原因会导致minor gc运行很慢？

  1. **新生代空间设置过大。**

  2. **对象引用链较长，进行可达性分析时间较长。**

  3. 新生代survivor区设置的比较小，清理后剩余的对象不能装进去需要移动到老年代，造成移动开销。

  4. 内存分配担保失败，由minor gc转化为full gc

  5. **采用的垃圾收集器效率较低，比如新生代使用serial收集器**

  > 《深入理解JVM》P65 内存分配与回收策略

  - **对象优先在Eden分配**

    大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够的空间进行分配时，虚拟机将发起一次Minor GC。

  - **大对象直接进入老年代**

    大对象对虚拟机的内存分配来说是个坏消息，经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。

  - **长期存活的对象将进入老年代**

    虚拟机既然采用了分代收集的思想来管理内存，那内存回收时就必须能识别哪些对象应该放在新生代，哪些对象应该放在老年代。为了做到这点，虚拟机给每个对象定义了一个对象年龄计数器。如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor区中每熬过一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁）时，就会被晋升到老年代中。对象今生老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold来设置。

  - **动态对象年龄判定**

    为了能更好地适应不同程序的内存状况，虚拟机并不总是要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代，**如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代**，无需等到MaxTenuringThreshold中要求的年龄。

  - **空间分配担保**

    在发生Minor GC时，虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小，如果大于，则改为直接进行一次Full GC。如果小于，则查看HandlePromotionFailure设置是否允许担保失败；如果允许，那只会进行Minor GC；如果不允许，则也要改为进行一次Full GC。

    前面提到过，新生代使用复制收集算法，但为了内存利用率，**只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况时（最极端就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，让Survivor无法容纳的对象直接进入老年代。**与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的空间，一共有多少对象会活下来，在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。

    取平均值进行比较其实仍然是一种动态概率的手段，也就是说如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁。

- Minor GC和Full GC触发条件

  Minor GC触发条件：当Eden区满时，触发Minor GC。

  Full GC触发条件：
  - 调用System.gc时，系统建议执行Full GC，但是不必然执行
  - 老年代空间不足
  - 方法区空间不足
  - 通过Minor GC后进入老年代的平均大小大于老年代的可用内存
  - 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小

## Java 8

> [https://snailclimb.gitee.io/javaguide/#/docs/java/What's%20New%20in%20JDK8/Java8Tutorial](https://snailclimb.gitee.io/javaguide/#/docs/java/What's%20New%20in%20JDK8/Java8Tutorial)

- **Lambda 表达式：Lambda允许把函数作为一个方法的参数**

  首先看看在老版本的Java中是如何排列字符串的：

  ```java
  List<String> names = Arrays.asList("peter", "anna", "mike", "xenia");

  Collections.sort(names, new Comparator<String>() {
      @Override
      public int compare(String a, String b) {
          return b.compareTo(a);
      }
  });
  ```

  只需要给静态方法Collections.sort 传入一个 List 对象以及一个比较器来按指定顺序排列。通常做法都是**创建一个匿名的比较器对象**然后将其传递给 sort 方法。

  在Java 8 中你就没必要使用这种传统的匿名对象的方式了，Java 8提供了更简洁的语法，lambda表达式：

  ```java
  Collections.sort(names, (String a, String b) -> {
      return b.compareTo(a);
  });
  ```

  可以看出，代码变得更段且更具有可读性，但是实际上还可以写得更短：

  ```java
  Collections.sort(names, (String a, String b) -> b.compareTo(a));
  ```

  对于函数体只有一行代码的，你可以去掉大括号{}以及return关键字，但是你还可以写得更短点：

  ```java
  names.sort((a, b) -> b.compareTo(a));
  ```

  List 类本身就有一个 sort 方法。并且Java编译器可以自动推导出参数类型，所以你可以不用再写一次类型。

- **方法和构造函数引用**

  ```java
  Converter<String, Integer> converter = Integer::valueOf;
  Integer converted = converter.convert("123");
  System.out.println(converted.getClass());   //class java.lang.Integer
  ```

  Java 8允许您**通过::关键字传递方法或构造函数的引用。** 上面的示例显示了如何引用静态方法。 但我们也可以引用对象方法：

  ```java
  class Something {
      String startsWith(String s) {
          return String.valueOf(s.charAt(0));
      }
  }
  ```

  ```java
  Something something = new Something();
  Converter<String, String> converter = something::startsWith;
  String converted = converter.convert("Java");
  System.out.println(converted);    // "J"
  ```

  接下来看看构造函数是如何使用::关键字来引用的，首先我们定义一个包含多个构造函数的简单类：

  ```java
  class Person {
      String firstName;
      String lastName;

      Person() {}

      Person(String firstName, String lastName) {
          this.firstName = firstName;
          this.lastName = lastName;
      }
  }
  ```

  接下来我们指定一个用来创建Person对象的对象工厂接口：

  ```java
  interface PersonFactory<P extends Person> {
      P create(String firstName, String lastName);
  }
  ```

  这里我们使用构造函数引用来将他们关联起来，而不是手动实现一个完整的工厂：

  ```java
  PersonFactory<Person> personFactory = Person::new;
  Person person = personFactory.create("Peter", "Parker");
  ```

  我们只需要使用 Person::new 来获取Person类构造函数的引用，Java编译器会自动根据PersonFactory.create方法的参数类型来选择合适的构造函数。

## 数据结构

#### 散列

- 选择散列函数

  - Division method

    - $h(k)=k \mod m$

  - Multiplication method

    - $m=2^r$，计算机有$w$位词

    - $h(k)=(A\cdot k\mod 2^w)\rm{rsh}(w-r)$
    - 模块轮 (Modular wheel)：将轮子旋转$k$个$A$，然后舍弃最后几位

- 处理冲突

  - 拉链法  

    填装因子$\alpha=表中记录数（键数）n/散列表长度（槽数）m$

    **不成功**搜索的期望时间$=\Theta(1+\alpha)$

  - 开放定址法：线性探查法、平方探查法、再散列法、伪随机序列法

    假设均匀散列，每个键等可能地将$m!$种排序之一作为其探查序列。

    定理：不成功搜索的期望探查次数 $E[$#$probes]\le1/(1-\alpha)$

#### B树和B+树

> 王道数据结构P243 B树和B+树

- B树

  一棵$m$阶B树或为空树，或为满足如下特征的$m$叉树：

  1. **树中每个结点至多有$m$棵子树**（即至多含有$m-1$个关键字）。

  2. **若根节点不是终端结点，则至少有2棵子树。**

  3. **除根结点外的所有非叶结点至少有$\lceil m/2\rceil$棵子树**（即至少含有$\lceil m/2\rceil-1$个关键字）

  4. 所有的非叶结点的结构：$n,P_0,K_1,P_1,K_2,P_2,...,K_n,P_n$. 其中$K_i$为结点的关键字，且满足$K_1\lt K_2\lt...\lt K_n$; $P_i$所指子树中所有结点的关键字均大于$K_i$, $n$为结点中关键字的个数。

  5. 所有的叶节点都出现再同一层次上，并且不带信息。

  B树的插入：定位（找到最底层的某个非叶结点），插入（分裂上移）

  B树的删除：不在终端结点删除（删除合并），在终端结点删除（兄弟够借，兄弟不够借）

- B+树

  $m$阶B+树与$m$阶B树的主要差异在于：

  1. 在B+树中，具有$n$个关键字的结点只含有$n$棵子树，即每个关键字对应一棵子树；而在B树中，具有$n$个关键字的结点含有$(n+1)$棵子树。

  2. 在B+树中，每个结点（非根内部结点）关键字个数$n$的范围时$\lceil m/2\rceil \le n \le m$（根结点：$1\le n\le m-1$）；在B树中，每个结点（非根内部结点）关键字个数$n$的范围是$\lceil m/2\rceil-1 \le n \le m-1$（根结点：$1\le n\le m-1$）。

  3. 在B+树中，叶结点包含信息，所有非叶节点仅起到索引作用，非叶结点中的每个索引项只含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。

  4. 在B+树中，叶结点包含了全部关键字，即在非叶结点中出现的关键字也会出现在叶结点中；而在B树中，叶结点包含的关键字和其他结点包含的关键字是不重复的。

## 网络

#### 网络概述

- TCP协议、IP协议、HTTP协议分别在哪一层？
  
  运输层，网络层，应用层。

  ![img](https://uploadfiles.nowcoder.com/images/20190814/980266035_1565787665824_1ABB2DC3D76311944FFDBE9980FBAADD)

  > 王道网络P15 ISO/OSI参考模型和TCP/IP模型
  
  OSI参考模型：物理层、数据链路层、网络层、运输层、会话层（会话管理）、表示层（数据格式转换）、应用层

  TCP/IP模型：网络接口层、网际层、传输层、应用层

  学习计算机网络：物理层、数据链路层、网络层、传输层、应用层

  > [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)

  **物理层**

  在物理层上所传送的数据单位是比特。 **物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。** 使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。

  **数据链路层**

  数据链路层(data link layer)通常简称为链路层。**两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。** 在两个相邻节点之间传送数据时，**数据链路层将网络层交下来的 IP 数据报组装成帧**，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。

  在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。 控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。

  **网络层**

  **在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。** 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。

  这里要注意：不要把运输层的“用户数据报 UDP ”和网络层的“ IP 数据报”弄混。另外，无论是哪一层的数据单元，都可笼统地用“分组”来表示。

  这里强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称.

  互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Protocol）和许多路由选择协议，因此互联网的网络层也叫做网际层或IP层。

  **运输层**

  **运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。** 应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。

  运输层主要使用以下两种协议:

  传输控制协议 TCP（Transmission Control Protocol）--提供面向连接的，可靠的数据传输服务。

  用户数据协议 UDP（User Datagram Protocol）--提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。
  
  **应用层**

  **应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。** 应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如**域名系统DNS**，支持万维网应用的 **HTTP协议**，支持电子邮件的 **SMTP协议** 等等。我们把应用层交互的数据单元称为报文。

#### 网络层

- arp协议和arp攻击

  地址解析协议。
  
  > [https://blog.csdn.net/wy_bk/article/details/78823573](https://blog.csdn.net/wy_bk/article/details/78823573)

  **ARP协议**

  ARP协议是一个年代相当“久远”的网络协议。ARP协议制定于1982年11月，英文全称：Address Resolution Protocol，即“地址解析协议”。

  我们知道，虽然终端设备想要上网必须具有公有IP地址，但是在Internet的TCP/IP协议中，IP地址的作用是标识一台主机或路由器与一条链路的接口，也就是说IP地址指明了数据由一个网络传输到另一个网络的路径，但是我们知道，为了节约IP地址，通常情况下，在一个内部网络中，主机常常使用RFC规定的三种私有IP地址作为局域网中主机的IP地址，而且主机的IP地址是由该网络的路由器动态分配的，如果数据的传输仅仅依赖于IP地址，那么当数据到达一个内部网络中时就可能因为目标主机的IP地址发生改变而将数据传输到了错误的目标主机。但是不同设备的物理地址（MAC）是全网唯一的，而且一般也不会被改变（MAC地址是写入网卡的，固定的），因此使用MAC地址作为信息的标识，定位目标网络设备就可以保证信息能够正确抵达目标主机。而通过目标设备的IP地址查找目标设备的MAC地址就是ARP协议的基本功能。

  **ARP协议的工作过程**

  由于内部网络中主机的IP地址往往是动态分配的，因此，在主机中是有ARP缓存的，记录着本网络中IP地址与MAC地址的对应关系。那么，这个ARP缓存是怎么生成的呢？首先，当网络中的主机A需要向主机B发送信息时，会将包含目标IP地址的ARP请求广播到该网络中的所有主机上，网络中的其他主机在收到主机A的ARP请求后可以自主的发送ARP应答报文，应答中包含自己的IP和自己的MAC地址，主机B也会发送这样的应答报文给主机A。这样主机A就知道了主机B的MAC地址与IP地址了。

  ARP协议的工作是建立在网络中各个主机之间相互信任的基础上的，一台主机在收到其他主机的ARP应答报文时并不会采取措施校验该报文的真实性，而是直接就记录到了自己的ARP缓存中以备下次使用。

  **ARP攻击**

  ARP攻击的第一步就是ARP欺骗。由上述“ARP协议的工作过程”我们知道，ARP协议基本没有对网络的安全性做任何思考，当时人们考虑的重点是如何保证网络通信能够正确和快速的完成——ARP协议工作的前提是默认了其所在的网络是一个善良的网络，每台主机在向网络中发送应答信号时都是使用的真实身份。不过后来，人们发现ARP应答中的IP地址和MAC地址中的信息是可以伪造的，并不一定是自己的真实IP地址和MAC地址，由此，ARP欺骗就产生了。

  **ARP欺骗**

  ARP的应答报文是可以伪造的。假设一个网络中有3台主机，分别为A、B和C。当主机A向网络中发送了ARP请求时，用于攻击的主机C可以假装是B，然后向主机A发送一个伪造的ARP应答报文，由于A并不会采取措施验证该报文真伪，而是直接存入自己的ARP缓存并在需要时使用（ARP缓存分两种，一种是静态ARP缓存，该类缓存只要主机不关机就一直存在。另一类是动态ARP缓存，该类缓存是有时效限制的，一般ARP动态缓存的最长生命周期是10分钟，如果一个动态缓存项目在2分钟内没有被使用，则删除，如果在两分钟内被使用了，则增加两分钟的生命周期，直到达到10分钟的最长生命周期后进行更新），由此，C就成功的欺骗了A。那么来自主机B的正确的应答报文去哪了？如果A收到了来自B的正确的应答报文，更新了自己的ARP缓存，那么C的ARP欺骗不就失败了吗？确实会发生这种情况，但是如果C不断的向网络中的各台主机大量发送伪造的ARP应答报文，直到同时欺骗了A和B，C就成功的对主机A和B进行了ARP欺骗。接下来C就可以监听A和B之间的流量，伪造A和B的通信内容或者阻止A和B的通信。

  > 王道网络P149 地址解析协议ARP

  无论网络层使用什么协议，在实际网络的链路上传送数据帧时，最终必须使用硬件地址。所以需要一种方法来完成IP地址到MAC地址的映射，这就是地址解析协议ARP。每个主机都设有一个ARP高速缓存，存放本局域网上各主机和路由器的IP地址到MAC地址的映射表，称ARP表，使用ARP协议来动态维护此ARP表。

  ARP工作在网络层，其工作原理：当主机A欲向本局域网上的某个主机B发送IP数据报时，就先在其ARP高速缓存中查看有无主机B的IP地址。如有，就可查出其对应的硬件地址，再将此硬件地址写入MAC帧，然后通过局域网将该MAC帧发往此硬件地址。如果没有，就通过使用目的MAC地址为FF-FF-FF-FF-FF-FF的帧来封装并广播ARP请求分组，可以使同一个局域网里的所有主机收到ARP请求。当主机B收到该ARP请求后，就会向主机A发出响应ARP分组，分组中包含主机B的IP与MAC地址的映射关系，主机A再收到后将此映射写入ARP缓存中，然后按查询到的硬件地址发送MAC帧。

- 什么是icmp协议，它的作用是什么？

  它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。

  > 王道网络P151 网络控制报文协议ICMP

  为了提高IP数据报交付成功的机会，在网络层使用了网际控制报文协议(ICMP)来允许主机或路由器报告差错和异常情况。ICMP协议是IP层协议。ICMP报文的种类有两种，即ICMP差错报告报文（包括源点抑制）和ICMP询问报文。

- DHCP协议

  > 王道网络P150 动态主机配置协议DHCP

  动态主机配置协议(DHCP)常用于给主机动态地分配IP地址，它提供了即插即用联网的机制，这种机制允许一台计算机加入新的网络和获取IP地址而不用手工参与。DHCP是应用层协议，它是基于UDP的。

- 路由器和交换机的区别

  1、工作层次不同：交换机比路由器更简单，路由器比交换器能获取更多信息

  交换机工作在数据链路层，而路由器工作在网络层

  2、数据转发所依据的对象不同

  交换机的数据转发依据是利用物理地址或者说MAC地址来确定转发数据的目的地址

  而路由器是依据ip地址进行工作的

  3、传统的交换机只能分割冲突域，不能分割广播域；而路由器可以分割广播域

#### 传输层

- 为什么tcp为什么要建立连接？

  保证可靠传输。

- 解释一下TCP为什么可靠一些

  三次握手，超时重传，滑动窗口，拥塞控制。

  > 王道网络P218

  TCP连接管理：三次握手、四次挥手
  
  TCP可靠传输：累计确认、超时和冗余ACK重传
  
  TCP流量控制：接收端控制发送端速率（发送窗口的实际大小是接受窗口和拥塞窗口的最小值）
  
  TCP拥塞控制：慢开始（指数规律增长）、拥塞避免（加法增大）、快恢复（j，乘法减小）

  > [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)
  
  **TCP 协议如何保证可靠传输**

  1. 应用数据被分割成 TCP 认为最适合发送的数据块。
  2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
  3. 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
  4. TCP 的接收端会丢弃重复的数据。
  5. 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
  6. 拥塞控制： 当网络拥塞时，减少数据的发送。
  7. ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
  8. 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

- 哪种应用场景会使用TCP协议，使用它的意义

  当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议

- TCP,UDP 协议的区别

  > [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/tcp-vs-udp.jpg)
  
  UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等

  TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

- TCP的连接和释放过程

  三次握手的过程

  1）主机A向主机B发送TCP连接请求数据包，其中包含主机A的初始序列号seq(A)=x。（其中报文中同步标志位SYN=1，ACK=0，表示这是一个TCP连接请求数据报文；序号seq=x，表明传输数据时的第一个数据字节的序号是x）；

  2）主机B收到请求后，会发回连接确认数据包。（其中确认报文段中，标识位SYN=1，ACK=1，表示这是一个TCP连接响应数据报文，并含主机B的初始序列号seq(B)=y，以及主机B对主机A初始序列号的确认号ack(B)=seq(A)+1=x+1）

  3）第三次，主机A收到主机B的确认报文后，还需作出确认，即发送一个序列号seq(A)=x+1；确认号为ack(A)=y+1的报文；

  四次挥手过程

  假设主机A为客户端，主机B为服务器，其释放TCP连接的过程如下：
  1） 关闭客户端到服务器的连接：首先客户端A发送一个FIN，用来关闭客户到服务器的数据传送，然后等待服务器的确认。其中终止标志位FIN=1，序列号seq=u。
  2） 服务器收到这个FIN，它发回一个ACK，确认号ack为收到的序号加1。
  3） 关闭服务器到客户端的连接：也是发送一个FIN给客户端。

  4） 客户段收到FIN后，并发回一个ACK报文确认，并将确认序号seq设置为收到序号加1。 首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。

  > 王道网络P213 TCP协议

  **TCP连接的建立**

  ![img](https://uploadfiles.nowcoder.com/images/20180927/308572_1538027722640_EBFE71FE6E03CBB1AAE38A25DC56AFB2)

  连接的建立经历以下3个步骤，通常称为“三次握手”。

  第一步：客户机的TCP首先向服务器的TCP发送一个连接请求报文段。这个特殊的报文段重不含应用层数据，起首部中的SYN标志位被置为1。另外，客户机会随机选择一个起始序号seq=x（连接请求报文不携带数据，但要消耗掉一个序号）

  第二步：服务器的TCP收到连接请求报文段后，如同意连接，就像客户机发回确认，并为该TCP连接分配TCP缓存和变量。在确认报文段中，SYN和ACK位都被置为1，确认号字段的值为x+1，并且服务器随机产生其实序号seq=y（确认报文不携带数据，但也要消耗掉一个序号）。确认报文段同样不包含应用层数据。

  第三步：当客户机收到确认报文段后，还要向服务器给出确认，并且也要给该连接分配缓存和变量。这个报文段的ACK标志位被置为1，序号字段为x+1，确认号字段ack=y+1。该报文段可以携带数据，如果不携带数据则不消耗序号。

  **TCP连接的释放**

  ![img](https://uploadfiles.nowcoder.com/images/20180927/308572_1538027843891_F17231DF387BA79A4CCC2E7CDD1C110E)

  TCP连接释放的过程通常称为“四次挥手”。

  第一步：客户机打算关闭连接，就向其TCP发送一个连接释放报文段，并停止再发送数据，主动关闭TCP连接，该报文段的FIN标志位被置为1，seq=u，它等于前面已传送过的数据的最后一个字节的序号加1（FIN报文段即使不携带数据，也要消耗一个序号）。TCP是全双工的，即可以想象成是一条TCP连接上有两条数据通路。当发送FIN报文时，发送FIN的一端就不能再发送数据，也就是关闭了其中一条数据通路，但对方好可以发送数据。

  第二步：服务器收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等于它前面已传送过的数据的最后一个字节的序号加1。此时，从客户机到服务器这个方向的连接就释放了，TCP连接处于半关闭状态。但服务器若发送数据，客户机仍要接收，即从服务器到客户机这个方向的连接并未关闭。

  第三步：若服务器已经没有要向客户机发送的数据，就通知TCP释放连接，此时它发出FIN=1的连接释放报文段。

  第四步：客户机收到连接释放报文段后，必须发出确认。在确认报文段中，ACK字段被置为1，确认号ack=w+1，序号seq=u+1。此时TCP连接还没有释放掉，必须经过时间等待计时器设置的时间2MSS后，A才进入到连接关闭状态。

  > [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)

  **为什么要三次握手**

  **三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

  第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

  第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

  第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

  所以三次握手就能确认双发收发功能都正常，缺一不可。

  **为什么要传回 SYN**

  接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。

  > SYN 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement[汉译：确认字符 ,在数据通信传输中，接收站发给发送站的一种传输控制字符。它表示确认发来的数据已经接受无误。 ]）消息响应。这样在客户机和服务器之间才能建立起可靠的TCP连接，数据才可以在客户机和服务器之间传递。

  **传了 SYN,为啥还要传 ACK**

  双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。

  **为什么要四次挥手**

  任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。

  举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

- 滑动窗口的作用

  [https://www.zhihu.com/question/32255109](https://www.zhihu.com/question/32255109)

  **滑动窗口实现面向流的可靠性**

  1）最基本的传输可靠性来源于“确认重传”机制。

  2）TCP的滑动窗口的可靠性也是建立在“确认重传”基础上的。

  3）发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，m 左边界。

  4）接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。

  **滑动窗口的流控特性**

  TCP的滑动窗口是动态的，我们可以想象成小学常见的一个数学题，一个水池，体积V，每小时进水量V1，出水量V2。当水池满了就不允许再注入了，如果有个液压系统控制水池大小，那么就可以控制水的注入速率和量。这样的水池就类似TCP的窗口。应用根据自身的处理能力变化，通过本端TCP接收窗口大小控制来对对对端的发送窗口流量限制。

  应用程序在需要（如内存不足）时，通过API通知TCP协议栈缩小TCP的接收窗口。然后TCP协议栈在下个段发送时包含新的窗口大小通知给对端，对端按通知的窗口来改变发送窗口，以此达到减缓发送速率的目的。

#### 应用层

- http请求中的304状态码的含义

- SSL四次握手的过程

- http1.1和1.0的区别

- 你知道的http请求，应答码502和504的区别

- http和https的区别

- 浏览器从接收到一个URL，到最后展示出页面，经历了哪些过程

- DNS的寻址过程

  > 王道网络P242 DNS系统

  域名系统DNS是因特网使用的命名系统，用来把便于人们记忆的含有特定含义的主机名转换为便于机器处理的IP地址。DNS系统采用客户/服务器模型，其协议运行在UDP之上，使用53号端口。

  递归查询（比较少用）、迭代查询
  
  本地域名服务器分别请求根域名服务器、顶级域名服务器、权限域名服务器

- 负载均衡 反向代理模式的优点、缺点

> [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)

- 在浏览器中输入url地址 ->> 显示主页的过程(面试常客)

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/url%E8%BE%93%E5%85%A5%E5%88%B0%E5%B1%95%E7%A4%BA%E5%87%BA%E6%9D%A5%E7%9A%84%E8%BF%87%E7%A8%8B.jpg)

  总体来说分为以下几个过程:

  1. DNS解析
  2. TCP连接
  3. 发送HTTP请求
  4. 服务器处理请求并返回HTTP报文
  5. 浏览器解析渲染页面
  6. 连接结束

- 各种协议与HTTP协议之间的关系

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E5%90%84%E7%A7%8D%E5%8D%8F%E8%AE%AE%E4%B8%8EHTTP%E5%8D%8F%E8%AE%AE%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.png)

- 状态码

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E7%8A%B6%E6%80%81%E7%A0%81.png)

- HTTP是不保存状态的协议,如何保存用户状态?

  HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个Session）。

  在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

  Cookie 被禁用怎么办?

  最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。

- Cookie的作用是什么?和Session有什么区别？

  Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。

  Cookie 一般用来保存用户信息 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

  Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。

  Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

- HTTP长连接,短连接

  在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

  而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：

  Connection:keep-alive
  在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

  HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。

- HTTP 1.0和HTTP 1.1的主要区别是什么?

  HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：

  长连接 : 在HTTP/1.0中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP 1.1起，默认使用长连接 ,默认开启Connection： keep-alive。 HTTP/1.1的持续连接有非流水线方式和流水线方式 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。

  错误状态响应码 :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

  缓存处理 :在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。

  带宽优化及网络连接的使用 :HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

- URI和URL的区别是什么?

  URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。

  URL(Uniform Resource Location) 是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

  URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

- HTTP 和 HTTPS 的区别？

  端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。

  安全性和资源消耗： HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

  对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等；

  非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。

- XML和JSON优缺点

  > https://www.cnblogs.com/sanmaospace/p/3139186.html

  (1).XML的优缺点

  <1>.XML的优点

  　　A.格式统一，符合标准；

  　　B.容易与其他系统进行远程交互，数据共享比较方便。

  <2>.XML的缺点

  　　A.XML文件庞大，文件格式复杂，传输占带宽；

  　　B.服务器端和客户端都需要花费大量代码来解析XML，导致服务器端和客户端代码变得异常复杂且不易维护；

  　　C.客户端不同浏览器之间解析XML的方式不一致，需要重复编写很多代码；

  　　D.服务器端和客户端解析XML花费较多的资源和时间。

  (2).JSON的优缺点

  <1>.JSON的优点：

  　　A.数据格式比较简单，易于读写，格式都是压缩的，占用带宽小；

  　　B.易于解析，客户端JavaScript可以简单的通过eval()进行JSON数据的读取；

  　　C.支持多种语言，包括ActionScript, C, C#, ColdFusion, Java, JavaScript, Perl, PHP, Python, Ruby等服务器端语言，便于服务器端的解析；

  　　D.在PHP世界，已经有PHP-JSON和JSON-PHP出现了，偏于PHP序列化后的程序直接调用，PHP服务器端的对象、数组等能直接生成JSON格式，便于客户端的访问提取；

  　　E.因为JSON格式能直接为服务器端代码使用，大大简化了服务器端和客户端的代码开发量，且完成任务不变，并且易于维护。

  <2>.JSON的缺点

  　　A.没有XML格式这么推广的深入人心和喜用广泛，没有XML那么通用性；

  　　B.JSON格式目前在Web Service中推广还属于初级阶段。

## 操作系统

- 什么是死锁？

  > 王道操作系统P114

  **死锁是指多个进程因竞争资源而造成一种僵局（互相等待）**，若无外力作用，这些进程都无法向前推进。

  例如，某计算机系统只有一台答应及和一台输入设备，进程P1正占用输入设备，同时又提出使用答应及的请求，但此时打印机正被进程P2所占用，而P2在未释放打印机之前，又提出请求使用正被P1占用着的输入设备。这样两个进程相互无休止地进行下去，均无法继续执行，此时两个进程陷入死锁状态。

  - 死锁预防：破坏死锁产生的四个必要条件，只要其中任一条件不成立，死锁就不会发生。

    - **互斥条件**：进程要求对锁分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占用。此时若有其他进程请求该资源，则请求进程只能等待。

    - **不剥夺条件**：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放）。

    - **请求和保持条件**：进程已经保持了至少一个资源，但由提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。

      为了破坏请求和保持条件，采用预先静态分配方法，即进程在运行前**一次申请完它所需要的全部资源**，在它的资源未满足前，不把它投入运行。

    - **循环等待条件**：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被链中下一个进程所请求。

      为了破坏循环等待条件，采用**顺序资源分配法**。首先给系统中的资源编号，规定**每个进程必须按编号递增的顺序请求资源**，同类资源一次申请完。

  - 死锁避免：银行家算法

  - 死锁检测与解除：资源分配图、死锁定理

- JAVA中如何确保N个线程可以访问N个资源，但同时又不导致死锁？

  > [https://www.nowcoder.com/questionTerminal/7192c9454277483d8711a7b4237a0bbe](<https://www.nowcoder.com/questionTerminal/7192c9454277483d8711a7b4237a0bbe>)

  多线程产生死锁需要四个条件，分别是互斥性，保持和请求，不可剥夺性还有要形成闭环，这四个条件缺一不可，只要破坏了其中一个条件就可以破坏死锁，其中最简单的方法就是线程都是以同样的顺序加锁和释放锁，也就是破坏了第四个条件。

- 64位和32位的区别

  32位操作系统针对的32位的CPU设计。64位操作系统针对的64位的CPU设计。

  > [https://blog.51cto.com/zliang90/1282301](https://blog.51cto.com/zliang90/1282301)
  
  32位电脑与64位电脑有什么不同？

  我们通常说的64位技术是相对于32位而言的，这个位数指的是CPU GPRs(General-Purpose Registers，通用寄存器)的数据宽度为64位，64位指令集就是运行64位数据的指令，也就是说处理器一次可以运行64bit数据。

- CentOS 和 Linux的关系

  CentOS是Linux众多得发行版本之一，linux有三大发行版本（：Slackware、debian、redhat）,而Redhat有收费的商业版和免费的开源版,商业版的业内称之为RHEL系列，CentOS是来自于依照开放源代码规定而公布的源代码重新编译而成。可以用CentOS替代商业版的RHEL使用。两者的不同，CentOS不包含封闭源代码软件，是免费的。

- LINUX下的线程

  LINUX实现的就是基于核心轻量级进程的“一对一”线程模型，一个线程实体对应一个核心轻量级进程，而线程之间的管理在核外函数库中实现。

- 系统线程数量上限

  > [https://www.nowcoder.com/questionTerminal/f2ed6675ef354bd3a9a3eed3dd30637f](https://www.nowcoder.com/questionTerminal/f2ed6675ef354bd3a9a3eed3dd30637f)
  
  对于32位的linux系统，一个进程的地址空间是4GB，其中用户态能访问3GB左右，一个线程的默认栈是10M，心算可知一个进程能同时开启300个线程，因此300左右是上限，因为进程其他部分也同样需要，数据段代码段堆动态库。至于64为则更多。

  在linux系统里一般是 32768大小 该配置存在于文件/proc/sys/kernel/pid_max

- 如何杀死一个进程：

  1. kill pid: 系统发送一个signal,程序收到信号后，会先释放资源，再关闭程序。

  2. kill -9 pid: -9表示强制执行。

- 怎么理解操作系统里的内存碎片，有什么解决办法？

  内存碎片分为：内部碎片和外部碎片。

  内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；

  内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。

  单道连续分配只有内部碎片。多道固定连续分配既有内部碎片，又有外部碎片。

  外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。

  外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。

  使用伙伴系统算法。

  > 王道操作系统P144 连续分配管理方式

  固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干个固定的区域，每个分区只装入一道作业。当程序小于固定分区大小时，也占用了一个完整的内存分区空间，这样分区内部有空间浪费，这种现象称为内部碎片。

  动态分区分配不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。动态分区在开始分配时是很好的，但是之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片，这些小的内存碎片称为外部碎片。克服外部碎片可以通过紧凑技术来解决。

- 什么是页式存储？

  > 王道操作系统 P147 非连续分配管理方式
  
  **基本分页存储管理方式**

  分页存储管理的逻辑地址结构：页号P、页内偏移量W
  
  页表项：页号P、块号b

  页号根据页表查到块号，与页内偏移量拼接，得到物理地址。

  **基本分段存储管理方式**

  分段系统中的逻辑地址结构：段号S、段内偏移量W

  段表项：段号S、段长C、基址b

  段号根据段表查到基址，加上段内偏移量，得到物理地址。

  **段页式管理方式**

  段页式系统的逻辑地址结构：段号S、页号P、页内偏移量W

  段号根据段表查到页表的起始地址。页号根据页表查到块号，与页内偏移量拼接，得到物理地址。

- 页面置换算法

  > 王道操作系统P176 页面置换算法

  - 最佳(OPT)置换算法

    最佳置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。

  - 先进先出(FIFO)置换算法

    优先淘汰最早进入内存的页面，亦即在内存中驻留时间最久的页面。

    FIFO算法会产生党所分配的物理块数增大而页故障数不增反减的异常现象，称为Belady异常。只有FIFO算法可能出现Belady异常，而LRU和OPT算法永远不会出现Belady异常。

  - 最近最久未使用(LRU)置换算法

    它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法未每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。

  - 时钟(CLOCK)置换算法

    又称为最近未用(NRU)算法。给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为1；当该页随后再被访问到时，它的使用位也被置为1。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。当遇到一个使用位为1的帧时，操作系统就将该位重新置为0。

## 数据库

#### MySQL

- 内连接、左外连接、右外连接、全连接

  > [https://blog.csdn.net/plg17/article/details/78758593](https://blog.csdn.net/plg17/article/details/78758593)

- MyISAM和InnoDB区别

  MyISAM是MySQL的默认数据库引擎（5.5版之前）。虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但MyISAM不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。不过，5.5版本之后，MySQL引入了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。

  大多数时候我们使用的都是 InnoDB 存储引擎，但是在某些情况下使用 MyISAM 也是合适的比如读密集的情况下。（如果你不介意 MyISAM 崩溃恢复问题的话）。

  两者的对比：

  1. **是否支持行级锁** : MyISAM 只有表级锁(table-level locking)，而InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。
  2. **是否支持事务和崩溃后的安全恢复**： MyISAM 强调的是性能，每次查询具有原子性,其执行速度比InnoDB类型更快，但是不提供事务支持。但是InnoDB 提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。
  3. **是否支持外键**： MyISAM不支持，而InnoDB支持。
  4. **是否支持MVCC** ：仅 InnoDB 支持。应对高并发事务, MVCC比单纯的加锁更高效;MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作;MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统一。推荐阅读：MySQL-InnoDB-MVCC多版本并发控制
  5. ......
  
  《MySQL高性能》上面有一句话这样写到:

  > 不要轻易相信“MyISAM比InnoDB快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。

  一般情况下我们选择 InnoDB 都是没有问题的，但是某些情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择MyISAM也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。

- 字符集及校对规则

  字符集指的是一种从二进制编码到某类字符符号的映射。校对规则则是指某种字符集下的排序规则。MySQL中每一种字符集都会对应一系列的校对规则。

  MySQL采用的是类似继承的方式指定字符集的默认值，每个数据库以及每张数据表都有自己的默认值，他们逐层继承。比如：某个库中所有表的默认字符集将是该数据库所指定的字符集（这些表在没有指定字符集的情况下，才会采用默认字符集）

- 索引

  MySQL索引使用的数据结构主要有**BTree索引** 和 **哈希索引** 。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。

  MySQL的BTree索引使用的是B树中的B+Tree，但对于主要的两种存储引擎的实现方式是不同的。

  - **MyISAM**: B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则**取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录**。这被称为“非聚簇索引”。
  
  - **InnoDB**: 其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，**树的叶节点data域保存了完整的数据记录**。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。而其余的索引都作为辅助索引，**辅助索引的data域存储相应记录主键的值而不是地址**，这也是和MyISAM不同的地方。**在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。**

  > [https://www.kancloud.cn/kancloud/theory-of-mysql-index/41852](https://www.kancloud.cn/kancloud/theory-of-mysql-index/41852)

- 查询缓存的使用

  > 执行查询语句的时候，会先查询缓存。不过，MySQL 8.0 版本后移除，因为这个功能不太实用。

  my.cnf加入以下配置，重启MySQL开启查询缓存

  ```properties
  query_cache_type=1
  query_cache_size=600000
  ```
  MySQL执行以下命令也可以开启查询缓存

  ```properties
  set global  query_cache_type=1;
  set global  query_cache_size=600000;
  ```
  如上，**开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果。** 这里的查询条件包括查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息。因此任何两个查询在任何字符上的不同都会导致缓存不命中。此外，如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果也不会被缓存。

  缓存建立之后，MySQL的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。

  **缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。** 因此，开启缓存查询要谨慎，尤其对于写密集的应用来说更是如此。如果开启，要注意合理控制缓存空间大小，一般来说其大小设置为几十MB比较合适。此外，**还可以通过sql_cache和sql_no_cache来控制某个查询语句是否需要缓存：**

  ```sql
  select sql_no_cache count(*) from usr;
  ```

- 什么是事务?

  **事务是逻辑上的一组操作，要么都执行，要么都不执行。**

  事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。

  事务的四大特性(ACID)

  1. **原子性（Atomicity）**： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
  2. **一致性（Consistency）**： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
  3. **隔离性（Isolation）**： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
  4. **持久性（Durability）**： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

  > [https://blog.csdn.net/chosen0ne/article/details/10036775](https://blog.csdn.net/chosen0ne/article/details/10036775)

  **一致性（Consistency）**

  一致性是指事务使得系统从一个一致的状态转换到另一个一致状态。事务的一致性决定了一个系统设计和实现的复杂度。事务可以不同程度的一致性：

  - 强一致性：读操作可以立即读到提交的更新操作。

  - 弱一致性：提交的更新操作，不一定立即会被读操作读到，此种情况会存在一个不一致窗口，指的是读操作可以读到最新值的一段时间。

  - 最终一致性：是弱一致性的特例。事务更新一份数据，最终一致性保证在没有其他事务更新同样的值的话，最终所有的事务都会读到之前事务更新的最新值。如果没有错误发生，不一致窗口的大小依赖于：通信延迟，系统负载等。

- **并发事务带来哪些问题?**

  在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。

  - **脏读（Dirty read）**: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
  - **丢失修改（Lost to modify）**: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。
  - **不可重复读（Unrepeatableread）**: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
  - **幻读（Phantom read）**: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
  
  **不可重复读和幻读区别：**

  不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。

- **事务隔离级别有哪些?MySQL的默认隔离级别是?**

  SQL 标准定义了四个隔离级别：

  - READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，**允许读取尚未提交的数据变更**，可能会导致脏读、幻读或不可重复读。
  - READ-COMMITTED(读取已提交)： **允许读取并发事务已经提交的数据**，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
  - REPEATABLE-READ(可重复读)： **对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改**，可以阻止脏读和不可重复读，但幻读仍有可能发生。
  - SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。**所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰**，也就是说，该级别可以防止脏读、不可重复读以及幻读。

  | 隔离级别 | 脏读 | 不可重复读 | 幻影读 |
  | - | - | - | - |
  | 读取未提交(READ-UNCOMMITTED) | √ | √ | √ |
  | 读取已提交(READ-COMMITTED) | × | √ | √ |
  | 可重复读(REPEATABLE-READ) | × |	× | √ |
  | 可串行化(SERIALIZABLE) | × | × | × |

  MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。

  这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server) 是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化) 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读） 并不会有任何性能损失。

  InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。

- **锁机制与InnoDB锁算法**

  MyISAM和InnoDB存储引擎使用的锁：

  - MyISAM采用表级锁(table-level locking)。
  - InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁
  
  表级锁和行级锁对比：

  - 表级锁： MySQL中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。
  - 行级锁： MySQL中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

  InnoDB存储引擎的锁的算法有三种：

  - Record lock：单个行记录上的锁
  - Gap lock：间隙锁，锁定一个范围，不包括记录本身
  - Next-key lock：record+gap 锁定一个范围，包含记录本身
  
  相关知识点：

  1. innodb对于行的查询使用next-key lock
  2. Next-locking keying为了解决Phantom Problem幻读问题
  3. 当查询的索引含有唯一属性时，将next-key lock降级为record key
  4. Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
  5. 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1

- 大表优化

  当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：

  1. 限定数据的范围

      务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；

  2. 读/写分离

      经典的数据库拆分方案，主库负责写，从库负责读；

  3. 垂直分区

      根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

      简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 如下图所示，这样来说大家应该就更容易理解了。

      ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9E%82%E7%9B%B4%E5%88%86%E5%8C%BA.png)
    
      - 垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。

      - 垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；
  
  4. 水平分区

      保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。

      水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。

      ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%B0%B4%E5%B9%B3%E6%8B%86%E5%88%86.png)

      水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。

      水平拆分能够 支持非常大的数据量存储，应用端改造也少，但 分片事务难以解决 ，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度 ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

  下面补充一下数据库分片的两种常见方案：

  - 客户端代理： 分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。 当当网的 Sharding-JDBC 、阿里的TDDL是两种比较常用的实现。
  - 中间件代理： 在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。 我们现在谈的 Mycat 、360的Atlas、网易的DDB等等都是这种架构的实现。

- 解释一下什么是池化设计思想。什么是数据库连接池?为什么需要数据库连接池?

  池化设计应该不是一个新名词。我们常见的如java线程池、jdbc连接池、redis连接池等就是这类设计的代表实现。这种设计会初始预设资源，解决的问题就是抵消每次获取资源的消耗，如创建线程的开销，获取远程连接的开销等。就好比你去食堂打饭，打饭的大妈会先把饭盛好几份放那里，你来了就直接拿着饭盒加菜即可，不用再临时又盛饭又打菜，效率就高了。除了初始化资源，池化设计还包括如下这些特征：池子的初始值、池子的活跃值、池子的最大值等，这些特征可以直接映射到java线程池和数据库连接池的成员属性中。

  数据库连接本质就是一个 socket 的连接。数据库服务端还要维护一些缓存和用户权限信息之类的 所以占用了一些内存。我们可以把数据库连接池是看做是维护的数据库连接的缓存，以便将来需要对数据库的请求时可以重用这些连接。为每个用户打开和维护数据库连接，尤其是对动态数据库驱动的网站应用程序的请求，既昂贵又浪费资源。**在连接池中，创建连接后，将其放置在池中，并再次使用它，因此不必建立新的连接。如果使用了所有连接，则会建立一个新连接并将其添加到池中。** 连接池还减少了用户必须等待建立与数据库的连接的时间。

- 分库分表之后,id 主键如何处理？

  因为要是分成多个表之后，每个表都是从 1 开始累加，这样是不对的，我们需要一个全局唯一的 id 来支持。

  生成全局 id 有下面这几种方式：

  - UUID：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。
  - 数据库自增 id : 两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。这种方式生成的 id 有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。
  - 利用 redis 生成 id : 性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。
  - Twitter的snowflake算法 ：Github 地址：https://github.com/twitter-archive/snowflake。
  - 美团的Leaf分布式ID生成系统 ：Leaf 是美团开源的分布式ID生成器，能保证全局唯一性、趋势递增、单调递增、信息安全，里面也提到了几种分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件。感觉还不错。美团技术团队的一篇文章：https://tech.meituan.com/2017/04/21/mt-leaf.html 。
  - ......

- 高性能优化规范建议

  **索引设计规范**
  
  1. 限制每张表上的索引数量,建议单张表索引不超过 5 个

      索引并不是越多越好！索引可以提高效率同样可以降低效率。

      索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。

      因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。
  
  2. 禁止给表中的每一列都建立单独的索引

      5.6 版本之前，一个 sql 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好。

  3. 每个 Innodb 表必须有个主键
  
      Innodb 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。

      Innodb 是按照主键索引的顺序来组织表的

      **不要使用更新频繁的列作为主键**，不适用多列主键（相当于联合索引）
  
      **不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长）**
  
      **主键建议使用自增 ID 值**
  
  4. 常见索引列建议
  
      出现在 SELECT、UPDATE、DELETE 语句的 **WHERE 从句中的列**
  
      **包含在 ORDER BY、GROUP BY、DISTINCT 中的字段**
  
      并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好
      
      **多表 join 的关联列**
  
  5. 如何选择索引列的顺序
  
      建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。

      **区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）**
  
      **尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）**
  
      使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）
  
  6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）
  
      重复索引示例：primary key(id)、index(id)、unique index(id)
  
      冗余索引示例：index(a,b,c)、index(a,b)、index(a)
  
  7. 对于频繁的查询优先考虑使用覆盖索引
  
      覆盖索引：就是包含了所有查询字段 (where,select,ordery by,group by 包含的字段) 的索引

      覆盖索引的好处：

      避免 Innodb 表进行索引的二次查询: Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。
  
      可以把随机 IO 变成顺序 IO 加快查询效率: 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。
  
  8. 索引 SET 规范
  
      尽量避免使用外键约束

      不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引
  
      外键可用于保证数据的参照完整性，但建议在业务端实现
  
      外键会影响父表和子表的写操作从而降低性能

- 数据库索引总结

  **为什么要使用索引**

  - 通过创建唯一性索引，可以保证数据库每一行数据的唯一性。
  - 可以大大加快数据的检索速度（大大减少的检索的数据量），这也是创建索引的最主要的原因。

  **索引有这么多优点，为什么不对表中的每一个列创建一个索引呢**

  - 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。
  - 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还有占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。
  - 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。

  **使用索引的注意事项**

  - **在经常使用在WHERE子句中的列上面创建索引**，加快条件的判断速度。
  - **在经常需要排序的列上创建索引**，因为索引已经排序，这样查询可以利用索引的排序，加快排序时间。
  - 对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引。
  - **在经常用在连接的列上，这些列主要是一些外键**，可以加快连接速度。
  - 避免where子句中对字段施加函数，这会造成无法命中索引。
  - **将打算加索引的列设置为NOT NULL，否则讲导致引擎放弃使用索引而进行全表扫描。**
  - 在使用limit offset查询缓慢时，可以借助索引来提高性能。

  **覆盖索引介绍**

  - 什么是覆盖索引

    如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。我们知道在InnoDB存储引擎中，如果不是主键索引，叶子结点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次，这样就会比较慢。覆盖索引就是要查询出的列和索引是对应的，不做徽标操作。
  
  - 覆盖索引使用实例

    现在我创建了索引(username, age)，在查询数据的时候：`select username, age from user where username = 'Java' and age = 22`，要查询出的列在叶子结点都存在，所以就不用回表。
  
  **选择索引和编写利用这些索引的查询的3个原则**

  1. 单个访问时很慢的。如果服务器从存储中读取一个数据块知识为了获取其中一行，那么就浪费了很多工作。最好读取的块中能包含尽可能多所需要的行。使用索引可以创建位置引，用以提高效率。

  2. 按顺序访问范围数据是很快的，这有两个原因。第一，顺序I/O不需要多次磁盘寻道，所以比随机I/O要快很多。第二，如果服务器能够按需要顺序读取数据，那么就不再需要额外的排序操作，并且GROUPBY查询也无需再做排序和将行按组进行聚合计算了。

  3. 索引覆盖查询是很快的。如果一个索引包含了查询需要的所有列，那么查询引擎就不需要再回表查找行。这避免了大量的单行访问，而上面的第1点已经写明单行访问时很慢的。

> [https://www.nowcoder.com/discuss/356120](https://www.nowcoder.com/discuss/356120)

- Mysql(innondb 下同) 有哪几种事务隔离级别？

  读取未提交、读取已提交、可重复读、可串行化

- 不同事务隔离级别分别会加哪些锁？

  **读取已提交级别：读取不加锁，写入、修改、删除加行锁。** 读（快照读）存在不可重复读的问题，解决方法是读取数据后，将这些数据加行锁。写（当前读）存在幻读的问题，解决方法是使用next-key锁。

  **可重复读级别：next-key锁=gap锁+行锁。** 行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。

  **可串行化：读加共享锁，写加排他锁，读写互斥。并发能力非常差。**

  > [https://tech.meituan.com/2014/08/20/innodb-lock.html](https://tech.meituan.com/2014/08/20/innodb-lock.html)

  - 读取已提交 Read Committed

    在RC级别中，数据的读取都是不加锁的，但是数据的写入、修改和删除是需要加锁的。

    |事务A | 事务B |
    |--|--|
    |begin;	|begin;|
    |update class_teacher set class_name=‘初三二班’ where teacher_id=1;	|update class_teacher set class_name=‘初三三班’ where teacher_id=1;|
    |commit;||

    为了防止并发过程中的修改冲突，事务A中MySQL给teacher_id=1的数据行加锁，并一直不commit（释放锁），那么事务B也就一直拿不到该行锁，wait直到超时。

    这时我们要注意到，teacher_id是有索引的，如果是没有索引的class_name呢？update class_teacher set teacher_id=3 where class_name = ‘初三一班’; 那么MySQL会给整张表的所有数据行的加行锁。这里听起来有点不可思议，但是当sql运行的过程中，MySQL并不知道哪些数据行是 class_name = ‘初三一班’的（没有索引嘛），如果一个条件无法通过索引快速过滤，存储引擎层面就会将所有记录加锁后返回，再由MySQL Server层进行过滤。

    但在实际使用过程当中，MySQL做了一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。可见即使是MySQL，为了效率也是会违反规范的。（参见《高性能MySQL》中文第三版p181）

    这种情况同样适用于MySQL的默认隔离级别RR。所以对一个数据量很大的表做批量修改的时候，如果无法使用相应的索引，MySQL Server过滤数据的的时候特别慢，就会出现虽然没有修改某些行的数据，但是它们还是被锁住了的现象。

  - 可重复读 Repeatable Read

    这是MySQL中InnoDB默认的隔离级别。我们姑且分“读”和“写”两个模块来讲解。

    **读**

    RC（不可重读）模式下的展现

    | 事务A                                                        | 事务B                                                      |
    | ------------------------------------------------------------ | ---------------------------------------------------------- |
    | begin;                                                       | begin;                                                     |
    | select id,class_name,teacher_id from class_teacher where teacher_id=1; ① |                                                            |
    |                                                              | update class_teacher set class_name='初三三班' where id=1; |
    |                                                              | commit;                                                    |
    | select id,class_name,teacher_id from class_teacher where teacher_id=1; ② |                                                            |
    | commit;                                                      |                                                            |

    ①
    | id | class_name | teacher_id |
    | -- | -- | -- |
    | 1 | 初三二班 | 1 |
    | 2 | 初三一班 | 1 |

    ②
    | id | class_name | teacher_id |
    | -- | -- | -- |
    | 1 | 初三三班 | 1 |
    | 2 | 初三一班 | 1 |

    读到了事务B修改的数据，和第一次查询的结果不一样，是不可重读的。

    我们注意到，当teacher_id=1时，事务A先做了一次读取，事务B中间修改了id=1的数据，并commit之后，事务A第二次读到的数据和第一次完全相同。所以说它是可重读的。那么MySQL是怎么做到的呢？

    > 不可重复读和幻读的区别
    >
    > 很多人容易搞混不可重复读和幻读，确实这两者有些相似。但不可重复读重点在于update和delete，而幻读的重点在于insert。
    >
    > 如果使用锁机制来实现这两种隔离级别，在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。
    >
    > 所以说不可重复读和幻读最大的区别，就在于如何通过锁机制来解决他们产生的问题。

    **写**

    > 对于读取历史数据的方式，我们叫它快照读 (snapshot read)，而读取数据库当前版本数据的方式，叫当前读 (current read)。
    > 
    > - 快照读：就是select
    >   - select * from table ….;
    > 
    > - 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。
    >   - select * from table where ? lock in share mode;
    >   - select * from table where ? for update;
    >   - insert;
    >   - update;
    >   - delete;
    
    事务的隔离级别中虽然只定义了读数据的要求，实际上这也可以说是写数据的要求。上文的“读”，实际是讲的快照读；而这里说的“写”就是当前读了。

    为了解决当前读中的幻读问题，MySQL事务使用了Next-Key锁。

    Next-Key锁是行锁和GAP（间隙锁）的合并，行锁上文已经介绍了，接下来说下GAP间隙锁。

    行锁可以防止不同事务版本的数据修改提交时造成数据冲突的情况。但如何避免别的事务插入数据就成了问题。我们可以看看RR级别和RC级别的对比

    RC级别：

    | 事务A                                                        | 事务B                                                        |
    | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | begin;                                                       | begin;                                                       |
    | select id,class_name,teacher_id from class_teacher where teacher_id=30; ① |                                                              |
    | update class_teacher set class_name='初三四班' where teacher_id=30; |                                                              |
    |                                                              | insert into class_teacher values (null,'初三二班',30);commit; |
    | select id,class_name,teacher_id from class_teacher where teacher_id=30; ② |                                                              |

    ① 

    |id|class_name|teacher_id|
    |-|-|-|
    |2|初三二班|30|

    ②

    |id|class_name|teacher_id|
    |-|-|-|
    |2|初三二班|30|
    |10|初三二班|30|

    RR级别：

    | 事务A                                                        | 事务B                                                        |
    | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | begin;                                                       | begin;                                                       |
    | select id,class_name,teacher_id from class_teacher where teacher_id=30; ① |                                                              |
    | update class_teacher set class_name='初三四班' where teacher_id=30; |                                                              |
    |                                                              | insert into class_teacher values (null,'初三二班',30);waiting.... |
    | select id,class_name,teacher_id from class_teacher where teacher_id=30; ② |                                                              |
    | commit;                                                      | 事务Acommit后，事务B的insert执行。                           |

    ①

    |id|class_name|teacher_id|
    |-|-|-|
    |2|初三二班|30|

    ②

    |id|class_name|teacher_id|
    |-|-|-|
    |2|初三二班|30|

    通过对比我们可以发现，在RC级别中，事务A修改了所有teacher_id=30的数据，但是当事务Binsert进新数据后，事务A发现莫名其妙多了一行teacher_id=30的数据，而且没有被之前的update语句所修改，这就是“当前读”的幻读。

    RR级别中，事务A在update后加锁，事务B无法插入新数据，这样事务A在update前后读的数据保持一致，避免了幻读。这个锁，就是Gap锁。

    MySQL是这么实现的：

    在class_teacher这张表中，teacher_id是个索引，那么它就会维护一套B+树的数据关系，为了简化，我们用链表结构来表达（实际上是个树形结构，但原理相同）

    ![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/b3b6a55f.png)

    如图所示，InnoDB使用的是聚集索引，teacher_id身为二级索引，就要维护一个索引字段和主键id的树状结构（这里用链表形式表现），并保持顺序排列。

    Innodb将这段数据分成几个个区间

    - (negative infinity, 5],
    - (5,30],
    - (30,positive infinity)；

    update class_teacher set class_name=‘初三四班’ where teacher_id=30;不仅用行锁，锁住了相应的数据行；同时也在两边的区间，（5,30]和（30，positive infinity），都加入了gap锁。这样事务B就无法在这个两个区间insert进新数据。

    受限于这种实现方式，Innodb很多时候会锁住不需要锁的区间。如下所示：

    | 事务A                                                        | 事务B                                                        | 事务C                                                  |
    | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------ |
    | begin;                                                       | begin;                                                       | begin;                                                 |
    | select id,class_name,teacher_id from class_teacher; ①        |                                                              |                                                        |
    | update class_teacher set class_name='初一一班' where teacher_id=20; |                                                              |                                                        |
    |                                                              | insert into class_teacher values (null,'初三五班',10);waiting ..... | insert into class_teacher values (null,'初三五班',40); |
    | commit;                                                      | 事务A commit之后，这条语句才插入成功                         | commit;                                                |
    |                                                              | commit;                                                      |                                                        |

    ①
    
    |id|class_name|teacher_id|
    |-|-|-|
    |1|初三一班|5|
    |2|初三二班|30|
    
    update的teacher_id=20是在(5，30]区间，即使没有修改任何数据，Innodb也会在这个区间加gap锁，而其它区间不会影响，事务C正常插入。

    如果使用的是没有索引的字段，比如update class_teacher set teacher_id=7 where class_name=‘初三八班（即使没有匹配到任何数据）’,那么会给全表加入gap锁。同时，它不能像上文中行锁一样经过MySQL Server过滤自动解除不满足条件的锁，因为没有索引，则这些字段也就没有排序，也就没有区间。除非该事务提交，否则其它事务无法插入任何数据。

    行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。

  - 可串行化 Serializable

    这个级别很简单，读加共享锁，写加排他锁，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差。如果你的业务并发的特别少或者没有并发，同时又要求数据及时可靠的话，可以使用这种模式。

- MVCC

  > [https://www.jianshu.com/p/8845ddca3b23](https://www.jianshu.com/p/8845ddca3b23)

  多版本并发控制

- mysql的行锁、表锁、间隙锁、意向锁分别是做什么的？

  > [https://blog.csdn.net/u010841296/article/details/84204701](https://blog.csdn.net/u010841296/article/details/84204701)

  - 共享锁Shared Locks（S锁）

    1、兼容性：加了S锁的记录，允许其他事务再加S锁，不允许其他事务再加X锁

    2、加锁方式：select…lock in share mode

  - 排他锁Exclusive Locks（X锁）

    1、兼容性：加了X锁的记录，不允许其他事务再加S锁或者X锁

    2、加锁方式：select…for update

  - 表锁：意向锁 Intention Locks，意向锁相互兼容

    1、表明“某个事务正在某些行持有了锁、或该事务准备去持有锁”

    2、意向锁的存在是为了协调行锁和表锁的关系，支持多粒度（表锁与行锁）的锁并存。

    3、例子：事务A修改user表的记录r，会给记录r上一把行级的排他锁（X），同时会给user表上一把意向排他锁（IX），这时事务B要给user表上一个表级的排他锁就会被阻塞。意向锁通过这种方式实现了行锁和表锁共存且满足事务隔离性的要求。

    4、
    
    1）**意向共享锁（IS锁）：事务在请求S锁前，要先获得IS锁**

    2）**意向排他锁（IX锁）：事务在请求X锁前，要先获得IX锁**

    q1：**为什么意向锁是表级锁呢？**

    当我们需要加一个排他锁时，需要根据意向锁去判断表中有没有数据行被锁定（行锁）：

    （1）如果意向锁是行锁，则需要遍历每一行数据去确认；

    （2）如果意向锁是表锁，则只需要判断一次即可知道有没数据行被锁定，提升性能。

    q2：**意向锁怎么支持表锁和行锁并存？**

    （1）首先明确并存的概念是指数据库同时支持表、行锁，而不是任何情况都支持一个表中同时有一个事务A持有行锁、又有一个事务B持有表锁，因为表一旦被上了一个表级的写锁，肯定不能再上一个行级的锁。

    （2）**如果事务A对某一行上锁，其他事务就不可能修改这一行。这与“事务B锁住整个表就能修改表中的任意一行”形成了冲突。所以，没有意向锁的时候，让行锁与表锁共存，就会带来很多问题。于是有了意向锁的出现，如q1的答案中，数据库不需要在检查每一行数据是否有锁，而是直接判断一次意向锁是否存在即可，能提升很多性能。**

  - 行锁：记录锁(Record Locks)

    （1）记录锁, 仅仅锁住索引记录的一行，在单条索引记录上加锁。

    （2）record lock锁住的永远是索引，而非记录本身，即使该表上没有任何索引，那么innodb会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。
    所以说当一条sql没有走任何索引时，那么将会在每一条聚合索引后面加X锁，这个类似于表锁，但原理上和表锁应该是完全不同的。

  - 行锁：间隙锁(Gap Locks)

    （1）区间锁, 仅仅锁住一个索引区间（开区间，不包括双端端点）。

    （2）在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身。比如在 1、2、3中，间隙锁的可能值有 (∞, 1)，(1, 2)，(2, ∞)。

    （3）间隙锁可用于防止幻读，保证索引间的不会被插入数据

  - 行锁：临键锁(Next-Key Locks)

    （1）record lock + gap lock, 左开右闭区间。

    （2）默认情况下，innodb使用next-key locks来锁定记录。select … for update

    （3）但当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。

    （4）Next-Key Lock在不同的场景中会退化:

    ![img](https://img-blog.csdnimg.cn/20181118210006461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA4NDEyOTY=,size_16,color_FFFFFF,t_70)

- 说说什么是最左匹配？

  > [https://segmentfault.com/a/1190000015416513](https://segmentfault.com/a/1190000015416513)

  **最左前缀匹配原则**

  在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，示例：
  对列col1、列col2和列col3建一个联合索引

  ```sql
  KEY test_col1_col2_col3 on test(col1,col2,col3);
  ```

  联合索引 test_col1_col2_col3 实际建立了(col1)、(col1,col2)、(col,col2,col3)三个索引。

  ```sql
  SELECT * FROM test WHERE col1=“1” AND clo2=“2” AND clo4=“4”
  ```

  上面这个查询语句执行时会依照最左前缀匹配原则，检索时会使用索引(col1,col2)进行数据匹配。

  **注意**

  索引的字段可以是任意顺序的，如：

  ```sql
  SELECT * FROM test WHERE col1=“1” AND clo2=“2”
  SELECT * FROM test WHERE col2=“2” AND clo1=“1”
  ```

  这两个查询语句都会用到索引(col1,col2)，mysql创建联合索引的规则是首先会对联合合索引的最左边的，也就是第一个字段col1的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个字段col2进行排序。其实就相当于实现了类似 order by col1 col2这样一种排序规则。

  有人会疑惑第二个查询语句不符合最左前缀匹配：首先可以肯定是两个查询语句都包含索引(col1,col2)中的col1、col2两个字段，只是顺序不一样，查询条件一样，最后所查询的结果肯定是一样的。既然结果是一样的，到底以何种顺序的查询方式最好呢？此时我们可以借助mysql查询优化器explain，explain会纠正sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。

  **为什么要使用联合索引**

  - 减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！
  - 覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。
  - 效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！

  > [https://segmentfault.com/a/1190000015416513](https://segmentfault.com/a/1190000015416513)

  **性能优化工具explain**

  > [https://segmentfault.com/a/1190000008131735](https://segmentfault.com/a/1190000008131735)

- 如何优化慢查询？

  > [https://database.51cto.com/art/201809/583239.htm](https://database.51cto.com/art/201809/583239.htm)

  - **索引优化**

    索引类型

    - **普通索引**：是最基本的索引，它没有任何限制。
    - **唯一索引**：与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。
    - **组合索引**：指多个字段上创建的索引，只有在查询条件中使用了创建索引时的***个字段，索引才会被使用。
    - **主键索引**：是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引
    - **全文索引**：主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。它可以在create table，alter table ，create index使用，不过目前只有char、varchar，text 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多。
    
    优化原则
    
    - **只要列中含有NULL值，就不要在此例设置索引**，复合索引如果有NULL值，此列在使用时也不会使用索引
    - 尽量使用短索引，如果可以，应该制定一个前缀长度
    - **对于经常在where子句使用的列设置索引**，这样会加快查找速度
    - **对于有多个列where或者order by子句的，应该建立复合索引**
    - 对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引
    - 尽量不要在列上进行运算（函数操作和表达式操作）
    - 尽量不要使用not in和<>操作

  - **SQL语句优化**

    优化原则
    
    - 查询时，**能不要\*就不用\*，尽量写全字段名**
    - **大部分情况连接效率远大于子查询**
    - 多使用explain和profile分析查询语句
    - **查看慢查询日志，找出执行时间长的sql语句优化**
    - 多表连接时，尽量**小表驱动大表，即小表 join 大表**
    - **在分页时使用limit**
    - 对于经常使用的查询，可以开启**缓存**

  - **大表优化**

    数据表拆分：主要就是垂直拆分和水平拆分。

    - **水平切分**:将记录散列到不同的表中，各表的结构完全相同，每次从分表中查询, 提高效率。
    - **垂直切分**:将表中大字段单独拆分到另外一张表, 形成一对一的关系。

- mysql索引为什么用的是b+ tree而不是b tree、红黑树

  > [https://blog.csdn.net/qq_35923749/article/details/88068659](https://blog.csdn.net/qq_35923749/article/details/88068659)

  B-树、B+树、红黑树，都是平衡查找树，那么查询效率上讲，平均都是O(logn)。使用什么哪种数据结构，肯定是出于提高数据库的查询效率的考虑。

  **一、B+树做索引而不用B-树**

  那么Mysql如何衡量查询效率呢？– 磁盘IO次数。

  一般来说索引非常大，尤其是关系性数据库这种数据量大的索引能达到亿级别，所以为了减少内存的占用，索引也会被存储在磁盘上。B-树/B+树 的特点就是每层节点数目非常多，层数很少，目的就是为了减少磁盘IO次数，但是B-树的每个节点都有data域（指针），这无疑增大了节点大小，说白了增加了磁盘IO次数（磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO多耗时），而B+树除了叶子节点其它节点并不存储数据，节点小，磁盘IO次数就少。

  - 优点一： B+树只有叶节点存放数据，其余节点用来索引，而B-树是每个索引节点都会有Data域。

  - 优点二： B+树所有的Data域在叶子节点，并且所有叶子节点之间都有一个链指针。 这样遍历叶子节点就能获得全部数据，这样就能进行区间访问啦。在数据库中基于范围的查询是非常频繁的，而B树不支持这样的遍历操作。

  **二、B+树做索引而不用红黑树**

  AVL 树（平衡二叉树）和红黑树（二叉查找树）基本都是存储在内存中才会使用的数据结构。在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况。为什么会出现这样的情况，我们知道要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。根据磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树可以有多个子女，从几十到上千，可以降低树的高度。

  数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。

- 分库分表如何选择分表键

  > [https://github.com/Meituan-Dianping/Zebra/wiki/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%88%86%E8%A1%A8%E9%94%AE%EF%BC%8C%E8%B7%AF%E7%94%B1%E8%A7%84%E5%88%99%E5%8F%8A%E5%88%86%E7%89%87%E6%95%B0](https://github.com/Meituan-Dianping/Zebra/wiki/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%88%86%E8%A1%A8%E9%94%AE%EF%BC%8C%E8%B7%AF%E7%94%B1%E8%A7%84%E5%88%99%E5%8F%8A%E5%88%86%E7%89%87%E6%95%B0)

  **分表键即分库/分表字段，是在水平拆分过程中用于生成拆分规则的数据表字段。**

  数据表拆分的首要原则，就是要尽可能找到数据表中的数据在业务逻辑上的主体，并确定大部分（或核心的）数据库操作都是围绕这个主体的数据进行，然后可使用该主体对应的字段作为分表键，进行分库分表。

  业务逻辑上的主体，通常与业务的应用场景相关，下面的一些典型应用场景都有明确的业务逻辑主体，可用于分表键：

  - 面向用户的互联网应用，都是围绕用户维度来做各种操作，那么业务逻辑主体就是用户，可使用用户对应的字段作为分表键；
  - 侧重于卖家的电商应用，都是围绕卖家维度来进行各种操作，那么业务逻辑主体就是卖家，可使用卖家对应的字段作为分表键；

  以此类推，其它类型的应用场景，大多也能找到合适的业务逻辑主体作为分表键的选择。

  如果确实找不到合适的业务逻辑主体作为分表键，那么可以考虑下面的方法来选择分表键：

  - 根据数据分布和访问的均衡度来考虑分表键，尽量将数据表中的数据相对均匀地分布在不同的物理分库/分表中，适用于大量分析型查询的应用场景（查询并发度大部分能维持为1）；
  - 按照数字（字符串）类型与时间类型字段相结合作为分表键，进行分库和分表，适用于日志检索类的应用场景。

  注意：无论选择什么拆分键，采用何种拆分策略，都要注意拆分值是否存在热点的问题，尽量规避热点数据来选择拆分键。

  注意：不一定需要拿数据库主键当做分表键，也可以拿其他业务值当分表键。拿主键当分表键的好处是可以散列均衡，减少热点问题。

- 分库分表的情况下，查询时一般是如何做排序的？

  > [https://cloud.tencent.com/developer/article/1404798](https://cloud.tencent.com/developer/article/1404798)

  **Mysql分库分表方案**

  - **为什么要分表**

    当一张表的数据达到几千万时，你查询一次所花的时间会变多，如果有联合查询的话，我想有可能会死在那儿了。分表的目的就在于此，减小数据库的负担，缩短查询时间。

  - **大数据量并且访问频繁的表，将其分为若干个表**

    比如对于某网站平台的数据库表-公司表，数据量很大，这种能预估出来的大数据量表，我们就事先分出个N个表，这个N是多少，根据实际情况而定。

    某网站现在的数据量至多是5000万条，可以设计每张表容纳的数据量是500万条，也就是拆分成10张表。

    那么如何判断某张表的数据是否容量已满呢?可以在程序段对于要新增数据的表，在插入前先做统计表记录数量的操作，当<500万条数据，就直接插入，当已经到达阀值，可以在程序段新创建数据库表(或者已经事先创建好)，再执行插入操作。

  - **利用merge存储引擎来实现分表**

    如果要把已有的大数据量表分开比较痛苦，最痛苦的事就是改代码，因为程序里面的sql语句已经写好了。用merge存储引擎来实现分表, 这种方法比较适合。

  **数据库架构**

  1. 简单的MySQL主从复制

      MySQL的主从复制解决了数据库的读写分离，并很好的提升了读的性能，其图如下：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/fqy4a9b1um.jpeg?imageView2/2/w/1620)
      
      其主从复制的过程如下图所示：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/odg78hats0.jpeg?imageView2/2/w/1620)

      但是，主从复制也带来其他一系列性能瓶颈问题：

      - 写入无法扩展
      - 写入无法缓存
      - 复制延时
      - 锁表率上升
      - 表变大，缓存率下降

  2. MySQL垂直分区

      如果把业务切割得足够独立，那把不同业务的数据放到不同的数据库服务器将是一个不错的方案，而且万一其中一个业务崩溃了也不会影响其他业务的正常进行，并且也起到了负载分流的作用，大大提升了数据库的吞吐能力。经过垂直分区后的数据库架构图如下：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/eiuihqsrb2.jpeg?imageView2/2/w/1620)

      然而，尽管业务之间已经足够独立了，但是有些业务之间或多或少总会有点联系，如用户，基本上都会和每个业务相关联，况且这种分区方式，也不能解决单张表数据量暴涨的问题，因此为何不试试水平分割呢?

  3. MySQL水平分片(Sharding)

      这是一个非常好的思路，将用户按一定规则（按id哈希）分组，并把该组用户的数据存储到一个数据库分片中，即一个sharding，这样随着用户数量的增加，只要简单地配置一台服务器即可，原理图如下：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/gztxxds73x.jpeg?imageView2/2/w/1620)

      如何来确定某个用户所在的shard呢，可以建一张用户和shard对应的数据表，每次请求先从这张表找用户的shard id，再从对应shard中查询相关数据，如下图所示：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/eyqabomfoa.jpeg?imageView2/2/w/1620)

  **单库单表**

  单库单表是最常见的数据库设计，例如，有一张用户(user)表放在数据库db中，所有的用户都可以在db库中的user表中查到。

  **单库多表**

  随着用户数量的增加，user表的数据量会越来越大，当数据量达到一定程度的时候对user表的查询会渐渐的变慢，从而影响整个DB的性能。如果使用mysql, 还有一个更严重的问题是，当需要添加一列的时候，mysql会锁表，期间所有的读写操作只能等待。

  可以通过某种方式将user进行水平的切分，产生两个表结构完全一样的user_0000,user_0001等表，user_0000 + user_0001 + …的数据刚好是一份完整的数据。

  **多库多表**

  随着数据量增加也许单台DB的存储空间不够，随着查询量的增加单台数据库服务器已经没办法支撑。这个时候可以再对数据库进行水平区分。

  **分库分表规则**

  设计表的时候需要确定此表按照什么样的规则进行分库分表。例如，当有新用户时，程序得确定将此用户信息添加到哪个表中；同理，当登录的时候我们得通过用户的账号找到数据库中对应的记录，所有的这些都需要按照某一规则进行。 

  **路由** 

  通过分库分表规则查找到对应的表和库的过程。如分库分表的规则是user_id mod 4的方式，当用户新注册了一个账号，账号id的123,我们可以通过id mod 4的方式确定此账号应该保存到User_0003表中。当用户123登录的时候，我们通过123 mod 4后确定记录在User_0003中。

  **分库分表产生的问题，及注意事项** 

  1. 分库分表维度的问题 

      假如用户购买了商品,需要将交易记录保存取来，如果按照用户的维度分表，则每个用户的交易记录都保存在同一表中，所以很快很方便的查找到某用户的 购买情况，但是某商品被购买的情况则很有可能分布在多张表中，查找起来比较麻烦。反之，按照商品维度分表，可以很方便的查找到此商品的购买情况，但要查找 到买人的交易记录比较麻烦。 

      所以常见的解决方式有： 

      - 通过扫表的方式解决，此方法基本不可能，效率太低了。 
      - 记录两份数据，一份按照用户纬度分表，一份按照商品维度分表。 
      
      通过搜索引擎解决，但如果实时性要求很高，又得关系到实时搜索。 

  2. 联合查询的问题 

      联合查询基本不可能，因为关联的表有可能不在同一数据库中。 

  3. 避免跨库事务 

      避免在一个事务中修改db0中的表的时候同时修改db1中的表，一个是操作起来更复杂，效率也会有一定影响。 

  4. 尽量把同一组数据放到同一DB服务器上 

      例如将卖家a的商品和交易信息都放到db0中，当db1挂了的时候，卖家a相关的东西可以正常使用。也就是说避免数据库中的数据依赖另一数据库中的数据。 

#### Redis

- redis性能为什么高?

  > [https://blog.csdn.net/xlgen157387/article/details/79470556](https://blog.csdn.net/xlgen157387/article/details/79470556)

  **Redis到底有多快**
  
  可以达到100000+的QPS（每秒内查询次数）。

  ![img](https://img-blog.csdn.net/2018030715491722?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDg3MDUxOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

  横轴是连接数，纵轴是QPS。
  
  **Redis为什么这么快**
  
  1、**完全基于内存**，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

  2、**数据结构简单**，对数据操作也简单，Redis中的数据结构是专门进行设计的；

  3、**采用单线程**，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

  4、使用**多路I/O复用模型**，非阻塞IO；

  5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

  以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨：

  多路 I/O 复用模型

  多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

  > [https://www.zhihu.com/question/28594409](https://www.zhihu.com/question/28594409)

  > 下面举一个例子，模拟一个tcp服务器处理30个客户socket。
  > 假设你是一个老师，让30个学生解答一道题目，然后检查学生做的是否正确，你有下面几个选择：
  >
  > 1. 第一种选择：**按顺序逐个检查**，先检查A，然后是B，之后是C、D。。。这中间如果有一个学生卡主，全班都会被耽误。
  >
  >     这种模式就好比，你用循环挨个处理socket，根本不具有并发能力。
  > 2. 第二种选择：你**创建30个分身**，每个分身检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个进程或者线程处理连接。
  > 3. 第三种选择，你**站在讲台上等，谁解答完谁举手**。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。
  >
  >     这种就是IO复用模型，Linux下的select、poll和epoll就是干这个的。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用**非阻塞模式**。
  >
  >     这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是**事件驱动**，所谓的reactor模式。

  **这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。** 采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。

- 单线程的redis如何利用多核cpu机器？

  > [https://blog.csdn.net/xlgen157387/article/details/79470556](https://blog.csdn.net/xlgen157387/article/details/79470556)

  我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。

  但是，我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！

- redis的缓存淘汰策略？

  > [https://blog.csdn.net/yangtuogege/article/details/77970896](https://blog.csdn.net/yangtuogege/article/details/77970896)

  redis 提供 6种数据淘汰策略：

  - volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
  - volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
  - volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
  - allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
  - allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
  - no-enviction（驱逐）：禁止驱逐数据

  上面提到的LRU（Least Recently Used）策略，实际上Redis实现的LRU并不是可靠的LRU，也就是名义上我们使用LRU算法淘汰键，但是实际上被淘汰的键并不一定是真正的最久没用的， 这里涉及到一个权衡的问题，如果需要在全部键空间内搜索最优解，则必然会增加系统的开销，Redis是单线程的， 也就是同一个实例在每一个时刻只能服务于一个客户端，所以耗时的操作一定要谨慎 。为了在一定成本内实现相对的LRU， 早期的Redis版本是基于采样的LRU，也就是放弃全部键空间内搜索解改为采样空间搜索最优解。自从Redis3.0版本之后， Redis作者对于基于采样的LRU进行了一些优化，目的是在一定的成本内让结果更靠近真实的LRU。

  **策略规则**

  如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru

  如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random

  volatile-lru策略和volatile-random策略适合我们将一个Redis实例既应用于缓存和又应用于持久化存储的时候，然而我们也可以通过使用两个Redis实例来达到相同的效果，将key设置过期时间实际上会消耗更多的内存，因此我们建议使用allkeys-lru策略从而更有效率的使用内存

  **失效的内部实现**

  消极方法（passive way），在主键被访问时如果发现它已经失效，那么就删除它

  积极方法（active way），周期性地从设置了失效时间的主键中选择一部分失效的主键删除

  主动删除：当前已用内存超过maxmemory限定时，触发主动清理策略，该策略由启动参数的配置决定

- redis如何持久化数据？

  > redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复)

  很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。

  Redis不同于Memcached的很重一点就是，Redis支持持久化，而且支持两种不同的持久化操作。**Redis的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file,AOF）。** 这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。

  **快照（snapshotting）持久化（RDB）**

  Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。

  快照持久化是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置：

  ```conf
  save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

  save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

  save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
  ```

  **AOF（append-only file）持久化**

  与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：

  ```conf
  appendonly yes
  ```

  开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。

  在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

  ```conf
  appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
  appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
  appendfsync no        #让操作系统决定何时进行同步
  ```

  为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

  **Redis 4.0 对于持久化机制的优化**

  Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。

  如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。

  **补充内容：AOF 重写**

  AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。

  AOF重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有AOF文件进行任何读入、分析或者写入操作。

  在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作。

- redis有哪几种数据结构？

  > redis 常见数据结构以及使用场景分析

  1.String

  > 常用命令: set,get,decr,incr,mget 等。

  String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。 常规key-value缓存应用； 常规计数：微博数，粉丝数等。

  2.Hash

  > 常用命令： hget,hset,hgetall 等。

  hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。比如下面我就用 hash 类型存放了我本人的一些信息：

  ```
  key=JavaUser293847
  value={
    “id”: 1,
    “name”: “SnailClimb”,
    “age”: 22,
    “location”: “Wuhan, Hubei”
  }
  ```

  3.List
  
  > 常用命令: lpush,rpush,lpop,rpop,lrange等

  list 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。

  Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

  另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。

  4.Set

  > 常用命令： sadd,spop,smembers,sunion 等

  set 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的。

  当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。

  比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：

  ```
  sinterstore key1 key2 key3     将交集存在key1内
  ```
  
  5.Sorted Set

  > 常用命令： zadd,zrange,zrem,zcard等

  和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。

  举例： 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 Sorted Set 结构进行存储。

- redis集群有哪几种形式？

  > [https://blog.csdn.net/wy0123/article/details/79583506](https://blog.csdn.net/wy0123/article/details/79583506)

  现在越来越多的项目都会利用到redis，多实例redis服务比单实例要复杂的多，这里面涉及到定位、容错、扩容等技术问题。我们常用sharding技术来对此进行管理，其集群模式主要有以下几种方式：

  1. 主从复制
  2. 哨兵模式
  3. Redis官方 Cluster集群模式（服务端sharding）
  4. Jedis sharding集群（客户端sharding）
  5. 利用中间件代理

  - **主从复制（Master-Slave Replication）**

    实现主从复制（Master-Slave Replication）的工作原理：Slave从节点服务启动并连接到Master之后，它将主动发送一个SYNC命令。Master服务主节点收到同步命令后将启动后台存盘进程，同时收集所有接收到的用于修改数据集的命令，在后台进程执行完毕后，Master将传送整个数据库文件到Slave，以完成一次完全同步。而Slave从节点服务在接收到数据库文件数据之后将其存盘并加载到内存中。此后，Master主节点继续将所有已经收集到的修改命令，和新的修改命令依次传送给Slaves，Slave将在本次执行这些数据修改命令，从而达到最终的数据同步。

    如果Master和Slave之间的链接出现断连现象，Slave可以自动重连Master，但是在连接成功之后，一次完全同步将被自动执行。

    **主从模式的优缺点**

    优点：

    - 同一个Master可以同步多个Slaves。
    - Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力。因此我们可以将Redis的Replication架构视为图结构。
    - Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求。
    - Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据
    - 为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成。即便如此，系统的伸缩性还是得到了很大的提高。
    - Master可以将数据保存操作交给Slaves完成，从而避免了在Master中要有独立的进程来完成此操作。
    - 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。
    
    缺点：

    - Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。
    - 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。
    - Redis的主从复制采用全量复制，复制过程中主机会fork出一个子进程对内存做一份快照，并将子进程的内存快照保存为文件发送给从机，这一过程需要确保主机有足够多的空余内存。若快照文件较大，对集群的服务能力会产生较大的影响，而且复制过程是在从机新加入集群或者从机和主机网络断开重连时都会进行，也就是网络波动都会造成主机和从机间的一次全量的数据复制，这对实际的系统运营造成了不小的麻烦。
    - Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。

    其实redis的主从模式很简单，在实际的生产环境中是很少使用的，我也不建议在实际的生产环境中使用主从模式来提供系统的高可用性，之所以不建议使用都是由它的缺点造成的，在数据量非常大的情况，或者对系统的高可用性要求很高的情况下，主从模式也是不稳定的。

  - **哨兵模式**

    该模式是从Redis的2.6版本开始提供的，但是当时这个版本的模式是不稳定的，直到Redis的2.8版本以后，这个哨兵模式才稳定下来，无论是主从模式，还是哨兵模式，这两个模式都有一个问题，不能水平扩容，并且这两个模式的高可用特性都会受到Master主节点内存的限制。

    Sentinel(哨兵)进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用。

    **Sentinel（哨兵）进程的作用**

    1. 监控(Monitoring): 哨兵(sentinel) 会不断地检查你的Master和Slave是否运作正常。
    2. 提醒(Notification)：当被监控的某个Redis节点出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知。
    3. 自动故障迁移(Automatic failover)：当一个Master不能正常工作时，哨兵(sentinel) 会开始一次自动故障迁移操作，它会将失效Master的其中一个Slave升级为新的Master, 并让失效Master的其他Slave改为复制新的Master；当客户端试图连接失效的Master时，集群也会向客户端返回新Master的地址，使得集群可以使用现在的Master替换失效Master。Master和Slave服务器切换后，Master的redis.conf、Slave的redis.conf和sentinel.conf的配置文件的内容都会发生相应的改变，即，Master主服务器的redis.conf配置文件中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换。

    **Sentinel（哨兵）进程的工作方式**

    1. 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
    2. 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
    3. 如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态
    4. 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）
    5. 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。
    6. 当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
    7. 若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。

    **哨兵模式的优缺点**

    优点:

    - 哨兵集群模式是基于主从模式的，所有主从的优点，哨兵模式同样具有。
    - 主从可以切换，故障可以转移，系统可用性更好。
    - 哨兵模式是主从模式的升级，系统更健壮，可用性更高。

    缺点:

    - Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。
    - 配置复杂
  
  - **Redis官方 Cluster集群模式**

    Redis Cluster是一种服务器Sharding技术，3.0版本开始正式提供。

    ![img](https://img-blog.csdn.net/20180319140642333?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3d5MDEyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    在这个图中，每一个蓝色的圈都代表着一个redis的服务器节点。它们任何两个节点之间都是相互连通的。客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点。对其进行存取和其他操作。

    **Redis集群数据分片**

    在redis的每一个节点上，都有这么两个东西，一个是插槽（slot）可以理解为是一个可以存储两个数值的一个变量这个变量的取值范围是：0-16383。还有一个就是cluster我个人把这个cluster理解为是一个集群管理的插件。当我们的存取的key到达的时候，redis会根据crc16的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。

    ![img](https://img-blog.csdn.net/20180319141211304?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3d5MDEyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    还有就是因为如果集群的话，是有好多个redis一起工作的，那么，就需要这个集群不是那么容易挂掉，所以呢，理论上就应该给集群中的每个节点至少一个备用的redis服务。这个备用的redis称为从节点（slave）。那么这个集群是如何判断是否有某个节点挂掉了呢？

    首先要说的是，每一个节点都存有这个集群所有主节点以及从节点的信息。

    它们之间通过互相的ping-pong判断是否节点可以连接上。如果有一半以上的节点去ping一个节点的时候没有回应，集群就认为这个节点宕机了，然后去连接它的备用节点。如果某个节点和所有从节点全部挂掉，我们集群就进入fail状态。还有就是如果有一半以上的主节点宕机，那么我们集群同样进入fail状态。这就是我们的redis的投票机制，具体原理如下图所示：

    ![img](https://img-blog.csdn.net/20180319141325659?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3d5MDEyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    Redis 3.0的集群方案有以下两个问题。

    1. 一个Redis实例具备了“数据存储”和“路由重定向”，完全去中心化的设计。这带来的好处是部署非常简单，直接部署Redis就行，不像Codis有那么多的组件和依赖。但带来的问题是很难对业务进行无痛的升级，如果哪天Redis集群出了什么严重的Bug，就只能回滚整个Redis集群。
    2. 对协议进行了较大的修改，对应的Redis客户端也需要升级。升级Redis客户端后谁能确保没有Bug？而且对于线上已经大规模运行的业务，升级代码中的Redis客户端也是一个很麻烦的事情。

    Redis Cluster是Redis 3.0以后才正式推出，时间较晚，目前能证明在大规模生产环境下成功的案例还不是很多，需要时间检验。

  - **Jedis sharding集群**

    Redis Sharding可以说是在Redis cluster出来之前业界普遍的采用方式，其主要思想是采用hash算法将存储数据的key进行hash散列，这样特定的key会被定为到特定的节点上。

    ![img](https://img-blog.csdn.net/20180319143624440?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3d5MDEyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    庆幸的是，Java Redis客户端驱动Jedis已支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool

    Jedis的Redis Sharding实现具有如下特点：

    1. 采用一致性哈希算法，将key和节点name同时hashing，然后进行映射匹配，采用的算法是MURMUR_HASH。采用一致性哈希而不是采用简单类似哈希求模映射的主要原因是当增加或减少节点时，不会产生由于重新匹配造成的rehashing。一致性哈希只影响相邻节点key分配，影响量小。
    2. 为了避免一致性哈希只影响相邻节点造成节点分配压力，ShardedJedis会对每个Redis节点根据名字(没有，Jedis会赋予缺省名字)会虚拟化出160个虚拟节点进行散列。根据权重weight，也可虚拟化出160倍数的虚拟节点。用虚拟节点做映射匹配，可以在增加或减少Redis节点时，key在各Redis节点移动再分配更均匀，而不是只有相邻节点受影响。
    3. ShardedJedis支持keyTagPattern模式，即抽取key的一部分keyTag做sharding，这样通过合理命名key，可以将一组相关联的key放入同一个Redis节点，这在避免跨节点访问相关数据时很重要。
  
    当然，Redis Sharding这种轻量灵活方式必然在集群其它能力方面做出妥协。比如扩容，当想要增加Redis节点时，尽管采用一致性哈希，毕竟还是会有key匹配不到而丢失，这时需要键值迁移。
  
    作为轻量级客户端sharding，处理Redis键值迁移是不现实的，这就要求应用层面允许Redis中数据丢失或从后端数据库重新加载数据。但有些时候，击穿缓存层，直接访问数据库层，会对系统访问造成很大压力。

  - **利用中间件代理**

    中间件的作用是将我们需要存入redis中的数据的key通过一套算法计算得出一个值。然后根据这个值找到对应的redis节点，将这些数据存在这个redis的节点中。

    常用的中间件有这几种

    - Twemproxy
    - Codis
    - nginx

- 有海量key和value都比较小的数据，在redis中如何存储才更省内存？

  > [https://zzyongx.github.io/blogs/redis-memory-optimization-when-store-small-data.html](https://zzyongx.github.io/blogs/redis-memory-optimization-when-store-small-data.html)

  - 使用二进制存储：**32位数转成16位数存储**

  - 使用SET和HSET混合的数据组织方式

    先看两个很有意思的配置，是专门为小Hash做准备（使用HSET），当Hash中的条目小于512，并且每个value小于64个字节时，Redis内部采用特殊的编码方式，可以使内存平均节省5倍。

    > https://www.jianshu.com/p/8764a3e7b090
    
    > 如果该 Map 的成员数比较少，则会采用类似一维线性的紧凑格式来存储该 Map，即省去了大量指针的内存开销

    ```
    hash-max-ziplist-entries 512
    hash-max-ziplist-value 64
    ```

    **我们可以把key-value的结构拆解成key-smallhash这样的结构来降低内存的使用**

- 如何保证redis和DB中的数据一致性？

  > 如何保证缓存与数据库双写时的数据一致性?

  > 一般情况下我们都是这样使用缓存的：先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。这种方式很明显会存在缓存和数据库的数据不一致的情况。

  你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？

  一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况

  串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。

  > [https://blog.csdn.net/qq_27384769/article/details/79499373](https://blog.csdn.net/qq_27384769/article/details/79499373)

  **数据一致性的原因**

  写流程：

  1）先淘汰cache

  2）再写db

  读流程：

  1）先读cache，如果数据命中hit则返回

  2）如果数据未命中miss则读db

  3）将db中读取出来的数据入缓存

  什么情况下可能出现缓存和数据库中数据不一致呢？

  ![img](https://github.com/csy512889371/learnDoc/raw/master/image/2018/redis/3.png)

  在分布式环境下，数据的读写都是并发的，上游有多个应用，通过一个服务的多个部署（为了保证可用性，一定是部署多份的），对同一个数据进行读写，在数据库层面并发的读写并不能保证完成顺序，也就是说后发出的读请求很可能先完成（读出脏数据）：

  a）发生了写请求A，A的第一步淘汰了cache（如上图中的1）

  b）A的第二步写数据库，发出修改请求（如上图中的2）

  c）发生了读请求B，B的第一步读取cache，发现cache中是空的（如上图中的步骤3）

  d）B的第二步读取数据库，发出读取请求，此时A的第二步写数据还没完成，读出了一个脏数据放入cache（如上图中的步骤4）

  即在数据库层面，后发出的请求4比先发出的请求2先完成了，读出了脏数据，脏数据又入了缓存，缓存与数据库中的数据不一致出现了

  **问题解决思路**

  能否做到先发出的请求一定先执行完成呢？常见的思路是“串行化” 

  ![img](https://github.com/csy512889371/learnDoc/raw/master/image/2018/redis/4.png)

  上图是一个service服务的上下游及服务内部详细展开，细节如下：

  1）service的上游是多个业务应用，上游发起请求对同一个数据并发的进行读写操作，上例中并发进行了一个uid=1的余额修改（写）操作与uid=1的余额查询（读）操作

  2）service的下游是数据库DB，假设只读写一个DB

  3）中间是服务层service，它又分为了这么几个部分

  3.1）最上层是任务队列

  3.2）中间是工作线程，每个工作线程完成实际的工作任务，典型的工作任务是通过数据库连接池读写数据库

  3.3）最下层是数据库连接池，所有的SQL语句都是通过数据库连接池发往数据库去执行的

- 如何解决缓存穿透和缓存雪崩？

  > 缓存雪崩和缓存穿透问题解决方案

  **缓存雪崩**

  什么是缓存雪崩？
  
  缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

  解决方法：

  - 事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。
  - 事中：本地ehcache缓存 + hystrix限流&降级，避免MySQL崩掉
  - 事后：利用 redis 持久化机制保存的数据尽快恢复缓存

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-25/6078367.jpg)

  **缓存穿透**

  什么是缓存穿透？

  缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。下面用图片展示一下(这两张图片不是我画的，为了省事直接在网上找的，这里说明一下)：

  正常缓存处理流程：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E6%AD%A3%E5%B8%B8%E7%BC%93%E5%AD%98%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-redis.png)

  缓存穿透情况处理流程：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-redis.png)

  一般MySQL 默认的最大连接数在 150 左右，这个可以通过 `show variables like '%max_connections%';`命令来查看。最大连接数一个还只是一个指标，cpu，内存，磁盘，网络等物理条件都是其运行指标，这些指标都会限制其并发能力！所以，一般 3000 个并发请求就能打死大部分数据库了。

  有哪些解决办法？

  最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。

  1）缓存无效 key : 如果缓存和数据库都查不到某个 key 的数据就写一个到 redis 中去并设置过期时间，具体命令如下：SET key value EX 10086。这种方式可以解决请求的 key 变化不频繁的情况，如何黑客恶意攻击，每次构建的不同的请求key，会导致 redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。

  另外，这里多说一嘴，一般情况下我们是这样设计 key 的： 表名:列名:主键名:主键值。

  如果用 Java 代码展示的话，差不多是下面这样的：

  ```java
  public Object getObjectInclNullById(Integer id) {
    // 从缓存中获取数据
    Object cacheValue = cache.get(id);
    // 缓存为空
    if (cacheValue == null) {
        // 从数据库中获取
        Object storageValue = storage.get(key);
        // 缓存空对象
        cache.set(key, storageValue);
        // 如果存储数据为空，需要设置一个过期时间(300秒)
        if (storageValue == null) {
            // 必须设置过期时间，否则有被攻击的风险
            cache.expire(key, 60 * 5);
        }
        return storageValue;
    }
    return cacheValue;
  }
  ```

  2）布隆过滤器：布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在与海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，我会先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。总结一下就是下面这张图(这张图片不是我画的，为了省事直接在网上找的)：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-redis.png)

- 如何用redis实现分布式锁？

  **什么是 RedLock**

  Redis 官方站这篇文章提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性：

  1. 安全特性：互斥访问，即永远只有一个 client 能拿到锁
  2. 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区
  3. 容错性：只要大部分 Redis 节点存活就可以正常提供服务

  **怎么在单节点上实现分布式锁**

  > SET resource_name my_random_value NX PX 30000

  主要依靠上述命令，该命令仅当 Key 不存在时（NX保证）set 值，并且设置过期时间 3000ms （PX保证），值 my_random_value 必须是所有 client 和所有锁请求发生期间唯一的，释放锁的逻辑是：

  ```lua
  if redis.call("get",KEYS[1]) == ARGV[1] then
      return redis.call("del",KEYS[1])
  else
      return 0
  end
  ```

  上述实现可以避免释放另一个client创建的锁，如果只有 del 命令的话，那么如果 client1 拿到 lock1 之后因为某些操作阻塞了很长时间，此时 Redis 端 lock1 已经过期了并且已经被重新分配给了 client2，那么 client1 此时再去释放这把锁就会造成 client2 原本获取到的锁被 client1 无故释放了，但现在为每个 client 分配一个 unique 的 string 值可以避免这个问题。至于如何去生成这个 unique string，方法很多随意选择一种就行了。

  **Redlock 算法**

  算法很易懂，起 5 个 master 节点，分布在不同的机房尽量保证可用性。为了获得锁，client 会进行如下操作：

  1. 得到当前的时间，微秒单位
  2. 尝试顺序地在 5 个实例上申请锁，当然需要使用相同的 key 和 random value，这里一个 client 需要合理设置与 master 节点沟通的 timeout 大小，避免长时间和一个 fail 了的节点浪费时间
  3. 当 client 在大于等于 3 个 master 上成功申请到锁的时候，且它会计算申请锁消耗了多少时间，这部分消耗的时间采用获得锁的当下时间减去第一步获得的时间戳得到，如果锁的持续时长（lock validity time）比流逝的时间多的话，那么锁就真正获取到了。
  4. 如果锁申请到了，那么锁真正的 lock validity time 应该是 origin（lock validity time） - 申请锁期间流逝的时间
  5. 如果 client 申请锁失败了，那么它就会在少部分申请成功锁的 master 节点上执行释放锁的操作，重置状态

  **失败重试**

  如果一个 client 申请锁失败了，那么它需要稍等一会在重试避免多个 client 同时申请锁的情况，最好的情况是一个 client 需要几乎同时向 5 个 master 发起锁申请。另外就是如果 client 申请锁失败了它需要尽快在它曾经申请到锁的 master 上执行 unlock 操作，便于其他 client 获得这把锁，避免这些锁过期造成的时间浪费，当然如果这时候网络分区使得 client 无法联系上这些 master，那么这种浪费就是不得不付出的代价了。

  **放锁**

  放锁操作很简单，就是依次释放所有节点上的锁就行了

  **性能、崩溃恢复和 fsync**

  如果我们的节点没有持久化机制，client 从 5 个 master 中的 3 个处获得了锁，然后其中一个重启了，这时注意 **整个环境中又出现了 3 个 master 可供另一个 client 申请同一把锁！** 违反了互斥性。如果我们开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在 server 挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。但是考虑断电之后呢，AOF部分命令没来得及刷回磁盘直接丢失了，除非我们配置刷回策略为 fsnyc = always，但这会损伤性能。解决这个问题的方法是，当一个节点重启之后，我们规定在 max TTL 期间它是不可用的，这样它就不会干扰原本已经申请到的锁，等到它 crash 前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作。

## 系统设计

#### Spring

- Spring 教程

  > [https://wiki.jikexueyuan.com/project/spring/hello-world-example.html](<https://wiki.jikexueyuan.com/project/spring/hello-world-example.html>)

  - HelloWorld实例

    - 创建源文件

      这里是 **HelloWorld.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class HelloWorld {
         private String message;
         public void setMessage(String message){
            this.message  = message;
         }
         public void getMessage(){
            System.out.println("Your Message : " + message);
         }
      }
      ```

      下面是第二个文件 **MainApp.java** 的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = 
                   new ClassPathXmlApplicationContext("Beans.xml");
            HelloWorld obj = (HelloWorld) context.getBean("helloWorld");
            obj.getMessage();
         }
      }
      ```

      关于主要程序有以下两个要点需要注意：

      - 第一步是我们使用框架 API **ClassPathXmlApplicationContext()** 来创建应用程序的上下文。这个 API 加载 beans 的配置文件并最终基于所提供的 API，它处理创建并初始化所有的对象，即在配置文件中提到的 beans。
      - 第二步是使用已创建的上下文的 **getBean()** 方法来获得所需的 bean。这个方法使用 bean 的 ID 返回一个最终可以转换为实际对象的通用对象。一旦有了对象，你就可以使用这个对象调用任何类的方法。

    - 创建 bean 的配置文件

      Beans.xml 用于给不同的 bean 分配唯一的 ID，并且控制不同值的对象的创建，而不会影响 Spring 的任何源文件。例如，使用下面的文件，你可以为 “message” 变量传递任何值，因此你就可以输出信息的不同值，而不会影响的 HelloWorld.java和MainApp.java 文件。让我们来看看它是如何工作的：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <bean id="helloWorld" class="com.tutorialspoint.HelloWorld">
             <property name="message" value="Hello World!"/>
         </bean>
      
      </beans>
      ```

      当 Spring 应用程序被加载到内存中时，框架利用了上面的配置文件来创建所有已经定义的 beans，并且按照 标签的定义为它们分配一个唯一的 ID。你可以使用 标签来传递在创建对象时使用不同变量的值。

  - IoC容器

    Spring 容器是 Spring 框架的核心。容器将创建对象，把它们连接在一起，配置它们，并管理他们的整个生命周期从创建到销毁。Spring 容器使用依赖注入（DI）来管理组成一个应用程序的组件。这些对象被称为 Spring Beans。

    - Sping 的 BeanFactory 容器

      **例子**

      下面是文件 **MainApp.java** 的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.beans.factory.InitializingBean;
      import org.springframework.beans.factory.xml.XmlBeanFactory;
      import org.springframework.core.io.ClassPathResource;
      public class MainApp {
         public static void main(String[] args) {
            XmlBeanFactory factory = new XmlBeanFactory
                                   (new ClassPathResource("Beans.xml"));
            HelloWorld obj = (HelloWorld) factory.getBean("helloWorld");
            obj.getMessage();
         }
      }
      ```

      在主程序当中，我们需要注意以下两点：

      - 第一步利用框架提供的 **XmlBeanFactory()** API 去生成工厂 bean 以及利用 **ClassPathResource()** API 去加载在路径 CLASSPATH 下可用的 bean 配置文件。**XmlBeanFactory()** API 负责创建并初始化所有的对象，即在配置文件中提到的 bean。
      - 第二步利用第一步生成的 bean 工厂对象的 **getBean()** 方法得到所需要的 bean。 这个方法通过配置文件中的 bean ID 来返回一个真正的对象，该对象最后可以用于实际的对象。一旦得到这个对象，就可以利用这个对象来调用任何方法。

    - Spring ApplicationContext 容器

      最常被使用的 ApplicationContext 接口实现：

      - **FileSystemXmlApplicationContext**：该容器从 XML 文件中加载已被定义的 bean。在这里，你需要提供给构造器 XML 文件的完整路径
      - **ClassPathXmlApplicationContext**：该容器从 XML 文件中加载已被定义的 bean。在这里，你不需要提供 XML 文件的完整路径，只需正确配置 CLASSPATH 环境变量即可，因为，容器会从 CLASSPATH 中搜索 bean 配置文件。
      - **WebXmlApplicationContext**：该容器会在一个 web 应用程序的范围内加载在 XML 文件中已被定义的 bean。

      **例子**

      下面是文件 **MainApp.java** 的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.FileSystemXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = new FileSystemXmlApplicationContext
                  ("C:/Users/ZARA/workspace/HelloSpring/src/Beans.xml");
            HelloWorld obj = (HelloWorld) context.getBean("helloWorld");
            obj.getMessage();
         }
      }
      ```

      在主程序当中，我们需要注意以下两点：

      - 第一步生成工厂对象。加载完指定路径下 bean 配置文件后，利用框架提供的 **FileSystemXmlApplicationContext** API 去生成工厂 bean。**FileSystemXmlApplicationContext** 负责生成和初始化所有的对象，比如，所有在 XML bean 配置文件中的 bean。
      - 第二步利用第一步生成的上下文中的 **getBean()** 方法得到所需要的 bean。 这个方法通过配置文件中的 bean ID 来返回一个真正的对象。一旦得到这个对象，就可以利用这个对象来调用任何方法。

  - Bean 定义

    被称作 bean 的对象是构成应用程序的支柱也是由 Spring IoC 容器管理的。bean 是一个被实例化，组装，并通过 Spring IoC 容器所管理的对象。这些 bean 是由用容器提供的配置元数据创建的，例如，已经在先前章节看到的，在 XML 的表单中的 定义。

    bean 定义包含称为**配置元数据**的信息，容器也需要知道下述配置元数据：

    - 如何创建一个 bean
    - bean 的生命周期的详细信息
    - bean 的依赖关系

    上述所有的配置元数据转换成一组构成每个 bean 定义的下列属性。

    | 属性                     | 描述                                                         |
    | ------------------------ | ------------------------------------------------------------ |
    | class                    | 这个属性是强制性的，并且指定用来创建 bean 的 bean 类。       |
    | name                     | 这个属性指定唯一的 bean 标识符。在基于 XML 的配置元数据中，你可以使用 ID 和/或 name 属性来指定 bean 标识符。 |
    | scope                    | 这个属性指定由特定的 bean 定义创建的对象的作用域，它将会在 bean 作用域的章节中进行讨论。 |
    | constructor-arg          | 它是用来注入依赖关系的，并会在接下来的章节中进行讨论。       |
    | properties               | 它是用来注入依赖关系的，并会在接下来的章节中进行讨论。       |
    | autowiring mode          | 它是用来注入依赖关系的，并会在接下来的章节中进行讨论。       |
    | lazy-initialization mode | 延迟初始化的 bean 告诉 IoC 容器在它第一次被请求时，而不是在启动时去创建一个 bean 实例。 |
    | initialization 方法      | 在 bean 的所有必需的属性被容器设置之后，调用回调方法。它将会在 bean 的生命周期章节中进行讨论。 |
    | destruction 方法         | 当包含该 bean 的容器被销毁时，使用回调方法。它将会在 bean 的生命周期章节中进行讨论。 |

  - Bean 的作用域

    当在 Spring 中定义一个 时，你必须声明该 bean 的作用域的选项。例如，为了强制 Spring 在每次需要时都产生一个新的 bean 实例，你应该声明 bean 的作用域的属性为 **prototype**。同理，如果你想让 Spring 在每次需要时都返回同一个bean实例，你应该声明 bean 的作用域的属性为 **singleton**。

    Spring 框架支持以下五个作用域，如果你使用 web-aware ApplicationContext 时，其中三个是可用的。

    | 作用域         | 描述                                                         |
    | -------------- | ------------------------------------------------------------ |
    | singleton      | 该作用域将 bean 的定义的限制在每一个 Spring IoC 容器中的一个单一实例(默认)。 |
    | prototype      | 该作用域将单一 bean 的定义限制在任意数量的对象实例。         |
    | request        | 该作用域将 bean 的定义限制为 HTTP 请求。只在 web-aware Spring ApplicationContext 的上下文中有效。 |
    | session        | 该作用域将 bean 的定义限制为 HTTP 会话。 只在web-aware Spring ApplicationContext的上下文中有效。 |
    | global-session | 该作用域将 bean 的定义限制为全局 HTTP 会话。只在 web-aware Spring ApplicationContext 的上下文中有效。 |

    **singleton 作用域：**

    如果作用域设置为 singleton，那么 Spring IoC 容器刚好创建一个由该 bean 定义的对象的实例。该单一实例将存储在这种单例 bean 的高速缓存中，以及针对该 bean 的所有后续的请求和引用都返回缓存对象。

    默认作用域是始终是 singleton，但是当仅仅需要 bean 的一个实例时，你可以在 bean 的配置文件中设置作用域的属性为 singleton，如下所示：

    ```xml
    <!-- A bean definition with singleton scope -->
    <bean id="..." class="..." scope="singleton">
        <!-- collaborators and configuration for this bean go here -->
    </bean>
    ```

    **例子**

    下面是 MainApp.java 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationContext;
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    public class MainApp {
       public static void main(String[] args) {
          ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
          HelloWorld objA = (HelloWorld) context.getBean("helloWorld");
          objA.setMessage("I'm object A");
          objA.getMessage();
          HelloWorld objB = (HelloWorld) context.getBean("helloWorld");
          objB.getMessage();
       }
    }
    ```

    下面是 singleton 作用域必需的配置文件 **Beans.xml**：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="helloWorld" class="com.tutorialspoint.HelloWorld" 
          scope="singleton">
       </bean>
    
    </beans>
    ```

    一旦你创建源代码和 bean 配置文件完成后，我们就可以运行该应用程序。如果你的应用程序一切都正常，将输出以下信息：

    ```
    Your Message : I'm object A
    Your Message : I'm object A
    ```

    **prototype 作用域**

    如果作用域设置为 prototype，那么每次特定的 bean 发出请求时 Spring IoC 容器就创建对象的新的 Bean 实例。一般说来，满状态的 bean 使用 prototype 作用域和没有状态的 bean 使用 singleton 作用域。

    为了定义 prototype 作用域，你可以在 bean 的配置文件中设置作用域的属性为 prototype，如下所示：

    ```xml
    <!-- A bean definition with singleton scope -->
    <bean id="..." class="..." scope="prototype">
       <!-- collaborators and configuration for this bean go here -->
    </bean>
    ```

    **例子**

    面是 **MainApp.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationContext;
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    public class MainApp {
       public static void main(String[] args) {
          ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
          HelloWorld objA = (HelloWorld) context.getBean("helloWorld");
          objA.setMessage("I'm object A");
          objA.getMessage();
          HelloWorld objB = (HelloWorld) context.getBean("helloWorld");
          objB.getMessage();
       }
    }
    ```

    下面是 **prototype** 作用域必需的配置文件 Beans.xml：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="helloWorld" class="com.tutorialspoint.HelloWorld" 
          scope="prototype">
       </bean>
    
    </beans>
    ```

    一旦你创建源代码和 Bean 配置文件完成后，我们就可以运行该应用程序。如果你的应用程序一切都正常，将输出以下信息：

    ```
    Your Message : I'm object A
    Your Message : null
    ```

  - Bean 的生命周期

    理解 Spring bean 的生命周期很容易。当一个 bean 被实例化时，它可能需要执行一些初始化使它转换成可用状态。同样，当 bean 不再需要，并且从容器中移除时，可能需要做一些清除工作。

    为了定义安装和拆卸一个 bean，我们只要声明带有 **init-method** 和/或 **destroy-method** 参数的 。init-method 属性指定一个方法，在实例化 bean 时，立即调用该方法。同样，destroy-method 指定一个方法，只有从容器中移除 bean 之后，才能调用该方法。

    **初始化回调**

    *org.springframework.beans.factory.InitializingBean* 接口指定一个单一的方法：

    ```java
    void afterPropertiesSet() throws Exception;
    ```

    因此，你可以简单地实现上述接口和初始化工作可以在 afterPropertiesSet() 方法中执行，如下所示：

    ```java
    public class ExampleBean implements InitializingBean {
       public void afterPropertiesSet() {
          // do some initialization work
       }
    }
    ```

    在基于 XML 的配置元数据的情况下，你可以使用 **init-method** 属性来指定带有 void 无参数方法的名称。例如：

    ```xml
    <bean id="exampleBean" 
             class="examples.ExampleBean" init-method="init"/>
    ```

    下面是类的定义：

    ```java
    public class ExampleBean {
       public void init() {
          // do some initialization work
       }
    }
    ```

    **销毁回调**

    *org.springframework.beans.factory.DisposableBean* 接口指定一个单一的方法：

    ```java
    void destroy() throws Exception;
    ```

    因此，你可以简单地实现上述接口并且结束工作可以在 destroy() 方法中执行，如下所示：

    ```java
    public class ExampleBean implements DisposableBean {
       public void destroy() {
          // do some destruction work
       }
    }
    ```

    在基于 XML 的配置元数据的情况下，你可以使用 **destroy-method** 属性来指定带有 void 无参数方法的名称。例如：

    ```xml
    <bean id="exampleBean"
             class="examples.ExampleBean" destroy-method="destroy"/>
    ```

    下面是类的定义：

    ```java
    public class ExampleBean {
       public void destroy() {
          // do some destruction work
       }
    }
    ```

    建议你不要使用 InitializingBean 或者 DisposableBean 的回调方法，因为 XML 配置在命名方法上提供了极大的灵活性。

    **例子**

    这里是 **HelloWorld.java** 的文件的内容：

    ```java
    package com.tutorialspoint;
    
    public class HelloWorld {
       private String message;
    
       public void setMessage(String message){
          this.message  = message;
       }
       public void getMessage(){
          System.out.println("Your Message : " + message);
       }
       public void init(){
          System.out.println("Bean is going through init.");
       }
       public void destroy(){
          System.out.println("Bean will destroy now.");
       }
    }
    ```

    下面是 **MainApp.java** 文件的内容。在这里，你需要注册一个在 AbstractApplicationContext 类中声明的关闭 hook 的 **registerShutdownHook()** 方法。它将确保正常关闭，并且调用相关的 destroy 方法。

    ```java
    package com.tutorialspoint;
    import org.springframework.context.support.AbstractApplicationContext;
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    public class MainApp {
       public static void main(String[] args) {
          AbstractApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
          HelloWorld obj = (HelloWorld) context.getBean("helloWorld");
          obj.getMessage();
          context.registerShutdownHook();
       }
    }
    ```

    下面是 init 和 destroy 方法必需的配置文件 **Beans.xml** 文件：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="helloWorld" 
           class="com.tutorialspoint.HelloWorld"
           init-method="init" destroy-method="destroy">
           <property name="message" value="Hello World!"/>
       </bean>
    
    </beans>
    ```

    一旦你创建源代码和 bean 配置文件完成后，我们就可以运行该应用程序。如果你的应用程序一切都正常，将输出以下信息：

    ```
    Bean is going through init.
    Your Message : Hello World!
    Bean will destroy now.
    ```

    **默认的初始化和销毁方法**

    如果你有太多具有相同名称的初始化或者销毁方法的 Bean，那么你不需要在每一个 bean 上声明**初始化方法**和**销毁方法**。框架使用 元素中的 **default-init-method** 和 **default-destroy-method** 属性提供了灵活地配置这种情况，如下所示：

    ```xml
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"
        default-init-method="init" 
        default-destroy-method="destroy">
    
       <bean id="..." class="...">
           <!-- collaborators and configuration for this bean go here -->
       </bean>
    
    </beans>
    ```

  - Bean 后置处理器

    **BeanPostProcessor** 接口定义回调方法，你可以实现该方法来提供自己的实例化逻辑，依赖解析逻辑等。你也可以在 Spring 容器通过插入一个或多个 BeanPostProcessor 的实现来完成实例化，配置和初始化一个bean之后实现一些自定义逻辑回调方法。

    你可以配置多个 BeanPostProcessor接口，通过设置 BeanPostProcessor 实现的 **Ordered** 接口提供的 **order** 属性来控制这些 BeanPostProcessor 接口的执行顺序。

    BeanPostProcessor 可以对 bean（或对象）实例进行操作，这意味着 Spring IoC 容器实例化一个 bean 实例，然后 BeanPostProcessor 接口进行它们的工作。

    **ApplicationContext** 会自动检测由 **BeanPostProcessor** 接口的实现定义的 bean，注册这些 bean 为后置处理器，然后通过在容器中创建 bean，在适当的时候调用它。

    这里是 **HelloWorld.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    public class HelloWorld {
       private String message;
       public void setMessage(String message){
          this.message  = message;
       }
       public void getMessage(){
          System.out.println("Your Message : " + message);
       }
       public void init(){
          System.out.println("Bean is going through init.");
       }
       public void destroy(){
          System.out.println("Bean will destroy now.");
       }
    }
    ```

    这是实现 BeanPostProcessor 的非常简单的例子，它在任何 bean 的初始化的之前和之后输入该 bean 的名称。你可以在初始化 bean 的之前和之后实现更复杂的逻辑，因为你有两个访问内置 bean 对象的后置处理程序的方法。

    这里是 **InitHelloWorld.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.beans.factory.config.BeanPostProcessor;
    import org.springframework.beans.BeansException;
    public class InitHelloWorld implements BeanPostProcessor {
       public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
          System.out.println("BeforeInitialization : " + beanName);
          return bean;  // you can return any other object as well
       }
       public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
          System.out.println("AfterInitialization : " + beanName);
          return bean;  // you can return any other object as well
       }
    }
    ```

    下面是 **MainApp.java** 文件的内容。在这里，你需要注册一个在 AbstractApplicationContext 类中声明的关闭 hook 的 **registerShutdownHook()** 方法。它将确保正常关闭，并且调用相关的 destroy 方法。

    ```java
    package com.tutorialspoint;
    import org.springframework.context.support.AbstractApplicationContext;
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    public class MainApp {
       public static void main(String[] args) {
          AbstractApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
          HelloWorld obj = (HelloWorld) context.getBean("helloWorld");
          obj.getMessage();
          context.registerShutdownHook();
       }
    }
    ```

    下面是 init 和 destroy 方法需要的配置文件 **Beans.xml** 文件：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="helloWorld" class="com.tutorialspoint.HelloWorld"
           init-method="init" destroy-method="destroy">
           <property name="message" value="Hello World!"/>
       </bean>
    
       <bean class="com.tutorialspoint.InitHelloWorld" />
    
    </beans>
    ```

    一旦你创建源代码和 bean 配置文件完成后，我们就可以运行该应用程序。如果你的应用程序一切都正常，将输出以下信息：

    ```
    BeforeInitialization : helloWorld
    Bean is going through init.
    AfterInitialization : helloWorld
    Your Message : Hello World!
    Bean will destroy now.
    ```

  - Bean 定义继承

    bean 定义可以包含很多的配置信息，包括构造函数的参数，属性值，容器的具体信息例如初始化方法，静态工厂方法名，等等。

    子 bean 的定义继承父定义的配置数据。子定义可以根据需要重写一些值，或者添加其他值。

    Spring Bean 定义的继承与 Java 类的继承无关，但是继承的概念是一样的。你可以定义一个父 bean 的定义作为模板和其他子 bean 就可以从父 bean 中继承所需的配置。

    当你使用基于 XML 的配置元数据时，通过使用父属性，指定父 bean 作为该属性的值来表明子 bean 的定义。

    **例子**

    下面是配置文件 **Beans.xml**，在该配置文件中我们定义有两个属性 *message1* 和 *message2* 的 “helloWorld” bean。然后，使用 **parent** 属性把 “helloIndia” bean 定义为 “helloWorld” bean 的孩子。这个子 bean 继承 *message2* 的属性，重写 *message1* 的属性，并且引入一个属性 *message3*。

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="helloWorld" class="com.tutorialspoint.HelloWorld">
          <property name="message1" value="Hello World!"/>
          <property name="message2" value="Hello Second World!"/>
       </bean>
    
       <bean id="helloIndia" class="com.tutorialspoint.HelloIndia" parent="helloWorld">
          <property name="message1" value="Hello India!"/>
          <property name="message3" value="Namaste India!"/>
       </bean>
    
    </beans>
    ```

    这里是 **HelloWorld.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    public class HelloWorld {
       private String message1;
       private String message2;
       public void setMessage1(String message){
          this.message1  = message;
       }
       public void setMessage2(String message){
          this.message2  = message;
       }
       public void getMessage1(){
          System.out.println("World Message1 : " + message1);
       }
       public void getMessage2(){
          System.out.println("World Message2 : " + message2);
       }
    }
    ```

    这里是 **HelloIndia.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    
    public class HelloIndia {
       private String message1;
       private String message2;
       private String message3;
    
       public void setMessage1(String message){
          this.message1  = message;
       }
    
       public void setMessage2(String message){
          this.message2  = message;
       }
    
       public void setMessage3(String message){
          this.message3  = message;
       }
    
       public void getMessage1(){
          System.out.println("India Message1 : " + message1);
       }
    
       public void getMessage2(){
          System.out.println("India Message2 : " + message2);
       }
    
       public void getMessage3(){
          System.out.println("India Message3 : " + message3);
       }
    }
    ```

    下面是 **MainApp.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    
    import org.springframework.context.ApplicationContext;
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    
    public class MainApp {
       public static void main(String[] args) {
          ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
    
          HelloWorld objA = (HelloWorld) context.getBean("helloWorld");
    
          objA.getMessage1();
          objA.getMessage2();
    
          HelloIndia objB = (HelloIndia) context.getBean("helloIndia");
          objB.getMessage1();
          objB.getMessage2();
          objB.getMessage3();
       }
    }
    ```

    一旦你创建源代码和 bean 配置文件完成后，我们就可以运行该应用程序。如果你的应用程序一切都正常，将输出以下信息：

    ```
    World Message1 : Hello World!
    World Message2 : Hello Second World!
    India Message1 : Hello India!
    India Message2 : Hello Second World!
    India Message3 : Namaste India!
    ```

    在这里你可以观察到，我们创建 “helloIndia” bean 的同时并没有传递 message2，但是由于 Bean 定义的继承，所以它传递了 message2。

    **Bean 定义模板**

    你可以创建一个 Bean 定义模板，不需要花太多功夫它就可以被其他子 bean 定义使用。在定义一个 Bean 定义模板时，你不应该指定**类**的属性，而应该指定带 **true** 值的**抽象**属性，如下所示：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="beanTeamplate" abstract="true">
          <property name="message1" value="Hello World!"/>
          <property name="message2" value="Hello Second World!"/>
          <property name="message3" value="Namaste India!"/>
       </bean>
    
       <bean id="helloIndia" class="com.tutorialspoint.HelloIndia" parent="beanTeamplate">
          <property name="message1" value="Hello India!"/>
          <property name="message3" value="Namaste India!"/>
       </bean>
    
    </beans>
    ```

    父 bean 自身不能被实例化，因为它是不完整的，而且它也被明确地标记为抽象的。当一个定义是抽象的，它仅仅作为一个纯粹的模板 bean 定义来使用的，充当子定义的父定义使用。

  - 依赖注入

    每个基于应用程序的 java 都有几个对象，这些对象一起工作来呈现出终端用户所看到的工作的应用程序。当编写一个复杂的 Java 应用程序时，应用程序类应该尽可能独立于其他 Java 类来增加这些类重用的可能性，并且在做单元测试时，测试独立于其他类的独立性。依赖注入（或有时称为布线）有助于把这些类粘合在一起，同时保持他们独立。

    假设你有一个包含文本编辑器组件的应用程序，并且你想要提供拼写检查。标准代码看起来是这样的：

    ```java
    public class TextEditor {
       private SpellChecker spellChecker;  
       public TextEditor() {
          spellChecker = new SpellChecker();
       }
    }
    ```

    在这里我们所做的就是创建一个 TextEditor 和 SpellChecker 之间的依赖关系。在控制反转的场景中，我们反而会做这样的事情：

    ```java
    public class TextEditor {
       private SpellChecker spellChecker;
       public TextEditor(SpellChecker spellChecker) {
          this.spellChecker = spellChecker;
       }
    }
    ```

    在这里，TextEditor 不应该担心 SpellChecker 的实现。SpellChecker 将会独立实现，并且在 TextEditor 实例化的时候将提供给 TextEditor，整个过程是由 Spring 框架的控制。

    在这里，我们已经从 TextEditor 中删除了全面控制，并且把它保存到其他地方（即 XML 配置文件），且依赖关系（即 SpellChecker 类）通过**类构造函数**被注入到 TextEditor 类中。因此，控制流通过依赖注入（DI）已经“反转”，因为你已经有效地委托依赖关系到一些外部系统。

    依赖注入的第二种方法是通过 TextEditor 类的 **Setter 方法**，我们将创建 SpellChecker 实例，该实例将被用于调用 setter 方法来初始化 TextEditor 的属性。

    - Spring 基于构造函数的依赖注入

      当容器调用带有一组参数的类构造函数时，基于构造函数的 DI 就完成了，其中每个参数代表一个对其他类的依赖。

      这是 **TextEditor.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class TextEditor {
         private SpellChecker spellChecker;
         public TextEditor(SpellChecker spellChecker) {
            System.out.println("Inside TextEditor constructor." );
            this.spellChecker = spellChecker;
         }
         public void spellCheck() {
            spellChecker.checkSpelling();
         }
      }
      ```

      下面是另一个依赖类文件 **SpellChecker.java** 的内容：

      ```java
      package com.tutorialspoint;
      public class SpellChecker {
         public SpellChecker(){
            System.out.println("Inside SpellChecker constructor." );
         }
         public void checkSpelling() {
            System.out.println("Inside checkSpelling." );
         } 
      }
      ```

      以下是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = 
                   new ClassPathXmlApplicationContext("Beans.xml");
            TextEditor te = (TextEditor) context.getBean("textEditor");
            te.spellCheck();
         }
      }
      ```

      下面是配置文件 **Beans.xml** 的内容，它有基于构造函数注入的配置：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor">
            <constructor-arg ref="spellChecker"/>
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      当你完成了创建源和 bean 配置文件后，让我们开始运行应用程序。如果你的应用程序运行顺利的话，那么将会输出下述所示消息：

      ```
      Inside SpellChecker constructor.
      Inside TextEditor constructor.
      Inside checkSpelling.
      ```

      **构造函数参数解析:**

      如果存在不止一个参数时，当把参数传递给构造函数时，可能会存在歧义。要解决这个问题，那么构造函数的参数在 bean 定义中的顺序就是把这些参数提供给适当的构造函数的顺序就可以了。考虑下面的类:

      ```java
      package x.y;
      public class Foo {
         public Foo(Bar bar, Baz baz) {
            // ...
         }
      }
      ```

      下述配置文件工作顺利：

      ```xml
      <beans>
         <bean id="foo" class="x.y.Foo">
            <constructor-arg ref="bar"/>
            <constructor-arg ref="baz"/>
         </bean>
      
         <bean id="bar" class="x.y.Bar"/>
         <bean id="baz" class="x.y.Baz"/>
      </beans>
      ```

      让我们再检查一下我们传递给构造函数不同类型的位置。考虑下面的类：

      ```java
      package x.y;
      public class Foo {
         public Foo(int year, String name) {
            // ...
         }
      }
      ```

      如果你使用 type 属性显式的指定了构造函数参数的类型，容器也可以使用与简单类型匹配的类型。例如：

      ```xml
      <beans>
      
         <bean id="exampleBean" class="examples.ExampleBean">
            <constructor-arg type="int" value="2001"/>
            <constructor-arg type="java.lang.String" value="Zara"/>
         </bean>
      
      </beans>
      ```

      最后并且也是最好的传递构造函数参数的方式，使用 index 属性来显式的指定构造函数参数的索引。下面是基于索引为 0 的例子，如下所示：

      ```xml
      <beans>
      
         <bean id="exampleBean" class="examples.ExampleBean">
            <constructor-arg index="0" value="2001"/>
            <constructor-arg index="1" value="Zara"/>
         </bean>
      
      </beans>
      ```

      最后，如果你想要向一个对象传递一个引用，你需要使用 标签的 **ref** 属性，如果你想要直接传递值，那么你应该使用如上所示的 **value** 属性。

    - Spring 基于设值函数的依赖注入

      当容器调用一个无参的构造函数或一个无参的静态 factory 方法来初始化你的 bean 后，通过容器在你的 bean 上调用设值函数，基于设值函数的 DI 就完成了。

      下面是 **TextEditor.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class TextEditor {
         private SpellChecker spellChecker;
         // a setter method to inject the dependency.
         public void setSpellChecker(SpellChecker spellChecker) {
            System.out.println("Inside setSpellChecker." );
            this.spellChecker = spellChecker;
         }
         // a getter method to return spellChecker
         public SpellChecker getSpellChecker() {
            return spellChecker;
         }
         public void spellCheck() {
            spellChecker.checkSpelling();
         }
      }
      ```

      在这里，你需要检查设值函数方法的名称转换。要设置一个变量 **spellChecker**，我们使用 **setSpellChecker()** 方法，该方法与 Java POJO 类非常相似。让我们创建另一个依赖类文件 **SpellChecker.java** 的内容：

      ```java
      package com.tutorialspoint;
      public class SpellChecker {
         public SpellChecker(){
            System.out.println("Inside SpellChecker constructor." );
         }
         public void checkSpelling() {
            System.out.println("Inside checkSpelling." );
         }  
      }
      ```

      以下是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = 
                   new ClassPathXmlApplicationContext("Beans.xml");
            TextEditor te = (TextEditor) context.getBean("textEditor");
            te.spellCheck();
         }
      }
      ```

      下面是配置文件 **Beans.xml** 的内容，该文件有基于设值函数注入的配置：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor">
            <property name="spellChecker" ref="spellChecker"/>
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      你应该注意定义在基于构造函数注入和基于设值函数注入中的 Beans.xml 文件的区别。唯一的区别就是在基于构造函数注入中，我们使用的是〈bean〉标签中的〈constructor-arg〉元素，而在基于设值函数的注入中，我们使用的是〈bean〉标签中的〈property〉元素。

      第二个你需要注意的点是，如果你要把一个引用传递给一个对象，那么你需要使用 标签的 **ref** 属性，而如果你要直接传递一个值，那么你应该使用 **value** 属性。

      当你完成了创建源和 bean 配置文件后，让我们开始运行应用程序。如果你的应用程序运行顺利的话，那么将会输出下述所示消息：

      ```
      Inside SpellChecker constructor.
      Inside setSpellChecker.
      Inside checkSpelling.
      ```

      **使用 p-namespace 实现 XML 配置：**

      如果你有许多的设值函数方法，那么在 XML 配置文件中使用 **p-namespace** 是非常方便的。让我们查看一下区别：

      以带有 标签的标准 XML 配置文件为例：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <bean id="john-classic" class="com.example.Person">
            <property name="name" value="John Doe"/>
            <property name="spouse" ref="jane"/>
         </bean>
      
         <bean name="jane" class="com.example.Person">
            <property name="name" value="John Doe"/>
         </bean>
      
      </beans>
      ```

      上述 XML 配置文件可以使用 **p-namespace** 以一种更简洁的方式重写，如下所示：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:p="http://www.springframework.org/schema/p"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <bean id="john-classic" class="com.example.Person"
            p:name="John Doe"
            p:spouse-ref="jane"/>
         </bean>
      
         <bean name="jane" class="com.example.Person"
            p:name="John Doe"/>
         </bean>
      
      </beans>
      ```

      在这里，你不应该区别指定原始值和带有 p-namespace 的对象引用。**-ref** 部分表明这不是一个直接的值，而是对另一个 bean 的引用。

  - 注入内部 Beans

    正如你所知道的 Java 内部类是在其他类的范围内被定义的，同理，**inner beans** 是在其他 bean 的范围内定义的 bean。因此在元素内的元素被称为内部bean，如下所示。

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="outerBean" class="...">
          <property name="target">
             <bean id="innerBean" class="..."/>
          </property>
       </bean>
    
    </beans>
    ```

    **例子**

    这里是 **TextEditor.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    public class TextEditor {
       private SpellChecker spellChecker;
       // a setter method to inject the dependency.
       public void setSpellChecker(SpellChecker spellChecker) {
          System.out.println("Inside setSpellChecker." );
          this.spellChecker = spellChecker;
       }  
       // a getter method to return spellChecker
       public SpellChecker getSpellChecker() {
          return spellChecker;
       }
       public void spellCheck() {
          spellChecker.checkSpelling();
       }
    }
    ```

    下面是另一个依赖的类文件 **SpellChecker.java** 内容：

    ```java
    package com.tutorialspoint;
    public class SpellChecker {
       public SpellChecker(){
          System.out.println("Inside SpellChecker constructor." );
       }
       public void checkSpelling(){
          System.out.println("Inside checkSpelling." );
       }   
    }
    ```

    下面是 **MainApp.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationContext;
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    public class MainApp {
       public static void main(String[] args) {
          ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
          TextEditor te = (TextEditor) context.getBean("textEditor");
          te.spellCheck();
       }
    }
    ```

    下面是使用**内部 bean** 为基于 setter 注入进行配置的配置文件 **Beans.xml** 文件：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <!-- Definition for textEditor bean using inner bean -->
       <bean id="textEditor" class="com.tutorialspoint.TextEditor">
          <property name="spellChecker">
             <bean id="spellChecker" class="com.tutorialspoint.SpellChecker"/>
           </property>
       </bean>
    
    </beans>
    ```

    一旦你创建源代码和 bean 配置文件完成后，我们就可以运行该应用程序。如果你的应用程序一切都正常，将输出以下信息：

    ```
    Inside SpellChecker constructor.
    Inside setSpellChecker.
    Inside checkSpelling.
    ```

  - 注入集合

    你已经看到了如何使用 **value** 属性来配置基本数据类型和在你的 bean 配置文件中使用 标签的 **ref** 属性来配置对象引用。这两种情况下处理奇异值传递给一个 bean。

    现在如果你想传递多个值，如 Java Collection 类型 List、Set、Map 和 Properties，应该怎么做呢。为了处理这种情况，Spring 提供了四种类型的集合的配置元素，如下所示：

    | 元素    | 描述                                                        |
    | ------- | ----------------------------------------------------------- |
    | <list>  | 它有助于连线，如注入一列值，允许重复。                      |
    | <set>   | 它有助于连线一组值，但不能重复。                            |
    | <map>   | 它可以用来注入名称-值对的集合，其中名称和值可以是任何类型。 |
    | <props> | 它可以用来注入名称-值对的集合，其中名称和值都是字符串类型。 |

    你可以使用 或 来连接任何 java.util.Collection 的实现或数组。

    你会遇到两种情况（a）传递集合中直接的值（b）传递一个 bean 的引用作为集合的元素。

    **例子**

    这里是 **JavaCollection.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import java.util.*;
    public class JavaCollection {
       List addressList;
       Set  addressSet;
       Map  addressMap;
       Properties addressProp;
       // a setter method to set List
       public void setAddressList(List addressList) {
          this.addressList = addressList;
       }
       // prints and returns all the elements of the list.
       public List getAddressList() {
          System.out.println("List Elements :"  + addressList);
          return addressList;
       }
       // a setter method to set Set
       public void setAddressSet(Set addressSet) {
          this.addressSet = addressSet;
       }
       // prints and returns all the elements of the Set.
       public Set getAddressSet() {
          System.out.println("Set Elements :"  + addressSet);
          return addressSet;
       }
       // a setter method to set Map
       public void setAddressMap(Map addressMap) {
          this.addressMap = addressMap;
       }  
       // prints and returns all the elements of the Map.
       public Map getAddressMap() {
          System.out.println("Map Elements :"  + addressMap);
          return addressMap;
       }
       // a setter method to set Property
       public void setAddressProp(Properties addressProp) {
          this.addressProp = addressProp;
       } 
       // prints and returns all the elements of the Property.
       public Properties getAddressProp() {
          System.out.println("Property Elements :"  + addressProp);
          return addressProp;
       }
    }
    ```

    下面是 **MainApp.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationContext;
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    public class MainApp {
       public static void main(String[] args) {
          ApplicationContext context = 
                 new ClassPathXmlApplicationContext("Beans.xml");
          JavaCollection jc=(JavaCollection)context.getBean("javaCollection");
          jc.getAddressList();
          jc.getAddressSet();
          jc.getAddressMap();
          jc.getAddressProp();
       }
    }
    ```

    下面是配置所有类型的集合的配置文件 **Beans.xml** 文件：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <!-- Definition for javaCollection -->
       <bean id="javaCollection" class="com.tutorialspoint.JavaCollection">
    
          <!-- results in a setAddressList(java.util.List) call -->
          <property name="addressList">
             <list>
                <value>INDIA</value>
                <value>Pakistan</value>
                <value>USA</value>
                <value>USA</value>
             </list>
          </property>
    
          <!-- results in a setAddressSet(java.util.Set) call -->
          <property name="addressSet">
             <set>
                <value>INDIA</value>
                <value>Pakistan</value>
                <value>USA</value>
                <value>USA</value>
            </set>
          </property>
    
          <!-- results in a setAddressMap(java.util.Map) call -->
          <property name="addressMap">
             <map>
                <entry key="1" value="INDIA"/>
                <entry key="2" value="Pakistan"/>
                <entry key="3" value="USA"/>
                <entry key="4" value="USA"/>
             </map>
          </property>
    
          <!-- results in a setAddressProp(java.util.Properties) call -->
          <property name="addressProp">
             <props>
                <prop key="one">INDIA</prop>
                <prop key="two">Pakistan</prop>
                <prop key="three">USA</prop>
                <prop key="four">USA</prop>
             </props>
          </property>
    
       </bean>
    
    </beans>
    ```

    一旦你创建源代码和 bean 配置文件完成后，我们就可以运行该应用程序。你应该注意这里不需要配置文件。如果你的应用程序一切都正常，将输出以下信息：

    ```
    List Elements :[INDIA, Pakistan, USA, USA]
    Set Elements :[INDIA, Pakistan, USA]
    Map Elements :{1=INDIA, 2=Pakistan, 3=USA, 4=USA}
    Property Elements :{two=Pakistan, one=INDIA, three=USA, four=USA}
    ```

    **注入 Bean 引用**

    下面的 Bean 定义将帮助你理解如何注入 bean 的引用作为集合的元素。甚至你可以将引用和值混合在一起，如下所示：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <!-- Bean Definition to handle references and values -->
       <bean id="..." class="...">
    
          <!-- Passing bean reference  for java.util.List -->
          <property name="addressList">
             <list>
                <ref bean="address1"/>
                <ref bean="address2"/>
                <value>Pakistan</value>
             </list>
          </property>
    
          <!-- Passing bean reference  for java.util.Set -->
          <property name="addressSet">
             <set>
                <ref bean="address1"/>
                <ref bean="address2"/>
                <value>Pakistan</value>
             </set>
          </property>
    
          <!-- Passing bean reference  for java.util.Map -->
          <property name="addressMap">
             <map>
                <entry key="one" value="INDIA"/>
                <entry key ="two" value-ref="address1"/>
                <entry key ="three" value-ref="address2"/>
             </map>
          </property>
    
       </bean>
    
    </beans>
    ```

    为了使用上面的 bean 定义，你需要定义 setter 方法，它们应该也能够是用这种方式来处理引用。

    **注入 null 和空字符串的值**

    如果你需要传递一个空字符串作为值，那么你可以传递它，如下所示：

    ```xml
    <bean id="..." class="exampleBean">
       <property name="email" value=""/>
    </bean>
    ```

    前面的例子相当于 Java 代码：exampleBean.setEmail("")。

    如果你需要传递一个 NULL 值，那么你可以传递它，如下所示：

    ```xml
    <bean id="..." class="exampleBean">
       <property name="email"><null/></property>
    </bean>
    ```

    前面的例子相当于 Java 代码：exampleBean.setEmail(null)。

  - Beans 自动装配

    Spring 容器可以在不使用 <constructor-arg> 和 <property> 元素的情况下**自动装配**相互协作的 bean 之间的关系，这有助于减少编写一个大的基于 Spring 的应用程序的 XML 配置的数量。

    **自动装配模式**

    下列自动装配模式，它们可用于指示 Spring 容器为来使用自动装配进行依赖注入。你可以使用 元素的 **autowire** 属性为一个 bean 定义指定自动装配模式。

    | 模式                                                         | 描述                                                         |
    | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | no                                                           | 这是默认的设置，它意味着没有自动装配，你应该使用显式的bean引用来连线。你不用为了连线做特殊的事。在依赖注入章节你已经看到这个了。 |
    | [byName](https://wiki.jikexueyuan.com/project/spring/beans-auto-wiring/spring-autowiring-byname.html) | 由属性名自动装配。Spring 容器看到在 XML 配置文件中 bean 的*自动装配*的属性设置为 *byName*。然后尝试匹配，并且将它的属性与在配置文件中被定义为相同名称的 beans 的属性进行连接。 |
    | [byType](https://wiki.jikexueyuan.com/project/spring/beans-auto-wiring/spring-autowiring-byType.html) | 由属性数据类型自动装配。Spring 容器看到在 XML 配置文件中 bean 的*自动装配*的属性设置为 *byType*。然后如果它的**类型**匹配配置文件中的一个确切的 bean 名称，它将尝试匹配和连接属性的类型。如果存在不止一个这样的 bean，则一个致命的异常将会被抛出。 |
    | [constructor](https://wiki.jikexueyuan.com/project/spring/beans-auto-wiring/spring-autowiring-by-Constructor.html) | 类似于 byType，但该类型适用于构造函数参数类型。如果在容器中没有一个构造函数参数类型的 bean，则一个致命错误将会发生。 |
    | autodetect                                                   | Spring首先尝试通过 *constructor* 使用自动装配来连接，如果它不执行，Spring 尝试通过 *byType* 来自动装配。 |

    可以使用 **byType** 或者 **constructor** 自动装配模式来连接数组和其他类型的集合。

    **自动装配的局限性**

    当自动装配始终在同一个项目中使用时，它的效果最好。如果通常不使用自动装配，它可能会使开发人员混淆的使用它来连接只有一个或两个 bean 定义。不过，自动装配可以显著减少需要指定的属性或构造器参数，但你应该在使用它们之前考虑到自动装配的局限性和缺点。

    | 限制         | 描述                                                         |
    | ------------ | ------------------------------------------------------------ |
    | 重写的可能性 | 你可以使用总是重写自动装配的 <constructor-arg> 和 <property> 设置来指定依赖关系。 |
    | 原始数据类型 | 你不能自动装配所谓的简单类型包括基本类型，字符串和类。       |
    | 混乱的本质   | 自动装配不如显式装配精确，所以如果可能的话尽可能使用显式装配。 |

    - Spring 自动装配 ‘byName’

      这种模式由属性名称指定自动装配。Spring 容器看作 beans，在 XML 配置文件中 beans 的 *auto-wire* 属性设置为 *byName*。然后，它尝试将它的属性与配置文件中定义为相同名称的 beans 进行匹配和连接。如果找到匹配项，它将注入这些 beans，否则，它将抛出异常。

      例如，在配置文件中，如果一个 bean 定义设置为自动装配 *byName*，并且它包含 *spellChecker* 属性（即，它有一个 *setSpellChecker(...)* 方法），那么 Spring 就会查找定义名为 *spellChecker* 的 bean，并且用它来设置这个属性。你仍然可以使用 <property> 标签连接其余的属性。下面的例子将说明这个概念。

      这里是 **TextEditor.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class TextEditor {
         private SpellChecker spellChecker;
         private String name;
         public void setSpellChecker( SpellChecker spellChecker ){
            this.spellChecker = spellChecker;
         }
         public SpellChecker getSpellChecker() {
            return spellChecker;
         }
         public void setName(String name) {
            this.name = name;
         }
         public String getName() {
            return name;
         }
         public void spellCheck() {
            spellChecker.checkSpelling();
         }
      }
      ```

      下面是另一个依赖类文件 **SpellChecker.java** 的内容：

      ```java
      package com.tutorialspoint;
      public class SpellChecker {
         public SpellChecker() {
            System.out.println("Inside SpellChecker constructor." );
         }
         public void checkSpelling() {
            System.out.println("Inside checkSpelling." );
         }   
      }
      ```

      下面是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = 
                   new ClassPathXmlApplicationContext("Beans.xml");
            TextEditor te = (TextEditor) context.getBean("textEditor");
            te.spellCheck();
         }
      }
      ```

      下面是在正常情况下的配置文件 **Beans.xml** 文件：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor">
             <property name="spellChecker" ref="spellChecker" />
             <property name="name" value="Generic Text Editor" />
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      但是，如果你要使用自动装配 “byName”，那么你的 XML 配置文件将成为如下：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor" 
            autowire="byName">
            <property name="name" value="Generic Text Editor" />
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      一旦你完成了创建源代码和 bean 的配置文件，我们就可以运行该应用程序。如果你的应用程序一切都正常，它将打印下面的消息：

      ```
      Inside SpellChecker constructor.
      Inside checkSpelling.
      ```

    - Spring 自动装配 ‘byType’

      这种模式由属性类型指定自动装配。Spring 容器看作 beans，在 XML 配置文件中 beans 的 *autowire* 属性设置为 *byType*。然后，如果它的 **type** 恰好与配置文件中 beans 名称中的一个相匹配，它将尝试匹配和连接它的属性。如果找到匹配项，它将注入这些 beans，否则，它将抛出异常。

      例如，在配置文件中，如果一个 bean 定义设置为自动装配 *byType*，并且它包含 *SpellChecker* 类型的 *spellChecker* 属性，那么 Spring 就会查找定义名为 *SpellChecker* 的 bean，并且用它来设置这个属性。你仍然可以使用 <property> 标签连接其余属性。下面的例子将说明这个概念，你会发现和上面的例子没有什么区别，除了 XML 配置文件已经被改变。

      这里是 **TextEditor.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class TextEditor {
         private SpellChecker spellChecker;
         private String name;
         public void setSpellChecker( SpellChecker spellChecker ) {
            this.spellChecker = spellChecker;
         }
         public SpellChecker getSpellChecker() {
            return spellChecker;
         }
         public void setName(String name) {
            this.name = name;
         }
         public String getName() {
            return name;
         }
         public void spellCheck() {
            spellChecker.checkSpelling();
         }
      }
      ```

      下面是另一个依赖类文件 **SpellChecker.java** 的内容：

      ```java
      package com.tutorialspoint;
      public class SpellChecker {
         public SpellChecker(){
            System.out.println("Inside SpellChecker constructor." );
         }
         public void checkSpelling() {
            System.out.println("Inside checkSpelling." );
         }   
      }
      ```

      下面是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = 
                   new ClassPathXmlApplicationContext("Beans.xml");
            TextEditor te = (TextEditor) context.getBean("textEditor");
            te.spellCheck();
         }
      }
      ```

      下面是在正常情况下的配置文件 **Beans.xml** 文件：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor">
            <property name="spellChecker" ref="spellChecker" />
            <property name="name" value="Generic Text Editor" />
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      但是，如果你要使用自动装配 “byType”，那么你的 XML 配置文件将成为如下：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor" 
            autowire="byType">
            <property name="name" value="Generic Text Editor" />
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="SpellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      一旦你完成了创建源代码和 bean 的配置文件，我们就可以运行该应用程序。如果你的应用程序一切都正常，它将打印下面的消息：

      ```
      Inside SpellChecker constructor.
      Inside checkSpelling.
      ```

    - Spring 由构造函数自动装配

      这种模式与 *byType* 非常相似，但它应用于构造器参数。Spring 容器看作 beans，在 XML 配置文件中 beans 的 *autowire* 属性设置为 *constructor*。然后，它尝试把它的构造函数的参数与配置文件中 beans 名称中的一个进行匹配和连线。如果找到匹配项，它会注入这些 bean，否则，它会抛出异常。

      例如，在配置文件中，如果一个 bean 定义设置为通过*构造函数*自动装配，而且它有一个带有 *SpellChecker* 类型的参数之一的构造函数，那么 Spring 就会查找定义名为 *SpellChecker* 的 bean，并用它来设置构造函数的参数。你仍然可以使用 <constructor-arg> 标签连接其余属性。下面的例子将说明这个概念。

      这里是 **TextEditor.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class TextEditor {
         private SpellChecker spellChecker;
         private String name;
         public TextEditor( SpellChecker spellChecker, String name ) {
            this.spellChecker = spellChecker;
            this.name = name;
         }
         public SpellChecker getSpellChecker() {
            return spellChecker;
         }
         public String getName() {
            return name;
         }
         public void spellCheck() {
            spellChecker.checkSpelling();
         }
      }
      ```

      下面是另一个依赖类文件 **SpellChecker.java** 的内容：

      ```java
      package com.tutorialspoint;
      public class SpellChecker {
         public SpellChecker(){
            System.out.println("Inside SpellChecker constructor." );
         }
         public void checkSpelling()
         {
            System.out.println("Inside checkSpelling." );
         }  
      }
      ```

      下面是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = 
                   new ClassPathXmlApplicationContext("Beans.xml");
            TextEditor te = (TextEditor) context.getBean("textEditor");
            te.spellCheck();
         }
      }
      ```

      下面是在正常情况下的配置文件 **Beans.xml** 文件：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor">
            <constructor-arg  ref="spellChecker" />
            <constructor-arg  value="Generic Text Editor"/>
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      但是，如果你要使用自动装配 “by constructor”，那么你的 XML 配置文件将成为如下：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor" 
            autowire="constructor">
            <constructor-arg value="Generic Text Editor"/>
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="SpellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      一旦你完成了创建源代码和 bean 的配置文件，我们就可以运行该应用程序。如果你的应用程序一切都正常，它将打印下面的消息：

      ```
      Inside SpellChecker constructor.
      Inside checkSpelling.
      ```

  - 基于注解的配置

    从 Spring 2.5 开始就可以使用**注解**来配置依赖注入。而不是采用 XML 来描述一个 bean 连线，你可以使用相关类，方法或字段声明的注解，将 bean 配置移动到组件类本身。

    在 XML 注入之前进行注解注入，因此后者的配置将通过两种方式的属性连线被前者重写。

    注解连线在默认情况下在 Spring 容器中不打开。因此，在可以使用基于注解的连线之前，我们将需要在我们的 Spring 配置文件中启用它。所以如果你想在 Spring 应用程序中使用的任何注解，可以考虑到下面的配置文件。

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns:context="http://www.springframework.org/schema/context"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
        http://www.springframework.org/schema/context
        http://www.springframework.org/schema/context/spring-context-3.0.xsd">
    
       <context:annotation-config/>
       <!-- bean definitions go here -->
    
    </beans>
    ```
    - Spring @Required 注释

      **@Required** 注释应用于 bean 属性的 setter 方法，它表明受影响的 bean 属性在配置时必须放在 XML 配置文件中，否则容器就会抛出一个 BeanInitializationException 异常。下面显示的是一个使用 @Required 注释的示例。

      下面是 **Student.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.beans.factory.annotation.Required;
      public class Student {
         private Integer age;
         private String name;
         @Required
         public void setAge(Integer age) {
            this.age = age;
         }
         public Integer getAge() {
            return age;
         }
         @Required
         public void setName(String name) {
            this.name = name;
         }
         public String getName() {
            return name;
         }
      }
      ```

      下面是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
            Student student = (Student) context.getBean("student");
            System.out.println("Name : " + student.getName() );
            System.out.println("Age : " + student.getAge() );
         }
      }
      ```

      下面是配置文件 **Beans.xml:** 文件的内容：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:context="http://www.springframework.org/schema/context"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
          http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context-3.0.xsd">
      
         <context:annotation-config/>
      
         <!-- Definition for student bean -->
         <bean id="student" class="com.tutorialspoint.Student">
            <property name="name"  value="Zara" />
      
            <!-- try without passing age and check the result -->
            <!-- property name="age"  value="11"-->
         </bean>
      
      </beans>
      ```

      一旦你已经完成的创建了源文件和 bean 配置文件，让我们运行一下应用程序。如果你的应用程序一切都正常的话，这将引起 *BeanInitializationException* 异常，并且会输出一下错误信息和其他日志消息：

      ```
      Property 'age' is required for bean 'student'
      ```

      下一步，在你按照如下所示从 “age” 属性中删除了注释，你可以尝试运行上面的示例：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:context="http://www.springframework.org/schema/context"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
          http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context-3.0.xsd">
      
         <context:annotation-config/>
      
         <!-- Definition for student bean -->
         <bean id="student" class="com.tutorialspoint.Student">
            <property name="name"  value="Zara" />
            <property name="age"  value="11"/>
         </bean>
      
      </beans>
      ```

      现在上面的示例将产生如下结果：

      ```
      Name : Zara
      Age : 11
      ```

    - Spring @Autowired 注释

      **@Autowired** 注释对在哪里和如何完成自动连接提供了更多的细微的控制。

      @Autowired 注释可以在 setter 方法中被用于自动连接 bean，就像 @Autowired 注释，容器，一个属性或者任意命名的可能带有多个参数的方法。

      **Setter 方法中的 @Autowired**

      你可以在 XML 文件中的 setter 方法中使用 **@Autowired** 注释来除去 元素。当 Spring遇到一个在 setter 方法中使用的 @Autowired 注释，它会在方法中视图执行 **byType** 自动连接。

      这里是 **TextEditor.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.beans.factory.annotation.Autowired;
      public class TextEditor {
         private SpellChecker spellChecker;
         @Autowired
         public void setSpellChecker( SpellChecker spellChecker ){
            this.spellChecker = spellChecker;
         }
         public SpellChecker getSpellChecker( ) {
            return spellChecker;
         }
         public void spellCheck() {
            spellChecker.checkSpelling();
         }
      }
      ```

      下面是另一个依赖的类文件 **SpellChecker.java** 的内容：

      ```java
      package com.tutorialspoint;
      public class SpellChecker {
         public SpellChecker(){
            System.out.println("Inside SpellChecker constructor." );
         }
         public void checkSpelling(){
            System.out.println("Inside checkSpelling." );
         }  
      }
      ```

      下面是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
            TextEditor te = (TextEditor) context.getBean("textEditor");
            te.spellCheck();
         }
      }
      ```

      下面是配置文件 **Beans.xml**：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:context="http://www.springframework.org/schema/context"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
          http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context-3.0.xsd">
      
         <context:annotation-config/>
      
         <!-- Definition for textEditor bean without constructor-arg  -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor">
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      一旦你已经完成的创建了源文件和 bean 配置文件，让我们运行一下应用程序。如果你的应用程序一切都正常的话，这将会输出以下消息：

      ```
      Inside SpellChecker constructor.
      Inside checkSpelling.
      ```

      **属性中的 @Autowired**

      你可以在属性中使用 **@Autowired** 注释来除去 setter 方法。当时使用 为自动连接属性传递的时候，Spring 会将这些传递过来的值或者引用自动分配给那些属性。所以利用在属性中 @Autowired 的用法，你的 **TextEditor.java** 文件将变成如下所示：

      ```java
      package com.tutorialspoint;
      import org.springframework.beans.factory.annotation.Autowired;
      public class TextEditor {
         @Autowired
         private SpellChecker spellChecker;
         public TextEditor() {
            System.out.println("Inside TextEditor constructor." );
         }  
         public SpellChecker getSpellChecker( ){
            return spellChecker;
         }  
         public void spellCheck(){
            spellChecker.checkSpelling();
         }
      }
      ```

      下面是配置文件 **Beans.xml**：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:context="http://www.springframework.org/schema/context"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
          http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context-3.0.xsd">
      
         <context:annotation-config/>
      
         <!-- Definition for textEditor bean -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor">
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      一旦你在源文件和 bean 配置文件中完成了上面两处改变，让我们运行一下应用程序。如果你的应用程序一切都正常的话，这将会输出以下消息：

      ```
      Inside TextEditor constructor.
      Inside SpellChecker constructor.
      Inside checkSpelling.
      ```

      **构造函数中的 @Autowired**

      你也可以在构造函数中使用 @Autowired。一个构造函数 @Autowired 说明当创建 bean 时，即使在 XML 文件中没有使用 元素配置 bean ，构造函数也会被自动连接。让我们检查一下下面的示例。

      这里是 **TextEditor.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.beans.factory.annotation.Autowired;
      public class TextEditor {
         private SpellChecker spellChecker;
         @Autowired
         public TextEditor(SpellChecker spellChecker){
            System.out.println("Inside TextEditor constructor." );
            this.spellChecker = spellChecker;
         }
         public void spellCheck(){
            spellChecker.checkSpelling();
         }
      }
      ```

      下面是配置文件 **Beans.xml**：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:context="http://www.springframework.org/schema/context"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
          http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context-3.0.xsd">
      
         <context:annotation-config/>
      
         <!-- Definition for textEditor bean without constructor-arg  -->
         <bean id="textEditor" class="com.tutorialspoint.TextEditor">
         </bean>
      
         <!-- Definition for spellChecker bean -->
         <bean id="spellChecker" class="com.tutorialspoint.SpellChecker">
         </bean>
      
      </beans>
      ```

      一旦你在源文件和 bean 配置文件中完成了上面两处改变，让我们运行一下应用程序。如果你的应用程序一切都正常的话，这将会输出以下消息：

      ```
      Inside TextEditor constructor.
      Inside SpellChecker constructor.
      Inside checkSpelling.
      ```

      **@Autowired 的（required=false）选项**

      默认情况下，@Autowired 注释意味着依赖是必须的，它类似于 @Required 注释，然而，你可以使用 @Autowired 的 **（required=false）** 选项关闭默认行为。

      即使你不为 age 属性传递任何参数，下面的示例也会成功运行，但是对于 name 属性则需要一个参数。你可以自己尝试一下这个示例，因为除了只有 **Student.java** 文件被修改以外，它和 @Required 注释示例是相似的。

      ```java
      package com.tutorialspoint;
      import org.springframework.beans.factory.annotation.Autowired;
      public class Student {
         private Integer age;
         private String name;
         @Autowired(required=false)
         public void setAge(Integer age) {
            this.age = age;
         }  
         public Integer getAge() {
            return age;
         }
         @Autowired
         public void setName(String name) {
            this.name = name;
         }   
         public String getName() {
            return name;
         }
      }
      ```

    - Spring @Qualifier 注释

      可能会有这样一种情况，当你创建多个具有相同类型的 bean 时，并且想要用一个属性只为它们其中的一个进行装配，在这种情况下，你可以使用 **@Qualifier** 注释和 **@Autowired** 注释通过指定哪一个真正的 bean 将会被装配来消除混乱。下面显示的是使用 @Qualifier 注释的一个示例。  

      这里是 **Student.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class Student {
         private Integer age;
         private String name;
         public void setAge(Integer age) {
            this.age = age;
         }   
         public Integer getAge() {
            return age;
         }
         public void setName(String name) {
            this.name = name;
         }  
         public String getName() {
            return name;
         }
      }
      ```

      这里是 **Profile.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.beans.factory.annotation.Autowired;
      import org.springframework.beans.factory.annotation.Qualifier;
      public class Profile {
         @Autowired
         @Qualifier("student1")
         private Student student;
         public Profile(){
            System.out.println("Inside Profile constructor." );
         }
         public void printAge() {
            System.out.println("Age : " + student.getAge() );
         }
         public void printName() {
            System.out.println("Name : " + student.getName() );
         }
      }
      ```

      下面是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml");
            Profile profile = (Profile) context.getBean("profile");
            profile.printAge();
            profile.printName();
         }
      }
      ```

      考虑下面配置文件 **Beans.xml** 的示例：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:context="http://www.springframework.org/schema/context"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
          http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context-3.0.xsd">
      
         <context:annotation-config/>
      
         <!-- Definition for profile bean -->
         <bean id="profile" class="com.tutorialspoint.Profile">
         </bean>
      
         <!-- Definition for student1 bean -->
         <bean id="student1" class="com.tutorialspoint.Student">
            <property name="name"  value="Zara" />
            <property name="age"  value="11"/>
         </bean>
      
         <!-- Definition for student2 bean -->
         <bean id="student2" class="com.tutorialspoint.Student">
            <property name="name"  value="Nuha" />
            <property name="age"  value="2"/>
         </bean>
      
      </beans>
      ```

      一旦你在源文件和 bean 配置文件中完成了上面两处改变，让我们运行一下应用程序。如果你的应用程序一切都正常的话，这将会输出以下消息：

      ```
      Inside Profile constructor.
      Age : 11
      Name : Zara
      ```

    - Spring JSR-250 注释

      Spring还使用基于 JSR-250 注释，它包括 @PostConstruct， @PreDestroy 和 @Resource 注释。因为你已经有了其他的选择，尽管这些注释并不是真正所需要的，但是关于它们仍然让我给出一个简短的介绍。

      **@PostConstruct 和 @PreDestroy 注释：**

      为了定义一个 bean 的安装和卸载，我们使用 **init-method** 和/或 **destroy-method** 参数简单的声明一下 。init-method 属性指定了一个方法，该方法在 bean 的实例化阶段会立即被调用。同样地，destroy-method 指定了一个方法，该方法只在一个 bean 从容器中删除之前被调用。

      你可以使用 **@PostConstruct** 注释作为初始化回调函数的一个替代，**@PreDestroy** 注释作为销毁回调函数的一个替代，其解释如下示例所示。 

      这里是 **HelloWorld.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import javax.annotation.*;
      public class HelloWorld {
         private String message;
         public void setMessage(String message){
            this.message  = message;
         }
         public String getMessage(){
            System.out.println("Your Message : " + message);
            return message;
         }
         @PostConstruct
         public void init(){
            System.out.println("Bean is going through init.");
         }
         @PreDestroy
         public void destroy(){
            System.out.println("Bean will destroy now.");
         }
      }
      ```

      下面是 **MainApp.java** 文件的内容。这里你需要注册一个关闭钩 **registerShutdownHook()** 方法，该方法在 AbstractApplicationContext 类中被声明。这将确保一个完美的关闭并调用相关的销毁方法。

      ```java
      package com.tutorialspoint;
      import org.springframework.context.support.AbstractApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            AbstractApplicationContext context = 
                                new ClassPathXmlApplicationContext("Beans.xml");
            HelloWorld obj = (HelloWorld) context.getBean("helloWorld");
            obj.getMessage();
            context.registerShutdownHook();
         }
      }
      ```

      下面是配置文件 **Beans.xml**，该文件在初始化和销毁方法中需要使用。

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:context="http://www.springframework.org/schema/context"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
          http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context-3.0.xsd">
      
         <context:annotation-config/>
      
         <bean id="helloWorld" 
             class="com.tutorialspoint.HelloWorld"
             init-method="init" destroy-method="destroy">
             <property name="message" value="Hello World!"/>
         </bean>
      
      </beans>
      ```

      一旦你在源文件和 bean 配置文件中完成了上面两处改变，让我们运行一下应用程序。如果你的应用程序一切都正常的话，这将会输出以下消息：

      ```
      Bean is going through init.
      Your Message : Hello World!
      Bean will destroy now.
      ```

      **@Resource 注释：**

      你可以在字段中或者 setter 方法中使用 **@Resource** 注释，它和在 Java EE 5 中的运作是一样的。@Resource 注释使用一个 ‘name’ 属性，该属性以一个 bean 名称的形式被注入。你可以说，它遵循 **by-name** 自动连接语义，如下面的示例所示：

      ```java
      package com.tutorialspoint;
      import javax.annotation.Resource;
      public class TextEditor {
         private SpellChecker spellChecker;
         @Resource(name= "spellChecker")
         public void setSpellChecker( SpellChecker spellChecker ){
            this.spellChecker = spellChecker;
         }
         public SpellChecker getSpellChecker(){
            return spellChecker;
         }
         public void spellCheck(){
            spellChecker.checkSpelling();
         }
      }
      ```

      如果没有明确地指定一个 ‘name’，默认名称源于字段名或者 setter 方法。在字段的情况下，它使用的是字段名；在一个 setter 方法情况下，它使用的是 bean 属性名称。

  - 基于 Java 的配置

    到目前为止，你已经看到如何使用 XML 配置文件来配置 Spring bean。如果你熟悉使用 XML 配置，那么我会说，不需要再学习如何进行基于 Java 的配置是，因为你要达到相同的结果，可以使用其他可用的配置。

    基于 Java 的配置选项，可以使你在不用配置 XML 的情况下编写大多数的 Spring，但是一些有帮助的基于 Java 的注解，解释如下：

    **@Configuration 和 @Bean 注解**

    带有 **@Configuration** 的注解类表示这个类可以使用 Spring IoC 容器作为 bean 定义的来源。**@Bean** 注解告诉 Spring，一个带有 @Bean 的注解方法将返回一个对象，该对象应该被注册为在 Spring 应用程序上下文中的 bean。最简单可行的 @Configuration 类如下所示：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.annotation.*;
    @Configuration
    public class HelloWorldConfig {
       @Bean 
       public HelloWorld helloWorld(){
          return new HelloWorld();
       }
    }
    ```

    上面的代码将等同于下面的 XML 配置：

    ```xml
    <beans>
       <bean id="helloWorld" class="com.tutorialspoint.HelloWorld" />
    </beans>
    ```

    在这里，带有 @Bean 注解的方法名称作为 bean 的 ID，它创建并返回实际的 bean。你的配置类可以声明多个 @Bean。一旦定义了配置类，你就可以使用 *AnnotationConfigApplicationContext* 来加载并把他们提供给 Spring 容器，如下所示：

    ```java
    public static void main(String[] args) {
       ApplicationContext ctx = 
       new AnnotationConfigApplicationContext(HelloWorldConfig.class); 
       HelloWorld helloWorld = ctx.getBean(HelloWorld.class);
       helloWorld.setMessage("Hello World!");
       helloWorld.getMessage();
    }
    ```

    你可以加载各种配置类，如下所示：

    ```java
    public static void main(String[] args) {
       AnnotationConfigApplicationContext ctx = 
       new AnnotationConfigApplicationContext();
       ctx.register(AppConfig.class, OtherConfig.class);
       ctx.register(AdditionalConfig.class);
       ctx.refresh();
       MyService myService = ctx.getBean(MyService.class);
       myService.doStuff();
    }
    ```

    **例子**

    这里是 **HelloWorldConfig.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.annotation.*;
    @Configuration
    public class HelloWorldConfig {
       @Bean 
       public HelloWorld helloWorld(){
          return new HelloWorld();
       }
    }
    ```

    这里是 **HelloWorld.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    
    public class HelloWorld {
       private String message;
    
       public void setMessage(String message){
          this.message  = message;
       }
    
       public void getMessage(){
          System.out.println("Your Message : " + message);
       }
    }
    ```

    下面是 **MainApp.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    
    import org.springframework.context.ApplicationContext;
    import org.springframework.context.annotation.*;
    
    public class MainApp {
       public static void main(String[] args) {
          ApplicationContext ctx = 
          new AnnotationConfigApplicationContext(HelloWorldConfig.class);
    
          HelloWorld helloWorld = ctx.getBean(HelloWorld.class);
    
          helloWorld.setMessage("Hello World!");
          helloWorld.getMessage();
       }
    }
    ```

    一旦你完成了创建所有的源文件并添加所需的额外的库后，我们就可以运行该应用程序。你应该注意这里不需要配置文件。如果你的应用程序一切都正常，将输出以下信息：

    ```
    Your Message : Hello World!
    ```

    **注入 Bean 的依赖性**

    当 @Beans 依赖对方时，表达这种依赖性非常简单，只要有一个 bean 方法调用另一个，如下所示：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.annotation.*;
    @Configuration
    public class AppConfig {
       @Bean
       public Foo foo() {
          return new Foo(bar());
       }
       @Bean
       public Bar bar() {
          return new Bar();
       }
    }
    ```

    这里，foo Bean 通过构造函数注入来接收参考基准。现在，让我们看到一个正在执行的例子：

    **例子**

    这里是 **TextEditorConfig.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.annotation.*;
    @Configuration
    public class TextEditorConfig {
       @Bean 
       public TextEditor textEditor(){
          return new TextEditor( spellChecker() );
       }
       @Bean 
       public SpellChecker spellChecker(){
          return new SpellChecker( );
       }
    }
    ```

    这里是 TextEditor.java 文件的内容：

    ```java
    package com.tutorialspoint;
    public class TextEditor {
       private SpellChecker spellChecker;
       public TextEditor(SpellChecker spellChecker){
          System.out.println("Inside TextEditor constructor." );
          this.spellChecker = spellChecker;
       }
       public void spellCheck(){
          spellChecker.checkSpelling();
       }
    }
    ```

    下面是另一个依赖的类文件 **SpellChecker.java** 的内容：

    ```java
    package com.tutorialspoint;
    public class SpellChecker {
       public SpellChecker(){
          System.out.println("Inside SpellChecker constructor." );
       }
       public void checkSpelling(){
          System.out.println("Inside checkSpelling." );
       }
    
    }
    ```

    下面是 **MainApp.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    
    import org.springframework.context.ApplicationContext;
    import org.springframework.context.annotation.*;
    
    public class MainApp {
       public static void main(String[] args) {
          ApplicationContext ctx = 
          new AnnotationConfigApplicationContext(TextEditorConfig.class);
    
          TextEditor te = ctx.getBean(TextEditor.class);
    
          te.spellCheck();
       }
    }
    ```

    一旦你完成了创建所有的源文件并添加所需的额外的库后，我们就可以运行该应用程序。你应该注意这里不需要配置文件。如果你的应用程序一切都正常，将输出以下信息：

    ```
    Inside SpellChecker constructor.
    Inside TextEditor constructor.
    Inside checkSpelling.
    ```

    **@Import 注解:**

    **@import** 注解允许从另一个配置类中加载 @Bean 定义。考虑 ConfigA 类，如下所示：

    ```java
    @Configuration
    public class ConfigA {
       @Bean
       public A a() {
          return new A(); 
       }
    }
    ```

    你可以在另一个 Bean 声明中导入上述 Bean 声明，如下所示：

    ```java
    @Configuration
    @Import(ConfigA.class)
    public class ConfigB {
       @Bean
       public B a() {
          return new A(); 
       }
    }
    ```

    现在，当实例化上下文时，不需要同时指定 ConfigA.class 和 ConfigB.class，只有 ConfigB 类需要提供，如下所示：

    ```java
    public static void main(String[] args) {
       ApplicationContext ctx = 
       new AnnotationConfigApplicationContext(ConfigB.class);
       // now both beans A and B will be available...
       A a = ctx.getBean(A.class);
       B b = ctx.getBean(B.class);
    }
    ```

    **生命周期回调**

    @Bean 注解支持指定任意的初始化和销毁的回调方法，就像在 bean 元素中 Spring 的 XML 的初始化方法和销毁方法的属性：

    ```java
    public class Foo {
       public void init() {
          // initialization logic
       }
       public void cleanup() {
          // destruction logic
       }
    }
    
    @Configuration
    public class AppConfig {
       @Bean(initMethod = "init", destroyMethod = "cleanup" )
       public Foo foo() {
          return new Foo();
       }
    }
    ```

    指定 Bean 的范围：

    默认范围是单实例，但是你可以重写带有 @Scope 注解的该方法，如下所示：

    ```java
    @Configuration
    public class AppConfig {
       @Bean
       @Scope("prototype")
       public Foo foo() {
          return new Foo();
       }
    }
    ```

  - Spring 中的事件处理

    你已经看到了在所有章节中 Spring 的核心是 **ApplicationContext**，它负责管理 beans 的完整生命周期。当加载 beans 时，ApplicationContext 发布某些类型的事件。例如，当上下文启动时，*ContextStartedEvent* 发布，当上下文停止时，*ContextStoppedEvent* 发布。

    通过 *ApplicationEvent* 类和 *ApplicationListener* 接口来提供在 *ApplicationContext* 中处理事件。如果一个 bean 实现 *ApplicationListener*，那么每次 *ApplicationEvent* 被发布到 ApplicationContext 上，那个 bean 会被通知。  

    Spring 提供了以下的标准事件：

    | 序号 | Spring 内置事件 & 描述                                       |
    | ---- | ------------------------------------------------------------ |
    | 1    | **ContextRefreshedEvent** *ApplicationContext* 被初始化或刷新时，该事件被发布。这也可以在 *ConfigurableApplicationContext* 接口中使用 refresh() 方法来发生。 |
    | 2    | **ContextStartedEvent**当使用 *ConfigurableApplicationContext* 接口中的 start() 方法启动 *ApplicationContext* 时，该事件被发布。你可以调查你的数据库，或者你可以在接受到这个事件后重启任何停止的应用程序。 |
    | 3    | **ContextStoppedEvent**当使用 *ConfigurableApplicationContext* 接口中的 stop() 方法停止 *ApplicationContext* 时，发布这个事件。你可以在接受到这个事件后做必要的清理的工作。 |
    | 4    | **ContextClosedEvent**当使用 *ConfigurableApplicationContext* 接口中的 close() 方法关闭 *ApplicationContext* 时，该事件被发布。一个已关闭的上下文到达生命周期末端；它不能被刷新或重启。 |
    | 5    | **RequestHandledEvent**这是一个 web-specific 事件，告诉所有 bean HTTP 请求已经被服务。 |

    由于 Spring 的事件处理是单线程的，所以如果一个事件被发布，直至并且除非所有的接收者得到的该消息，该进程被阻塞并且流程将不会继续。因此，如果事件处理被使用，在设计应用程序时应注意。

    **监听上下文事件**

    为了监听上下文事件，一个 bean 应该实现只有一个方法 **onApplicationEvent()** 的 *ApplicationListener* 接口。因此，我们写一个例子来看看事件是如何传播的，以及如何可以用代码来执行基于某些事件所需的任务。

    这里是 **HelloWorld.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    public class HelloWorld {
       private String message;
       public void setMessage(String message){
          this.message  = message;
       }
       public void getMessage(){
          System.out.println("Your Message : " + message);
       }
    }
    ```

    下面是 **CStartEventHandler.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationListener;
    import org.springframework.context.event.ContextStartedEvent;
    public class CStartEventHandler 
       implements ApplicationListener<ContextStartedEvent>{
       public void onApplicationEvent(ContextStartedEvent event) {
          System.out.println("ContextStartedEvent Received");
       }
    }
    ```

    下面是 **CStopEventHandler.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationListener;
    import org.springframework.context.event.ContextStoppedEvent;
    public class CStopEventHandler 
       implements ApplicationListener<ContextStoppedEvent>{
       public void onApplicationEvent(ContextStoppedEvent event) {
          System.out.println("ContextStoppedEvent Received");
       }
    }
    ```

    下面是 **MainApp.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    
    import org.springframework.context.ConfigurableApplicationContext;
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    
    public class MainApp {
       public static void main(String[] args) {
          ConfigurableApplicationContext context = 
          new ClassPathXmlApplicationContext("Beans.xml");
    
          // Let us raise a start event.
          context.start();
    
          HelloWorld obj = (HelloWorld) context.getBean("helloWorld");
    
          obj.getMessage();
    
          // Let us raise a stop event.
          context.stop();
       }
    }
    ```

    下面是配置文件 **Beans.xml** 文件：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="helloWorld" class="com.tutorialspoint.HelloWorld">
          <property name="message" value="Hello World!"/>
       </bean>
    
       <bean id="cStartEventHandler" 
             class="com.tutorialspoint.CStartEventHandler"/>
    
       <bean id="cStopEventHandler" 
             class="com.tutorialspoint.CStopEventHandler"/>
    
    </beans>
    ```

    一旦你完成了创建源和 bean 的配置文件，我们就可以运行该应用程序。如果你的应用程序一切都正常，将输出以下消息：

    ```
    ContextStartedEvent Received
    Your Message : Hello World!
    ContextStoppedEvent Received
    ```

  - Spring 中的自定义事件(?)

    这个是 **CustomEvent.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationEvent;
    public class CustomEvent extends ApplicationEvent{ 
       public CustomEvent(Object source) {
          super(source);
       }
       public String toString(){
          return "My Custom Event";
       }
    }
    ```

    下面是 **CustomEventPublisher.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationEventPublisher;
    import org.springframework.context.ApplicationEventPublisherAware;
    public class CustomEventPublisher 
       implements ApplicationEventPublisherAware {
       private ApplicationEventPublisher publisher;
       public void setApplicationEventPublisher
                  (ApplicationEventPublisher publisher){
          this.publisher = publisher;
       }
       public void publish() {
          CustomEvent ce = new CustomEvent(this);
          publisher.publishEvent(ce);
       }
    }
    ```

    下面是 **CustomEventHandler.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ApplicationListener;
    public class CustomEventHandler 
       implements ApplicationListener<CustomEvent>{
       public void onApplicationEvent(CustomEvent event) {
          System.out.println(event.toString());
       }
    }
    ```

    下面是 **MainApp.java** 文件的内容：

    ```java
    package com.tutorialspoint;
    import org.springframework.context.ConfigurableApplicationContext;  
    import org.springframework.context.support.ClassPathXmlApplicationContext;
    public class MainApp {
       public static void main(String[] args) {
          ConfigurableApplicationContext context = 
          new ClassPathXmlApplicationContext("Beans.xml");    
          CustomEventPublisher cvp = 
          (CustomEventPublisher) context.getBean("customEventPublisher");
          cvp.publish();  
          cvp.publish();
       }
    }
    ```

    下面是配置文件 **Beans.xml**：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    
    <beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
    
       <bean id="customEventHandler" 
          class="com.tutorialspoint.CustomEventHandler"/>
    
       <bean id="customEventPublisher" 
          class="com.tutorialspoint.CustomEventPublisher"/>
    
    </beans>
    ```

    一旦你完成了创建源和 bean 的配置文件后，我们就可以运行该应用程序。如果你的应用程序一切都正常，将输出以下信息：

    ```
    My Custom Event
    My Custom Event
    ```

  - Spring 框架的 AOP

    Spring 框架的一个关键组件是**面向方面的编程**(AOP)框架。面向方面的编程需要把程序逻辑分解成不同的部分称为所谓的关注点。跨一个应用程序的多个点的功能被称为**横切关注点**，这些横切关注点在概念上独立于应用程序的业务逻辑。有各种各样的常见的很好的方面的例子，如日志记录、审计、声明式事务、安全性和缓存等。

    在 OOP 中，关键单元模块度是类，而在 AOP 中单元模块度是方面。依赖注入帮助你对应用程序对象相互解耦和 AOP 可以帮助你从它们所影响的对象中对横切关注点解耦。AOP 是像编程语言的触发物，如 Perl，.NET，Java 或者其他。

    Spring AOP 模块提供拦截器来拦截一个应用程序，例如，当执行一个方法时，你可以在方法执行之前或之后添加额外的功能。  

    **通知的类型**

    Spring 方面可以使用下面提到的五种通知工作：

    | 通知           | 描述                                                         |
    | -------------- | ------------------------------------------------------------ |
    | 前置通知       | 在一个方法执行之前，执行通知。                               |
    | 后置通知       | 在一个方法执行之后，不考虑其结果，执行通知。                 |
    | 返回后通知     | 在一个方法执行之后，只有在方法成功完成时，才能执行通知。     |
    | 抛出异常后通知 | 在一个方法执行之后，只有在方法退出抛出异常时，才能执行通知。 |
    | 环绕通知       | 在建议方法调用之前和之后，执行通知。                         |

    - Spring 中基于 AOP 的 XML架构

      为了在本节的描述中使用 aop 命名空间标签，你需要导入 spring-aop 架构，如下所述：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
          xmlns:aop="http://www.springframework.org/schema/aop"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd 
          http://www.springframework.org/schema/aop 
          http://www.springframework.org/schema/aop/spring-aop-3.0.xsd ">
      
         <!-- bean definition & AOP specific configuration -->
      
      </beans>
      ```

      **声明一个 aspect**

      一个 **aspect** 是使用 元素声明的，支持的 bean 是使用 **ref** 属性引用的，如下所示：

      ```xml
      <aop:config>
         <aop:aspect id="myAspect" ref="aBean">
         ...
         </aop:aspect>
      </aop:config>
      <bean id="aBean" class="...">
      ...
      </bean>
      ```

      这里，“aBean” 将被配置和依赖注入，就像前面的章节中你看到的其他的 Spring bean 一样。

      **声明一个切入点**

      一个**切入点**有助于确定使用不同建议执行的感兴趣的连接点（即方法）。在处理基于配置的 XML 架构时，切入点将会按照如下所示定义：

      ```xml
      <aop:config>
         <aop:aspect id="myAspect" ref="aBean">
         <aop:pointcut id="businessService"
            expression="execution(* com.xyz.myapp.service.*.*(..))"/>
         ...
         </aop:aspect>
      </aop:config>
      <bean id="aBean" class="...">
      ...
      </bean>
      ```

      下面的示例定义了一个名为 “businessService” 的切入点，该切入点将与 com.tutorialspoint 包下的 Student 类中的 getName() 方法相匹配：

      ```xml
      <aop:config>
         <aop:aspect id="myAspect" ref="aBean">
         <aop:pointcut id="businessService"
            expression="execution(* com.tutorialspoint.Student.getName(..))"/>
         ...
         </aop:aspect>
      </aop:config>
      <bean id="aBean" class="...">
      ...
      </bean>
      ```

      **声明建议**

      你可以使用 <aop:{ADVICE NAME}> 元素在一个`<aop:aspect>`中声明五个建议中的任何一个，如下所示：

      ```xml
      <aop:config>
         <aop:aspect id="myAspect" ref="aBean">
            <aop:pointcut id="businessService"
               expression="execution(* com.xyz.myapp.service.*.*(..))"/>
            <!-- a before advice definition -->
            <aop:before pointcut-ref="businessService" 
               method="doRequiredTask"/>
            <!-- an after advice definition -->
            <aop:after pointcut-ref="businessService" 
               method="doRequiredTask"/>
            <!-- an after-returning advice definition -->
            <!--The doRequiredTask method must have parameter named retVal -->
            <aop:after-returning pointcut-ref="businessService"
               returning="retVal"
               method="doRequiredTask"/>
            <!-- an after-throwing advice definition -->
            <!--The doRequiredTask method must have parameter named ex -->
            <aop:after-throwing pointcut-ref="businessService"
               throwing="ex"
               method="doRequiredTask"/>
            <!-- an around advice definition -->
            <aop:around pointcut-ref="businessService" 
               method="doRequiredTask"/>
         ...
         </aop:aspect>
      </aop:config>
      <bean id="aBean" class="...">
      ...
      </bean>
      ```

      你可以对不同的建议使用相同的 **doRequiredTask** 或者不同的方法。这些方法将会作为 aspect 模块的一部分来定义。

      **基于 AOP 的 XML 架构的示例**

      这里是 **Logging.java** 文件的内容。这实际上是 aspect 模块的一个示例，它定义了在各个点调用的方法。

      ```java
      package com.tutorialspoint;
      public class Logging {
         /** 
          * This is the method which I would like to execute
          * before a selected method execution.
          */
         public void beforeAdvice(){
            System.out.println("Going to setup student profile.");
         }
         /** 
          * This is the method which I would like to execute
          * after a selected method execution.
          */
         public void afterAdvice(){
            System.out.println("Student profile has been setup.");
         }
         /** 
          * This is the method which I would like to execute
          * when any method returns.
          */
         public void afterReturningAdvice(Object retVal){
            System.out.println("Returning:" + retVal.toString() );
         }
         /**
          * This is the method which I would like to execute
          * if there is an exception raised.
          */
         public void AfterThrowingAdvice(IllegalArgumentException ex){
            System.out.println("There has been an exception: " + ex.toString());   
         }  
      }
      ```

      下面是 **Student.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class Student {
         private Integer age;
         private String name;
         public void setAge(Integer age) {
            this.age = age;
         }
         public Integer getAge() {
            System.out.println("Age : " + age );
            return age;
         }
         public void setName(String name) {
            this.name = name;
         }
         public String getName() {
            System.out.println("Name : " + name );
            return name;
         }  
         public void printThrowException(){
             System.out.println("Exception raised");
             throw new IllegalArgumentException();
         }
      }
      ```

      下面是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = 
                   new ClassPathXmlApplicationContext("Beans.xml");
            Student student = (Student) context.getBean("student");
            student.getName();
            student.getAge();      
            student.printThrowException();
         }
      }
      ```

      下面是配置文件 **Beans.xml**：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
          xmlns:aop="http://www.springframework.org/schema/aop"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd 
          http://www.springframework.org/schema/aop 
          http://www.springframework.org/schema/aop/spring-aop-3.0.xsd ">
      
         <aop:config>
            <aop:aspect id="log" ref="logging">
               <aop:pointcut id="selectAll" 
               expression="execution(* com.tutorialspoint.*.*(..))"/>
               <aop:before pointcut-ref="selectAll" method="beforeAdvice"/>
               <aop:after pointcut-ref="selectAll" method="afterAdvice"/>
               <aop:after-returning pointcut-ref="selectAll" 
                                    returning="retVal"
                                    method="afterReturningAdvice"/>
               <aop:after-throwing pointcut-ref="selectAll" 
                                   throwing="ex"
                                   method="AfterThrowingAdvice"/>
            </aop:aspect>
         </aop:config>
      
         <!-- Definition for student bean -->
         <bean id="student" class="com.tutorialspoint.Student">
            <property name="name"  value="Zara" />
            <property name="age"  value="11"/>      
         </bean>
      
         <!-- Definition for logging aspect -->
         <bean id="logging" class="com.tutorialspoint.Logging"/> 
      
      </beans>
      ```

      一旦你已经完成的创建了源文件和 bean 配置文件，让我们运行一下应用程序。如果你的应用程序一切都正常的话，这将会输出以下消息：

      ```
      Going to setup student profile.
      Name : Zara
      Student profile has been setup.
      Returning:Zara
      Going to setup student profile.
      Age : 11
      Student profile has been setup.
      Returning:11
      Going to setup student profile.
      Exception raised
      Student profile has been setup.
      There has been an exception: java.lang.IllegalArgumentException
      .....
      other exception content
      ```

      让我们来解释一下上面定义的在 com.tutorialspoint 中 选择所有方法的 。让我们假设一下，你想要在一个特殊的方法之前或者之后执行你的建议，你可以通过替换使用真实类和方法名称的切入点定义中的星号（*）来定义你的切入点来缩短你的执行。

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
          xmlns:aop="http://www.springframework.org/schema/aop"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd 
          http://www.springframework.org/schema/aop 
          http://www.springframework.org/schema/aop/spring-aop-3.0.xsd ">
      
         <aop:config>
         <aop:aspect id="log" ref="logging">
            <aop:pointcut id="selectAll" 
            expression="execution(* com.tutorialspoint.Student.getName(..))"/>
            <aop:before pointcut-ref="selectAll" method="beforeAdvice"/>
            <aop:after pointcut-ref="selectAll" method="afterAdvice"/>
         </aop:aspect>
         </aop:config>
      
         <!-- Definition for student bean -->
         <bean id="student" class="com.tutorialspoint.Student">
            <property name="name"  value="Zara" />
            <property name="age"  value="11"/>      
         </bean>
      
         <!-- Definition for logging aspect -->
         <bean id="logging" class="com.tutorialspoint.Logging"/> 
      
      </beans>
      ```

      如果你想要执行通过这些更改之后的示例应用程序，这将会输出以下消息：

      ```
      Going to setup student profile.
      Name : Zara
      Student profile has been setup.
      Age : 11
      Exception raised
      .....
      other exception content
      ```

    - Spring 中基于 AOP 的 @AspectJ

      @AspectJ 作为通过 Java 5 注释注释的普通的 Java 类，它指的是声明 aspects 的一种风格。通过在你的基于架构的 XML 配置文件中包含以下元素，@AspectJ 支持是可用的。

      ```
      <aop:aspectj-autoproxy/>
      ```

      **声明一个 aspect**

      Aspects 类和其他任何正常的 bean 一样，除了它们将会用 @AspectJ 注释之外，它和其他类一样可能有方法和字段，如下所示：

      ```java
      package org.xyz;
      import org.aspectj.lang.annotation.Aspect;
      @Aspect
      public class AspectModule {
      }
      ```

      它们将在 XML 中按照如下进行配置，就和其他任何 bean 一样：

      ```xml
      <bean id="myAspect" class="org.xyz.AspectModule">
         <!-- configure properties of aspect here as normal -->
      </bean>
      ```

      **声明一个切入点**

      一个**切入点**有助于确定使用不同建议执行的感兴趣的连接点（即方法）。在处理基于配置的 XML 架构时，切入点的声明有两个部分：

      - 一个切入点表达式决定了我们感兴趣的哪个方法会真正被执行。
      - 一个切入点标签包含一个名称和任意数量的参数。方法的真正内容是不相干的，并且实际上它应该是空的。

      下面的示例中定义了一个名为 ‘businessService’ 的切入点，该切入点将与 com.tutorialspoint 包下的类中可用的每一个方法相匹配：

      ```java
      import org.aspectj.lang.annotation.Pointcut;
      @Pointcut("execution(* com.xyz.myapp.service.*.*(..))") // expression 
      private void businessService() {}  // signature
      ```

      下面的示例中定义了一个名为 ‘getname’ 的切入点，该切入点将与 com.tutorialspoint 包下的 Student 类中的 getName() 方法相匹配：

      ```java
      import org.aspectj.lang.annotation.Pointcut;
      @Pointcut("execution(* com.tutorialspoint.Student.getName(..))") 
      private void getname() {}
      ```

      **声明建议**

      你可以使用 @{ADVICE-NAME} 注释声明五个建议中的任意一个，如下所示。这假设你已经定义了一个切入点标签方法 businessService()：

      ```java
      @Before("businessService()")
      public void doBeforeTask(){
       ...
      }
      @After("businessService()")
      public void doAfterTask(){
       ...
      }
      @AfterReturning(pointcut = "businessService()", returning="retVal")
      public void doAfterReturnningTask(Object retVal){
        // you can intercept retVal here.
        ...
      }
      @AfterThrowing(pointcut = "businessService()", throwing="ex")
      public void doAfterThrowingTask(Exception ex){
        // you can intercept thrown exception here.
        ...
      }
      @Around("businessService()")
      public void doAroundTask(){
       ...
      }
      ```

      你可以为任意一个建议定义你的切入点内联。下面是在建议之前定义内联切入点的一个示例：

      ```java
      @Before("execution(* com.xyz.myapp.service.*.*(..))")
      public doBeforeTask(){
       ...
      }
      ```

      **基于 AOP 的 @AspectJ 示例**

      为了理解上面提到的关于基于 AOP 的 @AspectJ 的概念，让我们编写一个示例，可以实现几个建议。

      这里是 **Logging.java** 文件的内容。这实际上是 aspect 模块的一个示例，它定义了在各个点调用的方法。

      ```java
      package com.tutorialspoint;
      import org.aspectj.lang.annotation.Aspect;
      import org.aspectj.lang.annotation.Pointcut;
      import org.aspectj.lang.annotation.Before;
      import org.aspectj.lang.annotation.After;
      import org.aspectj.lang.annotation.AfterThrowing;
      import org.aspectj.lang.annotation.AfterReturning;
      import org.aspectj.lang.annotation.Around;
      @Aspect
      public class Logging {
         /** Following is the definition for a pointcut to select
          *  all the methods available. So advice will be called
          *  for all the methods.
          */
         @Pointcut("execution(* com.tutorialspoint.*.*(..))")
         private void selectAll(){}
         /** 
          * This is the method which I would like to execute
          * before a selected method execution.
          */
         @Before("selectAll()")
         public void beforeAdvice(){
            System.out.println("Going to setup student profile.");
         }
         /** 
          * This is the method which I would like to execute
          * after a selected method execution.
          */
         @After("selectAll()")
         public void afterAdvice(){
            System.out.println("Student profile has been setup.");
         }
         /** 
          * This is the method which I would like to execute
          * when any method returns.
          */
         @AfterReturning(pointcut = "selectAll()", returning="retVal")
         public void afterReturningAdvice(Object retVal){
            System.out.println("Returning:" + retVal.toString() );
         }
         /**
          * This is the method which I would like to execute
          * if there is an exception raised by any method.
          */
         @AfterThrowing(pointcut = "selectAll()", throwing = "ex")
         public void AfterThrowingAdvice(IllegalArgumentException ex){
            System.out.println("There has been an exception: " + ex.toString());   
         }  
      }
      ```

      下面是 **Student.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      public class Student {
         private Integer age;
         private String name;
         public void setAge(Integer age) {
            this.age = age;
         }
         public Integer getAge() {
            System.out.println("Age : " + age );
            return age;
         }
         public void setName(String name) {
            this.name = name;
         }
         public String getName() {
            System.out.println("Name : " + name );
            return name;
         }
         public void printThrowException(){
            System.out.println("Exception raised");
            throw new IllegalArgumentException();
         }
      }
      ```

      下面是 **MainApp.java** 文件的内容：

      ```java
      package com.tutorialspoint;
      import org.springframework.context.ApplicationContext;
      import org.springframework.context.support.ClassPathXmlApplicationContext;
      public class MainApp {
         public static void main(String[] args) {
            ApplicationContext context = 
                   new ClassPathXmlApplicationContext("Beans.xml");
            Student student = (Student) context.getBean("student");
            student.getName();
            student.getAge();     
            student.printThrowException();
         }
      }
      ```

      下面是配置文件 **Beans.xml**：

      ```xml
      <?xml version="1.0" encoding="UTF-8"?>
      <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
          xmlns:aop="http://www.springframework.org/schema/aop"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.0.xsd 
          http://www.springframework.org/schema/aop 
          http://www.springframework.org/schema/aop/spring-aop-3.0.xsd ">
      
          <aop:aspectj-autoproxy/>
      
         <!-- Definition for student bean -->
         <bean id="student" class="com.tutorialspoint.Student">
            <property name="name"  value="Zara" />
            <property name="age"  value="11"/>      
         </bean>
      
         <!-- Definition for logging aspect -->
         <bean id="logging" class="com.tutorialspoint.Logging"/> 
      
      </beans>
      ```

      一旦你已经完成的创建了源文件和 bean 配置文件，让我们运行一下应用程序。如果你的应用程序一切都正常的话，这将会输出以下消息：

      ```
      Going to setup student profile.
      Name : Zara
      Student profile has been setup.
      Returning:Zara
      Going to setup student profile.
      Age : 11
      Student profile has been setup.
      Returning:11
      Going to setup student profile.
      Exception raised
      Student profile has been setup.
      There has been an exception: java.lang.IllegalArgumentException
      .....
      other exception content
      ```

  - JBDC框架(?)

  - 事务管理

    一个数据库事务是一个被视为单一的工作单元的操作序列。这些操作应该要么完整地执行，要么完全不执行。事务管理是一个重要组成部分，RDBMS 面向企业应用程序，以确保数据完整性和一致性。事务的概念可以描述为具有以下四个关键属性说成是 **ACID**。

  - Web MVC框架

    Spring web MVC 框架提供了模型-视图-控制的体系结构和可以用来开发灵活、松散耦合的 web 应用程序的组件。MVC 模式导致了应用程序的不同方面(输入逻辑、业务逻辑和 UI 逻辑)的分离，同时提供了在这些元素之间的松散耦合。

    - **模型**封装了应用程序数据，并且通常它们由 POJO 组成。
    - **视图**主要用于呈现模型数据，并且通常它生成客户端的浏览器可以解释的 HTML 输出。
    - **控制器**主要用于处理用户请求，并且构建合适的模型并将其传递到视图呈现。

    **定义控制器**

    DispatcherServlet 发送请求到控制器中执行特定的功能。**@Controller** 注释表明一个特定类是一个控制器的作用。**@RequestMapping** 注释用于映射 URL 到整个类或一个特定的处理方法。

    ```java
    @Controller
    @RequestMapping("/hello")
    public class HelloController{
       @RequestMapping(method = RequestMethod.GET)
       public String printHello(ModelMap model) {
          model.addAttribute("message", "Hello Spring MVC Framework!");
          return "hello";
       }
    }
    ```

    **@Controller** 注释定义该类作为一个 Spring MVC 控制器。在这里，第一次使用的 **@RequestMapping** 表明在该控制器中处理的所有方法都是相对于 **/hello** 路径的。下一个注释 **@RequestMapping(method = RequestMethod.GET)** 用于声明 *printHello()* 方法作为控制器的默认 service 方法来处理 HTTP GET 请求。你可以在相同的 URL 中定义其他方法来处理任何 POST 请求。

    你可以用另一种形式来编写上面的控制器，你可以在 *@RequestMapping* 中添加额外的属性，如下所示：

    ```java
    @Controller
    public class HelloController{
       @RequestMapping(value = "/hello", method = RequestMethod.GET)
       public String printHello(ModelMap model) {
          model.addAttribute("message", "Hello Spring MVC Framework!");
          return "hello";
       }
    }
    ```

    **值**属性表明 URL 映射到哪个处理方法，**方法**属性定义了 service 方法来处理 HTTP GET 请求。关于上面定义的控制器，这里有以下几个要注意的要点：

    - 你将在一个 service 方法中定义需要的业务逻辑。你可以根据每次需求在这个方法中调用其他方法。
    - 基于定义的业务逻辑，你将在这个**方法**中创建一个模型。你可以设置不同的模型属性，这些属性将被视图访问并显示最终的结果。这个示例创建了一个带有属性 “message” 的模型。
    - 一个定义的 service 方法可以返回一个包含**视图**名称的字符串用于呈现该模型。这个示例返回 “hello” 作为逻辑视图的名称。

- Spring Bean

  > [https://www.awaimai.com/2596.html](<https://www.awaimai.com/2596.html>)

  - 定义

    在 Spring 中，构成应用程序**主干**并由**Spring IoC容器**管理的**对象**称为**bean**。bean是一个由Spring IoC容器实例化、组装和管理的对象。

    关键信息：

    1. bean是对象，一个或者多个不限定
    2. bean由Spring中一个叫IoC的东西管理
    3. 我们的应用程序由一个个bean构成

  - 控制反转（IoC）

    **控制反转**英文全称：**Inversion of Control**，简称就是`IoC`。

    控制反转通过依赖注入（DI）方式**实现对象之间的松耦合关系**。

    程序运行时，依赖对象由【辅助程序】动态生成并注入到被依赖对象中，动态绑定两者的使用关系。

    Spring IoC容器就是这样的辅助程序，它负责对象的生成和依赖的注入，让后在交由我们使用。

    简而言之，就是：IoC就是**一个对象定义其依赖关系而不创建它们的过程**。

    - 私有属性保存依赖

      **第1点：使用私有属性保存依赖对象，并且只能通过构造函数参数传入，**

      构造函数的参数可以是**工厂方法**、**保存类对象的属性**、或者是**工厂方法返回值**。

      假设我们有一个`Computer`类：

      ```java
      public class Computer {
          private String cpu;     // CPU型号
          private int ram;        // RAM大小，单位GB
      
          public Computer(String cpu, int ram) {
              this.cpu = cpu;
              this.ram = ram;
          }
      }
      ```

      我们有另一个`Person`类依赖于`Computer`类，符合IoC的做法是这样：

      ```java
      public class Person {
          private Computer computer;
      
          public Person(Computer computer) {
              this.computer = computer;
          }
      }
      ```

      不符合IoC的做法如下：

      ```java
      // 直接在Person里实例化Computer类
      public class Person {
          private Computer computer = new Computer("AMD", 3);
      }
      
      // 通过【非构造函数】传入依赖
      public class Person {
          private Computer computer;
          
          public void init(Computer computer) {
              this.computer = computer;
          }
      }
      ```

    - 让Spring控制类构建过程

      **第2点：不用**`new`**，让Spring控制**`new`**过程。**

      在Spring中，我们基本不需要 `new` 一个类，这些都是让 Spring 去做的。

      Spring 启动时会把所需的类实例化成对象，如果需要依赖，则先实例化依赖，然后实例化当前类。

      因为依赖必须通过构建函数传入，所以实例化时，当前类就会接收并保存所有依赖的对象。

      这一步也就是所谓的**依赖注入**。

    - 这就是IoC

      在 Spring 中，**类的实例化、依赖的实例化、依赖的传入**都交由 Spring Bean 容器控制，

      而不是用`new`方式实例化对象、通过非构造函数方法传入依赖等常规方式。

      实质的控制权已经交由程序管理，而不是程序员管理，所以叫做控制反转。

  - Bean？

    - 概念1：**Bean容器**，或称spring ioc容器，主要用来管理对象和依赖，以及依赖的注入。
    - 概念2：bean是一个**Java对象**，根据bean规范编写出来的类，并由bean容器生成的对象就是一个bean。
    - 概念3：bean规范。

    ![img](https://www.awaimai.com/wp-content/uploads/2018/11/ioc-bean.png)

    bean规范如下：

    1. 所有属性为private
    2. 提供默认构造方法
    3. 提供getter和setter
    4. 实现serializable接口

---

- Spring中自动装配的方式

  - no：不进行自动装配，手动设置Bean的依赖关系。
  - byName：根据Bean的名字进行自动装配。
  - byType：根据Bean的类型进行自动装配。
  - constructor：类似于byType，不过是应用于构造器的参数，如果正好有一个Bean与构造器的参数类型相同则可以自动装配，否则会导致错误。
  - autodetect：如果有默认的构造器，则通过constructor的方式进行自动装配，否则使用byType的方式进行自动装配。

  自动装配没有自定义装配方式那么精确，而且不能自动装配简单属性（基本类型、字符串等），在使用时应注意。

  > [https://blog.csdn.net/topwqp/article/details/8686025](<https://blog.csdn.net/topwqp/article/details/8686025>)

  1：no   默认的方式是不进行自动装配，通过手工设置ref 属性来进行装配bean

  2：byName   通过参数名 自动装配，如果一个bean的name 和另外一个bean的 property 相同，就自动装配。

  3：byType   通过参数的数据类型自动自动装配，如果一个bean的数据类型和另外一个bean的property属性的数据类型兼容，就自动装配

  4：construct   构造方法中的参数通过byType的形式，自动装配。

  5：autodetect   如果有默认的构造方法，通过 construct的方式自动装配，否则使用 byType的方式自动装配。用于spring2.5 ，spring3.0测试不通过，估计是废弃了。

  **一： auto-wire  : no(默认方式)**

  首先定义测试需要的类：

  ```java
  package com.myapp.core.autowire;
   
  public class Book {
     public  String  toString(){
  	   return   "I'm  a book, read  me......";
     }
  }
  ```

  ```java
  package com.myapp.core.autowire;
   
  public class Person {
    
  	private  Book book;
  	
  	public  Person(Book book){
  		this.book= book;
  	}
  	
  	public void  setBook(Book book){
  		this.book = book;
  	}
  	
  	public  String  toString(){
  		return  "I'm  a person  I want  to  read  a book   "+ book;
  	}
  	
  	public Person(){
  		
  	}
  }
  ```

  默认方式配置：

  ```xml
  <?xml version="1.0" encoding="UTF-8"?>
  <beans xmlns="http://www.springframework.org/schema/beans"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://www.springframework.org/schema/beans
             http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">
   
    <!-- more bean definitions for data access objects go here -->
    
    <bean id="person" class="com.myapp.core.autowire.Person">
     <property name="book" ref="book" />
    </bean>
    
    <bean  id="book" class="com.myapp.core.autowire.Book"></bean>
    
  </beans>
  ```

  编写测试类：

  ```java
  com.myapp.core.autowire;
   
  import org.springframework.context.ApplicationContext;
  import org.springframework.context.support.ClassPathXmlApplicationContext;
   
  public class MainTest {
  	
  	 public static void main(String[] args) {
  		
  		 ApplicationContext  context  = new ClassPathXmlApplicationContext("resource/autowire.xml");
  		 
  		 Person   person =  (Person)context.getBean("person");
  		 
  		 System.out.println(person.toString());
  	}
    
  }
  ```

  **二：通过byName 自动装配：**

  修改配置文件如下：

  在这个例子中通过bean的属性名自动装配；因为这个 person bean的属性 book和配置文件中id为book的名字相同，所以Spring将通过setBook(Book book)自动装配。

  ```xml
  <!-- byName -->
  <bean id="person" class="com.myapp.core.autowire.Person" autowire="byName"></bean>
  <bean id="book" class="com.myapp.core.autowire.Book"></bean>
  ```

  **三：通过byType自动装配：**

  在这个例子中通过bean的属性名的类型进行自动装配；因为 person bean属性 book的类型和配置文件中id为book的类型相同，所以spring通过setBook(Book  book)自动装配。

  修改配置文件如下：

  ```xml
  <!-- byType -->
  <bean id="person" class="com.myapp.core.autowire.Person" autowire="byType"/>
  <bean id="book" class="com.myapp.core.autowire.Book"></bean>
  ```

  **四：通过construct自动装配：**

  通过构造方法的参数的数据类型进行自动装配，在这个例子中因为person的构造方法参数是Book类型，和配置文件中的id为book的类型相同，所以spring通过Person(Book book)构造方法进行自动装配。

  修改配置文件如下：

  ```xml
  <!-- construct -->
  <bean id="person" class="com.myapp.core.autowire.Person" autowire="constructor"/>
  <bean id="book" class="com.myapp.core.autowire.Book"></bean>
  ```

  **五：通过 autodetect 自动装配：**

  Spring 3.0配置的xml不能用于autodetect，spring3.0应该是去掉了这个功能，改用spring2.5配置可以顺利通过测试。

  首先使用construct的自动装配形式进行装配，如果没有construct就通过 byType的形式进行自动装配。

  ```xml
  <beans xmlns="http://www.springframework.org/schema/beans"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://www.springframework.org/schema/beans
  http://www.springframework.org/schema/beans/spring-beans-2.5.xsd">
      
    <bean id="person" class="com.myapp.core.autowire.Person"   autowire="autodetect"/>
    <bean id="book" class="com.myapp.core.autowire.Book"></bean>
    
  </beans>
  ```

  总结：

  自动装配不容易看出bean之间的引用关系，增加了阅读的复杂度，一般还是采用默认的方式手工进行配置，或者采用annotation的方式进行配置。

- IOC容器如何存储Bean对象的

  容器加载时会将所有单例的bean实例化并且放入hashmap中，再之后需要单例bean便从hashmap中get，如果hashmap中没有，则从spring ioc容器中实例化并放入hashmap，返回。非单例bean不会被放入hashmap中，只会从ioc容器中加载。

- Spring中Bean的作用域有哪些？

  在Spring的早期版本中，仅有两个作用域：singleton和prototype，前者表示Bean以单例的方式存在；后者表示每次从容器中调用Bean时，都会返回一个新的实例，prototype通常翻译为原型。

  设计模式中的创建型模式中也有一个原型模式，原型模式也是一个常用的模式，例如做一个室内设计软件，所有的素材都在工具箱中，而每次从工具箱中取出的都是素材对象的一个原型，可以通过对象克隆来实现原型模式。

  Spring 2.x中针对WebApplicationContext新增了3个作用域，分别是：request（每次HTTP请求都会创建一个新的Bean）、session（同一个HttpSession共享同一个Bean，不同的HttpSession使用不同的Bean）和globalSession（同一个全局Session共享一个Bean）。

  单例模式和原型模式都是重要的设计模式。一般情况下，无状态或状态不可变的类适合使用单例模式。在传统开发中，由于DAO持有Connection这个非线程安全对象因而没有使用单例模式；但在Spring环境下，所有DAO类对可以采用单例模式，因为Spring利用AOP和Java API中的ThreadLocal对非线程安全的对象进行了特殊处理。

- Spring中BeanFactory和ApplicationContext的区别

  > [https://blog.csdn.net/pseudonym_/article/details/72826059](<https://blog.csdn.net/pseudonym_/article/details/72826059>)

  **1. 两者的大概背景**

  BeanFactory：
  
  **BeanFactory是spring中比较原始，比较古老的Factory。因为比较古老，所以BeanFactory无法支持spring插件，例如：AOP、Web应用等功能。**

  ApplicationContext

  **ApplicationContext是BeanFactory的子类**，因为古老的BeanFactory无法满足不断更新的spring的需求，于是ApplicationContext就基本上代替了BeanFactory的工作，以一种更面向框架的工作方式以及对上下文进行分层和实现继承，并在这个基础上对功能进行扩展：

  <1>MessageSource, 提供国际化的消息访问

  <2>资源访问（如URL和文件）

  <3>事件传递

  <4>Bean的自动装配

  <5>各种不同应用层的Context实现

  **2. 利用BeanFactory获取bean**

  ```java
  //XmlBeanFactory是典型的BeanFactory。
  BeanFactory factory = new XmlBeanFactory("XXX.xml");
  //获取一个叫做mdzz的bean。在这个时候进行实例化。
  factory.getBean("mdzz");
  ```

   重点：**当我们使用BeanFactory去获取Bean的时候，我们只是实例化了该容器，而该容器中的bean并没有被实例化。当我们getBean的时候，才会实时实例化该bean对象。**

  **3. 利用ApplicationContext获取bean**

  ```java
  //当我们实例化XXX.xml的时候，该文件中配置的bean都会被实例化。（该bean scope是singleton）
  ApplicationContext appContext = new ClassPathXmlApplicationContext("XXX.xml");
  ```

   重点：**当我们使用ApplicationContext去获取bean的时候，在加载XXX.xml的时候，会创建所有的配置bean。**

  **4. 三种获取ApplicationContext对象引用的方法**

  ```java
  //第一种加载方法，加载的是classpath下的配置文件。
  ApplicationContext applicationContext = new ClassPathXmlApplicationContext("applicationContext.xml");
  //第二种加载方法，加载的是磁盘路径下的文件。
  ApplicationContext applicationContext = new FileSystemXmlApplicationContext("applicationContext.xml");
  //第三种加载方法，XmlWebApplicationContext，从web系统中加载。
  
  //得到配置文件后，就能拿到想要的对象。例如：
  HelloService helloService = (HelloService) applicationContext.getBean("userService");
  //在这当中getBean中的参数为你在配置文件下，这个对象的id，一个标识。123456789
  ```

  **5. 区别总结**

  <1>如果使用ApplicationContext，如果配置的bean是singleton，那么不管你有没有或想不想用它，它都会被实例化。好处是可以预先加载，坏处是浪费内存。

  <2>BeanFactory，当使用BeanFactory实例化对象时，配置的bean不会马上被实例化，而是等到你使用该bean的时候（getBean）才会被实例化。好处是节约内存，坏处是速度比较慢。多用于移动设备的开发。

  <3>没有特殊要求的情况下，应该使用ApplicationContext完成。因为BeanFactory能完成的事情，ApplicationContext都能完成，并且提供了更多接近现在开发的功能。

- 什么是IoC和DI？DI是如何实现的？

  IoC叫控制反转，是Inversion of Control的缩写，DI（Dependency Injection）叫依赖注入，是对IoC更简单的诠释。**控制反转是把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的"控制反转"就是对组件对象控制权的转移，从程序代码本身转移到了外部容器，由容器来创建对象并管理对象之间的依赖关系。**IoC体现了好莱坞原则 - "Don’t call me, we will call you"。依赖注入的基本原则是应用组件不应该负责查找资源或者其他依赖的协作对象。配置对象的工作应该由容器负责，查找资源的逻辑应该从应用组件的代码中抽取出来，交给容器来完成。DI是对IoC更准确的描述，即组件之间的依赖关系由容器在运行期决定，形象的来说，即**由容器动态的地将某种依赖关系注入到组件之中**。

  一个类A需要用到接口B中的方法，那么就需要为类A和接口B建立关联或依赖关系，最原始的方法是在类A中创建一个接口B的实现类C的实例，但这种方法需要开发人员自行维护二者的依赖关系，也就是说当依赖关系发生变动的时候需要修改代码并重新构建整个系统。如果通过一个容器来管理这些对象以及对象的依赖关系，则只需要在类A中定义好用于关联接口B的方法（构造器或setter方法），将类A和接口B的实现类C放入容器中，通过对容器的配置来实现二者的关联。

  依赖注入可以通过setter方法注入（设值注入）、构造器注入和接口注入三种方式来实现，Spring支持**setter注入**和**构造器注入**，通常使用构造器注入来注入必须的依赖关系，对于可选的依赖关系，则setter注入是更好的选择，setter注入需要类提供无参构造器或者无参的静态工厂方法来创建对象。

- 依赖注入的方式有哪几种？这些方法如何使用？

- @Controller和@RestController的区别

  @RestController注解相当于@ResponseBody ＋ @Controller合在一起的作用。

- 在以前的学习中有使用过Spring里面的注解吗？如果有请谈一下autowired 和resource区别是什么？
  
  1、共同点

  两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。

  2、不同点

  （1）@Autowired

  @Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。

  **@Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。**

  （2）@Resource

  **@Resource默认按照ByName自动注入**，由J2EE提供，需要导入包javax.annotation.Resource。**@Resource有两个重要的属性：name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。**

  > [https://blog.csdn.net/u010648555/article/details/76299467](https://blog.csdn.net/u010648555/article/details/76299467)

  **Spring常用注解**

  **一： 组件类注解**

  @Component ：标准一个普通的spring Bean类。 
  
  @Repository：标注一个DAO组件类。 
  
  @Service：标注一个业务逻辑组件类。 
  
  @Controller：标注一个控制器组件类。

  **二：装配bean时常用的注解**

  @Autowired：属于Spring 的org.springframework.beans.factory.annotation包下,可用于为类的属性、构造器、方法进行注值 
  
  @Resource：不属于spring的注解，而是来自于JSR-250位于java.annotation包下，使用该annotation为目标bean指定协作者Bean。 
  
  @PostConstruct 和 @PreDestroy 方法 实现初始化和销毁bean之前进行的操作

  相同点 
  
  @Resource的作用相当于@Autowired，均可标注在字段或属性的setter方法上。
  
  不同点

  a：提供方 

  @Autowired是Spring的注解，@Resource是javax.annotation注解，而是来自于JSR-250，J2EE提供，需要JDK1.6及以上。

  **b ：注入方式** 
  
  @Autowired只按照Type 注入；@Resource默认按Name自动注入，也提供按照Type 注入；

  **c：属性**

  @Autowired注解可用于为类的属性、构造器、方法进行注值。默认情况下，其依赖的对象必须存在（bean可用），如果需要改变这种默认方式，可以设置其required属性为false。
  还有一个比较重要的点就是，@Autowired注解默认按照类型装配，如果容器中包含多个同一类型的Bean，那么启动容器时会报找不到指定类型bean的异常，解决办法是结合**@Qualifier**注解进行限定，指定注入的bean名称。

  > **@Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。**
  
  @Resource有两个中重要的属性：name和type。name属性指定byName，如果没有指定name属性，当注解标注在字段上，即默认取字段的名称作为bean名称寻找依赖对象，当注解标注在属性的setter方法上，即默认取属性名作为bean名称寻找依赖对象。
  需要注意的是，@Resource如果没有指定name属性，并且按照默认的名称仍然找不到依赖对象时， @Resource注解会回退到按类型装配。但一旦指定了name属性，就只能按名称装配了。

  > **@Resource默认按照ByName自动注入**，由J2EE提供，需要导入包javax.annotation.Resource。**@Resource有两个重要的属性：name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。**

  d：
  
  @Resource注解的使用性更为灵活，可指定名称，也可以指定类型 ；@Autowired注解进行装配容易抛出异常，特别是装配的bean类型有多个的时候，而解决的办法是需要在增加@Qualifier进行限定。

  **三：@Component vs @Configuration and @Bean**

  **四：spring MVC模块注解**

  `@RestController` = `@Controller` + `@ResponseBody`
  
  `@RequestMapping`, `@PostMapping`, `@GetMapping`
  
  `@RequestBody`, `@RequestParam`, `@PathVariable`

  > [http://tengj.top/2016/04/28/javareflect/](http://tengj.top/2016/04/28/javareflect/)

  Java反射机制是指在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。
  
  用一句话总结就是**反射可以实现在运行时可以知道任意一个类的属性和方法。**
  
  **理解Class类和类类型**
  
  类是java.lang.Class类的实例对象，而Class是所有类的类。
  
  ```java
  Class c1 = Code.class;
  //这说明任何一个类都有一个隐含的静态成员变量class，这种方式是通过获取类的静态成员变量class得到的
  Class c2 = code1.getClass();
  //code1是Code的一个对象，这种方式是通过一个类的对象的getClass()方法获得的
  Class c3 = Class.forName("com.trigl.reflect.Code");
  //这种方法是Class类调用forName方法，通过一个类的全量限定名获得
  ```
  
  这里，c1、c2、c3都是Class的对象，他们是完全一样的，而且有个学名，叫做Code的类类型（class type）。

  **Java反射相关操作**

  获取成员方法Method

  ```java
  public Method getDeclaredMethod(String name, Class<?>... parameterTypes) // 得到该类所有的方法，不包括父类的
  public Method getMethod(String name, Class<?>... parameterTypes) // 得到该类所有的public方法，包括父类的
  ```

  获取成员变量Field

  ```java
  public Field getDeclaredField(String name) // 获得该类自身声明的所有变量，不包括其父类的变量
  public Field getField(String name) // 获得该类自所有的public成员变量，包括其父类变量
  ```
  
  获取构造函数Constructor
  ```java
  public Constructor<T> getDeclaredConstructor(Class<?>... parameterTypes) //  获得该类所有的构造器，不包括其父类的构造器
  public Constructor<T> getConstructor(Class<?>... parameterTypes) // 获得该类所以public构造器，包括父类
  ```

- bean的生命周期

  > [https://www.zhihu.com/question/38597960](<https://www.zhihu.com/question/38597960>)

  对于普通的Java对象，当new的时候创建对象，当它没有任何引用的时候被垃圾回收机制回收。而由Spring IoC容器托管的对象，它们的生命周期完全由容器控制。Spring中每个Bean的生命周期如下：

  ![img](https://pic1.zhimg.com/80/v2-baaf7d50702f6d0935820b9415ff364c_hd.jpg)

  1. **实例化Bean**

     对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。
     对于ApplicationContext容器，当容器启动结束后，便实例化所有的bean。
     容器通过获取BeanDefinition对象中的信息进行实例化。并且这一步仅仅是简单的实例化，并未进行依赖注入。
     实例化对象被包装在BeanWrapper对象中，BeanWrapper提供了设置对象属性的接口，从而避免了使用反射机制设置属性。

  2. **设置对象属性（依赖注入）**

     实例化后的对象被封装在BeanWrapper对象中，并且此时对象仍然是一个原生的状态，并没有进行依赖注入。
     紧接着，Spring根据BeanDefinition中的信息进行依赖注入。
     并且通过BeanWrapper提供的设置属性的接口完成依赖注入。

  3. 注入Aware接口

     紧接着，Spring会检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给bean。

  4. **BeanPostProcessor**

     当经过上述几个步骤后，bean对象已经被正确构造，但如果你想要对象被使用前再进行一些自定义的处理，就可以通过BeanPostProcessor接口实现。
     该接口提供了两个函数：

     - postProcessBeforeInitialzation( Object bean, String beanName )
       当前正在初始化的bean对象会被传递进来，我们就可以对这个bean作任何处理。
       这个函数会先于InitialzationBean执行，因此称为前置处理。
       所有Aware接口的注入就是在这一步完成的。
     - postProcessAfterInitialzation( Object bean, String beanName )
       当前正在初始化的bean对象会被传递进来，我们就可以对这个bean作任何处理。
       这个函数会在InitialzationBean完成后执行，因此称为后置处理。

  5. **InitializingBean与init-method**

     **当BeanPostProcessor的前置处理完成后就会进入本阶段。**
     InitializingBean接口只有一个函数：

     - afterPropertiesSet()

       这一阶段也可以在bean正式构造完成前增加我们自定义的逻辑，但它与前置处理不同，由于该函数并不会把当前bean对象传进来，因此在这一步没办法处理对象本身，只能增加一些额外的逻辑。
       若要使用它，我们需要让bean实现该接口，并把要增加的逻辑写在该函数中。然后Spring会在前置处理完成后检测当前bean是否实现了该接口，并执行afterPropertiesSet函数。

       当然，Spring为了降低对客户代码的侵入性，给bean的配置提供了init-method属性，该属性指定了在这一阶段需要执行的函数名。Spring便会在初始化阶段执行我们设置的函数。init-method本质上仍然使用了InitializingBean接口。

  6. **DisposableBean和destroy-method**

     和init-method一样，通过给destroy-method指定函数，就可以在bean销毁前执行指定的逻辑。

- 请简要说明一下IOC和AOP是什么？

  > [https://blog.csdn.net/bieleyang/article/details/78339361](<https://blog.csdn.net/bieleyang/article/details/78339361>)

  什么是DI机制？

  依赖注入（Dependecy Injection）和控制反转（Inversion of Control）是同一个概念，具体的讲：当某个角色 需要另外一个角色协助的时候，在传统的程序设计过程中，通常由调用者来创建被调用者的实例。但在spring中 创建被调用者的工作不再由调用者来完成，因此称为控制反转。创建被调用者的工作由spring来完成，然后注入调用者 因此也称为依赖注入。 spring以动态灵活的方式来管理对象 ， 注入的两种方式，设置注入和构造注入。 设置注入的优点：直观，自然 构造注入的优点：可以在构造器中决定依赖关系的顺序。

  什么是AOP？

  面向切面编程（AOP）完善spring的依赖注入（DI），面向切面编程在spring中主要表现为两个方面

  1.面向切面编程提供声明式事务管理

  2.spring支持用户自定义的切面

  面向切面编程（aop）是对面向对象编程（oop）的补充，面向对象编程将程序分解成各个层次的对象，面向切面编程将程序运行过程分解成各个切面。AOP从程序运行角度考虑程序的结构，提取业务处理过程的切面，oop是静态的抽象，aop是动态的抽象，是对应用执行过程中的步骤进行抽象，从而获得步骤之间的逻辑划分。

  > ioc：控制反转、依赖注入（核心原理：反射机制）（优点：借助于第三方IOC容器实现对象之间的依赖关系解耦）
  >
  > aop：**分离应用的业务逻辑和系统级服务**（如日志、事务管理、安全权限等）（核心原理：代理模式（动态代理））
  >
  > 代理模式（静态代理、动态代理）：（在不修改被代理对象源码的基础上，进行功能增强）

- Spring支持的事务管理类型有哪些？你在项目中会使用哪种方式？

  Spring支持**编程式事务管理**和**声明式事务管理**。许多Spring框架的用户选择声明式事务管理，因为这种方式和应用程序的关联较少，因此更加符合轻量级容器的概念。声明式事务管理要优于编程式事务管理，尽管在灵活性方面它弱于编程式事务管理，因为编程式事务允许你通过代码控制业务。

  事务分为全局事务和局部事务。全局事务由应用服务器管理，需要底层服务器JTA支持（如WebLogic、WildFly等）。局部事务和底层采用的持久化方案有关，例如使用JDBC进行持久化时，需要使用Connetion对象来操作事务；而采用Hibernate进行持久化时，需要使用Session对象来操作事务。

  这些事务的父接口都是PlatformTransactionManager。Spring的事务管理机制是一种典型的策略模式，PlatformTransactionManager代表事务管理接口，该接口定义了三个方法，该接口并不知道底层如何管理事务，但是它的实现类必须提供getTransaction()方法（开启事务）、commit()方法（提交事务）、rollback()方法（回滚事务）的多态实现，这样就可以用不同的实现类代表不同的事务管理策略。使用JTA全局事务策略时，需要底层应用服务器支持，而不同的应用服务器所提供的JTA全局事务可能存在细节上的差异，因此实际配置全局事务管理器是可能需要使用JtaTransactionManager的子类，如：WebLogicJtaTransactionManager（Oracle的WebLogic服务器提供）、UowJtaTransactionManager（IBM的WebSphere服务器提供）等。

- 你如何理解AOP中的连接点（Joinpoint）、切点（Pointcut）、增强（Advice）、引介（Introduction）、织入（Weaving）、切面（Aspect）这些概念？

  a. **连接点**（Joinpoint）：**程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。**Spring仅支持方法的连接点。

  b. **切点**（Pointcut）：**如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。**Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。

  c. **增强**（Advice）：**增强是织入到目标类连接点上的一段程序代码。**Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。*

  d. 引介（Introduction）：引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的为该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。

  e. 织入（Weaving）：织入是将增强添加到目标类具体连接点上的过程，AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。

  f. **切面**（Aspect）：**切面是由切点和增强（引介）组成的**，它包括了对横切关注功能的定义，也包括了对连接点的定义。

- AOP的原理是什么？

  > Java核心面试知识整理

  Spring 提供了两种方式来生成代理对象: JDKProxy 和Cglib，具体使用哪种方式生成由AopProxyFactory 根据AdvisedSupport 对象的配置来决定。**默认的策略是如果目标类是接口，则使用JDK 动态代理技术，否则使用Cglib 来生成代理。**

  - JDK动态接口代理

    JDK 动态代理主要涉及到java.lang.reflect 包中的两个类：Proxy 和InvocationHandler。InvocationHandler 是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编制在一起。Proxy 利用InvocationHandler 动态创建一个符合某一接口的实例，生成目标类的代理对象。
  
  - CGLib 动态代理

    CGLib 全称为Code Generation Library，是一个强大的高性能，高质量的代码生成类库，可以在运行期扩展Java 类与实现Java 接口，CGLib 封装了asm，可以再运行期动态生成新的class。和JDK 动态代理相比较：**JDK 创建代理有一个限制，就是只能为接口创建代理实例，而对于没有通过接口定义业务方法的类，则可以通过CGLib 创建动态代理。**

  > [https://juejin.im/post/5bf4fc84f265da611b57f906](<https://juejin.im/post/5bf4fc84f265da611b57f906>)

  **AOP简介**

  相信大家或多或少的了解过AOP，都知道它是面向切面编程，在网上搜索可以找到很多的解释。这里我用一句话来总结：AOP是能够让我们在不影响原有功能的前提下，为软件横向扩展功能。 那么横向扩展怎么理解呢，我们在WEB项目开发中，通常都遵守三层原则，包括控制层（Controller）->业务层（Service）->数据层（dao）,那么从这个结构下来的为纵向，它具体的某一层就是我们所说的横向。我们的AOP就是可以作用于这某一个横向模块当中的所有方法。

  我们在来看一下AOP和OOP的区别：AOP是OOP的补充，当我们需要为多个对象引入一个公共行为，比如日志，操作记录等，就需要在每个对象中引用公共行为，这样程序就产生了大量的重复代码，使用AOP可以完美解决这个问题。

  接下来介绍一下提到AOP就必须要了解的知识点：

  - 切面：拦截器类，其中会定义切点以及通知

  - 切点：具体拦截的某个业务点。

  - 通知：切面当中的方法，声明通知方法在目标业务层的执行位置，通知类型如下：

    1. 前置通知：@Before 在目标业务方法执行之前执行
    
    2. 后置通知：@After 在目标业务方法执行之后执行
    
    3. 返回通知：@AfterReturning 在目标业务方法返回结果之后执行
    
    4. 异常通知：@AfterThrowing 在目标业务方法抛出异常之后
    
    5. 环绕通知：@Around 功能强大，可代替以上四种通知，还可以控制目标业务方法是否执行以及何时执行

  **代码中实现举例**

  上面已经大概的介绍了AOP中需要了解的基本知识，也知道了AOP的好处，那怎么在代码中实现呢？给大家举个例子：我们现在有个学校管理系统，已经实现了对老师和学生的增删改，又新来个需求，说是对老师和学生的每次增删改做一个记录，到时候校长可以查看记录的列表。那么问题来了，怎么样处理是最好的解决办法呢？这里我罗列了三种解决办法，我们来看下他的优缺点。

  ![img](https://user-gold-cdn.xitu.io/2018/11/21/167357a2851d2cfc?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

  最简单的就是第一种方法，我们直接在每次的增删改的函数当中直接实现这个记录的方法，这样代码的重复度太高，耦合性太强，不建议使用。

  其次就是我们最长使用的，将记录这个方法抽离出来，其他的增删改调用这个记录函数即可，显然代码重复度降低，但是这样的调用还是没有降低耦合性。

  这个时候我们想一下AOP的定义，再想想我们的场景，其实我们就是要在不改变原来增删改的方法，给这个系统增加记录的方法，而且作用的也是一个层面的方法。这个时候我们就可以采用AOP来实现了。

  我们来看下代码的具体实现：

  1. 首先我定义了一个自定义注解作为切点
  ```java
  @Target(AnnotationTarget.FUNCTION)  //注解作用的范围，这里声明为函数
  @Order(Ordered.HIGHEST_PRECEDENCE)  //声明注解的优先级为最高，假设有多个注解，先执行这个
  annotation class Hanler(val handler: HandlerType)  //自定义注解类，HandlerType是一个枚举类型，里面定义的就是学生和老师的增删改操作，在这里就不展示具体内容了
  ```

  2. 接下来就是要定义切面类了
  ```java
  @Aspect   //该注解声明这个类为一个切面类
  @Component
  class HandlerAspect{
  
      @Autowired
      private lateinit var handlerService: HandlerService
  
      @AfterReturning("@annotation(handler)")   //当有函数注释了注解，将会在函数正常返回后在执行我们定义的方法
      fun hanler(hanler: Hanler) {
          handlerService.add(handler.operate.value)   //这里是真正执行记录的方法
      }
  }
  ```

  3. 最后就是我们本来的业务方法了
  ```java
  /**
  * 删除学生方法
  */
  @Handler(operate= Handler.STUDENT_DELETE)   //当执行到删除学生方法时，切面类就会起作用了,当学生正常删除后就会执行记录方法，我们就可以看到记录方法生成的数据
  fun delete(id：String) {
    studentService.delete(id)
  }
  ```

  **AOP实现原理**

  我们现在了解了代码中如何实现，那么AOP实现的原理是什么呢？之前看了一个博客说到，提到AOP大家都知道他的实现原理是动态代理，显然我之前就是不知道的，哈哈，但是相信阅读文章的你们一定是知道的。

  讲到动态代理就不得不说代理模式了， 代理模式的定义：给某一个对象提供一个代理，并由代理对象控制对原对象的引用。代理模式包含如下角色：subject：抽象主题角色，是一个接口。该接口是对象和它的代理共用的接口; RealSubject：真实主题角色，是实现抽象主题接口的类; Proxy:代理角色，内部含有对真实对象RealSubject的引用，从而可以操作真实对象。代理对象提供与真实对象相同的接口，以便代替真实对象。同时，代理对象可以在执行真实对象操作时，附加其他的操作，相当于对真实对象进行封装。如下图所示：

  ![img](https://user-gold-cdn.xitu.io/2018/11/22/1673a262814cef3e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

  ![img](https://user-gold-cdn.xitu.io/2018/11/22/1673a2653b02d775?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

  那么代理又分为静态代理和动态代理，这里写两个小的demo，动态代理采用的就是JDK代理。举个例子就是现在一个班上的学生需要交作业，现在由班长代理交作业，那么班长就是代理，学生就是被代理的对象。

  - 静态代理

    首先，我们创建一个Person接口。这个接口就是学生（被代理类），和班长（代理类）的公共接口，他们都有交作业的行为。这样，学生交作业就可以让班长来代理执行。

    ```java
    /**
     * Created by Mapei on 2018/11/7
     * 创建person接口
     */
    public interface Person {
        //交作业
        void giveTask();
    }
    ```

    Student类实现Person接口，Student可以具体实施交作业这个行为。

    ```java
    /**
     * Created by Mapei on 2018/11/7
     */
    public class Student implements Person {
        private String name;
        public Student(String name) {
            this.name = name;
        }

        public void giveTask() {
            System.out.println(name + "交语文作业");
        }
    }
    ```

    StudentsProxy类，这个类也实现了Person接口，但是还另外持有一个学生类对象，那么他可以代理学生类对象执行交作业的行为。

    ```java
    /**
     * Created by Mapei on 2018/11/7
     * 学生代理类，也实现了Person接口，保存一个学生实体，这样就可以代理学生产生行为
     */
    public class StudentsProxy implements Person{
        //被代理的学生
        Student stu;

        public StudentsProxy(Person stu) {
            // 只代理学生对象
            if(stu.getClass() == Student.class) {
                this.stu = (Student)stu;
            }
        }

        //代理交作业，调用被代理学生的交作业的行为
        public void giveTask() {
            stu.giveTask();
        }
    }
    ```

    下面测试一下，看代理模式如何使用：

    ```java
    /**
     * Created by Mapei on 2018/11/7
     */
    public class StaticProxyTest {
        public static void main(String[] args) {
            //被代理的学生林浅，他的作业上交有代理对象monitor完成
            Person linqian = new Student("林浅");

            //生成代理对象，并将林浅传给代理对象
            Person monitor = new StudentsProxy(linqian);

            //班长代理交作业
            monitor.giveTask();
        }
    }
    ```

    这里并没有直接通过林浅（被代理对象）来执行交作业的行为，而是通过班长（代理对象）来代理执行了。这就是代理模式。代理模式就是在访问实际对象时引入一定程度的间接性，这里的间接性就是指不直接调用实际对象的方法，那么我们在代理过程中就可以加上一些其他用途。比如班长在帮林浅交作业的时候想告诉老师最近林浅的进步很大，就可以轻松的通过代理模式办到。在代理类的交作业之前加入方法即可。这个优点就可以运用在spring中的AOP，我们能在一个切点之前执行一些操作，在一个切点之后执行一些操作，这个切点就是一个个方法。这些方法所在类肯定就是被代理了，在代理过程中切入了一些其他操作。

  - 动态代理

    动态代理和静态代理的区别是，**静态代理的的代理类是我们自己定义好的，在程序运行之前就已经编译完成，但是动态代理的代理类是在程序运行时创建的。** 相比于静态代理，动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。比如我们想在每个代理方法之前都加一个处理方法，我们上面的例子中只有一个代理方法，如果还有很多的代理方法，就太麻烦了，我们来看下动态代理是怎么去实现的。

    首先还是定义一个Person接口:

    ```java
    /**
     * Created by Mapei on 2018/11/7
     * 创建person接口
     */
    public interface Person {
        //交作业
        void giveTask();
    }
    ```

    接下来是创建需要被代理的实际类，也就是学生类：

    ```java
    /**
     * Created by Mapei on 2018/11/7
     */
    public class Student implements Person {
        private String name;
        public Student(String name) {
            this.name = name;
        }

        public void giveTask() {
            System.out.println(name + "交语文作业");
        }
    }
    ```

    创建StuInvocationHandler类，实现InvocationHandler接口，这个类中持有一个被代理对象的实例target。InvocationHandler中有一个invoke方法，所有执行代理对象的方法都会被替换成执行invoke方法。

    ```java
    /**
     * Created by Mapei on 2018/11/7
     */
    public class StuInvocationHandler<T> implements InvocationHandler {
        //invocationHandler持有的被代理对象
        T target;

        public StuInvocationHandler(T target) {
            this.target = target;
        }

        /**
        * proxy:代表动态代理对象
        * method：代表正在执行的方法
        * args：代表调用目标方法时传入的实参
        */
        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
            System.out.println("代理执行" +method.getName() + "方法");
            Object result = method.invoke(target, args);
            return result;
        }
    }
    ```

    那么接下来我们就可以具体的创建代理对象了。

    ```java
    /**
     * Created by Mapei on 2018/11/7
     * 代理类
     */
    public class ProxyTest {
        public static void main(String[] args) {

            //创建一个实例对象，这个对象是被代理的对象
            Person linqian = new Student("林浅");

            //创建一个与代理对象相关联的InvocationHandler
            InvocationHandler stuHandler = new StuInvocationHandler<Person>(linqian);

            //创建一个代理对象stuProxy来代理linqian，代理对象的每个执行方法都会替换执行Invocation中的invoke方法
            Person stuProxy = (Person) Proxy.newProxyInstance(Person.class.getClassLoader(), new Class<?>[]{Person.class}, stuHandler);

            //代理执行交作业的方法
            stuProxy.giveTask();
        }
    }
    ```

    我们执行代理测试类，首先我们创建了一个需要被代理的学生林浅，将林浅传入stuHandler中，我们在创建代理对象stuProxy时，将stuHandler作为参数，那么所有执行代理对象的方法都会被替换成执行invoke方法，也就是说，最后执行的是StuInvocationHandler中的invoke方法。所以在看到下面的运行结果也就理所当然了。

- aop的应用场景有哪些？

  > [https://zhuanlan.zhihu.com/p/83204146](https://zhuanlan.zhihu.com/p/83204146)

  **为什么会有面向切面编程（AOP）？**

  我们知道Java是一个面向对象（OOP）的语言，但它有一些弊端，比如当我们需要为多个不具有继承关系的对象引入一个公共行为，例如日志、权限验证、事务等功能时，只能在在每个对象里引用公共行为。这样做不便于维护，而且有大量重复代码。AOP的出现弥补了OOP的这点不足。

  **Spring AOP 中设计的一些核心知识，面试问题？**

  1、能说一下Spring AOP用的是哪种设计模式？

  回答：代理模式。

  2、 能简单聊一下你对代理模式的理解吗？

  记住一些贴近日常的示例方便理解，如买火车票，Windows 里面的快捷方式...

  3、 知道JDK代理和Cglib代理有什么区别？

  我们不需要创建代理类，JDK 在运行时为我们动态的来创建，JDK代理是接口

  若目标类不存在接口,则使用Cglib生成代理

  不管是JDK代理还是Cglib代理本质上都是对字节码进行操作

  4、让你实现一个JDK实现动态代理？你的思路是什么？

  Proxy: 定义一个自己的Proxy类

  InvocationHandler：定义一个自己的InvocationHandler类

  ClassLoad：自定义类加载器（方便加载我们自己指定的路径下面的类）

  **SpringAOP的在实际应用中场景有哪些？**

  1. **Authentication 权限**
  2. Caching 缓存
  3. Context passing 内容传递
  4. Error handling 错误处理
  5. Lazy loading 懒加载
  6. **Debugging 调试**
  7. logging，tracing，profiling and monitoring 记录跟踪 优化 校准
  8. Performance optimization 性能优化
  9. **Persistence 持久化**
  10. Resource pooling 资源池
  11. Synchronization 同步
  12. **Transactions 事务**
  13. **Logging 日志**

- Spring框架为企业级开发带来的好处有哪些？

  - 非侵入式：支持基于POJO的编程模式，不强制性的要求实现Spring框架中的接口或继承Spring框架中的类。
  
  - IoC容器：IoC容器帮助应用程序管理对象以及对象之间的依赖关系，对象之间的依赖关系如果发生了改变只需要修改配置文件而不是修改代码，因为代码的修改可能意味着项目的重新构建和完整的回归测试。有了IoC容器，程序员再也不需要自己编写工厂、单例，这一点特别符合Spring的精神"不要重复的发明轮子"。
  
  - AOP（面向切面编程）：将所有的横切关注功能封装到切面（aspect）中，通过配置的方式将横切关注功能动态添加到目标代码上，进一步实现了业务逻辑和系统服务之间的分离。另一方面，有了AOP程序员可以省去很多自己写代理类的工作。
  
  - MVC：Spring的MVC框架为Web表示层提供了更好的解决方案。
  
  - 事务管理：Spring以宽广的胸怀接纳多种持久层技术，并且为其提供了声明式的事务管理，在不需要任何一行代码的情况下就能够完成事务管理。
  
  - 其他：选择Spring框架的原因还远不止于此，Spring为Java企业级开发提供了一站式选择，你可以在需要的时候使用它的部分和全部，更重要的是，甚至可以在感觉不到Spring存在的情况下，在你的项目中使用Spring提供的各种优秀的功能。

- spring框架的优点都有哪些？

  Spring是一个轻量级的DI和AOP容器框架，在项目的中的使用越来越广泛，它的优点主要有以下几点：

  Spring是一个非侵入式框架，其目标是使应用程序代码对框架的依赖最小化，应用代码可以在没有Spring或者其他容器的情况运行。

  Spring提供了一个一致的编程模型，使应用直接使用POJO开发，从而可以使运行环境隔离开来。

  Spring推动应用的设计风格向面向对象及面向接口编程转变，提高了代码的重用性和可测试性。

  Spring改进了结构体系的选择，虽然作为应用平台，Spring可以帮助我们选择不同的技术实现，比如从Hibernate切换到其他的ORM工具，从Struts切换到Spring MVC,尽管我们通常不会这么做，但是我们在技术方案上选择使用Spring作为应用平台，Spring至少为我们提供了这种可能性的选择，从而降低了平台锁定风险。

- Struts拦截器和Spring AOP有什么区别？

  拦截器是AOP的一种实现，struts2 拦截器采用xwork2的interceptor！而spring的AOP基于IoC基础,其底层采用动态代理与CGLIB代理两种方式结合的实现方式。

- 请简单介绍一下spring？

  Spring是一个轻量级框架，可以一站式构建你的企业级应用。

  Spring的模块大概分为6个。分别是：

  1、Core Container（Spring的核心）【重要】

  2、AOP（面向切面编程）【重要】

  3、Messaging（消息发送的支持）

  4、Data Access/Integration（数据访问和集成）

  5、Web（主要是SpringWeb内容，包括MVC）【重要】

  6、Test（Spring测试支持，包含JUint等测试单元的支持） 
  
  7、Instrumentation（设备支持，比如Tomcat的支持）

- 持久层设计要考虑的问题有哪些？请谈一下你用过的持久层框架都有哪些？

  所谓"持久"就是将数据保存到可掉电式存储设备中以便今后使用，简单的说，就是将内存中的数据保存到关系型数据库、文件系统、消息队列等提供持久化支持的设备中。持久层就是系统中专注于实现数据持久化的相对独立的层面。

  持久层设计的目标包括：
  - 数据存储逻辑的分离，提供抽象化的数据访问接口。
  - 数据访问底层实现的分离，可以在不修改代码的情况下切换底层实现。
  - 资源管理和调度的分离，在数据访问层实现统一的资源调度（如缓存机制）。
  - 数据抽象，提供更面向对象的数据操作。

  持久层框架有：
  - Hibernate
  - MyBatis
  - TopLink
  - Guzz
  - jOOQ
  - Spring Data
  - ActiveJDBC

#### 设计模式

> Java面试突击

> 设计模式比较常见的就是让你手写一个单例模式（注意单例模式的几种不同的实现方法）或者让你说一下某个常见的设计模式在你的项目中是如何使用的，另外面试官还有可能问你抽象工厂和工厂方法模式的区别、工厂模式的思想这样的问题。
>
> 建议把代理模式、观察者模式、（抽象）工厂模式好好看一下，这三个设计模式也很重要。

- 单例模式

  > [https://blog.csdn.net/qq_34337272/article/details/80455972](https://blog.csdn.net/qq_34337272/article/details/80455972)

  - 单例模式简介

    **为什么要用单例模式呢？**

    在我们的系统中，有一些对象其实我们只需要一个，比如说：线程池、缓存、对话框、注册表、日志对象、充当打印机、显卡等设备驱动程序的对象。事实上，这一类对象只能有一个实例，如果制造出多个实例就可能会导致一些问题的产生，比如：程序的行为异常、资源使用过量、或者不一致性的结果。

    简单来说使用单例模式可以带来下面几个好处:

    对于频繁使用的对象，可以省略创建对象所花费的时间，这对于那些重量级对象而言，是非常可观的一笔系统开销；
    由于 new 操作的次数减少，因而对系统内存的使用频率也会降低，这将减轻 GC 压力，缩短 GC 停顿时间。

    **为什么不使用全局变量确保一个类只有一个实例呢？**

    我们知道全局变量分为静态变量和实例变量，静态变量也可以保证该类的实例只存在一个。

    只要程序加载了类的字节码，不用创建任何实例对象，静态变量就会被分配空间，静态变量就可以被使用了。

    但是，如果说这个对象非常消耗资源，而且程序某次的执行中一直没用，这样就造成了资源的浪费。**利用单例模式的话，我们就可以实现在需要使用时才创建对象，这样就避免了不必要的资源浪费。** 不仅仅是因为这个原因，在程序中我们要尽量避免全局变量的使用，大量使用全局变量给程序的调试、维护等带来困难。

  - 单例的模式的实现

    通常单例模式在Java语言中，有两种构建方式：

    - **饿汉方式。指全局的单例实例在类装载时构建。**
    - **懒汉方式。指全局的单例实例在第一次被使用时构建。**
    
    不管是那种创建方式，它们通常都存在下面几点相似处：

    - 单例类**必须要有一个 private 访问级别的构造函数，只有这样，才能确保单例不会在系统中的其他代码内被实例化;**
    - **uniqueInstance 成员变量和 getInstance 方法必须是 static 的。**

    **饿汉方式(线程安全)**

    ```java
    public class Singleton {
        //在静态初始化器中创建单例实例，这段代码保证了线程安全
        private static Singleton uniqueInstance = new Singleton();
        //Singleton类只有一个构造方法并且是被private修饰的，所以用户无法通过new方法创建该对象实例
        private Singleton(){}
        public static Singleton getInstance(){
            return uniqueInstance;
        }
    }
    ```

    所谓 “饿汉方式” 就是说JVM在加载这个类时就马上创建此唯一的单例实例，不管你用不用，先创建了再说，如果一直没有被使用，便浪费了空间，典型的空间换时间，每次调用的时候，就不需要再判断，节省了运行时间。

    **懒汉式（非线程安全和synchronized关键字线程安全版本 ）**

    ```java
    public class Singleton {  
        private static Singleton uniqueInstance;  
        private Singleton (){}   
        //没有加入synchronized关键字的版本是线程不安全的
        public static Singleton getInstance() {
            //判断当前单例是否已经存在，若存在则返回，不存在则再建立单例
            if (uniqueInstance == null) {  
                uniqueInstance = new Singleton();  
            }  
            return uniqueInstance;  
        }  
    }
    ```

    所谓 “ 懒汉式” 就是说单例实例在第一次被使用时构建，而不是在JVM在加载这个类时就马上创建此唯一的单例实例。

    但是上面这种方式很明显是线程不安全的，如果多个线程同时访问getInstance()方法时就会出现问题。如果想要保证线程安全，一种比较常见的方式就是在getInstance() 方法前加上synchronized关键字，如下：

    ```java
    public static synchronized Singleton getInstance() {  
	      if (instance == null) {  
	          uniqueInstance = new Singleton();  
	      }  
	      return uniqueInstance;  
    } 
    ```

    我们知道synchronized关键字偏重量级锁。虽然在JavaSE1.6之后synchronized关键字进行了主要包括：为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升。

    但是在程序中每次使用getInstance() 都要经过synchronized加锁这一层，这难免会增加getInstance()的方法的时间消费，而且还可能会发生阻塞。我们下面介绍到的 双重检查加锁版本 就是为了解决这个问题而存在的。

    **懒汉式(双重检查加锁版本)**

    利用双重检查加锁（double-checked locking），首先检查是否实例已经创建，如果尚未创建，“才”进行同步。这样以来，只有一次同步，这正是我们想要的效果。

    ```java
    public class Singleton {
        //volatile保证，当uniqueInstance变量被初始化成Singleton实例时，多个线程可以正确处理uniqueInstance变量
        private volatile static Singleton uniqueInstance;
        private Singleton() {}
        public static Singleton getInstance() {
            //检查实例，如果不存在，就进入同步代码块
            if (uniqueInstance == null) {
                //只有第一次才彻底执行这里的代码
                synchronized(Singleton.class) {
                    //进入同步代码块后，再检查一次，如果仍是null，才创建实例
                    if (uniqueInstance == null) {
                        uniqueInstance = new Singleton();
                    }
                }
            }
            return uniqueInstance;
        }
    }
    ```

    很明显，这种方式相比于使用synchronized关键字的方法，可以大大减少getInstance() 的时间消费。

    我们上面使用到了volatile关键字来保证数据的可见性。

    **懒汉式（登记式/静态内部类方式）**

    静态内部实现的单例是懒加载的且线程安全。

    只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 instance（只有第一次使用这个单例的实例的时候才加载，同时不会有线程安全问题）。

    ```java
    public class Singleton {  
        private static class SingletonHolder {  
            private static final Singleton INSTANCE = new Singleton();  
        }  
        private Singleton (){}  
        public static final Singleton getInstance() {  
            return SingletonHolder.INSTANCE;  
        }  
    }
    ```

    **饿汉式（枚举方式）**

    这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。 它更简洁，自动支持序列化机制，绝对防止多次实例化 （如果单例类实现了Serializable接口，默认情况下每次反序列化总会创建一个新的实例对象，关于单例与序列化的问题可以查看这一篇文章《单例与序列化的那些事儿》），同时这种方式也是《Effective Java 》以及《Java与模式》的作者推荐的方式。

    ```java
    public enum Singleton {
        //定义一个枚举的元素，它就是 Singleton 的一个实例
        INSTANCE;  
        
        public void doSomeThing() {  
          System.out.println("枚举方法实现单例");
        }  
    }
    ```

    使用方法：

    ```java
    public class ESTest {
        public static void main(String[] args) {
            Singleton singleton = Singleton.INSTANCE;
            singleton.doSomeThing();//output:枚举方法实现单例
        }
    }
    ```

    > 这种方法在功能上与公有域方法相近，但是它更加简洁，无偿提供了序列化机制，绝对防止多次实例化，即使是在面对复杂序列化或者反射攻击的时候。虽然这种方法还没有广泛采用，但是单元素的枚举类型已经成为实现Singleton的最佳方法。 —-《Effective Java 中文版 第二版》

- 工厂模式

  > [https://blog.csdn.net/qq_34337272/article/details/80472071](https://blog.csdn.net/qq_34337272/article/details/80472071)

  - 工厂模式介绍
  
    **工厂模式的定义**
    
    在基类中定义创建对象的一个接口，让子类决定实例化哪个类。工厂方法让一个类的实例化延迟到子类中进行。

    **工厂模式的分类**

    （1）简单工厂（Simple Factory）模式，又称静态工厂方法模式（Static Factory Method Pattern）。

    （2）工厂方法（Factory Method）模式，又称多态性工厂（Polymorphic Factory）模式或虚拟构造子（Virtual Constructor）模式；

    （3）抽象工厂（Abstract Factory）模式，又称工具箱（Kit 或Toolkit）模式。

    **工厂模式的例子**

    (1) Spring中通过getBean(“xxx”)获取Bean；

    (2) Java消息服务JMS中(下面以消息队列ActiveMQ为例子)

    ```java
    ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://192.168.25.155:61616");
    ```

    **为什么要用工厂模式**

    (1) 解耦 ：把对象的创建和使用的过程分开

    (2) 降低代码重复: 如果创建某个对象的过程都很复杂，需要一定的代码量，而且很多地方都要用到，那么就会有很多的重复代码。

    (3) 降低维护成本 ：由于创建过程都由工厂统一管理，所以发生业务逻辑变化，不需要找到所有需要创建对象的地方去逐个修正，只需要在工厂里修改即可，降低维护成本。

  - 简单工厂模式

    严格的说，简单工厂模式并不是23种常用的设计模式之一，它只算工厂模式的一个特殊实现。简单工厂模式在实际中的应用相对于其他2个工厂模式用的还是相对少得多，因为它只适应很多简单的情况。

    最重要的是它违背了我们在概述中说的 开放-封闭原则 （虽然可以通过反射的机制来避免，后面我们会介绍到） 。因为每次你要新添加一个功能，都需要在生switch-case 语句（或者if-else 语句）中去修改代码，添加分支条件。

  - 工厂方法模式

    工厂方法模式应该是在工厂模式家族中是用的最多模式，一般项目中存在最多的就是这个模式。

    工厂方法模式是简单工厂的进一步深化， **在工厂方法模式中，我们不再提供一个统一的工厂类来创建所有的对象，而是针对不同的对象提供不同的工厂。** 也就是说 每个对象都有一个与之对应的工厂 。

  - 抽象工厂模式

    在工厂方法模式中，其实我们有一个潜在意识的意识。那就是我们生产的都是同一类产品。**抽象工厂模式是工厂方法的仅一步深化，在这个模式中的工厂类不单单可以创建一种产品，而是可以创建一组产品。**

    抽象工厂是生产一整套有产品的（至少要生产两个产品)，这些产品必须相互是有关系或有依赖的，而工厂方法中的工厂是生产单一产品的工厂。

- 代理模式

  > [https://www.ibm.com/developerworks/cn/java/j-lo-proxy-pattern/index.html](https://www.ibm.com/developerworks/cn/java/j-lo-proxy-pattern/index.html)

- 观察者模式

  > [https://design-patterns.readthedocs.io/zh_CN/latest/behavioral_patterns/observer.html](https://design-patterns.readthedocs.io/zh_CN/latest/behavioral_patterns/observer.html)

## 工具

## 项目

#### SpringBoot

- SpringBoot介绍

  > [https://github.com/Snailclimb/springboot-guide/blob/master/docs/start/springboot-introduction.md#%E4%B8%80-springboot%E4%BB%8B%E7%BB%8D](https://github.com/Snailclimb/springboot-guide/blob/master/docs/start/springboot-introduction.md#%E4%B8%80-springboot%E4%BB%8B%E7%BB%8D)
  
  我们知道Spring是重量级企业开发框架 Enterprise JavaBean（EJB） 的替代品，Spring为企业级Java开发提供了一种相对简单的方法，通过 依赖注入 和 面向切面编程 ，用简单的 Java对象（Plain Old Java Object，POJO） 实现了EJB的功能

  虽然Spring的组件代码是轻量级的，但它的配置却是重量级的（需要大量XML配置） 。Spring 2.5引入了基于注解的组件扫描，这消除了大量针对应用程序自身组件的显式XML配置。Spring 3.0引入了基于Java的配置，这是一种类型安全的可重构配置方式，可以代替XML。

  尽管如此，我们依旧没能逃脱配置的魔爪。开启某些Spring特性时，比如事务管理和Spring MVC，还是需要用XML或Java进行显式配置。启用第三方库时也需要显式配置，比如基于Thymeleaf的Web视图。配置Servlet和过滤器（比如Spring的DispatcherServlet）同样需要在web.xml或Servlet初始化代码里进行显式配置。组件扫描减少了配置量，Java配置让它看上去简洁不少，但Spring还是需要不少配置。

  光配置这些XML文件都够我们头疼的了，占用了我们大部分时间和精力。除此之外，相关库的依赖非常让人头疼，不同库之间的版本冲突也非常常见。

  从本质上来说，Spring Boot就是Spring，它做了那些没有它你自己也会去做的Spring Bean配置。

- Spring Boot 项目结构分析

  [https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/sringboot-restful-web-service.md](https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/sringboot-restful-web-service.md)

  1. Application.java是项目的启动类
  2. **domain目录主要用于实体（Entity）与数据访问层（Repository）**
  3. **service 层主要是业务类代码**
  4. **controller 负责页面访问控制**
  5. config 目录主要放一些配置类

- 开发 RestFul Web 服务

  > [https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/sringboot-restful-web-service.md](https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/sringboot-restful-web-service.md)

  **RESTful Web 服务介绍**

  RESTful Web 服务与传统的 MVC 开发一个关键区别是返回给客户端的内容的创建方式：传统的 MVC 模式开发会直接返回给客户端一个视图，但是 RESTful Web 服务一般会将返回的数据以 JSON 的形式返回，这也就是现在所推崇的前后端分离开发。

  1. `@RestController` **将返回的对象数据直接以 JSON 或 XML 形式写入 HTTP 响应(Response)中。** 绝大部分情况下都是直接以 JSON 形式返回给客户端，很少的情况下才会以 XML 形式返回。转换成 XML 形式还需要额为的工作，上面代码中演示的直接就是将对象数据直接以 JSON 形式写入 HTTP 响应(Response)中。关于@Controller和@RestController 的对比，我会在下一篇文章中单独介绍到（**@Controller +@ResponseBody= @RestController**）。
  2. `@RequestMapping` :上面的示例中没有指定 GET 与 PUT、POST 等，因为**@RequestMapping默认映射所有HTTP Action**，你可以使用@RequestMapping(method=ActionType)来缩小这个映射。
  3. `@PostMapping`实际上就等价于 @RequestMapping(method = RequestMethod.POST)，同样的 @DeleteMapping ,@GetMapping也都一样，常用的 HTTP Action 都有一个这种形式的注解所对应。
  4. `@PathVariable` :取url地址中的参数。@RequestParam url的查询参数值。
  5. `@RequestBody`:可以将 HttpRequest body 中的 JSON 类型数据反序列化为合适的 Java 类型。
  6. ResponseEntity: 表示整个HTTP Response：状态码，标头和正文内容。我们可以使用它来自定义HTTP Response 的内容。

  > `@RestController` = `@Controller` + `@ResponseBody`
  >
  > `@RequestMapping`, `@PostMapping`, `@GetMapping`
  >
  > `@RequestBody`, `@RequestParam`

- Spring Boot JPA 基础：常见操作解析

  > [https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/springboot-jpa.md](https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/springboot-jpa.md)

  实体类：为这个类添加了 @Entity 注解代表它是数据库持久化类

  创建操作数据库的 Repository 接口：首先这个接口加了 @Repository 注解，代表它和数据库操作有关。另外，它继承了 JpaRepository<Person, Long>接口

- JPA 中非常重要的连表查询就是这么简单

  > [https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/springboot-jpa-lianbiao.md](https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/springboot-jpa-lianbiao.md)

  **连表查询**
  
  我们需要创建一个包含我们需要的 Person 信息的 DTO 对象,我们简单第将其命名为 UserDTO，用于保存和传输我们想要的信息。

  sql 语句和我们平时写的没啥区别，差别比较大的就是里面有一个 new 对象的操作。

  **分页操作**

  为了实现分页，我们在@Query注解中还添加了 countQuery 属性。

  传入Pageable pageable，返回Page<UserDTO>

- 面试题

  **什么是 Spring Boot?**

  首先，重要的是要理解 Spring Boot 并不是一个框架，它是一种创建独立应用程序的更简单方法，只需要很少或没有配置（相比于 Spring 来说）。Spring Boot最好的特性之一是它利用现有的 Spring 项目和第三方项目来开发适合生产的应用程序。

  **说出使用Spring Boot的主要优点**

  1. 开发基于 Spring 的应用程序很容易。
  2. Spring Boot 项目所需的开发或工程时间明显减少，通常会提高整体生产力。
  3. **Spring Boot不需要编写大量样板代码、XML配置和注释。**
  4. Spring引导应用程序可以很容易地与Spring生态系统集成，如Spring JDBC、Spring ORM、Spring Data、Spring Security等。
  5. Spring Boot遵循“固执己见的默认配置”，以减少开发工作（默认配置可以修改）。
  6. **Spring Boot 应用程序提供嵌入式HTTP服务器，如Tomcat和Jetty，可以轻松地开发和测试web应用程序。**（这点很赞！普通运行Java程序的方式就能运行基于Spring Boot web 项目，省事很多）
  7. Spring Boot提供命令行接口(CLI)工具，用于开发和测试Spring Boot应用程序，如Java或Groovy。
  8. Spring Boot提供了多种插件，可以使用内置工具(如Maven和Gradle)开发和测试Spring Boot应用程序。

  **什么是 Spring Boot Starters?**

  Spring Boot Starters 是一系列依赖关系的集合，因为它的存在，项目的依赖之间的关系对我们来说变的更加简单了。举个例子：在没有Spring Boot Starters之前，我们开发REST服务或Web应用程序时; 我们需要使用像Spring MVC，Tomcat和Jackson这样的库，这些依赖我们需要手动一个一个添加。但是，有了 Spring Boot Starters 我们只需要一个只需添加一个spring-boot-starter-web一个依赖就可以了，这个依赖包含的字依赖中包含了我们开发REST 服务需要的所有依赖。

  ```xml
  <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-web</artifactId>
  </dependency>
  ```

  **如何在Spring Boot应用程序中使用Jetty而不是Tomcat?**

  Spring Boot Web starter使用Tomcat作为默认的嵌入式servlet容器, 如果你想使用 Jetty 的话只需要修改pom.xml(Maven)或者build.gradle(Gradle)就可以了。

  **介绍一下@SpringBootApplication注解**

  大概可以把 `@SpringBootApplication `看作是 `@Configuration`、`@EnableAutoConfiguration`、`@ComponentScan ` 注解的集合。根据 SpringBoot官网，这三个注解的作用分别是：

  - `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制
  - `@ComponentScan`： 扫描被`@Component` (`@Service`,`@Controller`)注解的bean，注解默认会扫描该类所在的包下所有的类。
  - `@Configuration`：允许在上下文中注册额外的bean或导入其他配置类

  **(重要)Spring Boot 的自动配置是如何实现的?**

  这个是因为@SpringBootApplication 注解的原因。

  **Spring Boot支持哪些嵌入式web容器？**

  Spring Boot支持以下嵌入式servlet容器:

  | **Name**     | **Servlet Version** |
  | ------------ | ------------------- |
  | Tomcat 9.0   | 4.0                 |
  | Jetty 9.4    | 3.1                 |
  | Undertow 2.0 | 4.0                 |

  您还可以将Spring引导应用程序部署到任何Servlet 3.1+兼容的 Web 容器中。

  这就是你为什么可以通过直接像运行 普通 Java 项目一样运行 SpringBoot 项目。这样的确省事了很多，方便了我们进行开发，降低了学习难度。

  **什么是Spring Security ?**

  Spring Security 应该属于 Spring 全家桶中学习曲线比较陡峭的几个模块之一，下面我将从起源和定义这两个方面来简单介绍一下它。

  - **起源：** Spring Security 实际上起源于 Acegi Security，这个框架能为基于 Spring 的企业应用提供强大而灵活安全访问控制解决方案，并且框架这个充分利用 Spring 的 IoC 和 AOP 功能，提供声明式安全访问控制的功能。后面，随着这个项目发展， Acegi Security 成为了Spring官方子项目，后来被命名为 “Spring Security”。
  - **定义：**Spring Security 是一个功能强大且高度可以定制的框架，侧重于为Java 应用程序提供身份验证和授权。——[官方介绍](https://spring.io/projects/spring-security)。

#### Shiro

> [https://www.cnblogs.com/wmyskxz/p/10229148.html](https://www.cnblogs.com/wmyskxz/p/10229148.html)

> [https://blog.csdn.net/qq_26648623/article/details/84062666](https://blog.csdn.net/qq_26648623/article/details/84062666)

- 应用安全的四大基石

  认证：用户身份识别，通常被称为用户“登录”。

  授权：访问控制。比如某个用户是否具有某个操作的使用权限。

  会话管理：特定于用户的会话管理,甚至在非web 或 EJB 应用程序。

  加密：在对数据源使用加密算法加密的同时，保证易于使用。

- 三个主要的理念

  Subject：当前用户，Subject 可以是一个人，但也可以是第三方服务、守护进程帐户、时钟守护任务或者其它–当前和软件交互的任何事件。

  SecurityManager：管理所有Subject，SecurityManager 是 Shiro 架构的核心，配合内部安全组件共同组成安全伞。
  
  Realms：用于进行权限信息的验证，我们自己实现。Realm 本质上是一个特定的安全 DAO：它封装与数据源连接的细节，得到Shiro 所需的相关的数据。在配置 Shiro 的时候，你必须指定至少一个Realm 来实现认证（authentication）和/或授权（authorization）。

- Shiro 加密

  在之前的学习中，我们在数据库中保存的密码都是明文的，一旦数据库数据泄露，那就会造成不可估算的损失，所以我们通常都会使用非对称加密，简单理解也就是不可逆的加密，而 md5 加密算法就是符合这样的一种算法。

  如上面的 123456 用 Md5 加密后，得到的字符串：e10adc3949ba59abbe56e057f20f883e，就无法通过计算还原回 123456，我们把这个加密的字符串保存在数据库中，等下次用户登录时我们把密码通过同样的算法加密后再从数据库中取出这个字符串进行比较，就能够知道密码是否正确了，这样既保留了密码验证的功能又大大增加了安全性，但是问题是：虽然无法直接通过计算反推回密码，但是我们仍然可以通过计算一些简单的密码加密后的 Md5 值进行比较，推算出原来的密码

  比如我的密码是 123456，你的密码也是，通过 md5 加密之后的字符串一致，所以你也就能知道我的密码了，如果我们把常用的一些密码都做 md5 加密得到一本字典，那么就可以得到相当一部分的人密码，这也就相当于“破解”了一样，所以其实也没有我们想象中的那么“安全”。

  既然相同的密码 md5 一样，那么我们就让我们的原始密码再加一个随机数，然后再进行 md5 加密，这个随机数就是我们说的盐(salt)，这样处理下来就能得到不同的 Md5 值，当然我们需要把这个随机数盐也保存进数据库中，以便我们进行验证。

  另外我们可以通过多次加密的方法，即使黑客通过一定的技术手段拿到了我们的密码 md5 值，但它并不知道我们到底加密了多少次，所以这也使得破解工作变得艰难。

#### Maven

  > [https://blog.csdn.net/weixin_37766296/article/details/79594837](https://blog.csdn.net/weixin_37766296/article/details/79594837)

  **优点**

  1. Maven是一个项目管理和综合工具。Maven提供了开发人员构建一个完整的生命周期框架。
  2. 在多个开发团队环境时，Maven可以设置按标准在非常短的时间里完成配置工作，使开发人员的工作更加轻松。
  3. Maven增加可重用性并负责建立相关的任务。

  > [https://www.cnblogs.com/sgh1023/p/10900130.html](https://www.cnblogs.com/sgh1023/p/10900130.html)

  **Maven常用命令**

  clean：删除项目中已经编译好的信息，删除target目录

  compile：Maven工程的编译命令，用于编译项目的源代码，将src/main/java下的文件编译成class文件输出到target目录下。

  test：使用合适的单元测试框架运行测试。

  package：将编译好的代码打包成可分发的格式，如JAR，WAR。

  install：安装包至本地仓库，以备本地的其它项目作为依赖使用。

  deploy：复制最终的包至远程仓库，共享给其它开发人员和项目（通常和一次正式的发布相关）。

  每一个构建项目的命令都对应了maven底层一个插件。

  **Maven命令package、install、deploy的联系与区别**

  mvn clean package依次执行了clean、resources、compile、testResources、testCompile、test、jar(打包)等7个阶段。

  mvn clean install依次执行了clean、resources、compile、testResources、testCompile、test、jar(打包)、install等8个阶段。

  mvn clean deploy依次执行了clean、resources、compile、testResources、testCompile、test、jar(打包)、install、deploy等9个阶段。

  主要区别：

  package命令完成了项目编译、单元测试、打包功能，但没有把打好的可执行jar包（war包或其它形式的包）布署到本地maven仓库和远程maven私服仓库。

  install命令完成了项目编译、单元测试、打包功能，同时把打好的可执行jar包（war包或其它形式的包）布署到本地maven仓库，但没有布署到远程maven私服仓库。

  deploy命令完成了项目编译、单元测试、打包功能，同时把打好的可执行jar包（war包或其它形式的包）布署到本地maven仓库和远程maven私服仓库。　

  **Maven生命周期**

  清理生命周期：运行mvn clean将调用清理生命周期 。

  默认生命周期：是一个软件应用程序构建过程的总体模型 。

  compile，test，package，install，deploy

  站点生命周期：为一个或者一组项目生成项目文档和报告，使用较少。

#### JPA

- JPA和MyBatis的区别

  > [https://blog.csdn.net/yunzhonmghe/article/details/78069449](https://blog.csdn.net/yunzhonmghe/article/details/78069449)

  **对于数据的操作，hibernate是面向对象的，而MyBatis是面向关系的。**

  > [https://blog.csdn.net/chehec2010/article/details/91195770](https://blog.csdn.net/chehec2010/article/details/91195770)

  Mybatis可以进行更细致的SQL优化,查询必要的字段,但是需要维护SQL和查询结果集的映射。数据库的移植性较差,针对不同的数据库编写不同的SQL。

  **Hibernate对数据库提供了较为完整的封装,封装了基本的DAO层操作,有较好的数据库移植性。**但是学习周期长，开发难度大于Mybatis。

  > [https://blog.csdn.net/u013905744/article/details/90812229](https://blog.csdn.net/u013905744/article/details/90812229)

  1. spring data jpa实现了jpa（java persistence api）功能，即可以实现pojo转换为关系型数据库记录的功能，通俗来讲就是可以不写任何的建表sql语句了。jpa是spring data jpa功能的一个子集。而mybatis并没有jpa功能，建表语句还是要自己写的。

  2. **spring data jpa是全自动框架，不需要写任何sql。**而mybatis是半自动框架，需要自己写sql，mybatis-plus为mybatis赋能，使其也可以基本上不需要写任何模板sql。

- 多表联查

  关系映射@OneToOne, @OneToMany, @ManyToOne

  > [https://blog.wuwii.com/jpa-query-muti.html](https://blog.wuwii.com/jpa-query-muti.html)

  > [https://blog.csdn.net/johnf_nash/article/details/80642581](https://blog.csdn.net/johnf_nash/article/details/80642581)

#### ElasticSearch & Solr

  > [https://www.cnblogs.com/jajian/p/9801154.html](https://www.cnblogs.com/jajian/p/9801154.html)
  
  全文搜索引擎的索引建立都是根据**倒排索引**的方式生成索引。

#### 分词算法

> [https://zhuanlan.zhihu.com/p/33261835](https://zhuanlan.zhihu.com/p/33261835)

- 基于词表的分词方法
  - 正向最大匹配法(forward maximum matching method, FMM)
  - 逆向最大匹配法(backward maximum matching method, BMM)
  - N-最短路径方法
- 基于统计模型的分词方法
  - 基于N-gram语言模型的分词方法
- 基于序列标注的分词方法
  - 基于HMM的分词方法
  - 基于CRF的分词方法
  - 基于词感知机的分词方法
  - 基于深度学习的端到端的分词方法

#### 爬虫

- 防爬

  > [https://segmentfault.com/a/1190000005840672](https://segmentfault.com/a/1190000005840672)

  - 后台对访问进行统计，如果单个IP访问超过阈值，予以封锁。
  - 后台对访问进行统计，如果单个session访问超过阈值，予以封锁。
  - 后台对访问进行统计，如果单个userAgent访问超过阈值，予以封锁。
  - 用JavaScript混淆

  > [https://www.zhihu.com/question/26221432](https://www.zhihu.com/question/26221432)

  - 模拟浏览器提交。

    简单的，使用 webkit 来提交数据，这个基本可以过大多数浏览源检测的反爬系统了。
  
    但是有的反爬系统检测浏览源的时候，会根据大众浏览器的一些特性，比如 IE，Firefox，Chrome 等的私有 js 函数来判定浏览器，这样 webkit ，以及一些封装好的 无界面浏览器 也被当成爬虫了。当然，你也可以利用调用 chromuim 来爬取数据，但是这个资源开销就更大了。

  - 控制单 ip/账号 频率。

    挂私有代理来爬的就不说了，大家都会用，但是对于一般人来说，几万 ip 差不多是极限了，所以一个 ip 还是得多次请求，账号同理。而控制了爬取速度，则意味着爬完一圈需要更多时间。时间都是成本。

  - 控制爬取策略。

    如果简单的只对目标数据进行爬取，那么如果反爬系统对访问概况和用户行为进行分析，其实很简单就能判定爬虫的那堆 ip : 你除了这堆数据什么都没访问，一看就不是正常用户。
  
    当然策略这个东西，就需要更多的博弈了。爬虫要增加迷惑度，需要去访问一些无关的东西，最后是研究正常用户的访问流程，然后模拟一遍。再者，控制速度。毕竟反爬系统的统计区间是肯定有限制的，不可能拿一个月的数据都分析一遍找出爬虫。

#### 项目介绍

我负责智能执法平台里用户授权的工作，从用户查询到他所拥有的权限，开发接口管理用户角色、角色、权限的增删改查，和它们之间的多对多关系的增删改查。另外我还负责法规的检索和推荐的工作。

#### 项目的问题

解决检索项目在服务器不能正常运行的问题

(1) 页面的搜索结果不能正常显示，但是后台并没有报错。

(2) 直接运行flask项目中的入口python文件没有问题，用uwsgi将配置文件中的3行多线程相关的内容注释掉也可以正常运行。

(3) 定位发现是调用HanLP的函数过程中线程会卡住。原因是利用python的jpype调用Hanlp的java源代码时，不能为新开启的线程分配JVM。解决方法是在每个API的开头添加两行代码，判断并为线程分配JVM。

#### Docker

## 开放性

- 后端新的技术

  **微服务**

  > [https://www.zhihu.com/question/65502802](https://www.zhihu.com/question/65502802)

  完全拆分后各个服务可以采用异构的技术。比如数据分析服务可以使用数据仓库作为持久化层，以便于高效地做一些统计计算；商品服务和促销服务访问频率比较大，因此加入了缓存机制等。

  微服务架构还有一个技术外的好处，它使整个系统的分工更加明确，责任更加清晰，每个人专心负责为其他人提供更好的服务。

  微服务架构整个应用分散成多个服务，定位故障点非常困难。在微服务架构中，一个服务故障可能会产生雪崩效用，导致整个系统故障。

  **云计算**

  云计算是一种商业计算模型。它将计算任务分布在大量计算机构成的资源池上，使各种应用系统能够根据需要获取计算力、存储空间和信息服务。

  云计算的三种服务模式
  
  - SaaS(Software as a Service，软件即服务)
  - PaaS(Platform as a Service，平台即服务)
  - IaaS(Infrastructure as a Service，基础架构即服务)

  云计算的基础技术

  - 虚拟化技术：系统虚拟化的目的是通过使用虚拟化管理器（Virtual Machine Monitor，简称VMM）在一台物理机上虚拟和运行一台或多台虚拟机（Virtual Machine，简称VM）。
  - 容器技术：提供应用运行的环境支持；封装系统资源，提供应用SDK；对应用进行管理、统计

  **Java特性：G1垃圾收集器、Java8（Lambda表达式、方法引用）**

  **Redis**

  **大数据计算：Spark，大数据存储：Hive、HBase，消息队列Kafka**

## 面经

- 牛客

  > [https://www.nowcoder.com/discuss/356120](https://www.nowcoder.com/discuss/356120)
  
  **集合**

  - ArrayList与LinkedList的实现和区别
  - HashMap：了解其数据结构、hash冲突如何解决（链表和红黑树）、扩容时机、扩容时避免rehash的优化
  - LinkedHashMap：了解基本原理、哪两种有序、如何用它实现LRU
  - TreeMap：了解数据结构、了解其key对象为什么必须要实现Compare接口、如何用它实现一致性哈希

  常见问题

  - hashmap如何解决hash冲突，为什么hashmap中的链表需要转成红黑树？
  - hashmap什么时候会触发扩容？
  - **jdk1.8之前并发操作hashmap时为什么会有死循环的问题？**
  - **hashmap扩容时每个entry需要再计算一次hash吗？**
  - hashmap的数组长度为什么要保证是2的幂？
  - **如何用LinkedHashMap实现LRU？**
  - **如何用TreeMap实现一致性hash？**

  **线程安全的集合**
  
  - Collections.synchronized：了解其实现原理
  - CopyOnWriteArrayList：了解写时复制机制、了解其适用场景、思考为什么没有ConcurrentArrayList
  - ConcurrentHashMap：了解实现原理、扩容时做的优化、与HashTable对比。
  - BlockingQueue：了解LinkedBlockingQueue、ArrayBlockingQueue、DelayQueue、SynchronousQueue

  常见问题

  - ConcurrentHashMap是如何在保证并发安全的同时提高性能？
  - ConcurrentHashMap是如何让多线程同时参与扩容？
  - LinkedBlockingQueue、DelayQueue是如何实现的？
  - CopyOnWriteArrayList是如何保证线程安全的？

  **I/O**

  - 了解BIO和NIO的区别、了解多路复用机制

  常见问题

  - 同步阻塞、同步非阻塞、异步的区别？
  - **select、poll、eopll的区别？**
  - java NIO与BIO的区别？
  - reactor线程模型是什么?

  **并发**

  - synchronized：了解偏向锁、轻量级锁、重量级锁的概念以及升级机制、以及和ReentrantLock的区别
  - CAS：了解AtomicInteger实现原理、CAS适用场景、如何实现乐观锁
  - AQS：了解AQS内部实现、及依靠AQS的同步类比如ReentrantLock、Semaphore、CountDownLatch、CyclicBarrier等的实现
  - ThreadLocal：了解ThreadLocal使用场景和内部实现
  - ThreadPoolExecutor：了解线程池的工作原理以及几个重要参数的设置

  常见问题

  - synchronized与ReentrantLock的区别？
  - 乐观锁和悲观锁的区别？
  - 如何实现一个乐观锁？
  - AQS是如何唤醒下一个线程的？
  - ReentrantLock如何实现公平和非公平锁是如何实现？
  - CountDownLatch和CyclicBarrier的区别？各自适用于什么场景？
  - 适用ThreadLocal时要注意什么？比如说内存泄漏?
  - 说一说往线程池里提交一个任务会发生什么？
  - 线程池的几个参数如何设置？
  - 线程池的非核心线程什么时候会被释放？
  - 如何排查死锁？

  **JVM**
  
  - GC：垃圾回收基本原理、几种常见的垃圾回收器的特性、重点了解CMS（或G1）以及一些重要的参数
  - 内存区域：能说清jvm的内存划分

  常见问题

  - CMS GC回收分为哪几个阶段？分别做了什么事情？
  - CMS有哪些重要参数？
  - Concurrent Model Failure和ParNew promotion failed什么情况下会发生？
  - CMS的优缺点？
  - 有做过哪些GC调优？
  - 为什么要划分成年轻代和老年代？
  - 年轻代为什么被划分成eden、survivor区域？
  - 年轻代为什么采用的是复制算法？
  - 老年代为什么采用的是标记清除、标记整理算法
  - 什么情况下使用堆外内存？要注意些什么？
  - 堆外内存如何被回收？
  - jvm内存区域划分是怎样的？

  **Mysql**

  - 事务隔离级别、锁、索引的数据结构、聚簇索引和非聚簇索引、最左匹配原则、查询优化（explain等命令）

  常见问题

  - Mysql(innondb 下同) 有哪几种事务隔离级别？
  - 不同事务隔离级别分别会加哪些锁？
  - mysql的行锁、表锁、间隙锁、意向锁分别是做什么的？
  - 说说什么是最左匹配？
  - 如何优化慢查询？
  - mysql索引为什么用的是b+ tree而不是b tree、红黑树
  - 分库分表如何选择分表键
  - 分库分表的情况下，查询时一般是如何做排序的？

  **Redis（或其他缓存系统）**

  - redis工作模型、redis持久化、redis过期淘汰机制、redis分布式集群的常见形式、分布式锁、缓存击穿、缓存雪崩、缓存一致性问题

  常见问题

  - redis性能为什么高?
  - 单线程的redis如何利用多核cpu机器？
  - redis的缓存淘汰策略？
  - redis如何持久化数据？
  - redis有哪几种数据结构？
  - redis集群有哪几种形式？
  - 有海量key和value都比较小的数据，在redis中如何存储才更省内存？
  - 如何保证redis和DB中的数据一致性？
  - 如何解决缓存穿透和缓存雪崩？
  - 如何用redis实现分布式锁？

  **中间件、存储、以及其他框架**

  - Spring：bean的生命周期、循环依赖问题、spring cloud（如项目中有用过）、AOP的实现、spring事务传播
  
  - java动态***和cglib动态***的区别（经常结合spring一起问所以就放这里了）
  - spring中bean的生命周期是怎样的？
  - 属性注入和构造器注入哪种会有循环依赖的问题？

  > [https://www.nowcoder.com/discuss/368408?type=2&order=4&pos=5&page=1](https://www.nowcoder.com/discuss/368408?type=2&order=4&pos=5&page=1)

  **ZooKeeper**

  - CAP定理
  - ZAB协议
  - leader选举算法和流程
  
  **Redis**

  - Redis的应用场景
  - Redis支持的数据类型（必考）
  - zset跳表的数据结构（必考）
  - Redis的数据过期策略（必考）
  - Redis的LRU过期策略的具体实现
  - 如何解决Redis缓存雪崩，缓存穿透问题
  - Redis的持久化机制（必考）
  - Redis的管道pipeline

  **Mysql**

  - 事务的基本要素
  - 事务隔离级别（必考）
  - 如何解决事务的并发问题(脏读，幻读)（必考）
  - MVCC多版本并发控制（必考）
  - binlog,redolog,undolog都是什么，起什么作用
  - InnoDB的行锁/表锁
  - myisam和innodb的区别，什么时候选择myisam
  - 为什么选择B+树作为索引结构（必考）
  - 索引B+树的叶子节点都可以存哪些东西（必考）
  - 查询在什么时候不走（预期中的）索引（必考）
  - sql如何优化
  - explain是如何解析sql的
  - order by原理
  
  **JVM**

  - 运行时数据区域（内存模型）（必考）
  - 垃圾回收机制（必考）
  - 垃圾回收算法（必考）
  - Minor GC和Full GC触发条件
  - GC中Stop the world（STW）
  - 各垃圾回收器的特点及区别
  - 双亲委派模型
  - JDBC和双亲委派模型关系
  
  **Java基础**

  - HashMap和ConcurrentHashMap区别（必考）
  - ConcurrentHashMap的数据结构（必考）
  - 高并发HashMap的环是如何产生的
  - volatile作用（必考）
  - Atomic类如何保证原子性（CAS操作）（必考）
  - synchronized和Lock的区别（必考）
  - 为什么要使用线程池（必考）
  - 核心线程池ThreadPoolExecutor的参数（必考）
  - ThreadPoolExecutor的工作流程（必考）
  - 如何控制线程池线程的优先级
  - 线程之间如何通信
  - Boolean占几个字节
  - jdk1.8/jdk1.7都分别新增了哪些特性
  - Exception和Error
  
  **Spring**

  - Spring的IOC/AOP的实现（必考）
  - 动态代理的实现方式（必考）
  - Spring如何解决循环依赖（三级缓存）（必考）
  - Spring的后置处理器
  - Spring的@Transactional如何实现的（必考）
  - Spring的事务传播级别
  - BeanFactory和ApplicationContext的联系和区别
  
  **其他**

  - 高并发系统的限流如何实现
  - 高并发秒杀系统的设计
  - 负载均衡如何设计
  
  **补充**

  另外还会考一些计算机网络，操作系统啊之类的。像消息队列，RPC框架这种考的比较少。计算机网络就是分层啊，tcp/udp啊，三次握手之类的。操作系统就是进程与线程啊，进程的数据结构以及如何通信之类的。数据结构的排序算法也比较常考，考的话一定会让你手写个快排。剩下的算法题就靠LeetCode的积累了。其实非算法岗考的算法题都蛮简单的，很多题完全就是考察你智力是否正常，稍微难点的涉及到一些算法思想的按照LeetCode题目类型的分类，每种题做一两道基本就能完全应付面试了。
  
  > [https://www.nowcoder.com/discuss/342084?type=2&order=4&pos=2&page=1](https://www.nowcoder.com/discuss/342084?type=2&order=4&pos=2&page=1)

  - **重写equals()是否需要重写hashcode()，不重写会有什么后果**
  - 自旋锁和阻塞锁的区别
  - 公平锁和非公平锁的区别
  - jdk中哪种数据结构或工具可以实现当多个线程到达某个状态时执行一段代码
  - 栅栏和闭锁的区别
  - 如何使用信号量实现上述情况
  - 新生代和年老代的GC算法分别是什么
  - 标记清除和标记整理的区别
  - 了解过CMS收集器吗
  - 解释HTTPs，HTTPs为什么要用对称加密+非对称加密，相对于只使用非对称加密有什么好处
  - 给定一个表，其中有三列（员工名称，工资，部门号），找出每个部门工资最高的员工
  - LeetCode 863 二叉树中所有距离为K的结点
  - 用过哪些Java开源框架
  - 讲一讲对Spring的理解
  - 看过IOC和AOP的源码吗
  - 它们底层是如何实现的
  - 用过其他什么框架
  - 了解过分布式或者微服务的开源框架吗
  - 讲一讲对分布式系统模型的理解
  - 分布式系统中有一个节点宕机怎么办
  - 分布式系统如何实现负载均衡
  - MySQL和Oracle数据库有哪些不同
  - 数据库有哪些锁
  - 表锁和行锁的区别
  - 哪些场景需要加表锁
  - 插入一条数据需要加什么锁
  - 分布式数据库如何保证数据可靠性
  - 了解过MySQL的主从复制吗
  
  > [https://www.nowcoder.com/discuss/372983](https://www.nowcoder.com/discuss/372983)

  - 如何实现延时任务
  - 如何实现限流
  - 线程池的参数
  - epoll和poll的区别
  - 如何自己实现内存分配和管理？不太懂，然后说了jvm的垃圾回收机制
  - Redis的key过期策略
  - 缓存穿透和缓存雪崩
  - 分布式锁
  - 如何实现全局的id生成策略
  - 悲观锁和乐观锁
  - 写个producer-consumer
  - 两线程交替打印
  - 线程模拟100分钱随机分给20个人，每个人最少分配到2分钱
  - MVCC
  - HTTPS
  - ElasticSearch的查询过程
  - Kafka如何保证高可用
  - Reids的集群和选主
  - 分布式一致性算法
  - 如何实现定时关单

  > [https://www.nowcoder.com/discuss/382503](https://www.nowcoder.com/discuss/382503)

  - 数据库的三大范式和约束类型
  - 线程生命周期

  > [https://www.nowcoder.com/discuss/382603](https://www.nowcoder.com/discuss/382603)

  - 知道MySQL插入和查询分别用的是什么锁吗？
  - 引用计数法与GC Root可达性分析法区别
  - CAS机制会出现什么问题
  - RabbitMQ了解吗？丢失消息，重复消费问题怎么处理？

  > [https://www.nowcoder.com/discuss/382329](https://www.nowcoder.com/discuss/382329)

  - 如何衡量一个哈希算法的好坏
  - 哈希解决冲突的4种方法
  - cookie和session的生命周期
  - 集群中的session会遇到什么问题，有什么解决方案呢
  - 常量过多会导致什么问题
  - JDK8用了哪种回收器，内存空间管理和以前相比有哪些提升（Parallel Scavenge + Parallel Old）
  - 构造函数的加载顺序，多个构造函数先加载哪一个
  - group by中使用的having是用来干啥的
  - 服务治理介绍一下
  - 远程调用需要从注册中心代理吗
  - 如果注册中心代理的话并发量太大不会承受不了，怎么解决

  > [https://www.nowcoder.com/discuss/382110](https://www.nowcoder.com/discuss/382110)

  - bio. nio
  - linux五种io模型
  - poll 和 epoll 的区别
  - synchronized底层原理
  - AQS
  - 聚簇索引非聚簇索引
  - timewait和closewait状态含义

  > [https://www.nowcoder.com/discuss/381858](https://www.nowcoder.com/discuss/381858)

  - synchronized用在静态和非静态方法的区别

  > [https://www.nowcoder.com/discuss/381849](https://www.nowcoder.com/discuss/381849)

  - jre和jdk的区别
  - 如何理解僵尸进程，如何解决僵尸进程

  > [https://www.nowcoder.com/discuss/381726](https://www.nowcoder.com/discuss/381726)

  - 结合数据库三大范式聊聊，项目的表设计
  - redis为什么快？在多核cpu下redis单线程浪费？
  - redis击穿
  - redis与mysql数据同步
  - redis集群
  - redis分布式锁的实现(https://www.cnblogs.com/williamjie/p/9395659.html)
  - 海量数据，找重复数量前几的数据
  - 写个死锁
  - 处理日志，获取error的日志，去重，排序（本意是让用shell写的，但我不会，就用Java写了）
  - 写个LRU
  - 泛型、通配符区别
  - 红黑树为什么插入效率高
  - MySQL执行SQL的流程
  - 选择排序原理，时间、空间复杂度
  - 访问量太大redis支撑不住怎么办
  - 爬虫用的是什么？有用框架吗？有用多线程爬虫吗？
  - 用过哪些SpringCloud组件
  - redis数据结构
  - redis zset set区别
  - redis在增删改查时为什么单线程 还那么快？io模型？
  - MYSQL日志种类 undolog redolog分别是做什么的？(https://www.jianshu.com/p/57c510f4ec28)
  - MYSQL如何实现MVCC(https://blog.csdn.net/nmjhehe/article/details/98470570)
  - MYSQL优化，Explain 有哪些信息

  > [https://www.nowcoder.com/discuss/380853](https://www.nowcoder.com/discuss/380853)

  - 线程安全的单例模式
  - 类加载时机
  - 虚拟内存，内存爆了怎么办
  - https能讲一下吗(https://www.jianshu.com/p/14cd2c9d2cd2)
  - 数据库聚集索引和非聚集索引能讲一下吗
  - read commited隔离级别解决什么问题，通过什么实现(https://blog.csdn.net/fxkcsdn/article/details/82694357)
  - 数据库行锁是互斥锁还是其他还是什么类型的锁呢，读操作会阻塞吗(https://blog.csdn.net/arkblue/article/details/53895150)

  > [https://www.nowcoder.com/discuss/164967](https://www.nowcoder.com/discuss/164967)

  - 如何判断一颗二叉树是另一颗二叉树的子树
  - tcp如果在发送数据的时候服务器宕机了会怎么样，服务器又好了又会怎么样呢
  - 用过缓存，Redis吗，用过分布式吗，比如kafka或者dubbo

  > [https://www.nowcoder.com/discuss/219099](https://www.nowcoder.com/discuss/219099)

  - 大量用户产生很多消息，消息队列怎么处理
  - 消费者消费不完怎么处理

  > [https://www.nowcoder.com/discuss/362693](https://www.nowcoder.com/discuss/362693)

  - 线程池（具体参数，拒绝策略，减少线程的机制，具体实现类及对应的阻塞队列，阻塞队列有什么特点，为什么用这个阻塞队列，线程复用的原理）(https://blog.csdn.net/testcs_dn/article/details/78083966)
  - JVM（对象是否可回收的判断条件，怎么判断，回收算法，垃圾回收器的类别及特点，担保机制）
  - JAVA内存模型
  - 线程之间的通信方式，通过volatile，synchronized，Lock的实现类那些，结合内存模型去讲。
  - MyBatis、spring、springboot相关（面试题较常见）
  - Linux常用命令
  - redis的数据结构那些，讲了skiplist、ziplist、sds等，结合使用场景说了下(https://blog.csdn.net/chenssy/article/details/89599232)

  > [https://www.nowcoder.com/discuss/370072](https://www.nowcoder.com/discuss/370072)

  - transient关键字的作用
  - synchronized关键字加的地方，有什么区别，底层实现
  - 算法：两个数值原地交换值，不能使用第三个变量(https://blog.csdn.net/qq_39411607/article/details/80989996)

  > [https://www.nowcoder.com/discuss/198399](https://www.nowcoder.com/discuss/198399)

  - 事务传播
  - 变量的初始化顺序(https://www.zhihu.com/question/49196023)

  > [https://www.nowcoder.com/discuss/370435](https://www.nowcoder.com/discuss/370435)

  - 写题：由于记账错误，给定的一个正整数序列里面，有两个数字重复了，同时缺少了一个数字。 要求写一个函数，找出序列中重复的数字和缺少的数字。（set、异或） 例如： 输入：[1, 5, 2, 2, 3] 输出：[2, 4] 附加： 如果题目为缺少x个数字，并且输入序列可能有不匹配的重复和缺少项

  - 进程线程协程(https://blog.csdn.net/fadbgfnbxb/article/details/88787361)

  > [https://www.nowcoder.com/discuss/192690](https://www.nowcoder.com/discuss/192690)

  - 逻辑题，25匹赛马🐎，5条赛道，求前三快的马(https://www.nowcoder.com/questionTerminal/e07d8e0df93b4f6b93a3fadbe72f2c7c)

  > [https://www.nowcoder.com/discuss/98120](https://www.nowcoder.com/discuss/98120)

  - 了解过其他AOP包：ASPECTJ么
  - start之后线程就会马上调用吗
  - 了解过乐观锁和悲观锁么，如何自己实现一个乐观锁 
  - hashMap高并发下的缺陷？链表为什么会成环？(https://blog.csdn.net/wthfeng/article/details/88972137)
  - 类隔离
  - 包冲突
  - 有了解过RPC么
  - 了解过一致性Hash么？
  - Java1.8做了什么优化，新特性

  > [https://www.nowcoder.com/discuss/238370](https://www.nowcoder.com/discuss/238370)

  - 反射的作用，反射相关的类(https://snailclimb.gitee.io/javaguide/#/docs/java/basic/reflection)
  - 假设一个场景，支付系统和订单系统，支付失败后订单系统怎么知道失败（感觉是分布式事务的一致性，我开始问他是两个系统吗？是分布式吗？他也不回答我，后面复述一遍问题我又问了一遍分布式事务的一致性，他才说是的）(https://www.cnblogs.com/luxiaoxun/p/8832915.html)

  > [https://www.nowcoder.com/discuss/258249](https://www.nowcoder.com/discuss/258249)

  - 反射的原理及应用
  - spring四种事务的实现方式(https://blog.csdn.net/chinacr07/article/details/78817449)
  - cap和base
  - 问了几个设计模式 工厂 策略 *** 观察者 适配器 桥接等，jdk里面用到了哪些说说
  - 分布式秒杀如果不用mq怎么做？我说直接去掉mq用异步➕分布式事务，大佬说不好，还有吗？
  - 统计用户url访问次数，我说用拦截器存redis，大佬问java有没有提供这种系统或者工具直接用？我说令牌桶也行，大佬没说话

  > [https://www.nowcoder.com/discuss/89956](https://www.nowcoder.com/discuss/89956)

  - 字符串连接的几种方法和区别(https://www.cnblogs.com/lujiahua/p/11408689.html)
  - 自己实现线程池如何实现
  - 如何防止重复买
  - String类为什么要设计为final(https://www.zhihu.com/question/31345592)
  
  > [https://www.nowcoder.com/discuss/381334](https://www.nowcoder.com/discuss/381334)

  - JDBC
  - synchronized和lock底层实现，区别

  > [https://www.nowcoder.com/discuss/87868](https://www.nowcoder.com/discuss/87868)

  - Java的线程池说一下，各个参数的作用，如何进行的。
  - Redis讲一下
  - 分布式系统的全局id如何实现。用zookeeper如何实现的呢，机器号+时间戳即可。
  - 分布式锁的方案，redis和zookeeper那个好，如果是集群部署，高并发情况下哪个性能更好。
  - kafka了解么，了解哪些消息队列。
  - 反射的作用是什么
  - 了解哪些中间件，dubbo，rocketmq，mycat等。
  - dubbo中的rpc如何实现。
  - 自己实现rpc应该怎么做
  - dubbo的服务注册与发现。

  > [https://www.nowcoder.com/discuss/244392](https://www.nowcoder.com/discuss/244392)

  - Mybatis是如何做到动态sql解析
  - Mybatis是如何实现xml文件与实体类的映射
  - java中反射获取到的属性和方法是存储在什么地方(字节码、方法区)
  - 反射如何获取方法上的注解(https://www.cnblogs.com/a591378955/p/8350499.html)
  - 注解和接口的区别(https://www.cnblogs.com/linshenghui/p/11213867.html)
  - Redis中的命令(https://www.runoob.com/redis/redis-keys.html)(https://www.php.cn/faq/417108.html)

  > [https://bbs.byr.cn/#!article/ParttimeJob/856659](https://bbs.byr.cn/#!article/ParttimeJob/856659)

  > JAVA研发工程师

  - 希望你是2021年应届毕业生（校招）
  - 扎实的java编程基础（java语法原理，java容器原理，jvm原理（jvm调优加分），java并发（越深越好）），熟悉java开发体系，如果能有一定的项目开发经验那就更好了。
  - 表达问题思路清晰，良好的沟通能力与技术学习能力 （后面项我列举了最好了解一下的知识）
  - 有过用mysql等数据库使用经验
  - 了解http，操作系统，计网等基础知识(我另一篇推荐知识的博客有这些，大概简单的勉强够用)
  - 了解一些简单的设计模式（常见的那些最好看过一些源码，实现过一些，项目中用到过并有自己的理解）
  - 了解SSM，SpringBoot 等框架加分（建议初学以spring，spring boot，mybatis框架开始，这是现在很多公司的主流架构）
  - 了解WEB开发相关技术，如HTML，CSS，JavaScript，ajax 等加分（优先度不高，安心安心）
  - 了解分布式架构加分（缓存建议学一下redis，消息队列可以学一下kafka，rocketmq，分布式事务了解一些，分布式锁可以学一下zookeeper，rpc可以看dubbo）
  - 了解高可用架构加分(比如看看Hystrix，优先级不高~ )
  - 了解微服务加分（公司项目现在设计的很轻量级，一般都是微服务架构的，了解一下有好处，这是未来所有公司架构的升级方向）

  - 热点数据请求太多，redis负载均衡全都hash到一个节点上，如何处理(https://www.cnblogs.com/rjzheng/p/10874537.html)

## 面试

- 阿里

  - 红黑树
  - ARP协议
  - java如何实现多态：虚函数子类重写，然后让父类对象指针指向子类，这是调用虚函数
  - leetcode751：给你一个cidr网络段，算出所有合理的ip，比如1.2.3.4/24，输出1.2.3.1~1.2.3.254
  - leetcode 1143：求两个字符串的最长公共子串
  - 如何解决hashmap线程不安全，concurrenthashmap的原理，扩容为什么是2的幂
  - SpringBoot实现的原理、AOP的原理、注解的原理（xml配置加注入）
  - 线程池
  - 最大的优点，AOP的原理
  - java1.8类加载是在哪里发生的（方法区移到元空间，在直接内存里）
  
  - JVM的内存划分，解释各个区域的作用，JVM为什么要这么分区
  - 分布式：paxos协议的leader选举
  - 两个字符数组求交集
  - jvm分区
  - redis介绍
  - tcpip协议介绍
  - 索引优化有哪些
  
  - 单链表序列化反序列化，结点中存字符串怎么办，类比网络中组包分包
  - 数据库表怎么设计，用户登录怎么保证安全性，数据库建索引了吗，为什么要把这些列作为索引， 索引建立顺序怎么确定
  - shiro中的token保存在什么地方
  - concurrenthashmap的场景：抢票
  - hibernate多对多是怎么查询的，hibernate多对多模型介绍下，数据库表索引设计顺序设计，为啥选择shiro
  - session怎么分布式存储（cookie，redis）
  - 并发打印foobar
  - 三个瓶身可以换一瓶酒，七个瓶盖可以换一瓶酒，初始x瓶酒，一共可以喝几瓶酒（考虑借瓶子、瓶盖再还回去）
  - atomiclong atomicadder
  - 随机生成1到一亿的数，怎么保证不重复（布隆过滤器），误报怎么办
  - hashmap concurrenthashmap(1.7 1.8 多线程扩容死循环 put的位置是NULL就用CAS插入，如果是forward就参与扩容，最后加syn锁)

  - Hashmap底层结构（1.7 1.8）concurrenthashmap怎么保证高效地操作(https://blog.csdn.net/qq_36520235/article/details/82417949)
  - 线程池优点、线程池的参数在什么场景下应该怎么配置、IO密集型线程跟CPU密集型线程的线程池参数怎么配置
  - 如何自定义一个注解(https://blog.csdn.net/xsp_happyboy/article/details/80987484)
  - 有没有接触过什么新技术(Docker)(https://zhuanlan.zhihu.com/p/62653543)(https://zhuanlan.zhihu.com/p/62653543)(https://www.cnblogs.com/linguoguo/p/10754756.html)
  - 有没有知道其他的数据库、非关系型数据库、分布式数据库(Redis)
  - Redis的使用场景，按你的理解如何设计一个秒杀系统(https://www.jianshu.com/p/d789ea15d060)
    > 1. 后台使用redis分布式数据库来保存秒杀的物品的信息，整体的服务架构可以使用 集群模式+主从模式，每个服务器分担一定的请求，并在主服务器出现故障后由哨兵节点及时切换到从服务器。  
    > 2. 在此期间，不要将缓存中的数据与数据库进行同步，等时间过后再进行同步。  
    > 3. 在数据持久化过程中，使用AOF方式，并可以把AOF持久化的时间间隔调整稍微长一点，减少持久化操作的次数。 
    > 4. 在redis缓存中，设置要秒杀的物品的信息永不过期，防止出现缓存雪崩的问题，并使用布隆过滤器来过滤掉来自客户端的一些无效恶意请求
    > 5. 服务器处理请求时，使用消息队列，减轻服务器并发操作的压力
    > 6. 当整体某些下游服务出现故障时，对故障服务进行熔断，防止影响整体服务的性能； 当整体服务的负载过高时，可以适当对某些服务进行降级，减低整体服务的负载
  - 在低并发的场景下，如何保证redis与数据库的数据一致性
  - Session的持久化问题
  - 登录人数的统计问题
  - 用户关闭了网页，服务器知道，并让用户登出
  - 如果有了用户违反了一些操作，怎么禁用这些用户的任何操作和登录（禁止token）
  - AomicLong跟LongAdder的区别
  - 使用Random生成 1~1亿的数字到文件中，如何保证不重复、单线程和多线程环境下
  - Java1.8 1.9 1.10的区别 jdk源码中用到了哪些设计模式
  - Shiro的过程，如果这个人的角色权限信息修改了，session中这个人的信息应该怎么办
  - 用户登陆的过程（实质上就是一次浏览器请求页面的过程）
  - 如果项目的qps很高的话项目怎么设计（分布式）
  - Servlet知不知道 他的生命周期
  - 线程池的使用，应该注意哪些问题，原生的线程池有哪些隐患
  - Springboot为啥能提供服务（因为有tomcat） tomcat你知道有啥东西吗，或者能配置什么东西 项目怎么配置运行过程中的jvm一些信息
  - Cpu怎么排查，怎么查看进程的信息，有没有导出过dump文件，你能看到什么东西
  - 服务集群了解过没
  - Rpc是什么，java原生的rpc知不知道 rmi知不知道

- 头条

  - 100瓶药水，其中只有一瓶有毒。给你一些老鼠，老鼠吃了之后24小时内会死亡。请问这24小时内，你需要最少多少只老鼠，可以把那瓶毒药试出来？
  - 交替打印ABC

- 领英

  - 链表排序：自顶向上的归并排序

- 腾讯

  - 一个长度一亿的数组，大量有序，少量无序，把数组改成链表怎么做

- 猿辅导

  - 二叉树后序遍历

- 美团

  - where a=x,b>y,c=z会不会走联合索引c,b,a(https://blog.csdn.net/weixin_42935902/article/details/96887763)
  - mysql优化器的策略(https://blog.csdn.net/hsd2012/article/details/51526733)