---
layout:     post
title:      "总结"
subtitle:   ""
date:       2020-07-05 12:00:00
author:     "盈盈冲哥"
header-img: "img/fleabag.jpg"
mathjax: true
catalog: true
tags:
    - 学习
---

> [https://snailclimb.gitee.io/javaguide/#/?id=java]https://snailclimb.gitee.io/javaguide/#/?id=java

> [https://github.com/hanggegreat/CS-Tree](https://github.com/hanggegreat/CS-Tree)

> [https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#nginx](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#nginx)

## 分布式

1. 分层：应用层、服务层、数据层

2. 如何优化性能？

	- 缓存：CDN、反向代理、本地缓存、分布式缓存（一致性Hash算法）
	- 均衡负载：分布式（不同服务部署在不同）、集群（多台机器提供相同的服务）
	- 异步（消息队列削峰、线程池）
  - 数据库分库分表、读写分离

3. 分布式缓存的一致性Hash算法

  一致性Hash算法通过一致性Hash环实现key到缓存服务器的Hash映射。

  具体算法过程为：先构造一个长度为$2^32$的整数环（一致性Hash环），根据节点名称的Hash值将缓存服务器节点放置在这个Hash环上。然后根据需要缓存的数据的key值计算得到其Hash值，在Hash环上顺时针查找距离这个key的Hash值最近的缓存服务器节点。

  当缓存服务器集群需要扩容时，只需要将新加入的节点名称的Hash值放入一致性Hash环中，由于key时顺时针查找其最近的节点，因此新加入的节点只影响整个环中的一小段。

3. session管理

  - session复制：在集群中的几台服务器之间同步session对象，使得每台服务器上都保存所有用户的session信息。
  
  - session绑定：负载均衡服务器总是将来源于同一IP的请求分发到同一台服务器上。
  
  - 利用cookie记录session
  
  - session服务器

4. 指标：吞吐量（TPS、QPS、HPS）、响应时间、并发数

5. 安全

	- XSS攻击（跨站点脚本攻击）：注入恶意HTML脚本
	- SQL注入攻击：攻击者在HTTP请求中注入恶意SQL命令
	- CSRF攻击（跨站点请求伪造）：攻击者通过跨站请求，以合法的用户身份伪造请求进行非法操作

6. 加密

	- 单项散列加密：MD5, SHA1

    虽然不能通过算法将单向散列密文反算得到密文，但是由于人们设置密码具有一定的模式，因此通过彩虹表（人们常用密码和对应的密文关系表）等手段可以进行猜测式破解。

    为了加强单项散列计算的安全性，还会给散列算法加点盐，盐相当于加密的密钥，增加破解难度。

	- 对称加密：DES、RC

    对称加密是指加密和解密使用的密钥是同一个密钥（或者可以互相推算）。

	- 非对称加密：RSA

    不同于对称加密，非对称加密和解密使用的密钥不是同一密钥，其中一个对外界公开，被称作公钥，另一个只有所有者知道，被称为私钥。用公钥加密的信息必须用私钥才能解开，反之，用私钥加密的信息只有用公钥才能解开。

7. 高可用设计：服务降级、服务限流、超时设置、缓存、异步、幂等性设计

8. 幂等

  > https://www.jianshu.com/p/cea3675a590b
  > https://www.cnblogs.com/wxgblogs/p/6639272.html
  
  - 概念：一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。

  - 我们常用的HTTP协议的方法是具有幂等性语义要求的，比如：get方法用于获取资源，不应有副作用，因此是幂等的；post方法用于创建资源，每次请求都会产生新的资源，因此不具备幂等性；put方法用于更新资源，是幂等的；delete方法用于删除资源，也是幂等的。

  - 幂等的应用场景

    1）微服务场景，除了成功、失败两种状态，还会有第三个情况【未知】，也就是超时。如果超时了，微服务框架一般会进行重试。

    2）用户交互的时候多次点击。如：快速点击按钮多次。

    3）MQ消息中间件，消息重复消费。

    4）第三方平台的接口（如：支付成功回调接口），因为异常也会导致多次异步回调。

    5）其他应用服务根据自身的特性，也有可能进行重试。

  - 保证幂等的手段

    唯一的业务单号[悲观锁、乐观锁、唯一索引、Redis缓存]、token

    - 唯一业务单号

      最简单的，需要通过唯一的业务单号来保证幂等。也就是说相同的业务单号，认为是同一笔业务。使用这个唯一的业务单号来确保，后面多次的相同的业务单号的处理逻辑和执行效果是一致的。

    - 对变更行为加锁

      上述的保证幂等方案是分成两步的，第②步依赖第①步的查询结果，无法保证原子性的。在高并发下就会出现下面的情况：第二次请求在第一次请求第②步订单状态还没有修改为‘已支付状态’的情况下到来。既然得出了这个结论，余下的问题也就变得简单：把查询和变更状态操作加锁，将并行操作改为串行操作。

    - 唯一索引

      但是，在某些场景，你可能又想提供无锁的高并发幂等，那么你可以选择为业务单号加上唯一的索引或者组合索引，在并发的场景中，只有第一笔插入的交易请求能够成功，后续的请求哪怕是慢1ms或者更短时间，都会触发数据库的唯一索引异常而失败，那么你可以捕获这个异常。

    - 数据库操作时使用插入或更新（select + insert）

      如果已经存在就更新，不存在时才插入

    - 多版本控制

      这种方法适合在更新的场景中，比如我们要更新商品的名字，这时我们就可以在更新的接口中增加一个版本号，来做幂等

    - 防重-Redis缓存

      又或者你想把幂等放在服务的最前端，减少实际服务处理的资源浪费，在请求一到达时就提前去重，不让他有执行的机会，那么你可以考虑引入一个redis或类似的组件，将业务请求单号缓存在这个分布式锁的组件内。那么，每当订单发起交易请求，交易系统会去Redis缓存中查询是否存在该订单号的Key，如果不存在，则向Redis增加Key为订单号。查询订单是否已经执行，如果没有则转发到交易系统，执行完成后删除该订单号的Key。当然，Redis是提供分布式节点下的原子事务操作的。

    - 状态机

      通常是根据业务流程构建一个状态机，保证业务中每个流程只会在对应的状态下执行。如果一个业务操作步骤完成就进入下一个状态，这时候来了上一个状态的操作就不允许变更状态，保证了业务的幂等性。

    - token机制

      通常是每次操作都生成一个唯一 token 凭证，服务器通过这个唯一凭证保证同样的操作不会被执行两次，服务器在去重实现上可以采用独立kv数据库，去重表等多种实现。Token 机制应该是适用范围最广泛的一种幂等设计方案。比如AWS的API就是采用这一机制，调用方生成client token，要求token全局唯一，AWS根据client token做幂等操作。

8. 微服务

	> [大白话入门 Spring Cloud](https://snailclimb.gitee.io/javaguide/#/docs/system-design/micro-service/spring-cloud?id=%e5%bc%95%e5%87%ba-spring-cloud-bus)
  
  Spring Cloud抽象了一套通用的开发模式，依赖于RPC、网关、服务发现、配置管理、限流熔断、分布式链路跟踪的具体实现。

  - Eureka 服务发现框架

    服务发现：其实就是一个“中介”，整个过程中有三个角色：服务提供者(出租房子的)、服务消费者(租客)、服务中介(房屋中介)。

    服务提供者： 就是提供一些自己能够执行的一些服务给外界。

    服务消费者： 就是需要使用一些服务的“用户”。

    服务中介： 其实就是服务提供者和服务消费者之间的“桥梁”，服务提供者可以把自己注册到服务中介那里，而服务消费者如需要消费一些服务(使用一些功能)就可以在服务中介中寻找注册在服务中介的服务提供者。

    服务注册 Register：

    官方解释：当 Eureka 客户端向 Eureka Server 注册时，它提供自身的元数据，比如IP地址、端口，运行状况指示符URL，主页等。

    结合中介理解：房东 (提供者 Eureka Client Provider)在中介 (服务器 Eureka Server) 那里登记房屋的信息，比如面积，价格，地段等等(元数据 metaData)。

    服务续约 Renew：

    官方解释：Eureka 客户会每隔30秒(默认情况下)发送一次心跳来续约。 通过续约来告知 Eureka Server 该 Eureka 客户仍然存在，没有出现问题。 正常情况下，如果 Eureka Server 在90秒没有收到 Eureka 客户的续约，它会将实例从其注册表中删除。

    结合中介理解：房东 (提供者 Eureka Client Provider) 定期告诉中介 (服务器 Eureka Server) 我的房子还租(续约) ，中介 (服务器Eureka Server) 收到之后继续保留房屋的信息。

    获取注册列表信息 Fetch Registries：

    官方解释：Eureka 客户端从服务器获取注册表信息，并将其缓存在本地。客户端会使用该信息查找其他服务，从而进行远程调用。该注册列表信息定期（每30秒钟）更新一次。每次返回注册列表信息可能与 Eureka 客户端的缓存信息不同, Eureka 客户端自动处理。如果由于某种原因导致注册列表信息不能及时匹配，Eureka 客户端则会重新获取整个注册表信息。 Eureka 服务器缓存注册列表信息，整个注册表以及每个应用程序的信息进行了压缩，压缩内容和没有压缩的内容完全相同。Eureka 客户端和 Eureka 服务器可以使用JSON / XML格式进行通讯。在默认的情况下 Eureka 客户端使用压缩 JSON 格式来获取注册列表的信息。

    结合中介理解：租客(消费者 Eureka Client Consumer) 去中介 (服务器 Eureka Server) 那里获取所有的房屋信息列表 (客户端列表 Eureka Client List) ，而且租客为了获取最新的信息会定期向中介 (服务器 Eureka Server) 那里获取并更新本地列表。

    服务下线 Cancel：

    官方解释：Eureka客户端在程序关闭时向Eureka服务器发送取消请求。 发送请求后，该客户端实例信息将从服务器的实例注册表中删除。该下线请求不会自动完成，它需要调用以下内容：DiscoveryManager.getInstance().shutdownComponent();

    结合中介理解：房东 (提供者 Eureka Client Provider) 告诉中介 (服务器 Eureka Server) 我的房子不租了，中介之后就将注册的房屋信息从列表中剔除。

    服务剔除 Eviction：

    官方解释：在默认的情况下，当Eureka客户端连续90秒(3个续约周期)没有向Eureka服务器发送服务续约，即心跳，Eureka服务器会将该服务实例从服务注册列表删除，即服务剔除。

    结合中介理解：房东(提供者 Eureka Client Provider) 会定期联系 中介 (服务器 Eureka Server) 告诉他我的房子还租(续约)，如果中介 (服务器 Eureka Server) 长时间没收到提供者的信息，那么中介会将他的房屋信息给下架(服务剔除)。

  - Ribbon 进程内负载均衡器

    Ribbon 是运行在消费者端的负载均衡器，其工作原理就是 Consumer 端获取到了所有的服务列表之后，在其内部使用负载均衡算法，进行对多个系统的调用。

    Nginx 和 Ribbon 的对比

    和 Ribbon 不同的是，Nignx是一种集中式的负载均衡器。

    何为集中式呢？简单理解就是 将所有请求都集中起来，然后再进行负载均衡。

    在 Nginx 中请求是先进入负载均衡器，而在 Ribbon 中是先在客户端进行负载均衡才进行请求的。

    Ribbon 的几种负载均衡算法

    负载均衡，不管 Nginx 还是 Ribbon 都需要其算法的支持，如果我没记错的话 Nginx 使用的是 轮询和加权轮询算法。而在 Ribbon 中有更多的负载均衡调度算法，其默认是使用的 RoundRobinRule 轮询策略。

    - RoundRobinRule：轮询策略。Ribbon 默认采用的策略。若经过一轮轮询没有找到可用的 provider，其最多轮询 10 轮。若最终还没有找到，则返回 null。
    - RandomRule: 随机策略，从所有可用的 provider 中随机选择一个。
    - RetryRule: 重试策略。先按照 RoundRobinRule 策略获取 provider，若获取失败，则在指定的时限内重试。默认的时限为 500 毫秒。

  - Open Feign 服务调用映射

  - Hystrix 服务降级熔断器

    所谓 熔断 就是服务雪崩的一种有效解决方案。当指定时间窗内的请求失败率达到设定阈值时，系统将通过 断路器 直接将此请求链路断开。

    也就是我们上面服务B调用服务C在指定时间窗内，调用的失败率到达了一定的值，那么 Hystrix 则会自动将 服务B与C 之间的请求都断了，以免导致服务雪崩现象。

    降级是为了更好的用户体验，当一个方法调用异常时，通过执行另一种代码逻辑来给用户友好的回复。

  - Zuul 微服务网关

    在上面我们学习了 Eureka 之后我们知道了 服务提供者 是 消费者 通过 Eureka Server 进行访问的，即 Eureka Server 是 服务提供者 的统一入口。那么整个应用中存在那么多 消费者 需要用户进行调用，这个时候用户该怎样访问这些 消费者工程 呢？当然可以像之前那样直接访问这些工程。但这种方式没有统一的消费者工程调用入口，不便于访问与管理，而 Zuul 就是这样的一个对于 消费者 的统一入口。

    网关是系统唯一对外的入口，介于客户端与服务器端之间，用于对请求进行鉴权、限流、 路由、监控等功能。网关有的功能，Zuul 基本都有。而 Zuul 中最关键的就是 路由和过滤器 了。

    Zuul 的路由功能

    Consumer 向 Eureka Server 进行注册，网关只要注册就能拿到所有 Consumer 的信息，拿到信息就可以获取所有的 Consumer 的元数据(名称，ip，端口)，拿到这些元数据就可以直接可以做路由映射。包括统一前缀、路由策略配置、服务名屏蔽、路径屏蔽、敏感请求头屏蔽。

    Zuul 的过滤功能

    如果说，路由功能是 Zuul 的基操的话，那么过滤器就是 Zuul的利器了。毕竟所有请求都经过网关(Zuul)，那么我们可以进行各种过滤，这样我们就能实现 限流，灰度发布，权限控制 等等。

    过滤器类型：Pre、Routing、Post。前置Pre就是在请求之前进行过滤，Routing路由过滤器就是我们上面所讲的路由策略，而Post后置过滤器就是在 Response 之前进行过滤的过滤器。你可以观察上图结合着理解，并且下面我会给出相应的注释。

    令牌桶限流

    首先我们会有个桶，如果里面没有满那么就会以一定 固定的速率 会往里面放令牌，一个请求过来首先要从桶中获取令牌，如果没有获取到，那么这个请求就拒绝，如果获取到那么就放行。

    Zuul 的过滤器还可以实现 权限校验，包括上面提到的 灰度发布 等等。

  - Config 微服务统一配置中心

    当我们的微服务系统开始慢慢地庞大起来，那么多 Consumer 、Provider 、Eureka Server 、Zuul 系统都会持有自己的配置，这个时候我们在项目运行的时候可能需要更改某些应用的配置，如果我们不进行配置的统一管理，我们只能去每个应用下一个一个寻找配置文件然后修改配置文件再重启应用。

    首先对于分布式系统而言我们就不应该去每个应用下去分别修改配置文件，再者对于重启应用来说，服务无法访问所以直接抛弃了可用性，这是我们更不愿见到的。

    那么有没有一种方法既能对配置文件统一地进行管理，又能在项目运行时动态修改配置文件呢？

    Spring Cloud Config 就是能将各个 应用/系统/模块 的配置文件存放到 统一的地方然后进行管理(Git 或者 SVN)。

    Spring Cloud Config 就暴露出一个接口给启动应用来获取它所想要的配置文件，应用获取到配置文件然后再进行它的初始化工作。

    一般我们会使用 Bus 消息总线 + Spring Cloud Config 进行配置的动态刷新。

  - Bus 消息总线

    Spring Cloud Bus 的作用就是管理和广播分布式系统中的消息，也就是消息引擎系统中的广播模式。

9. 分布式id

  > [分布式id生成方案总结](https://snailclimb.gitee.io/javaguide/#/docs/system-design/micro-service/%E5%88%86%E5%B8%83%E5%BC%8Fid%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93)

  - UUID：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。
  - 数据库自增 id：业务系统每次需要一个ID时，都需要请求数据库获取，性能低，并且如果此数据库实例下线了，那么将影响所有的业务系统。
  - 数据库多主模式：两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。问题是无法新增实例。
  - 利用redis生成id
  - 号端模式

    ```sql
    CREATE TABLE id_generator (
      id int(10) NOT NULL,
      current_max_id bigint(20) NOT NULL COMMENT '当前最大id',
      increment_step int(10) NOT NULL COMMENT '号段的长度',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;
    ```

    ```sql
    update id_generator set current_max_id=#{newMaxId}, version=version+1 where version = #{version}
    ```

  - twitter snowflake雪花算法：时间戳、工作机器id、序列号
  - 美团Leaf

9. 限流

  > [限流的算法有哪些？](https://snailclimb.gitee.io/javaguide/#/docs/system-design/micro-service/limit-request)

  - 固定窗口计数器算法：规定我们单位时间处理的请求数量。
  - 滑动窗口计数器算法：例如我们的接口限流每分钟处理60个请求，我们可以把 1 分钟分为60个窗口。每隔1秒移动一次， 如果当前窗口的请求计数总和超过了限制的数量的话就不再处理其他请求。
  - 漏桶算法：往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。
  - 令牌桶算法：首先我们会有个桶，如果里面没有满那么就会以一定 固定的速率 会往里面放令牌，一个请求过来首先要从桶中获取令牌，如果没有获取到，那么这个请求就拒绝，如果获取到那么就放行。

9. Zookeeper

  > [Zookeeper](https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/ZooKeeper)

  > [Zookeeper plus](https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/ZooKeeper-plus)

  > [Zab：Zookeeper 中的分布式一致性协议介绍](https://www.jianshu.com/p/fb527a64deee)

  - CAP原理

    - 数据一致性：数据强一致、数据用户一致、数据最终一致
    - 数据可用性
    - 分区耐受性（系统具有跨网络分区的伸缩性）

  - BASE理论

    - 基本可用
    - 软状态
    - 最终一致性

  - 2PC

    阶段一：提交事务请求（投票）

    当要执行一个分布式事务的时候，事务发起者首先向协调者发起事务请求，然后协调者会给所有参与者发送 prepare 请求（其中包括事务内容）告诉参与者你们需要执行事务了，如果能执行我发的事务内容那么就先执行但不提交，执行后请给我回复。然后参与者收到 prepare 消息后，他们会开始执行事务（但不提交），并将 Undo 和 Redo 信息记入事务日志中，之后参与者就向协调者反馈是否准备好了。

    阶段二：执行事务提交（执行）

    第二阶段主要是协调者根据参与者反馈的情况来决定接下来是否可以进行事务的提交操作，即提交事务或者回滚事务。

    比如这个时候 所有的参与者 都返回了准备好了的消息，这个时候就进行事务的提交，协调者此时会给所有的参与者发送 Commit 请求 ，当参与者收到 Commit 请求的时候会执行前面执行的事务的 提交操作 ，提交完毕之后将给协调者发送提交成功的响应。

    而如果在第一阶段并不是所有参与者都返回了准备好了的消息，那么此时协调者将会给所有参与者发送 回滚事务的 rollback 请求，参与者收到之后将会 回滚它在第一阶段所做的事务处理 ，然后再将处理情况返回给协调者，最终协调者收到响应后便给事务发起者返回处理失败的结果。

    问题

    - 单点故障问题，如果协调者挂了那么整个系统都处于不可用的状态了。
    - 阻塞问题，即当协调者发送 prepare 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着资源不释放，如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能。
    - 数据不一致问题，比如当第二阶段，协调者只发送了一部分的 commit 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题。

  - 3PC

    三阶段提交是两阶段提交的改进版，将两阶段提交协议的提交事务请求（投票）过程一分为二，形成由CanCommit、PreCommit和doCommit三个阶段组成的事务处理协议。

    阶段一：CanCommit

    协调者向所有参与者发送 CanCommit 请求，参与者收到请求后会根据自身情况查看是否能执行事务，如果可以则返回 YES 响应并进入预备状态，否则返回 NO 。

    阶段二：PreCommit

    协调者根据参与者返回的响应来决定是否可以进行下面的 PreCommit 操作。如果上面参与者返回的都是 YES，那么协调者将向所有参与者发送 PreCommit 预提交请求，参与者收到预提交请求后，会进行事务的执行操作，并将 Undo 和 Redo 信息写入事务日志中 ，最后如果参与者顺利执行了事务则给协调者返回成功的响应。如果在第一阶段协调者收到了 任何一个 NO 的信息，或者 在一定时间内 并没有收到全部的参与者的响应，那么就会中断事务，它会向所有参与者发送中断请求（abort），参与者收到中断请求之后会立即中断事务，或者在一定时间内没有收到协调者的请求，它也会中断事务。

    阶段三：doCommit

    这个阶段其实和 2PC 的第二阶段差不多，如果协调者收到了所有参与者在 PreCommit 阶段的 YES 响应，那么协调者将会给所有参与者发送 DoCommit 请求，参与者收到 DoCommit 请求后则会进行事务的提交工作，完成后则会给协调者返回响应，协调者收到所有参与者返回的事务提交成功的响应之后则完成事务。若协调者在 PreCommit 阶段 收到了任何一个 NO 或者在一定时间内没有收到所有参与者的响应 ，那么就会进行中断请求的发送，参与者收到中断请求后则会 通过上面记录的回滚日志 来进行事务的回滚操作，并向协调者反馈回滚状况，协调者收到参与者返回的消息后，中断事务。

    问题
    
    3PC 通过一系列的超时机制很好的缓解了阻塞问题，但是最重要的一致性并没有得到根本的解决，比如在 PreCommit 阶段，当一个参与者收到了请求之后其他参与者和协调者挂了或者出现了网络分区，这个时候收到消息的参与者都会进行事务提交，这就会出现数据不一致性问题。

  - Paxos算法：解决分布式一致性的算法

    - prepare阶段：提案者将具有全局唯一性的递增的编号N发送给表决者。表决者同意大于本地编号maxN（批准过的最大提案编号）的提案。
    - accept阶段：提案者收到半数以上表决者的批准，就会发送提案和编号。表决者再次比较，同意大于等于批准过的最大提案编号的提案。提案者收到半数以上同意，向所有表决者发送提案提交编号。

  - ZAB协议

    ZAB 中的三个角色

    Leader 领导者：集群中 唯一的写请求处理者 ，能够发起投票（投票也是为了进行写请求）。

    Follower 跟随者：能够接收客户端的请求，如果是读请求则可以自己处理，如果是写请求则要转发给 Leader 。在选举过程中会参与投票，有选举权和被选举权 。

    Observer 观察者：就是没有选举权和被选举权的 Follower 。

    协议内容
    
    消息广播模式：Zab 协议中，所有的写请求都由 leader 来处理。正常工作状态下，leader 接收请求并通过广播协议来处理。

    1. Leader 接收到消息请求后，将消息赋予一个全局唯一的 64 位自增 id，叫做：zxid，通过 zxid 的大小比较即可实现因果有序这一特性。
    2. Leader 通过先进先出队列（通过 TCP 协议来实现，以此实现了全局有序这一特性）将带有 zxid 的消息作为一个提案（proposal）分发给所有 follower。
    3. 当 follower 接收到 proposal，先将 proposal 写到硬盘，写硬盘成功后再向 leader 回一个 ACK。
    4. 当 leader 接收到合法数量的 ACKs 后，leader 就向所有 follower 发送 COMMIT 命令，同时会在本地执行该消息。
    5. 当 follower 收到消息的 COMMIT 命令时，就会执行该消息

    崩溃恢复模式：当服务初次启动，或者 leader 节点挂了，系统就会进入恢复模式，直到选出了有合法数量 follower 的新 leader，然后新 leader 负责将整个系统同步到最新状态。

    由于之前讲的 Zab 协议的广播部分不能处理 leader 挂掉的情况，Zab 协议引入了恢复模式来处理这一问题。为了使 leader 挂了后系统能正常工作，需要解决以下两个问题：

    - 已经被处理的消息不能丢

      这一情况会出现在以下场景：当 leader 收到合法数量 follower 的 ACKs 后，就向各个 follower 广播 COMMIT 命令，同时也会在本地执行 COMMIT 并向连接的客户端返回「成功」。但是如果在各个 follower 在收到 COMMIT 命令前 leader 就挂了，导致剩下的服务器并没有执行都这条消息。

      消息 1 的 COMMIT 命令 Server1（leader）和 Server2（follower） 上执行了，但是 Server3 还没有收到消息 1 的 COMMIT 命令，此时 leader Server1 已经挂了，客户端很可能已经收到消息 1 已经成功执行的回复，经过恢复模式后需要保证所有机器都执行了消息 1。

      为了实现已经被处理的消息不能丢这个目的，Zab 的恢复模式使用了以下的策略：

      1. 选举拥有 proposal 最大值（即 zxid 最大） 的节点作为新的 leader：由于所有提案被 COMMIT 之前必须有合法数量的 follower ACK，即必须有合法数量的服务器的事务日志上有该提案的 proposal，因此，只要有合法数量的节点正常工作，就必然有一个节点保存了所有被 COMMIT 消息的 proposal 状态。
      2. 新的 leader 将自己事务日志中 proposal 但未 COMMIT 的消息处理。
      3. 新的 leader 与 follower 建立先进先出的队列， 先将自身有而 follower 没有的 proposal 发送给 follower，再将这些 proposal 的 COMMIT 命令发送给 follower，以保证所有的 follower 都保存了所有的 proposal、所有的 follower 都处理了所有的消息。

    - 被丢弃的消息不能再次出现

      这一情况会出现在以下场景：当 leader 接收到消息请求生成 proposal 后就挂了，其他 follower 并没有收到此 proposal，因此经过恢复模式重新选了 leader 后，这条消息是被跳过的。 此时，之前挂了的 leader 重新启动并注册成了 follower，他保留了被跳过消息的 proposal 状态，与整个系统的状态是不一致的，需要将其删除。

      在 Server1 挂了后系统进入新的正常工作状态后，消息 3被跳过，此时 Server1 中的 P3 需要被清除。

      Zab 通过巧妙的设计 zxid 来实现这一目的。一个 zxid 是64位，高 32 是纪元（epoch）编号，每经过一次 leader 选举产生一个新的 leader，新 leader 会将 epoch 号 +1。低 32 位是消息计数器，每接收到一条消息这个值 +1，新 leader 选举后这个值重置为 0。这样设计的好处是旧的 leader 挂了后重启，它不会被选举为 leader，因为此时它的 zxid 肯定小于当前的新 leader。当旧的 leader 作为 follower 接入新的 leader 后，新的 leader 会让它将所有的拥有旧的 epoch 号的未被 COMMIT 的 proposal 清除。
  
  - Zookeeper
    
    ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。

    Zookeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心(提供发布订阅服务)。 服务生产者将自己提供的服务注册到Zookeeper中心，服务的消费者在进行服务调用的时候先到Zookeeper中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者的内容与数据。在 Dubbo架构中 Zookeeper 就担任了注册中心这一角色。

    为什么最好使用奇数台服务器构成 ZooKeeper 集群？

    所谓的zookeeper容错是指，当宕掉几个zookeeper服务器之后，剩下的个数必须大于宕掉的个数的话整个zookeeper才依然可用。假如我们的集群中有n台zookeeper服务器，那么也就是剩下的服务数必须大于n/2。先说一下结论，2n和2n-1的容忍度是一样的，都是n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。 比如假如我们有3台，那么最大允许宕掉1台zookeeper服务器，如果我们有4台的的时候也同样只允许宕掉1台。 假如我们有5台，那么最大允许宕掉2台zookeeper服务器，如果我们有6台的的时候也同样只允许宕掉2台。

    概念
    
    - 会话（Session）

      Session 指的是 ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session的sessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。

      在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。

    - Znode

      在谈到分布式的时候，我们通常说的“节点"是指组成集群的每一台机器。然而，在Zookeeper中，“节点"分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。

      Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。

      在Zookeeper中，node可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。 另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL.一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。

    - 版本

      在前面我们已经提到，Zookeeper 的每个 ZNode 上都会存储数据，对应于每个ZNode，Zookeeper 都会为其维护一个叫作 Stat 的数据结构，Stat 中记录了这个 ZNode 的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）

    - Watcher

      Watcher（事件监听器），是Zookeeper中的一个很重要的特性。Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。

    - ACL

      Zookeeper采用ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了5种权限。

    ZooKeeper 设计目标

    - 简单的数据模型：ZooKeeper 允许分布式进程通过共享的层次结构命名空间进行相互协调，这与标准文件系统类似。 名称空间由 ZooKeeper 中的数据寄存器组成 - 称为znode，这些类似于文件和目录。 与为存储设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量和低延迟。
    - 可构建集群：为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的。
    - 顺序访问：对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。 这个编号也叫做时间戳——zxid（Zookeeper Transaction Id）
    - 高性能：ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。
    
    Zookeeper 应用场景
    
    - 选主
    
      还记得上面我们的所说的临时节点吗？因为 Zookeeper 的强一致性，能够很好地在保证 在高并发的情况下保证节点创建的全局唯一性 (即无法重复创建同样的节点)。

      利用这个特性，我们可以 让多个客户端创建一个指定的节点 ，创建成功的就是 master。

      但是，如果这个 master 挂了怎么办？？？

      你想想为什么我们要创建临时节点？还记得临时节点的生命周期吗？master 挂了是不是代表会话断了？会话断了是不是意味着这个节点没了？还记得 watcher 吗？我们是不是可以 让其他不是 master 的节点监听节点的状态 ，比如说我们监听这个临时节点的父节点，如果子节点个数变了就代表 master 挂了，这个时候我们 触发回调函数进行重新选举 ，或者我们直接监听节点的状态，我们可以通过节点是否已经失去连接来判断 master 是否挂了等等。
	
      总的来说，我们可以完全 利用 临时节点、节点状态 和 watcher 来实现选主的功能，临时节点主要用来选举，节点状态和watcher 可以用来判断 master 的活性和进行重新选举。
	
    - 分布式锁
    
      分布式锁的实现方式有很多种，比如 Redis 、数据库 、zookeeper 等。个人认为 zookeeper 在实现分布式锁这方面是非常非常简单的。

      上面我们已经提到过了 zk在高并发的情况下保证节点创建的全局唯一性，这玩意一看就知道能干啥了。实现互斥锁呗，又因为能在分布式的情况下，所以能实现分布式锁呗。

      如何实现呢？这玩意其实跟选主基本一样，我们也可以利用临时节点的创建来实现。

      首先肯定是如何获取锁，因为创建节点的唯一性，我们可以让多个客户端同时创建一个临时节点，创建成功的就说明获取到了锁 。然后没有获取到锁的客户端也像上面选主的非主节点创建一个 watcher 进行节点状态的监听，如果这个互斥锁被释放了（可能获取锁的客户端宕机了，或者那个客户端主动释放了锁）可以调用回调函数重新获得锁。

      zk 中不需要向 redis 那样考虑锁得不到释放的问题了，因为当客户端挂了，节点也挂了，锁也释放了。
      
      那能不能使用 zookeeper 同时实现 共享锁和独占锁 呢？答案是可以的，不过稍微有点复杂而已。

      还记得 有序的节点 吗？

      这个时候我规定所有创建节点必须有序，当你是读请求（要获取共享锁）的话，如果 没有比自己更小的节点，或比自己小的节点都是读请求 ，则可以获取到读锁，然后就可以开始读了。若比自己小的节点中有写请求 ，则当前客户端无法获取到读锁，只能等待前面的写请求完成。

      如果你是写请求（获取独占锁），若 没有比自己更小的节点 ，则表示当前客户端可以直接获取到写锁，对数据进行修改。若发现 有比自己更小的节点，无论是读操作还是写操作，当前客户端都无法获取到写锁 ，等待所有前面的操作完成。

      这就很好地同时实现了共享锁和独占锁，当然还有优化的地方，比如当一个锁得到释放它会通知所有等待的客户端从而造成 羊群效应 。此时你可以通过让等待的节点只监听他们前面的节点。

      具体怎么做呢？其实也很简单，你可以让 读请求监听比自己小的最后一个写请求节点，写请求只监听比自己小的最后一个节点。
    
    - 命名服务
    
      如何给一个对象设置ID，大家可能都会想到 UUID，但是 UUID 最大的问题就在于它太长了。。。(太长不一定是好事，嘿嘿嘿)。那么在条件允许的情况下，我们能不能使用 zookeeper 来实现呢？

      我们之前提到过 zookeeper 是通过 树形结构 来存储数据节点的，那也就是说，对于每个节点的 全路径，它必定是唯一的，我们可以使用节点的全路径作为命名方式了。而且更重要的是，路径是我们可以自己定义的，这对于我们对有些有语意的对象的ID设置可以更加便于理解。
    
    - 集群管理和注册中心
    
      可能我们会有这样的需求，我们需要了解整个集群中有多少机器在工作，我们想对集群的每台机器的运行时状态进行数据采集，对集群中机器进行上下线操作等等。

      而 zookeeper 天然支持的 watcher 和 临时节点能很好的实现这些需求。我们可以为每条机器创建临时节点，并监控其父节点，如果子节点列表有变动（我们可能创建删除了临时节点），那么我们可以使用在其父节点绑定的 watcher 进行状态监控和回调。
      
      至于注册中心也很简单，我们同样也是让 服务提供者 在 zookeeper 中创建一个临时节点并且将自己的 ip、port、调用方式 写入节点，当 服务消费者 需要进行调用的时候会 通过注册中心找到相应的服务的地址列表(IP端口什么的) ，并缓存到本地(方便以后调用)，当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从地址列表中取一个服务提供者的服务器调用服务。

      当服务提供者的某台服务器宕机或下线时，相应的地址会从服务提供者地址列表中移除。同时，注册中心会将新的服务地址列表发送给服务消费者的机器并缓存在消费者本机（当然你可以让消费者进行节点监听，我记得 Eureka 会先试错，然后再更新）。

10. 分布式锁

  > [分布式锁](https://juejin.im/post/6844903688088059912#heading-12)

  - 基于MySQL实现
  - 基于Redis实现
  - 基于zk实现

10. Kafka

  https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/kafka-inverview

  https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/Kafka%E5%85%A5%E9%97%A8%E7%9C%8B%E8%BF%99%E4%B8%80%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86
  
  - 流程

    1: 第一步心跳请求，客户端启动以后，主动链接castle，请求需要往哪个集群上生产和消费

    2: 第二步心跳响应，castle返回客户端，“你往192.168.1.1” 这个broker上生产消息或拉取消息。

    3: 第三步，客户端链接Broker，生产消息到broker上，或从broker上拉取消息消费。

    4: 以后第一步和第二步会一直重复，这就是所谓的“Mafka心跳”，客户端会始终和Castle保持一个“请求/响应”循环，目的是为了接收服务端的调度和控制指令。

  - 名词

    Broker: 存储实际消息的地方，一台服务器，多个服务器(broker)组成一个集群。

    Castle: 中控调度，调度客户端从哪个机器上拉取消息，或把消息生产到哪台机器上去。

    ClientSDK: 业务使用的api，来生产或消费消息。

    Topic: 主题、队列

    生产者、上游

    消费者、下游，多台相同的消费者组成消费组

    Partition、主题分区、消息分片、分片：设想你发给Mafka 一万条消息，Mafka保存的时候，把它切成了4块，每块2500条消息，分别放到了四个不同的机器上。

    消息副本、replica、消息复制

    Topic的Ack属性：3个副本（一个主本，两个副本），如果Ack设为-1表示3个副本都接受到消息才算成功，如果是1表示主本收到消息就算成功，存在消息丢失风险（主本刚接收到消息返回给发送端成功，同步线程还未将消息复制给副本，此时主本机器宕机了，副本机器转换为主本，消息丢失）。同步线程会保证消息主本和副本复制时延在1秒内，所以Ack设置为1的极端情况下最大可能会丢失1秒内的消息。

    死信：某条消息无法消费成功，一直卡在这条消息处，无法消费后面的消息。解决方法：在topic管理页面里打开死信，处理消息如果失败会扔进死信队列，先消费后面的消息，过一段时间再消费。

11. ElasticSearch

  - 节点

    - Master Node

      - 处理创建、删除索引请求 / 决定分⽚分配到哪个节点
      - 维护并更新Cluster State
    
    - Master Eligible Node

      - 在Master节点出现故障时，参与选主流程，成为Master Node
    
    - Data Node

      - 保存分⽚数据，通过增加Data Node，可以解决数据⽔平扩展
      - 和数据单点的问题
    
    - Coordinating Node

      - 负责将请求转发到正确的节点
      - 处理query AND fetch的结果集
  
  - 分⽚—分布式存储的基⽯

    - Primary Shard

      - 主分⽚在索引创建时指定，默认不能修改

    - Replica Shard
    
      - 数量可以动态调整，提⾼数据的可⽤性
      - 提升查询性能
      - 副本数量过多，会降低写⼊性能，增加磁盘负担
  
  - 倒排索引&正排索引

    倒排索引可以实现从term到document的快速查询，但是没法实现排序，这个时候就需要⽤到正排索引。es是通过doc_value和field_data来实现正排索引的。

    doc_value是在lucene构建倒排索引时，根据原始mapping配置判断是否额外建⽴⼀个有序的正排索引（基于documentId—>field value的映射列表）

    doc_value默认对所有字段启⽤，除了analyzed string，针对analyzed string，如果需要排序，需要开启field_data。

    doc_value本质上是⼀个序列化的列式存储，这个结构⾮常适⽤于聚合、排序、脚本等操作，也⾮常便于压缩。和倒排索引⼀样，doc_value也会序列化到磁盘，这样对性能和扩展性有很⼤帮助。

  - indexing的过程

    1. 将document写⼊index buffer，同时记录trans_log；
    2. 将index buffer写⼊segment，但不执⾏fsync，也不清理trans_log；
      - 这个过程叫做refresh，默认1s⼀次；
      - Index buffer占满时，也会触发refresh；
    3. 调⽤fsync，将缓存中的segments写⼊磁盘，清空trans_log；
      - 这个动作叫做flush，默认30min⼀次；
      - trans_log满（默认512M），也会触发flush；
  
  - 索引定义

    字段类型—>是否需要搜索—>是否需要分词—>是否需要聚合及排序

    字段类型：Text vs keyword

    - Text
      - ⽤于⽂本分析，⽂本会被Analyzer分词
      - 默认不⽀持聚合分析和排序，需要设置fielddata=true

    - Keyword
      - 适⽤于不需要分词的场景，精确匹配查询效率最⾼
      - ⽀持sorting和aggregations

  - 关于分⻚

    es提供三种分⻚查询的机制
    - from / size（es默认限定10000个⽂档）
    - search after（不⽀持跳⻚）
    - scroll API（遍历期间，更新的数据不会拿到）

    使⽤场景及建议
    - 需要全部⽂档，例如导出数据，允许⼀定误差（⽐如导出期间新增的数据）——scroll
    - 分⻚
      - 数据量⼩，且只查询最新的数据，使⽤from / size
      - 深度分⻚，使⽤search after，禁⽤跳⻚

  - 常⽤的优化设计建议

    - 基于时间序列拆分索引
    - 节点职责分离
      - eligible master node：使⽤低配的CPU，RAM和磁盘
      - data node：使⽤⾼配的CPU，RAM和磁盘
    - 写⼊性能优化
      - 客户端通过bulk API批量写
      - 服务端降低IO开销，如提⾼refresh interval
      - 降低CPU和存储开销，如减少不必要的索引 / 分词 / doc_value
      - 极致的性能追求（牺牲可靠性）
        - 临时将副本修改为0（针对初始化导⼊数据场景）
        - 修改trans_log配置（不每次落盘，60s fsync⼀次）
    - 定期做segment merge，segments过多，term_index会占⽤较⼤内存，影响集群性能

  - yyy

    特点：分布式，水平扩展，REST API

    功能：海量数据的存储管理以及几乎实时的搜索和数据分析

    分布式架构：存储水平扩容，PB级数据，一台机器可以多个es节点；可用性：部分节点宕机集群不受影响

    节点：至少三个master节点能够保证系统的正常运行状态（高可用性），主节点宕机剩下两个自主选举新的主节点，分为master&data节点，master对磁盘内存要求不高，不存数据，data反之，因此根据不同功能配置不同的机器；data node 通过分片来实现备份，即主分片和副本分片，如下“分片”所述

    master：处理创建，删除索引/决定分片的分配；维护更新cluster

    data：保存分片数据，增加此类型node可以水平扩展

    coordinating：请求转发到节点，处理query&fetch结果

    分片：一个分片是一个lucene索引，业务类不要超过20g，日志类不超过50g；太大了恢复起来会比较慢，保持合适大小能够提高集群的效率；主分片不能修改；副本分片数量可以动态调整，提升查询的性能，过多则影响磁盘写入性能；主分片和副本分布在不同节点，如果主分片宕机则内容会分到副本分片上

    索引：对term_dictionary做一个term_index，然后找到posting list再找到各个document，通过refresh来达到近实时的查询效率，refresh之前是读不到数据的，refresh的时间间隔即其近实时的效率（那要是refresh的时间间隔调短会怎样？refresh时间间隔变长为什么能够优化：提高interval可以降低IO的开销，因为索引是根据segment去写入的，会涉及到IO操作，如果很频繁则会比较消耗IO；refresh除了固定的时间间隔还有可以根据indexbox的大小，满足任意一个都会进行refresh。

    倒排索引：实现term到document的快速查询，但是没法排序，具体信息可参考↓

    官方：https://www.elastic.co/guide/cn/elasticsearch/guide/cn/inverted-index.html

    https://blog.csdn.net/hu948162999/article/details/81386384

    https://www.cnblogs.com/cjsblog/p/10327673.html

    正排索引：基于documentId->field value的映射列表，实现排序；doc_value是构建倒排时候，根据原始mapping配置判断是否有有序的正排索引，默认对所有字段启用，本质是一个序列化的列式存储；默认doc_value在磁盘当中，但是如果有词频之类的会加载到内存中

    query过程：query & fetch ，document在磁盘中的存储是按照块存储的，然后有一个文档位置的索引；从内存找到磁盘中对应的倒排索引的位置，然后在磁盘中找到倒排表->document ID->document block index->document block

    indexing：document->index buffer(with trans_log recorded); index buffer->segment (default refresh every one second); 

    内存分配：在JVM heap中地下有fieldData和其他缓存，可以设置断路器，节点中es的存在jvm heap，lucene的存在外部的heap中，会加载到jvm的缓存中提高之后的查询效率

    索引定义：搜索/分词/聚合&排序：text or keyword  ； 嵌套对象 & 父子结构；索引设计避免过多字段（不移维护，mapping存在cluster state过大集群性能受影响，reindex成本高）

    分页：from/size(<=10000 documents)数据量小且要最IN; search after(no jump)深度分页，禁止跳页； scroll API(no updating during iterating)需要全部文档，允许一定偏差

    优化：基于时间序列拆分索引；节点职责分离；写入优化；定期进行segment merge

  - ES和MySQL的区别

    1. 一个ES集群可以包含多个**索引（数据库）**，每个索引又包含了很多**类型（表）**，类型中包含了很多**文档（行）**，每个文档使用 JSON 格式存储数据，包含了很多**字段（列）**。

    2. ES**分布式搜索（一个索引包含多个分片，分片包括主分片和副本分片；选举master结点）**，传统数据库遍历式搜索

    3. ES采用**倒排索引（单词到文档）**，传统数据库采用B+树索引

    4. ES**没有用户验证和权限控制**

    5. ES**没有事务**的概念，不支持回滚，误删不能恢复
  
  - elasticsearch的倒排索引是什么

    传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。有了倒排索引，就能实现o（1）时间复杂度 的效率检索文章了，极大的提高了检索效率。

    倒排索引的底层实现是基于：**FST（Finite State Transducer）数据结构**。lucene从4+版本后开始大量使用的数据结构是FST。FST有两个优点：

    1）**空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；**

    2）**查询速度快。O(len(str))的查询时间复杂度。**
  
  - elasticsearch是如何实现master选举的

    选举流程大致描述如下：

    第一步：确认候选主节点数达标，elasticsearch.yml设置的值discovery.zen.minimum_master_nodes；

    第二步：比较：先判定是否具备master资格，具备候选主节点资格的优先返回；若两节点都为候选主节点，则id小的值会主节点。注意这里的id为string类型。
  
  - Elasticsearch写入数据的工作原理, 查询数据的工作原理, 搜索数据的工作原理分别是什么?

    **Elasticsearch写入数据的工作原理**

    - **客户端发送请求到任意一个协调节点(Coordinating Node), 然后协调节点将请求转发给master节点.**
    - **master节点对document进行路由, 将document写入主分片.**
    - **document写入主分片后, 将数据同步到副本分片.**
    - 主分片和副本分片都写入成功后, 返回响应结果给客户端.
    
    (1) document写入主分片的详细过程

    - **Document写入Index Buffer(ES进程缓冲), 同时将写命令记录到Transaction Log.**
    - **每隔1秒或Index Buffer空间被占满后, Index Buffer中的数据被写入新的Segment中, 并进入OS Cache, 这个过程叫Refresh.** (此时倒排索引已创建, 存在OS Cache中, 数据可被搜索)
    - 重复前面两个步骤.
    - 每隔30分钟或Transaction Log占满后, 先进行Refresh操作, 然后将OS Cache中的Segment刷入磁盘, 这个过程叫Flush.
    - 删除旧Transaction Log, 创建一个新的Transaction Log.
    - ES定期合并磁盘中的Segment File, 同时清除那些被标记为delete的文档.
    
    (2) **ES被称为近实时(Near Realtime)的原因**

    **从上文"document写入主分片的详细过程"中可以知道, Refresh操作每秒执行一次, 只有执行Refresh操作之后, 倒排索引才会被创建, 数据才能被搜索, 这就是ES被称为近实时的原因.**

    (3) ES存在数据丢失的问题

    从上文"document写入主分片的详细过程"中可以知道, document写入Index Buffer的同时会将写命令记录到Transaction Log, 目的是如果数据落盘之前机器宕机了, 可以从Transaction Log中恢复数据. 但在旧版本中Transaction Log不是默认落盘的, 它会先写入OS Cache中, 每隔5s才会被刷入磁盘, 所以如果在Transaction Log落盘前机器宕机了, 数据就完全丢失了.

    在新版本7.x中, Transaction Log是默认落盘的, 也就不会有数据丢失的问题. (index.translog.durability, index.translog.sync_interval)

    **Elasticsearch查询数据的工作原理(Get查询)**

    - **客户端发送请求到任意一个协调节点(Coordinating Node).**
    - **协调节点根据id进行路由, 找到对应的分片.**
    - **根据round-robin随机轮询算法, 在主分片和其他副本分片中随机选择一个, 进行查询.**
    - 将对应的document返回给协调节点.
    - 协调节点返回document给客户端.
    
    **Elasticsearch搜索数据的工作原理**

    - **客户端发送请求到任意一个协调节点(Coordinating Node).**
    - **协调节点将搜索请求转发给所有分片(主分片和副本分片采用随机轮询算法选一个)**
    - **每个分片将自己的搜素结果(这里只有id)返回给协调节点**
    - **协调节点对搜索结果进行合并, 排序, 分页等操作, 得出最终结果.**
    - **协调节点根据最终结果的id去各个分片上拉取document, 返回给客户端.**
  
  - Elasticsearch之四种搜索类型和搜索原理

    **Elasticsearch在搜索过程中存在以下几个问题：**

    第一、 **数量问题**。 比如， 用户需要搜索"衣服"， 要求返回符合条件的前 10 条。 但在 5个分片中， 可能都存储着衣服相关的数据。 所以 ES 会向这 5 个分片都发出查询请求， 并且要求每个分片都返回符合条件的 10 条记录。当ES得到返回的结果后，进行整体排序，然后取最符合条件的前10条返给用户。 这种情况， ES 中 5 个 shard 最多会收到 10*5=50条记录， 这样返回给用户的结果数量会多于用户请求的数量。
    
    第二、 **排名问题**。 上面说的搜索， 每个分片计算符合条件的前 10 条数据都是基于自己分片的数据进行打分计算的。计算分值使用的词频和文档频率等信息都是基于自己分片的数据进行的， 而 ES 进行整体排名是基于每个分片计算后的分值进行排序的(相当于打分依据就不一样， 最终对这些数据统一排名的时候就不准确了)， 这就可能会导致排名不准确的问题。如果我们想更精确的控制排序， 应该先将计算排序和排名相关的信息（ 词频和文档频率等打分依据） 从 5 个分片收集上来， 进行统一计算， 然后使用整体的词频和文档频率为每个分片中的数据进行打分， 这样打分依据就一样了。

    **Elasticsearch的搜索类型（SearchType类型）**

    1、 query and fetch
    
    向索引的所有分片 （ shard）都发出查询请求， 各分片返回的时候把元素文档 （ document）和计算后的排名信息一起返回。
    
    这种搜索方式是最快的。 因为相比下面的几种搜索方式， 这种查询方法只需要去 shard查询一次。 但是各个 shard 返回的结果的数量之和可能是用户要求的 size 的 n 倍。
    
    优点：这种搜索方式是最快的。因为相比后面的几种es的搜索方式，这种查询方法只需要去shard查询一次。
    
    缺点：返回的数据量不准确， 可能返回(N*分片数量)的数据并且数据排名也不准确，同时各个shard返回的结果的数量之和可能是用户要求的size的n倍。

    2、 query then fetch（ es 默认的搜索方式）

    如果你搜索时， 没有指定搜索方式， 就是使用的这种搜索方式。 这种搜索方式， 大概分两个步骤：

    第一步， 先向所有的 shard 发出请求， 各分片只返回文档 id(注意， 不包括文档 document)和排名相关的信息(也就是文档对应的分值)， 
    然后按照各分片返回的文档的分数进行重新排序和排名， 取前 size 个文档。
　　
    第二步， 根据文档 id 去相关的 shard 取 document。 这种方式返回的 document 数量与用户要求的大小是相等的。
    
    优点：返回的数据量是准确的。
　　
    缺点：性能一般，并且数据排名不准确。

    3、 DFS query and fetch
　　
    这种方式比第一种方式多了一个 DFS 步骤，有这一步，可以更精确控制搜索打分和排名。也就是在进行查询之前， 先对所有分片发送请求， 把所有分片中的词频和文档频率等打分依据全部汇总到一块， 再执行后面的操作。

    优点：数据排名准确

    缺点：性能一般；返回的数据量不准确， 可能返回(N*分片数量)的数据

    4、 DFS query then fetch
　　
    比第 2 种方式多了一个 DFS 步骤。也就是在进行查询之前， 先对所有分片发送请求， 把所有分片中的词频和文档频率等打分依据全部汇总到一块， 再执行后面的操作。

　　优点：返回的数据量是准确的，数据排名准确

　　缺点：性能最差【 这个最差只是表示在这四种查询方式中性能最慢， 也不至于不能忍受，如果对查询性能要求不是非常高， 而对查询准确度要求比较高的时候可以考虑这个】

　　DFS 是一个什么样的过程？

　　从 es 的官方网站我们可以发现， DFS 其实就是在进行真正的查询之前， 先把各个分片的词频率和文档频率收集一下， 然后进行词搜索的时候， 各分片依据全局的词频率和文档频率进行搜索和排名。 显然如果使用 DFS_QUERY_THEN_FETCH 这种查询方式， 5效率是最低的，因为一个搜索， 可能要请求 3 次分片。 但， 使用 DFS 方法， 搜索精度是最高的。
  
  - Elasticsearch在数据量很大的情况下（数十亿级别）如何提高搜索性能?

    (1) 善于利用OS Cache

    如果Elasticsearch的每次搜索都要落盘, 那搜索性能肯定很差, 将达到秒级. 但**如果ES集群中的数据量等于OS Cache的容量, 那每次搜索都会直接走OS Cache, 这样性能就会很高, 达到毫秒级.**

    ES集群中的数据量最好不要超过OS Cache的容量, 最低要求也不能超过OS Cache的两倍. 比如我们ES集群有3台机器, 每台机器64G内存, 为每个节点的ES JVM Heap分配32G内存, 最终集群的OS Cache为 32G * 3 = 96G内存. 我们ES集群中的数据量最优情况是不超过96G, 最低要求的情况是不超过192G.

    (2) 数据建模

    从上文"善于利用OS Cache"中我们知道, 我们要保证ES集群中的数据量不超过OS Cache的容量, 那么我们在数据建模的时候就要注意两点:

    - **不要将MySQL表中的所有字段都写入ES, 只写入一部分会被搜索的字段.**
    - **对于MySQL中具有关联关系的表, 我们直接将关联字段写入ES中或在应用端处理关联关系, 禁止在ES中处理关联关系.**

    (3) 数据预热

    如果我们无法做到让ES集群中的数据量不超过OS Cache的容量, **那我们做一个缓存预热子系统, 定时搜索"热数据", 让其进入OS Cache.**

    (4) 冷热分离

    在数据预热的基础上我们还可以进行冷热数据分离, 比如我们有6台机器, 创建两个索引, 每个索引3个分片, **一个索引放热数据, 一个索引放冷数据**. 热数据量一般只占总数据量的10%, 这样我们就能保证热数据都在OS Cache中. 而冷数据虽然占总数据的90%, 但却只有10%的用户访问, 性能差点是可以接受的.

    (5) 分页性能优化

    **深度分页的性能是很差的, 我们要防止出现深度分页的情况, 用滚动翻页来代替深度分页.**

    - search after
    - scroll

  - ES分页

    Elasticsearch分页api有三种:

    - from/size（深度分页。当我们进行一个分页查询from=990, size=10时:首先在每个分片上先都获取 1000 个文档，通过 Coordinating Node 聚合所有结果，再通过排序选取前 1000 个文档。页数越深，占用内存就越多。）
    - search after（用来实时的获取下一页文档信息, 它不支持指定页数(from), 只能往下翻.）
    - scroll（用来处理大数据量的分页搜索, 不适用于实时的分页搜索. scroll分页搜索每次都会创建一个快照, 新数据写入只能影响到后续的分页搜索.）

  - Elasticsearch生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？

    (1) ES生产集群我们部署了5台机器, 每台机器是6核64G的, 集群总内存是320G.

    (2) 我们ES集群的日增量数据大概是2000万条, 500MB左右; 每月增量数据大概是6亿条, 15G左右. 目前系统已经运行了几个月, 现在ES集群里数据总量大概是100G左右.

    (3) 目前线上有5个索引（这个结合你们自己业务来, 看看自己有哪些数据可以放ES的）, 每个索引的数据量大概是20G, 所以这个数据量之内, 我们每个索引分配的是8个shard, 比默认的5个shard多了3个shard.
  
  - 常用命令

    创建索引模板 PUT _template/...
      settings: 分片数、备份数
      mappings: properties 字段类型
    创建索引 PUT ...
    查询 GET _search
      query: match _all, term (精确查找), match(模糊匹配), range (范围查找), [bool: filter, should (或), must (与)]
    java中的写法：jsonbuilder，client发送请求；类似JPA

12. RPC

  https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/why-use-rpc

  https://blog.csdn.net/top_code/article/details/54615853

12. Dubbo

  https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/dubbo

12. Thrift

  https://blog.csdn.net/kesonyk/article/details/50924489
 
  https://www.jianshu.com/p/15dbc8665648

13. Redis

14. Databus

  读数据：读缓存，读数据库，写缓存

  写数据：淘汰缓存，写数据库，（写缓存）

  问题：写数据库后，写缓存失败怎么办？读数据后写缓存时，数据库又更新了怎么办？

  解决：Databus，强一致协议（比如两阶段提交，paxos等）

15. 秒杀

  - 超卖

    https://blog.csdn.net/glamour2015/article/details/105179738/

    https://hacpai.com/article/1536335417613

    https://www.jianshu.com/p/39b3a95240c4

## 网络

1. OSI七层模型：物理层、数据链路层、网络层、传输层、会话层（会话管理）、表示层（数据格式转换）、应用层

2. ARP协议（网络层）：IP地址->MAC地址

    每个主机都设有一个ARP高速缓存，先查ARP表，如果没有就通过使用目的MAC地址为FF-FF-FF-FF-FF-FF的帧来封装并广播ARP请求分组。

3. TCP和UDP

    TCP提供可靠的面向连接的服务，增加了开销，用于文件传输、发送和接受邮件、远程登录等场景。

    UDP不建立连接，不提供可靠服务，用于语音、视频。

4. TCP为什么可靠一些

    TCP连接管理：三次握手、四次挥手

    TCP可靠传输：累计确认、超时和冗余ACK

    TCP流量控制：发送窗口的实际大小是接受窗口和拥塞窗口的最小值

    TCP拥塞控制：慢开始（指数规模增长）、拥塞避免（加法增大）、快恢复（乘法减小）

5. 滑动窗口的作用

    - 滑动窗口实现面向六的可靠性，只有在收到ACK确认的情况下移动左边界

    - 滑动窗口的流控特性

6. TCP连接和释放过程

    三次握手

    1. 客户机到服务器：SYN
    2. 服务器到客户机：SYN/ACK
    3. 客户机到服务器：ACK

    四次挥手

    1. 客户机到服务器：FIN
    2. 服务器到客户机：ACK
    
        CLOSE_WAIT

    3. 服务器到客户机：FIN/ACK

        TIME_WAIT
    
    4. 客户机到服务器：ACK

    - 为什么A还要发送一次确认呢？

      防止已经失效的连接请求报文段突然又传到了B，因而产生错误，浪费B的资源。
    
    - CLOSE_WAIT：半关闭状态，即A已经没有数据要发送了，但B若发送数据，A仍要接受。

    - TIME_WAIT：为什么A在TIME_WAIT状态必须等待2MSL（最长报文段寿命，建议为2min）？

      1. 为了保证A发送的最后一个ACK报文段能够到达B
      2. 防止已失效的连接请求报文段出现在本连接中
    
7. DNS的寻址过程

    1. 浏览器缓存、DNS缓存
    2. hosts文件
    3. 本地域名服务器分别请求根域名服务器、顶级域名服务器、权限域名服务器
    
        递归查询（比较少用）、迭代查询
    
8. 在浏览器输入url到显示主页的过程：DNS解析、TCP连接、发送HTTP请求、服务器解析渲染页面

9. 状态码

    1XX：信息性状态码

    2XX：成功状态码

    3XX：重定向状态码

    4XX：客户端错误状态码

    5XX：服务端错误状态码

    - 200 OK：表示从客户端发来的请求在服务端被正常处理了。
    - 201 Created：请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。
    - 202 Accepted：服务器已接受请求，但尚未处理。正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。
    - 204 No Content：代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。
    - 206 Partial Content：表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求。

    - 301 Moved Permanently：永久性重定向。表示请求的资源已被分配了新的URL，以后应使用资源现在所指的URL。
    - 302 Found：临时性重定向。表示请求的资源已被分配了新的URL，希望用户能使用新的URL访问。和301状态码相似，但302状态码代表资源不是被永久移动，只是临时性质的。
    - 304 Not Modified：表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回304.

    - 400 Bad Request：表示请求报文中存在语法错误。
    - 401 Unauthorized：表示发送的请求需要有通过HTTP认证的认证信息。
    - 403 Forbidden：对请求资源的访问被服务器拒绝了。
    - 404 Not Found：表明服务器上无法找到请求的资源。

    - 500 Internal Server Error：表示服务器端在执行请求时发生了错误。
    - 503 Service Unavailable：表明服务器暂时处于超负荷或正在进行停机维护，现在无法处理请求。

10. HTTP/1.1默认使用长连接，在响应头加入Connection: keep-alive。在使用长连接的情况下，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭。

11. HTTPS过程

  客户端向服务端发送HTTPS请求，服务端将自己的公钥发送给客户端，客户端利用公钥加密密钥，发起第二个HTTPS请求，将加密之后的密钥发送给服务端，服务端用私钥解密密钥，将加密后的密文发送给客户端，客户端利用密钥解密。

12. HTTP 2.0

  多个请求可同时在一个连接上并行执行。

13. HTTPS与HTTP的区别

  - 传输信息安全性不同
  - 连接方式不同：HTTPS由SSL+HTTP协议构建
  - 端口不同：HTTP 80, HTTPS 443
  - 证书申请方式不同：HTTPS需要到CA申请证书

14. 请求报文的结构

  - 请求行：请求方法GET/POST、URL、协议版本HTTP1.0/HTTP1.1
  - 请求首部：图解HTTP P80
  - 请求主体

15. GET请求和POST请求

  - GET请求参数在URL中，POST请求在请求主体中
  - GET请求具有幂等性，多词调用和一次调用是一样的，没有副作用

## 设计模式

1. 面对对象

- 封装：对象包含它能操作所需的所有信息，包括变量和方法，好处是减少耦合，内部可以自由修改，具有清晰的对外接口。
- 继承：is-a的关系，弗雷变子类不得不变，强耦合。
- 多态：子类以父类的身份出现，调用父类的方法，使用的是子类的实现。

2. 原则

- 单一职责原则：就一个类而言，应该仅有一个引起它变化的原因。
- 开放封闭原则：软件实体对于扩展是开放的，对于更改是封闭的。
- 依赖倒转原则：A.高层模块不应该依赖低层模块，两个都应该依赖抽象。B. 抽象不应该依赖细节，细节应该依赖抽象。
- 里氏替换原则：子类型必须能够替换掉它们的父类型。
- 合成/聚合复用原则：尽量使用合成/聚合，尽量不要使用继承。

3. 设计模式

- 简单工厂模式
- 工程方法模式：产品接口、工厂接口、具体产品、具体工厂，一个具体工厂生产一个具体产品。
- 抽象工厂模式：一个具体工厂创建一组具体工厂。
- 策略模式：上下文类（维护一个对策略的引用），策略类，具体策略类
- 代理模式：主体类（定义真是主体类和代理类的共同接口），真实主体类，代理类（保存一个引用是的代理可以访问真实主体）
- 观察者模式（发布-订阅模式）：主体类（可以增加和删除观察者对象）、观察者（再得到主体的通知时更新自己）、具体主体、具体观察者
- 适配器模式：将一个类的接口转换成客户希望的另一个接口
- 桥接模式：实现系统可能有多角度分类，每一种分类都有可能变化，那么九八这种多角度分离出来让它们独立变化，减少它们之间的耦合。
- 单例模式

  ```java
  public class Singleton {
      private volatile static Sinleton uniqueInstance;
      private Singleton() {}
      public static SIngleton getInstance() {
          if (uniqueInstance == null) {
	      synchronized (Singleton.class) {
	          if (uniqueInstance == null) {
		      uniqueInstance = new Singleton();
		  }
	      }
	  }
      }
  }
  ```

## 数据库

## Java 

1. 简单类型8种：short, int, long, float, double, boolean, byte, char

2. NIO：非阻塞IO，调用者不用一直等着结果返回。线程控制选择器，选择不同的通道来读取缓存区。

3. Linux的5中IO模型：阻塞、非阻塞、异步、IO复用、信号驱动IO

4. select, poll, epoll的区别

  - select需要把文件描述符(fd)集合从用户态拷贝到内核态，并在内核态遍历文件描述符。
  - poll与select类似，文件描述符集合的描述结构不同。
  - epoll会在注册时吧所有文件描述符拷贝进内核，每个文件描述符只会拷贝一次，挂到等待队列上。

5. Object类方法：hashCode(), equals(), notify(), wait(), toString(), clone(), getClass(), finalize()

6. 接口和抽象类的区别：方法再接口中不能有实现；一个类可以实现多个接口，但只能继承一个抽象类。

7. String：不可变
StringBuffer：可变，线程安全synchronized
StringBuilder：可变，线程不安全

8. final

  - 修饰变量：值再初始化后不能更改
  - 修饰类：类不能被继承，所有成员方法都会被隐式指定为final

9. static

  - 修饰成员变量和方法
  - 静态代码块
  - 静态内部类（不能引用外部非static成员变量和方法）

10. 通配符?用于实例化泛型对象，T用于定义泛型类

11. List, Set, Map

  - List: ArrayList, Vector, LinkedList
  - Set, Map: HashMap, HashTable. LinkedHashMap, TreeMap

12. HashMap

  - hash = h ^ (h >>> 16)，高16位和低16位都反映到低位上，使hash更均匀
  - 到table[(n-1)&hash]取值（取hash的低位）
  - 扩容：新数组newTable为原数组的2倍；如果节点是TreeNode，分成2棵树；如果是节点，hash&oldCap==0放在原索引，否则原索引+oldCap.
  - JDK 8前，并发扩容产生循环链表，get时死循环。JDK 8不会死循环，但仍然会产生数据丢失。

13. ==和equals()的区别

  - ==判断2个对象的地址是否相等
  - equals()没有重写时等价于==，可以重写

14. hashCode()和equals()

  - HashMap比较key是否相同时，先判断hashCode是否相同，再比较equals()是否相同。
  - 2个对象相等，散列码相同。
  - equals()重写过，hashCode()也要重写，否则有可能2个对象相同散列码不同，散列到不同的散列桶中找不到key

15. 重写equals()的约定

  (1) 使用==操作符检查参数是否时这个对象的引用
  (2) 使用instance检查是否为正确的类型
  (3) 把参数转换成正确的类型
  (4) 比较每个关键域是否匹配
  (5) 死牢equals()方法是否满足自反性、对称性、传递性、一致性、非空性

16. 重写hashCode

  (1) int result = 17;
  (2) 对于每个关键域：
  a. 计算关键域int类型的散列码c，float, double转成int, long, long: (int) (f^(f>>>32))
  b. result=31*result+c

17. TreeMap的底层实现是红黑树，AVL树是严格平衡，红黑树是弱平衡

18. 红黑树性质

  (1) 每个节点要么是红色，要么是黑色
  (2) 根节点永远是黑色的
  (3) 叶结点是空节点，并且是黑色的
  (4) 每个红色节点的2个子节点都是黑色的
  (5)从任一节点到其子树的每个叶结点都包含相同数量的黑色节点

19. Java 8

  - lambda表达式
  - 方法引用
  - 接口的默认方法
  - stream()
  - Optional

## 并发

1. 并发执行有可能比串行慢，因为线程有创建和上下文切换的开销

2. 使用Lmbench测量上下文切换时长，vmstat测量上下文切换的次数

3. 如何减少上下文切换

  - CAS算法，不用加锁
  - 使用最少线程
  - 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换

4. synchronized

  - 3种形式
  
    - 对于普通的同步方法，锁的是当前实例对象
    - 对于静态同步方法，锁的是当前类的Class对象
    - 对于同步方法块，锁的是synchronized括号里配置的对象
  
  - JVM基于进入和退出Monitor对象来实现方法同步和代码块同步。代码块同步是使用monitorenter和monitorexit指令实现的，而方法同步时使用ACC_SYNCHRONIZED标志位实现的。

5. Java对象头的Mark Word中存储对象的hashCode、分代年龄和锁标记位。

  - 偏向锁：Mark Word中存储指向当前线程的偏向锁。
  - 轻量级锁：线程尝试使用CAS将对象头中的MarkWord替换为指向锁记录的指针。
  - 重量级锁

6. CAS的三大问题

  (1) ABA问题
  (2) 循环时间长开销大
  (3) 只能保证一个共享变量的原子操作

7. JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本。

  如果线程A要和B通信，必须要经历下面2个步骤：
  
  (1) 线程A把本地内存A中更新过的共享变量刷新到主内存中去。
  (2) 线程B到主内存中去读取线程A之前已经更新过的共享变量。

8. 为什么要使用多线程（主要原因是IO阻塞和多CPU）

  - 单核时代提高CPU和IO的综合利用率
  - 多核时代提高CPU利用率
  - 业务更快的响应时间

9. 设置线程优先级时，针对频繁阻塞的线程需设置较高的优先级，而偏重计算的线程设置较低的优先级，确保处理器不会被独占。

10. 线程的状态

  - NEW
  - TERMINATED
  - RUNNABLE：运行中，包括就绪和运行
  - BLOCKED：阻塞于锁
  - WAITING：等待其他线程通知
  - TIME_WAITING：超时等待，可以在指定时间自行返回

11. 当一个Java虚拟机中不存在非Daemon线程时，Java虚拟机将会退出。

12. 线程通过方法isInterrupted()来判断是否被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标志位进行复位。

13. 除了中断以外，还可以利用一个boolean变量来控制是否需要停止任务并终止该线程。

14. suspend()调用后不会释放已经占有的资源（比如锁），而是占有着资源进入睡眠状态。

  stop()终结一个线程时不会保证线程资源正常释放
  
  yield()方法会临时暂停正在执行的线程，来让有同样优先级的线程有机会执行。yield()方法不保证当前的线程会暂停或停止，但是可以保证当前线程调用yield方法时会放弃CPU。

15. 线程间通信

  - wait/notify
  - volatile/synchronized
  - join
  - countdownlatch/cyclicbarrier

16. Fork/Join框架

  FOrk就是把一个大任务切分成若干子任务，Join就是合并这些子任务的执行结果。
  
  工作窃取算法是指某个线程从其他队列中窃取任务来执行。充分利用线程进行并行计算，减少了线程的竞争。

17. AtomicInteger

  ```java
  public final int getAndIncrement() {
      for (;;) {
          int current = get();
    int next = current + 1;
    if (compareAndSet(current, next)) {
        return current;
    }
      }
  }
 
  public final boolean compareAndSet(int expect, int update) {
      return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
  }
  ```

18. 线程池的好处

  - 降低资源消耗
  - 提高响应速度
  - 提高线程的可管理性
   
19. 线程池的参数

  (1) corePoolSize：核心线程数

  (2) runnableTaskQueue：任务队列

  ArrayBockingQueue：有界

  LinkedBlockingQueue：有界，默认Integer.MAX_VALUE

  SynchronousQUeue：不存储元素

  PriorityBlockingQueue：具有优先级、无限

  (3) maxPoolSize：线程池的最大数量

  (4) ThreadFactory：创建线程的工厂

  (5) RejectExxcutionHandler 饱和策略

  AbortPolicy 直接抛出异常

  CallerRunPolicy 调用者所用线程

  DiscardOldestPolicy 丢弃最早

  DiscardPolicy 丢弃

  (6) keepAliveTime 线程池工作线程空闲后，保持存活的时间

20. 线程池提交任务

  execute()提交不需要返回值的任务，输入Runnable类实例

  submit()提交需要返回值的任务，输入Runnale或Callable，返回一个future对象，future的get()方法会阻塞到任务完成并返回返回值

21. 关闭线程池

  RUNNING

  SHUTDOWN(shutdown) 继续处理等待队列

  STOP(shutdownNow)不在处理等待队列，中断正在执行的线程

22. CPU密集型任务应配置尽可能小的线程，如N_CPU+1;IO密集型任务线程并不是一直在执行任务，应配置尽可能多的线程，如2N_CPU.

23. Executor

  (1) FixedThreadPool
  (2) SingleThreadExecutor
  (3) CachedThreadExecutor
  (4) ScheduledTHreadExecutor

24. Future接口和实现Future接口的FUtureTask类用来表示异步计算的结果。

25. Runnable接口不会返回结果，而Callable接口可以返回结果。

26. CopyOnWriteArrayList：修改时，复制原有数据，将修改内容写入副本。写完后再去替换原来的数据。

27. java.util.comncurrent并发包

  并发容器 concurrentHashMap

  原子变量 AtomicInteger

  显式锁 lock

  同步工具 semaphore, countdownlatch, cyclicbarrier

	线程池

28. 可重入锁独有的功能

	- 指定公平锁还是非公平锁
	- Condition条件类，分组环形需要唤醒的线程
	- 中断等待锁

29. ThreadLocal内存泄漏

	key为弱引用，value为强引用，key被清理掉，value未被清理

30. 强引用：不会被清理

  弱引用：生存到下一次垃圾收集发生之前
	
	软引用：系统将要内存溢出异常前回收

	虚引用：唯一目的就是被回收前收到一个系统通知

31. CountDownLatch: countDown()，方法技术减1，一等多

  CyclicBarrier: await()计数减1，多个线程互相等待

32. 创建线程的方法

	- 继承Thread类
	- 实现Runnable接口，传进Thread
	- 实现Callable接口，传进Thread
	- 线程池

33. 线程同步的方法

  - synchronized
	- volatile
	- 重入锁
	- ThreadLocal
	- 阻塞队列
	- 原子变量

34. 重入：获取锁的操作粒度是线程而不是调用

35. AQS

  https://www.cnblogs.com/waterystone/p/4920797.html

## JVM

1. 双亲委派模型

  如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器完成。只有当父类加载器自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子类加载器才会尝试自己去加载。
  
2. 三种系统提供的类加载器

  - 启动类加载器
  - 扩展类加载器
  - 应用程序类加载器

3. 破坏双亲委派模型

  - ClassLoader.loadClass()方法
  - 线程上下文加载器
  - 用户对程序的动态性要求

4. 双亲委派模型的好处

  - 避免类的重复加载
  - Java的核心API不被篡改

5. 线程的实现

  - 内核线程，一对一线程模型
  - 用户线程，一对多线程模型

6. Amdahl定律：并行化来压榨计算机运算能力

7. 类加载的过程

 - 加载
 - 连接：验证、准备、解析
 - 初始化

8. volatile

  - 第一个语义：保证此变量对所有线程的可见性
  - volatile变量的运算再并发下一样时不安全的
  - 第二个语义：禁止指令重排序优化

9. happends-before先行发生

  happens-before是Java内存模型中定义的2项操作之间的偏序关系。如果说操作A先行发生于操作B，其实就是说发生操作B之前，操作A产生的影响能被B观察到。

  程序次序规则、volatile变量规则

10. JVM运行时数据区域

  线程私有的：程序计数器、虚拟机栈、本地方法栈
  
  线程共享的：堆、方法区

  JDK 8中用元数据去代替永久代实现方法区，并把字符串常量池和类静态变量迁移到堆中存放。

  为什么要用元数据区代替永久代？
  
  (1) 字符串存在永久代，容易出现性能问题
  
  (2) 类信息比较难确定大小，永久代空间分配困难

11. 垃圾回收GC

   - 根搜索算法：GC Roots向下搜索，判断是否可达
   
     GC Roots包括下面几种：
   
     1. 虚拟机栈中引用的对象
     2. 本地方法栈中引用的对象
     3. 方法区中的的常量变量引用的对象
     4. 方法区中的类静态变量引用的对象

   - 分代收集算法
   
     Eden: From Survivor: To Survivor = 8:1:1
     
     Eden区和From Survivor区中还存活的对象移动到To Survivor区，对象优先在Eden区分配，大对象直接进入老年代，长期存活的对象将进入老年代（15岁），老年代分配担保
   
   - Minor GC的触发条件：Eden区满
   
   - Full GC的触发条件
   
     1. 调用System.gc时建议执行Full GC
     2. 老年代空间不足
     3. 方法区空间不足
     4. 老年代担保空间不足
   
   - 新生代的收集器：Serial（串行）、ParNew（并行）、Parallel（高吞吐量），使用复制算法
   
   - 老年代的收集器有Serial Old、Parallel Old，使用标记-整理算法
   
   - CMS收集器基于标记-清楚算法，步骤分为初始标记、并发标记、重新标记、并发清除
   
   - G1收集器将Java堆划分为多个大小相等的独立区域（Region），相关引用记录在Region对应的Remembered Set中。从整体看基于标记-整理算法，从局部（2个Region之间）看基于复制算法。步骤分为初始标记、比并发标记、最终标记、筛选回收。

12. OOM、CPU占用过高排查

  - jsp：列出正在运行的虚拟机进程
  - jstat：统计信息，包括分区占用情况
  - **jmap：内存映像**
  - **jstack：堆栈跟踪**
  - VisualVM：生成浏览堆转储快照、分析CPU、内存性能
  - top ps

## Spring

## 操作系统

	1. 死锁：互斥、不剥夺、请求保持（一次申请完所需的全部资源）、循环等待（顺序资源分配法）

	2. 页式存储

		- 页号根据页表查到块号，与页内偏移量拼接，得到物理地址
		- 连续的逻辑地址->不连续的物理地址

	3. 缺页中断

		在请求分页系统中，每当所要访问的页面不在内存时，便产生一个缺页中断，请求操作系统将所缺页调入内存。
	
	4. 页面置换算法

		OPT, FIFO, LRU, CLOCK
