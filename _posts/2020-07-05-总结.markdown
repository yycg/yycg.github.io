---
layout:     post
title:      "总结"
subtitle:   ""
date:       2020-07-05 12:00:00
author:     "盈盈冲哥"
header-img: "img/fleabag.jpg"
mathjax: true
catalog: true
tags:
    - 学习
---

> [https://snailclimb.gitee.io/javaguide/#/?id=java]https://snailclimb.gitee.io/javaguide/#/?id=java

> [https://github.com/hanggegreat/CS-Tree](https://github.com/hanggegreat/CS-Tree)

> [https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#nginx](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#nginx)

## 分布式

1. 分层：应用层、服务层、数据层

2. 如何优化性能？

	- 缓存：CDN、反向代理、本地缓存、分布式缓存（一致性Hash算法）
	- 均衡负载：分布式（不同服务部署在不同）、集群（多台机器提供相同的服务）
	- 异步（消息队列削峰、线程池）
  - 数据库分库分表、读写分离

3. 分布式缓存的一致性Hash算法

  一致性Hash算法通过一致性Hash环实现key到缓存服务器的Hash映射。

  具体算法过程为：先构造一个长度为$2^32$的整数环（一致性Hash环），根据节点名称的Hash值将缓存服务器节点放置在这个Hash环上。然后根据需要缓存的数据的key值计算得到其Hash值，在Hash环上顺时针查找距离这个key的Hash值最近的缓存服务器节点。

  当缓存服务器集群需要扩容时，只需要将新加入的节点名称的Hash值放入一致性Hash环中，由于key时顺时针查找其最近的节点，因此新加入的节点只影响整个环中的一小段。

3. session管理

  - session复制：在集群中的几台服务器之间同步session对象，使得每台服务器上都保存所有用户的session信息。
  
  - session绑定：负载均衡服务器总是将来源于同一IP的请求分发到同一台服务器上。
  
  - 利用cookie记录session
  
  - session服务器

4. 指标：吞吐量（TPS、QPS、HPS）、响应时间、并发数

5. 安全

	- XSS攻击（跨站点脚本攻击）：注入恶意HTML脚本
	- SQL注入攻击：攻击者在HTTP请求中注入恶意SQL命令
	- CSRF攻击（跨站点请求伪造）：攻击者通过跨站请求，以合法的用户身份伪造请求进行非法操作

6. 加密

	- 单项散列加密：MD5, SHA1

    虽然不能通过算法将单向散列密文反算得到密文，但是由于人们设置密码具有一定的模式，因此通过彩虹表（人们常用密码和对应的密文关系表）等手段可以进行猜测式破解。

    为了加强单项散列计算的安全性，还会给散列算法加点盐，盐相当于加密的密钥，增加破解难度。

	- 对称加密：DES、RC

    对称加密是指加密和解密使用的密钥是同一个密钥（或者可以互相推算）。

	- 非对称加密：RSA

    不同于对称加密，非对称加密和解密使用的密钥不是同一密钥，其中一个对外界公开，被称作公钥，另一个只有所有者知道，被称为私钥。用公钥加密的信息必须用私钥才能解开，反之，用私钥加密的信息只有用公钥才能解开。

7. 高可用设计：服务降级、服务限流、超时设置、缓存、异步、幂等性设计

8. 幂等

  > https://www.jianshu.com/p/cea3675a590b
  > https://www.cnblogs.com/wxgblogs/p/6639272.html
  
  - 概念：一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。

  - 我们常用的HTTP协议的方法是具有幂等性语义要求的，比如：get方法用于获取资源，不应有副作用，因此是幂等的；post方法用于创建资源，每次请求都会产生新的资源，因此不具备幂等性；put方法用于更新资源，是幂等的；delete方法用于删除资源，也是幂等的。

  - 幂等的应用场景

    1）微服务场景，除了成功、失败两种状态，还会有第三个情况【未知】，也就是超时。如果超时了，微服务框架一般会进行重试。

    2）用户交互的时候多次点击。如：快速点击按钮多次。

    3）MQ消息中间件，消息重复消费。

    4）第三方平台的接口（如：支付成功回调接口），因为异常也会导致多次异步回调。

    5）其他应用服务根据自身的特性，也有可能进行重试。

  - 保证幂等的手段

    唯一的业务单号[悲观锁、乐观锁、唯一索引、Redis缓存]、token

    - 唯一业务单号

      最简单的，需要通过唯一的业务单号来保证幂等。也就是说相同的业务单号，认为是同一笔业务。使用这个唯一的业务单号来确保，后面多次的相同的业务单号的处理逻辑和执行效果是一致的。

    - 对变更行为加锁

      上述的保证幂等方案是分成两步的，第②步依赖第①步的查询结果，无法保证原子性的。在高并发下就会出现下面的情况：第二次请求在第一次请求第②步订单状态还没有修改为‘已支付状态’的情况下到来。既然得出了这个结论，余下的问题也就变得简单：把查询和变更状态操作加锁，将并行操作改为串行操作。

    - 唯一索引

      但是，在某些场景，你可能又想提供无锁的高并发幂等，那么你可以选择为业务单号加上唯一的索引或者组合索引，在并发的场景中，只有第一笔插入的交易请求能够成功，后续的请求哪怕是慢1ms或者更短时间，都会触发数据库的唯一索引异常而失败，那么你可以捕获这个异常。

    - 数据库操作时使用插入或更新（select + insert）

      如果已经存在就更新，不存在时才插入

    - 多版本控制

      这种方法适合在更新的场景中，比如我们要更新商品的名字，这时我们就可以在更新的接口中增加一个版本号，来做幂等

    - 防重-Redis缓存

      又或者你想把幂等放在服务的最前端，减少实际服务处理的资源浪费，在请求一到达时就提前去重，不让他有执行的机会，那么你可以考虑引入一个redis或类似的组件，将业务请求单号缓存在这个分布式锁的组件内。那么，每当订单发起交易请求，交易系统会去Redis缓存中查询是否存在该订单号的Key，如果不存在，则向Redis增加Key为订单号。查询订单是否已经执行，如果没有则转发到交易系统，执行完成后删除该订单号的Key。当然，Redis是提供分布式节点下的原子事务操作的。

    - 状态机

      通常是根据业务流程构建一个状态机，保证业务中每个流程只会在对应的状态下执行。如果一个业务操作步骤完成就进入下一个状态，这时候来了上一个状态的操作就不允许变更状态，保证了业务的幂等性。

    - token机制

      通常是每次操作都生成一个唯一 token 凭证，服务器通过这个唯一凭证保证同样的操作不会被执行两次，服务器在去重实现上可以采用独立kv数据库，去重表等多种实现。Token 机制应该是适用范围最广泛的一种幂等设计方案。比如AWS的API就是采用这一机制，调用方生成client token，要求token全局唯一，AWS根据client token做幂等操作。

8. 微服务

	> [大白话入门 Spring Cloud](https://snailclimb.gitee.io/javaguide/#/docs/system-design/micro-service/spring-cloud?id=%e5%bc%95%e5%87%ba-spring-cloud-bus)
  
  Spring Cloud抽象了一套通用的开发模式，依赖于**RPC、网关、服务发现、配置管理、限流熔断、分布式链路跟踪**的具体实现。

  - Eureka 服务发现框架

    服务发现：其实就是一个“中介”，整个过程中有三个角色：服务提供者(出租房子的)、服务消费者(租客)、服务中介(房屋中介)。

    服务提供者： 就是提供一些自己能够执行的一些服务给外界。

    服务消费者： 就是需要使用一些服务的“用户”。

    服务中介： 其实就是服务提供者和服务消费者之间的“桥梁”，服务提供者可以把自己注册到服务中介那里，而服务消费者如需要消费一些服务(使用一些功能)就可以在服务中介中寻找注册在服务中介的服务提供者。

    服务注册 Register：

    官方解释：当 Eureka 客户端向 Eureka Server 注册时，它提供自身的元数据，比如IP地址、端口，运行状况指示符URL，主页等。

    结合中介理解：房东 (提供者 Eureka Client Provider)在中介 (服务器 Eureka Server) 那里登记房屋的信息，比如面积，价格，地段等等(元数据 metaData)。

    服务续约 Renew：

    官方解释：Eureka 客户会每隔30秒(默认情况下)发送一次心跳来续约。 通过续约来告知 Eureka Server 该 Eureka 客户仍然存在，没有出现问题。 正常情况下，如果 Eureka Server 在90秒没有收到 Eureka 客户的续约，它会将实例从其注册表中删除。

    结合中介理解：房东 (提供者 Eureka Client Provider) 定期告诉中介 (服务器 Eureka Server) 我的房子还租(续约) ，中介 (服务器Eureka Server) 收到之后继续保留房屋的信息。

    获取注册列表信息 Fetch Registries：

    官方解释：Eureka 客户端从服务器获取注册表信息，并将其缓存在本地。客户端会使用该信息查找其他服务，从而进行远程调用。该注册列表信息定期（每30秒钟）更新一次。每次返回注册列表信息可能与 Eureka 客户端的缓存信息不同, Eureka 客户端自动处理。如果由于某种原因导致注册列表信息不能及时匹配，Eureka 客户端则会重新获取整个注册表信息。 Eureka 服务器缓存注册列表信息，整个注册表以及每个应用程序的信息进行了压缩，压缩内容和没有压缩的内容完全相同。Eureka 客户端和 Eureka 服务器可以使用JSON / XML格式进行通讯。在默认的情况下 Eureka 客户端使用压缩 JSON 格式来获取注册列表的信息。

    结合中介理解：租客(消费者 Eureka Client Consumer) 去中介 (服务器 Eureka Server) 那里获取所有的房屋信息列表 (客户端列表 Eureka Client List) ，而且租客为了获取最新的信息会定期向中介 (服务器 Eureka Server) 那里获取并更新本地列表。

    服务下线 Cancel：

    官方解释：Eureka客户端在程序关闭时向Eureka服务器发送取消请求。 发送请求后，该客户端实例信息将从服务器的实例注册表中删除。该下线请求不会自动完成，它需要调用以下内容：DiscoveryManager.getInstance().shutdownComponent();

    结合中介理解：房东 (提供者 Eureka Client Provider) 告诉中介 (服务器 Eureka Server) 我的房子不租了，中介之后就将注册的房屋信息从列表中剔除。

    服务剔除 Eviction：

    官方解释：在默认的情况下，当Eureka客户端连续90秒(3个续约周期)没有向Eureka服务器发送服务续约，即心跳，Eureka服务器会将该服务实例从服务注册列表删除，即服务剔除。

    结合中介理解：房东(提供者 Eureka Client Provider) 会定期联系 中介 (服务器 Eureka Server) 告诉他我的房子还租(续约)，如果中介 (服务器 Eureka Server) 长时间没收到提供者的信息，那么中介会将他的房屋信息给下架(服务剔除)。

  - Ribbon 进程内负载均衡器

    Ribbon 是运行在消费者端的负载均衡器，其工作原理就是 Consumer 端获取到了所有的服务列表之后，在其内部使用负载均衡算法，进行对多个系统的调用。

    Nginx 和 Ribbon 的对比

    和 Ribbon 不同的是，Nignx是一种集中式的负载均衡器。

    何为集中式呢？简单理解就是 将所有请求都集中起来，然后再进行负载均衡。

    在 Nginx 中请求是先进入负载均衡器，而在 Ribbon 中是先在客户端进行负载均衡才进行请求的。

    Ribbon 的几种负载均衡算法

    负载均衡，不管 Nginx 还是 Ribbon 都需要其算法的支持，如果我没记错的话 Nginx 使用的是 轮询和加权轮询算法。而在 Ribbon 中有更多的负载均衡调度算法，其默认是使用的 RoundRobinRule 轮询策略。

    - RoundRobinRule：轮询策略。Ribbon 默认采用的策略。若经过一轮轮询没有找到可用的 provider，其最多轮询 10 轮。若最终还没有找到，则返回 null。
    - RandomRule: 随机策略，从所有可用的 provider 中随机选择一个。
    - RetryRule: 重试策略。先按照 RoundRobinRule 策略获取 provider，若获取失败，则在指定的时限内重试。默认的时限为 500 毫秒。

  - Open Feign 服务调用映射

  - Hystrix 服务降级熔断器

    所谓 熔断 就是服务雪崩的一种有效解决方案。当指定时间窗内的请求失败率达到设定阈值时，系统将通过 断路器 直接将此请求链路断开。

    也就是我们上面服务B调用服务C在指定时间窗内，调用的失败率到达了一定的值，那么 Hystrix 则会自动将 服务B与C 之间的请求都断了，以免导致服务雪崩现象。

    降级是为了更好的用户体验，当一个方法调用异常时，通过执行另一种代码逻辑来给用户友好的回复。

  - Zuul 微服务网关

    在上面我们学习了 Eureka 之后我们知道了 服务提供者 是 消费者 通过 Eureka Server 进行访问的，即 Eureka Server 是 服务提供者 的统一入口。那么整个应用中存在那么多 消费者 需要用户进行调用，这个时候用户该怎样访问这些 消费者工程 呢？当然可以像之前那样直接访问这些工程。但这种方式没有统一的消费者工程调用入口，不便于访问与管理，而 Zuul 就是这样的一个对于 消费者 的统一入口。

    网关是系统唯一对外的入口，介于客户端与服务器端之间，用于对请求进行鉴权、限流、 路由、监控等功能。网关有的功能，Zuul 基本都有。而 Zuul 中最关键的就是 路由和过滤器 了。

    Zuul 的**路由**功能

    Consumer 向 Eureka Server 进行注册，网关只要注册就能拿到所有 Consumer 的信息，拿到信息就可以获取所有的 Consumer 的元数据(名称，ip，端口)，拿到这些元数据就可以直接可以做路由映射。包括统一前缀、路由策略配置、服务名屏蔽、路径屏蔽、敏感请求头屏蔽。

    Zuul 的**过滤**功能

    如果说，路由功能是 Zuul 的基操的话，那么过滤器就是 Zuul的利器了。毕竟所有请求都经过网关(Zuul)，那么我们可以进行各种过滤，这样我们就能实现 限流，灰度发布，权限控制 等等。

    过滤器类型：Pre、Routing、Post。前置Pre就是在请求之前进行过滤，Routing路由过滤器就是我们上面所讲的路由策略，而Post后置过滤器就是在 Response 之前进行过滤的过滤器。

    令牌桶限流

    首先我们会有个桶，如果里面没有满那么就会以一定 固定的速率 会往里面放令牌，一个请求过来首先要从桶中获取令牌，如果没有获取到，那么这个请求就拒绝，如果获取到那么就放行。

    Zuul 的过滤器还可以实现 **权限校验**，包括上面提到的 **灰度发布** 等等。

  - Config 微服务统一配置中心

    当我们的微服务系统开始慢慢地庞大起来，那么多 Consumer 、Provider 、Eureka Server 、Zuul 系统都会持有自己的配置，这个时候我们在项目运行的时候可能需要更改某些应用的配置，如果我们不进行配置的统一管理，我们只能去每个应用下一个一个寻找配置文件然后修改配置文件再重启应用。

    首先对于分布式系统而言我们就不应该去每个应用下去分别修改配置文件，再者对于重启应用来说，服务无法访问所以直接抛弃了可用性，这是我们更不愿见到的。

    那么有没有一种方法既能对配置文件统一地进行管理，又能在项目运行时动态修改配置文件呢？

    Spring Cloud Config 就是能将各个 应用/系统/模块 的配置文件存放到 统一的地方然后进行管理(Git 或者 SVN)。

    Spring Cloud Config 就暴露出一个接口给启动应用来获取它所想要的配置文件，应用获取到配置文件然后再进行它的初始化工作。

    一般我们会使用 Bus 消息总线 + Spring Cloud Config 进行配置的动态刷新。

  - Bus 消息总线

    Spring Cloud Bus 的作用就是管理和广播分布式系统中的消息，也就是消息引擎系统中的广播模式。

9. 分布式id

  > [分布式id生成方案总结](https://snailclimb.gitee.io/javaguide/#/docs/system-design/micro-service/%E5%88%86%E5%B8%83%E5%BC%8Fid%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93)

  - UUID：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。
  - 数据库自增 id：业务系统每次需要一个ID时，都需要请求数据库获取，性能低，并且如果此数据库实例下线了，那么将影响所有的业务系统。
  - 数据库多主模式：两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。问题是无法新增实例。
  - 利用redis生成id
  - 号端模式

    ```sql
    CREATE TABLE id_generator (
      id int(10) NOT NULL,
      current_max_id bigint(20) NOT NULL COMMENT '当前最大id',
      increment_step int(10) NOT NULL COMMENT '号段的长度',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;
    ```

    ```sql
    update id_generator set current_max_id=#{newMaxId}, version=version+1 where version = #{version}
    ```

  - twitter snowflake雪花算法：时间戳、工作机器id、序列号
  - 美团Leaf

9. 限流

  > [限流的算法有哪些？](https://snailclimb.gitee.io/javaguide/#/docs/system-design/micro-service/limit-request)

  - 固定窗口计数器算法：规定我们单位时间处理的请求数量。
  - 滑动窗口计数器算法：例如我们的接口限流每分钟处理60个请求，我们可以把 1 分钟分为60个窗口。每隔1秒移动一次， 如果当前窗口的请求计数总和超过了限制的数量的话就不再处理其他请求。
  - 漏桶算法：往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。
  - 令牌桶算法：首先我们会有个桶，如果里面没有满那么就会以一定 固定的速率 会往里面放令牌，一个请求过来首先要从桶中获取令牌，如果没有获取到，那么这个请求就拒绝，如果获取到那么就放行。

9. Zookeeper

  > [Zookeeper](https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/ZooKeeper)

  > [Zookeeper plus](https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/ZooKeeper-plus)

  > [Zab：Zookeeper 中的分布式一致性协议介绍](https://www.jianshu.com/p/fb527a64deee)

  - CAP原理

    - 数据一致性：数据强一致、数据用户一致、数据最终一致
    - 数据可用性
    - 分区耐受性（系统具有跨网络分区的伸缩性）

  - BASE理论

    - 基本可用
    - 软状态
    - 最终一致性

  - 2PC

    阶段一：提交事务请求（投票）

    当要执行一个分布式事务的时候，事务发起者首先向协调者发起事务请求，然后协调者会给所有参与者发送 prepare 请求（其中包括事务内容）告诉参与者你们需要执行事务了，如果能执行我发的事务内容那么就先执行但不提交，执行后请给我回复。然后参与者收到 prepare 消息后，他们会开始执行事务（但不提交），并将 Undo 和 Redo 信息记入事务日志中，之后参与者就向协调者反馈是否准备好了。

    阶段二：执行事务提交（执行）

    第二阶段主要是协调者根据参与者反馈的情况来决定接下来是否可以进行事务的提交操作，即提交事务或者回滚事务。

    比如这个时候 所有的参与者 都返回了准备好了的消息，这个时候就进行事务的提交，协调者此时会给所有的参与者发送 Commit 请求 ，当参与者收到 Commit 请求的时候会执行前面执行的事务的 提交操作 ，提交完毕之后将给协调者发送提交成功的响应。

    而如果在第一阶段并不是所有参与者都返回了准备好了的消息，那么此时协调者将会给所有参与者发送 回滚事务的 rollback 请求，参与者收到之后将会 回滚它在第一阶段所做的事务处理 ，然后再将处理情况返回给协调者，最终协调者收到响应后便给事务发起者返回处理失败的结果。

    问题

    - 单点故障问题，如果协调者挂了那么整个系统都处于不可用的状态了。
    - 阻塞问题，即当协调者发送 prepare 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着资源不释放，如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能。
    - 数据不一致问题，比如当第二阶段，协调者只发送了一部分的 commit 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题。

  - 3PC

    三阶段提交是两阶段提交的改进版，将两阶段提交协议的提交事务请求（投票）过程一分为二，形成由CanCommit、PreCommit和doCommit三个阶段组成的事务处理协议。

    阶段一：CanCommit

    协调者向所有参与者发送 CanCommit 请求，参与者收到请求后会根据自身情况查看是否能执行事务，如果可以则返回 YES 响应并进入预备状态，否则返回 NO 。

    阶段二：PreCommit

    协调者根据参与者返回的响应来决定是否可以进行下面的 PreCommit 操作。如果上面参与者返回的都是 YES，那么协调者将向所有参与者发送 PreCommit 预提交请求，参与者收到预提交请求后，会进行事务的执行操作，并将 Undo 和 Redo 信息写入事务日志中 ，最后如果参与者顺利执行了事务则给协调者返回成功的响应。如果在第一阶段协调者收到了 任何一个 NO 的信息，或者 在一定时间内 并没有收到全部的参与者的响应，那么就会中断事务，它会向所有参与者发送中断请求（abort），参与者收到中断请求之后会立即中断事务，或者在一定时间内没有收到协调者的请求，它也会中断事务。

    阶段三：doCommit

    这个阶段其实和 2PC 的第二阶段差不多，如果协调者收到了所有参与者在 PreCommit 阶段的 YES 响应，那么协调者将会给所有参与者发送 DoCommit 请求，参与者收到 DoCommit 请求后则会进行事务的提交工作，完成后则会给协调者返回响应，协调者收到所有参与者返回的事务提交成功的响应之后则完成事务。若协调者在 PreCommit 阶段 收到了任何一个 NO 或者在一定时间内没有收到所有参与者的响应 ，那么就会进行中断请求的发送，参与者收到中断请求后则会 通过上面记录的回滚日志 来进行事务的回滚操作，并向协调者反馈回滚状况，协调者收到参与者返回的消息后，中断事务。

    问题
    
    3PC 通过一系列的超时机制很好的缓解了阻塞问题，但是最重要的一致性并没有得到根本的解决，比如在 PreCommit 阶段，当一个参与者收到了请求之后其他参与者和协调者挂了或者出现了网络分区，这个时候收到消息的参与者都会进行事务提交，这就会出现数据不一致性问题。

  - Paxos算法：解决分布式一致性的算法

    - prepare阶段：提案者将具有全局唯一性的递增的编号N发送给表决者。表决者同意大于本地编号maxN（批准过的最大提案编号）的提案。
    - accept阶段：提案者收到半数以上表决者的批准，就会发送提案和编号。表决者再次比较，同意大于等于批准过的最大提案编号的提案。提案者收到半数以上同意，向所有表决者发送提案提交编号。

  - ZAB协议

    ZAB 中的三个角色

    Leader 领导者：集群中 唯一的写请求处理者 ，能够发起投票（投票也是为了进行写请求）。

    Follower 跟随者：能够接收客户端的请求，如果是读请求则可以自己处理，如果是写请求则要转发给 Leader 。在选举过程中会参与投票，有选举权和被选举权 。

    Observer 观察者：就是没有选举权和被选举权的 Follower 。

    协议内容
    
    消息广播模式：Zab 协议中，所有的写请求都由 leader 来处理。正常工作状态下，leader 接收请求并通过广播协议来处理。

    1. Leader 接收到消息请求后，将消息赋予一个全局唯一的 64 位自增 id，叫做：zxid，通过 zxid 的大小比较即可实现因果有序这一特性。
    2. Leader 通过先进先出队列（通过 TCP 协议来实现，以此实现了全局有序这一特性）将带有 zxid 的消息作为一个提案（proposal）分发给所有 follower。
    3. 当 follower 接收到 proposal，先将 proposal 写到硬盘，写硬盘成功后再向 leader 回一个 ACK。
    4. 当 leader 接收到合法数量的 ACKs 后，leader 就向所有 follower 发送 COMMIT 命令，同时会在本地执行该消息。
    5. 当 follower 收到消息的 COMMIT 命令时，就会执行该消息

    崩溃恢复模式：当服务初次启动，或者 leader 节点挂了，系统就会进入恢复模式，直到选出了有合法数量 follower 的新 leader，然后新 leader 负责将整个系统同步到最新状态。

    由于之前讲的 Zab 协议的广播部分不能处理 leader 挂掉的情况，Zab 协议引入了恢复模式来处理这一问题。为了使 leader 挂了后系统能正常工作，需要解决以下两个问题：

    - 已经被处理的消息不能丢

      这一情况会出现在以下场景：当 leader 收到合法数量 follower 的 ACKs 后，就向各个 follower 广播 COMMIT 命令，同时也会在本地执行 COMMIT 并向连接的客户端返回「成功」。但是如果在各个 follower 在收到 COMMIT 命令前 leader 就挂了，导致剩下的服务器并没有执行都这条消息。

      消息 1 的 COMMIT 命令 Server1（leader）和 Server2（follower） 上执行了，但是 Server3 还没有收到消息 1 的 COMMIT 命令，此时 leader Server1 已经挂了，客户端很可能已经收到消息 1 已经成功执行的回复，经过恢复模式后需要保证所有机器都执行了消息 1。

      为了实现已经被处理的消息不能丢这个目的，Zab 的恢复模式使用了以下的策略：

      1. 选举拥有 proposal 最大值（即 zxid 最大） 的节点作为新的 leader：由于所有提案被 COMMIT 之前必须有合法数量的 follower ACK，即必须有合法数量的服务器的事务日志上有该提案的 proposal，因此，只要有合法数量的节点正常工作，就必然有一个节点保存了所有被 COMMIT 消息的 proposal 状态。
      2. 新的 leader 将自己事务日志中 proposal 但未 COMMIT 的消息处理。
      3. 新的 leader 与 follower 建立先进先出的队列， 先将自身有而 follower 没有的 proposal 发送给 follower，再将这些 proposal 的 COMMIT 命令发送给 follower，以保证所有的 follower 都保存了所有的 proposal、所有的 follower 都处理了所有的消息。

    - 被丢弃的消息不能再次出现

      这一情况会出现在以下场景：当 leader 接收到消息请求生成 proposal 后就挂了，其他 follower 并没有收到此 proposal，因此经过恢复模式重新选了 leader 后，这条消息是被跳过的。 此时，之前挂了的 leader 重新启动并注册成了 follower，他保留了被跳过消息的 proposal 状态，与整个系统的状态是不一致的，需要将其删除。

      在 Server1 挂了后系统进入新的正常工作状态后，消息 3被跳过，此时 Server1 中的 P3 需要被清除。

      Zab 通过巧妙的设计 zxid 来实现这一目的。一个 zxid 是64位，高 32 是纪元（epoch）编号，每经过一次 leader 选举产生一个新的 leader，新 leader 会将 epoch 号 +1。低 32 位是消息计数器，每接收到一条消息这个值 +1，新 leader 选举后这个值重置为 0。这样设计的好处是旧的 leader 挂了后重启，它不会被选举为 leader，因为此时它的 zxid 肯定小于当前的新 leader。当旧的 leader 作为 follower 接入新的 leader 后，新的 leader 会让它将所有的拥有旧的 epoch 号的未被 COMMIT 的 proposal 清除。
  
  - Zookeeper
    
    ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。

    Zookeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心(提供发布订阅服务)。 服务生产者将自己提供的服务注册到Zookeeper中心，服务的消费者在进行服务调用的时候先到Zookeeper中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者的内容与数据。在 Dubbo架构中 Zookeeper 就担任了注册中心这一角色。

    为什么最好使用奇数台服务器构成 ZooKeeper 集群？

    所谓的zookeeper容错是指，当宕掉几个zookeeper服务器之后，剩下的个数必须大于宕掉的个数的话整个zookeeper才依然可用。假如我们的集群中有n台zookeeper服务器，那么也就是剩下的服务数必须大于n/2。先说一下结论，2n和2n-1的容忍度是一样的，都是n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。 比如假如我们有3台，那么最大允许宕掉1台zookeeper服务器，如果我们有4台的的时候也同样只允许宕掉1台。 假如我们有5台，那么最大允许宕掉2台zookeeper服务器，如果我们有6台的的时候也同样只允许宕掉2台。

    概念
    
    - 会话（Session）

      Session 指的是 ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session的sessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。

      在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。

    - Znode

      在谈到分布式的时候，我们通常说的“节点"是指组成集群的每一台机器。然而，在Zookeeper中，“节点"分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。

      Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。

      在Zookeeper中，node可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。 另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL.一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。

    - 版本

      在前面我们已经提到，Zookeeper 的每个 ZNode 上都会存储数据，对应于每个ZNode，Zookeeper 都会为其维护一个叫作 Stat 的数据结构，Stat 中记录了这个 ZNode 的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）

    - Watcher

      Watcher（事件监听器），是Zookeeper中的一个很重要的特性。Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。

    - ACL

      Zookeeper采用ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了5种权限。

    ZooKeeper 设计目标

    - 简单的数据模型：ZooKeeper 允许分布式进程通过共享的层次结构命名空间进行相互协调，这与标准文件系统类似。 名称空间由 ZooKeeper 中的数据寄存器组成 - 称为znode，这些类似于文件和目录。 与为存储设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量和低延迟。
    - 可构建集群：为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的。
    - 顺序访问：对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。 这个编号也叫做时间戳——zxid（Zookeeper Transaction Id）
    - 高性能：ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。
    
    Zookeeper 应用场景
    
    - 选主
    
      还记得上面我们的所说的临时节点吗？因为 Zookeeper 的强一致性，能够很好地在保证 在高并发的情况下保证节点创建的全局唯一性 (即无法重复创建同样的节点)。

      利用这个特性，我们可以 让多个客户端创建一个指定的节点 ，创建成功的就是 master。

      但是，如果这个 master 挂了怎么办？？？

      你想想为什么我们要创建临时节点？还记得临时节点的生命周期吗？master 挂了是不是代表会话断了？会话断了是不是意味着这个节点没了？还记得 watcher 吗？我们是不是可以 让其他不是 master 的节点监听节点的状态 ，比如说我们监听这个临时节点的父节点，如果子节点个数变了就代表 master 挂了，这个时候我们 触发回调函数进行重新选举 ，或者我们直接监听节点的状态，我们可以通过节点是否已经失去连接来判断 master 是否挂了等等。
	
      总的来说，我们可以完全 利用 临时节点、节点状态 和 watcher 来实现选主的功能，临时节点主要用来选举，节点状态和watcher 可以用来判断 master 的活性和进行重新选举。
	
    - 分布式锁
    
      分布式锁的实现方式有很多种，比如 Redis 、数据库 、zookeeper 等。个人认为 zookeeper 在实现分布式锁这方面是非常非常简单的。

      上面我们已经提到过了 zk在高并发的情况下保证节点创建的全局唯一性，这玩意一看就知道能干啥了。实现互斥锁呗，又因为能在分布式的情况下，所以能实现分布式锁呗。

      如何实现呢？这玩意其实跟选主基本一样，我们也可以利用临时节点的创建来实现。

      首先肯定是如何获取锁，因为创建节点的唯一性，我们可以让多个客户端同时创建一个临时节点，创建成功的就说明获取到了锁 。然后没有获取到锁的客户端也像上面选主的非主节点创建一个 watcher 进行节点状态的监听，如果这个互斥锁被释放了（可能获取锁的客户端宕机了，或者那个客户端主动释放了锁）可以调用回调函数重新获得锁。

      zk 中不需要向 redis 那样考虑锁得不到释放的问题了，因为当客户端挂了，节点也挂了，锁也释放了。
      
      那能不能使用 zookeeper 同时实现 共享锁和独占锁 呢？答案是可以的，不过稍微有点复杂而已。

      还记得 有序的节点 吗？

      这个时候我规定所有创建节点必须有序，当你是读请求（要获取共享锁）的话，如果 没有比自己更小的节点，或比自己小的节点都是读请求 ，则可以获取到读锁，然后就可以开始读了。若比自己小的节点中有写请求 ，则当前客户端无法获取到读锁，只能等待前面的写请求完成。

      如果你是写请求（获取独占锁），若 没有比自己更小的节点 ，则表示当前客户端可以直接获取到写锁，对数据进行修改。若发现 有比自己更小的节点，无论是读操作还是写操作，当前客户端都无法获取到写锁 ，等待所有前面的操作完成。

      这就很好地同时实现了共享锁和独占锁，当然还有优化的地方，比如当一个锁得到释放它会通知所有等待的客户端从而造成 羊群效应 。此时你可以通过让等待的节点只监听他们前面的节点。

      具体怎么做呢？其实也很简单，你可以让 读请求监听比自己小的最后一个写请求节点，写请求只监听比自己小的最后一个节点。
    
    - 命名服务
    
      如何给一个对象设置ID，大家可能都会想到 UUID，但是 UUID 最大的问题就在于它太长了。。。(太长不一定是好事，嘿嘿嘿)。那么在条件允许的情况下，我们能不能使用 zookeeper 来实现呢？

      我们之前提到过 zookeeper 是通过 树形结构 来存储数据节点的，那也就是说，对于每个节点的 全路径，它必定是唯一的，我们可以使用节点的全路径作为命名方式了。而且更重要的是，路径是我们可以自己定义的，这对于我们对有些有语意的对象的ID设置可以更加便于理解。
    
    - 集群管理和注册中心
    
      可能我们会有这样的需求，我们需要了解整个集群中有多少机器在工作，我们想对集群的每台机器的运行时状态进行数据采集，对集群中机器进行上下线操作等等。

      而 zookeeper 天然支持的 watcher 和 临时节点能很好的实现这些需求。我们可以为每条机器创建临时节点，并监控其父节点，如果子节点列表有变动（我们可能创建删除了临时节点），那么我们可以使用在其父节点绑定的 watcher 进行状态监控和回调。
      
      至于注册中心也很简单，我们同样也是让 服务提供者 在 zookeeper 中创建一个临时节点并且将自己的 ip、port、调用方式 写入节点，当 服务消费者 需要进行调用的时候会 通过注册中心找到相应的服务的地址列表(IP端口什么的) ，并缓存到本地(方便以后调用)，当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从地址列表中取一个服务提供者的服务器调用服务。

      当服务提供者的某台服务器宕机或下线时，相应的地址会从服务提供者地址列表中移除。同时，注册中心会将新的服务地址列表发送给服务消费者的机器并缓存在消费者本机（当然你可以让消费者进行节点监听，我记得 Eureka 会先试错，然后再更新）。

10. 分布式锁

  > [分布式锁](https://blog.csdn.net/wuzhiwei549/article/details/80692278)

  - 基于MySQL实现：对method_name字段做唯一性约束
  - 基于Redis实现
  - 基于zk实现

    Znode分为四种类型：

    1.持久节点 （PERSISTENT）

    默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在 。

    2.持久节点顺序节点（PERSISTENT_SEQUENTIAL）

    所谓顺序节点，就是在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号。

    3.临时节点（EPHEMERAL）

    和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。

    4.临时顺序节点（EPHEMERAL_SEQUENTIAL）

    顾名思义，临时顺序节点结合和临时节点和顺序节点的特点：在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号；当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。

    Zookeeper分布式锁的原理

    获取锁

    首先，在Zookeeper当中创建一个持久节点ParentLock。当第一个客户端想要获得锁时，需要在ParentLock这个节点下面创建一个临时顺序节点 Lock1。

    之后，Client1查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock1是不是顺序最靠前的一个。如果是第一个节点，则成功获得锁。

    这时候，如果再有一个客户端 Client2 前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock2。

    Client2查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock2是不是顺序最靠前的一个，结果发现节点Lock2并不是最小的。

    于是，Client2向排序仅比它靠前的节点Lock1注册Watcher，用于监听Lock1节点是否存在。这意味着Client2抢锁失败，进入了等待状态。

    释放锁

    释放锁分为两种情况：

    1.任务完成，客户端显示释放

    当任务完成时，Client1会显示调用删除节点Lock1的指令。

    2.任务执行过程中，客户端崩溃

    获得锁的Client1在任务执行过程中，如果Duang的一声崩溃，则会断开与Zookeeper服务端的链接。根据临时节点的特性，相关联的节点Lock1会随之自动删除。

    由于Client2一直监听着Lock1的存在状态，当Lock1节点被删除，Client2会立刻收到通知。这时候Client2会再次查询ParentLock下面的所有节点，确认自己创建的节点Lock2是不是目前最小的节点。如果是最小，则Client2顺理成章获得了锁。

10. Kafka

  > [Kafka面试题总结](https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/kafka-inverview)

  > [Kafka入门](https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/Kafka%E5%85%A5%E9%97%A8%E7%9C%8B%E8%BF%99%E4%B8%80%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86)

  > [kafka是如何保证消息不被重复消费的](https://www.cnblogs.com/756623607-zhang/p/10506909.html)
  
  - 流程

    1: 第一步心跳请求，客户端启动以后，主动链接castle，请求需要往哪个集群上生产和消费

    2: 第二步心跳响应，castle返回客户端，“你往192.168.1.1” 这个broker上生产消息或拉取消息。

    3: 第三步，客户端链接Broker，生产消息到broker上，或从broker上拉取消息消费。

    4: 以后第一步和第二步会一直重复，这就是所谓的“Mafka心跳”，客户端会始终和Castle保持一个“请求/响应”循环，目的是为了接收服务端的调度和控制指令。

  - 名词

    Broker: 存储实际消息的地方，一台服务器，多个服务器(broker)组成一个集群。

    Castle: 中控调度，调度客户端从哪个机器上拉取消息，或把消息生产到哪台机器上去。

    ClientSDK: 业务使用的api，来生产或消费消息。

    Topic: 主题、队列

    生产者、上游

    消费者、下游，多台相同的消费者组成消费组

    Partition、主题分区、消息分片、分片：设想你发给Mafka 一万条消息，Mafka保存的时候，把它切成了4块，每块2500条消息，分别放到了四个不同的机器上。

    消息副本、replica、消息复制

    Topic的Ack属性：3个副本（一个主本，两个副本），如果Ack设为-1表示3个副本都接受到消息才算成功，如果是1表示主本收到消息就算成功，存在消息丢失风险（主本刚接收到消息返回给发送端成功，同步线程还未将消息复制给副本，此时主本机器宕机了，副本机器转换为主本，消息丢失）。同步线程会保证消息主本和副本复制时延在1秒内，所以Ack设置为1的极端情况下最大可能会丢失1秒内的消息。

    死信：某条消息无法消费成功，一直卡在这条消息处，无法消费后面的消息。解决方法：在topic管理页面里打开死信，处理消息如果失败会扔进死信队列，先消费后面的消息，过一段时间再消费。
  
  - Kafka 的消息模型知道吗？

    发布-订阅模型:Kafka 消息模型

    发布订阅模型（Pub-Sub） 使用主题（Topic） 作为消息通信载体，类似于广播模式；发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。

  - Kafka 的多副本机制了解吗？带来了什么好处？

    还有一点我觉得比较重要的是 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

    生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。

    Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？

    Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。

    Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。
  
  - Zookeeper 在 Kafka 中的作用知道吗？

    ZooKeeper 主要为 Kafka 提供元数据的管理的功能。

    从图中我们可以看出，Zookeeper 主要为 Kafka 做了下面这些事情：

    1. Broker 注册 ：在 Zookeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去
    2. Topic 注册 ： 在 Kafka 中，同一个Topic 的消息会被分成多个分区并将其分布在多个 Broker 上，这些分区信息及与 Broker 的对应关系也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：/brokers/topics/my-topic/Partitions/0、/brokers/topics/my-topic/Partitions/1
    3. 负载均衡 ：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。
    4. ......
  
  - Kafka 如何保证消息的消费顺序？

    我们在使用消息队列的过程中经常有业务场景需要严格保证消息的消费顺序，比如我们同时发了 2 个消息，这 2 个消息对应的操作分别对应的数据库操作是：更改用户会员等级、根据会员等级计算订单价格。假如这两条消息的消费顺序不一样造成的最终结果就会截然不同。

    我们知道 Kafka 中 Partition(分区)是真正保存消息的地方，我们发送的消息都被放在了这里。而我们的 Partition(分区) 又存在于 Topic(主题) 这个概念中，并且我们可以给特定 Topic 指定多个 Partition。

    每次添加消息到 Partition(分区) 的时候都会采用尾加法，如上图所示。Kafka 只能为我们保证 Partition(分区) 中的消息有序，而不能保证 Topic(主题) 中的 Partition(分区) 的有序。

    所以，我们就有一种很简单的保证消息消费顺序的方法：1 个 Topic 只对应一个 Partition。这样当然可以解决问题，但是破坏了 Kafka 的设计初衷。

    Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 。

    总结一下，对于如何保证 Kafka 中消息消费的顺序，有了下面两种方法：
    
    1. 1 个 Topic 只对应一个 Partition。
    2. （推荐）发送消息的时候指定 key/Partition。

  - Kafka 如何保证消息不丢失

    生产者丢失消息的情况
    
    生产者(Producer) 调用send方法发送消息之后，消息可能因为网络问题并没有发送过去。

    所以，我们不能默认在调用send方法发送消息之后判断消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。
  
    消费者丢失消息的情况

    我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。

    当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。

    解决办法也比较粗暴，我们手动关闭闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。
  
  - kafka是如何保证消息不被重复消费的

    kafka有个offset的概念，当每个消息被写进去后，都有一个offset，代表他的序号，然后consumer消费该数据之后，隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了。下次我要是重启，就会继续从上次消费到的offset来继续消费。

　　但是当我们直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset。等重启之后，少数消息就会再次消费一次。
    
    通过保证消息队列消费的幂等性来保证消息不被重复消费。

11. ElasticSearch

  - 节点

    - Master Node

      - 处理创建、删除索引请求 / 决定分⽚分配到哪个节点
      - 维护并更新Cluster State
    
    - Master Eligible Node

      - 在Master节点出现故障时，参与选主流程，成为Master Node
    
    - Data Node

      - 保存分⽚数据，通过增加Data Node，可以解决数据⽔平扩展
      - 和数据单点的问题
    
    - Coordinating Node

      - 负责将请求转发到正确的节点
      - 处理query AND fetch的结果集
  
  - 分⽚—分布式存储的基⽯

    - Primary Shard

      - 主分⽚在索引创建时指定，默认不能修改

    - Replica Shard
    
      - 数量可以动态调整，提⾼数据的可⽤性
      - 提升查询性能
      - 副本数量过多，会降低写⼊性能，增加磁盘负担
  
  - 倒排索引&正排索引

    倒排索引可以实现从term到document的快速查询，但是没法实现排序，这个时候就需要⽤到正排索引。es是通过doc_value和field_data来实现正排索引的。

    doc_value是在lucene构建倒排索引时，根据原始mapping配置判断是否额外建⽴⼀个有序的正排索引（基于documentId—>field value的映射列表）

    doc_value默认对所有字段启⽤，除了analyzed string，针对analyzed string，如果需要排序，需要开启field_data。

    doc_value本质上是⼀个序列化的列式存储，这个结构⾮常适⽤于聚合、排序、脚本等操作，也⾮常便于压缩。和倒排索引⼀样，doc_value也会序列化到磁盘，这样对性能和扩展性有很⼤帮助。

  - indexing的过程

    1. 将document写⼊index buffer，同时记录trans_log；
    2. 将index buffer写⼊segment，但不执⾏fsync，也不清理trans_log；
      - 这个过程叫做refresh，默认1s⼀次；
      - Index buffer占满时，也会触发refresh；
    3. 调⽤fsync，将缓存中的segments写⼊磁盘，清空trans_log；
      - 这个动作叫做flush，默认30min⼀次；
      - trans_log满（默认512M），也会触发flush；
  
  - 索引定义

    字段类型—>是否需要搜索—>是否需要分词—>是否需要聚合及排序

    字段类型：Text vs keyword

    - Text
      - ⽤于⽂本分析，⽂本会被Analyzer分词
      - 默认不⽀持聚合分析和排序，需要设置fielddata=true

    - Keyword
      - 适⽤于不需要分词的场景，精确匹配查询效率最⾼
      - ⽀持sorting和aggregations

  - 关于分⻚

    es提供三种分⻚查询的机制
    - from / size（es默认限定10000个⽂档）
    - search after（不⽀持跳⻚）
    - scroll API（遍历期间，更新的数据不会拿到）

    使⽤场景及建议
    - 需要全部⽂档，例如导出数据，允许⼀定误差（⽐如导出期间新增的数据）——scroll
    - 分⻚
      - 数据量⼩，且只查询最新的数据，使⽤from / size
      - 深度分⻚，使⽤search after，禁⽤跳⻚

  - 常⽤的优化设计建议

    - 基于时间序列拆分索引
    - 节点职责分离
      - eligible master node：使⽤低配的CPU，RAM和磁盘
      - data node：使⽤⾼配的CPU，RAM和磁盘
    - 写⼊性能优化
      - 客户端通过bulk API批量写
      - 服务端降低IO开销，如提⾼refresh interval
      - 降低CPU和存储开销，如减少不必要的索引 / 分词 / doc_value
      - 极致的性能追求（牺牲可靠性）
        - 临时将副本修改为0（针对初始化导⼊数据场景）
        - 修改trans_log配置（不每次落盘，60s fsync⼀次）
    - 定期做segment merge，segments过多，term_index会占⽤较⼤内存，影响集群性能

  - 学妹的整理

    特点：分布式，水平扩展，REST API

    功能：海量数据的存储管理以及几乎实时的搜索和数据分析

    分布式架构：存储水平扩容，PB级数据，一台机器可以多个es节点；可用性：部分节点宕机集群不受影响

    节点：至少三个master节点能够保证系统的正常运行状态（高可用性），主节点宕机剩下两个自主选举新的主节点，分为master&data节点，master对磁盘内存要求不高，不存数据，data反之，因此根据不同功能配置不同的机器；data node 通过分片来实现备份，即主分片和副本分片，如下“分片”所述

    master：处理创建，删除索引/决定分片的分配；维护更新cluster

    data：保存分片数据，增加此类型node可以水平扩展

    coordinating：请求转发到节点，处理query&fetch结果

    分片：一个分片是一个lucene索引，业务类不要超过20g，日志类不超过50g；太大了恢复起来会比较慢，保持合适大小能够提高集群的效率；主分片不能修改；副本分片数量可以动态调整，提升查询的性能，过多则影响磁盘写入性能；主分片和副本分布在不同节点，如果主分片宕机则内容会分到副本分片上

    索引：对term_dictionary做一个term_index，然后找到posting list再找到各个document，通过refresh来达到近实时的查询效率，refresh之前是读不到数据的，refresh的时间间隔即其近实时的效率（那要是refresh的时间间隔调短会怎样？refresh时间间隔变长为什么能够优化：提高interval可以降低IO的开销，因为索引是根据segment去写入的，会涉及到IO操作，如果很频繁则会比较消耗IO；refresh除了固定的时间间隔还有可以根据indexbox的大小，满足任意一个都会进行refresh。

    倒排索引：实现term到document的快速查询，但是没法排序，具体信息可参考↓

    官方：https://www.elastic.co/guide/cn/elasticsearch/guide/cn/inverted-index.html

    https://blog.csdn.net/hu948162999/article/details/81386384

    https://www.cnblogs.com/cjsblog/p/10327673.html

    正排索引：基于documentId->field value的映射列表，实现排序；doc_value是构建倒排时候，根据原始mapping配置判断是否有有序的正排索引，默认对所有字段启用，本质是一个序列化的列式存储；默认doc_value在磁盘当中，但是如果有词频之类的会加载到内存中

    query过程：query & fetch ，document在磁盘中的存储是按照块存储的，然后有一个文档位置的索引；从内存找到磁盘中对应的倒排索引的位置，然后在磁盘中找到倒排表->document ID->document block index->document block

    indexing：document->index buffer(with trans_log recorded); index buffer->segment (default refresh every one second); 

    内存分配：在JVM heap中地下有fieldData和其他缓存，可以设置断路器，节点中es的存在jvm heap，lucene的存在外部的heap中，会加载到jvm的缓存中提高之后的查询效率

    索引定义：搜索/分词/聚合&排序：text or keyword  ； 嵌套对象 & 父子结构；索引设计避免过多字段（不移维护，mapping存在cluster state过大集群性能受影响，reindex成本高）

    分页：from/size(<=10000 documents)数据量小且要最IN; search after(no jump)深度分页，禁止跳页； scroll API(no updating during iterating)需要全部文档，允许一定偏差

    优化：基于时间序列拆分索引；节点职责分离；写入优化；定期进行segment merge

  - ES和MySQL的区别

    1. 一个ES集群可以包含多个**索引（数据库）**，每个索引又包含了很多**类型（表）**，类型中包含了很多**文档（行）**，每个文档使用 JSON 格式存储数据，包含了很多**字段（列）**。

    2. ES**分布式搜索（一个索引包含多个分片，分片包括主分片和副本分片；选举master结点）**，传统数据库遍历式搜索

    3. ES采用**倒排索引（单词到文档）**，传统数据库采用B+树索引

    4. ES**没有用户验证和权限控制**

    5. ES**没有事务**的概念，不支持回滚，误删不能恢复
  
  - elasticsearch的倒排索引是什么

    传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。有了倒排索引，就能实现o（1）时间复杂度 的效率检索文章了，极大的提高了检索效率。

    倒排索引的底层实现是基于：**FST（Finite State Transducer）数据结构**。lucene从4+版本后开始大量使用的数据结构是FST。FST有两个优点：

    1）**空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；**

    2）**查询速度快。O(len(str))的查询时间复杂度。**
  
  - elasticsearch是如何实现master选举的

    选举流程大致描述如下：

    第一步：确认候选主节点数达标，elasticsearch.yml设置的值discovery.zen.minimum_master_nodes；

    第二步：比较：先判定是否具备master资格，具备候选主节点资格的优先返回；若两节点都为候选主节点，则id小的值会主节点。注意这里的id为string类型。
  
  - Elasticsearch写入数据的工作原理, 查询数据的工作原理, 搜索数据的工作原理分别是什么?

    **Elasticsearch写入数据的工作原理**

    - **客户端发送请求到任意一个协调节点(Coordinating Node), 然后协调节点将请求转发给master节点.**
    - **master节点对document进行路由, 将document写入主分片.**
    - **document写入主分片后, 将数据同步到副本分片.**
    - 主分片和副本分片都写入成功后, 返回响应结果给客户端.
    
    (1) document写入主分片的详细过程

    - **Document写入Index Buffer(ES进程缓冲), 同时将写命令记录到Transaction Log.**
    - **每隔1秒或Index Buffer空间被占满后, Index Buffer中的数据被写入新的Segment中, 并进入OS Cache, 这个过程叫Refresh.** (此时倒排索引已创建, 存在OS Cache中, 数据可被搜索)
    - 重复前面两个步骤.
    - 每隔30分钟或Transaction Log占满后, 先进行Refresh操作, 然后将OS Cache中的Segment刷入磁盘, 这个过程叫Flush.
    - 删除旧Transaction Log, 创建一个新的Transaction Log.
    - ES定期合并磁盘中的Segment File, 同时清除那些被标记为delete的文档.
    
    (2) **ES被称为近实时(Near Realtime)的原因**

    **从上文"document写入主分片的详细过程"中可以知道, Refresh操作每秒执行一次, 只有执行Refresh操作之后, 倒排索引才会被创建, 数据才能被搜索, 这就是ES被称为近实时的原因.**

    (3) ES存在数据丢失的问题

    从上文"document写入主分片的详细过程"中可以知道, document写入Index Buffer的同时会将写命令记录到Transaction Log, 目的是如果数据落盘之前机器宕机了, 可以从Transaction Log中恢复数据. 但在旧版本中Transaction Log不是默认落盘的, 它会先写入OS Cache中, 每隔5s才会被刷入磁盘, 所以如果在Transaction Log落盘前机器宕机了, 数据就完全丢失了.

    在新版本7.x中, Transaction Log是默认落盘的, 也就不会有数据丢失的问题. (index.translog.durability, index.translog.sync_interval)

    **Elasticsearch查询数据的工作原理(Get查询)**

    - **客户端发送请求到任意一个协调节点(Coordinating Node).**
    - **协调节点根据id进行路由, 找到对应的分片.**
    - **根据round-robin随机轮询算法, 在主分片和其他副本分片中随机选择一个, 进行查询.**
    - 将对应的document返回给协调节点.
    - 协调节点返回document给客户端.
    
    **Elasticsearch搜索数据的工作原理**

    - **客户端发送请求到任意一个协调节点(Coordinating Node).**
    - **协调节点将搜索请求转发给所有分片(主分片和副本分片采用随机轮询算法选一个)**
    - **每个分片将自己的搜素结果(这里只有id)返回给协调节点**
    - **协调节点对搜索结果进行合并, 排序, 分页等操作, 得出最终结果.**
    - **协调节点根据最终结果的id去各个分片上拉取document, 返回给客户端.**
  
  - Elasticsearch之四种搜索类型和搜索原理

    **Elasticsearch在搜索过程中存在以下几个问题：**

    第一、 **数量问题**。 比如， 用户需要搜索"衣服"， 要求返回符合条件的前 10 条。 但在 5个分片中， 可能都存储着衣服相关的数据。 所以 ES 会向这 5 个分片都发出查询请求， 并且要求每个分片都返回符合条件的 10 条记录。当ES得到返回的结果后，进行整体排序，然后取最符合条件的前10条返给用户。 这种情况， ES 中 5 个 shard 最多会收到 10*5=50条记录， 这样返回给用户的结果数量会多于用户请求的数量。
    
    第二、 **排名问题**。 上面说的搜索， 每个分片计算符合条件的前 10 条数据都是基于自己分片的数据进行打分计算的。计算分值使用的词频和文档频率等信息都是基于自己分片的数据进行的， 而 ES 进行整体排名是基于每个分片计算后的分值进行排序的(相当于打分依据就不一样， 最终对这些数据统一排名的时候就不准确了)， 这就可能会导致排名不准确的问题。如果我们想更精确的控制排序， 应该先将计算排序和排名相关的信息（ 词频和文档频率等打分依据） 从 5 个分片收集上来， 进行统一计算， 然后使用整体的词频和文档频率为每个分片中的数据进行打分， 这样打分依据就一样了。

    **Elasticsearch的搜索类型（SearchType类型）**

    1、 query and fetch
    
    向索引的所有分片 （ shard）都发出查询请求， 各分片返回的时候把元素文档 （ document）和计算后的排名信息一起返回。
    
    这种搜索方式是最快的。 因为相比下面的几种搜索方式， 这种查询方法只需要去 shard查询一次。 但是各个 shard 返回的结果的数量之和可能是用户要求的 size 的 n 倍。
    
    优点：这种搜索方式是最快的。因为相比后面的几种es的搜索方式，这种查询方法只需要去shard查询一次。
    
    缺点：返回的数据量不准确， 可能返回(N*分片数量)的数据并且数据排名也不准确，同时各个shard返回的结果的数量之和可能是用户要求的size的n倍。

    2、 query then fetch（ es 默认的搜索方式）

    如果你搜索时， 没有指定搜索方式， 就是使用的这种搜索方式。 这种搜索方式， 大概分两个步骤：

    第一步， 先向所有的 shard 发出请求， 各分片只返回文档 id(注意， 不包括文档 document)和排名相关的信息(也就是文档对应的分值)， 
    然后按照各分片返回的文档的分数进行重新排序和排名， 取前 size 个文档。
　　
    第二步， 根据文档 id 去相关的 shard 取 document。 这种方式返回的 document 数量与用户要求的大小是相等的。
    
    优点：返回的数据量是准确的。
　　
    缺点：性能一般，并且数据排名不准确。

    3、 DFS query and fetch
　　
    这种方式比第一种方式多了一个 DFS 步骤，有这一步，可以更精确控制搜索打分和排名。也就是在进行查询之前， 先对所有分片发送请求， 把所有分片中的词频和文档频率等打分依据全部汇总到一块， 再执行后面的操作。

    优点：数据排名准确

    缺点：性能一般；返回的数据量不准确， 可能返回(N*分片数量)的数据

    4、 DFS query then fetch
　　
    比第 2 种方式多了一个 DFS 步骤。也就是在进行查询之前， 先对所有分片发送请求， 把所有分片中的词频和文档频率等打分依据全部汇总到一块， 再执行后面的操作。

　　优点：返回的数据量是准确的，数据排名准确

　　缺点：性能最差【 这个最差只是表示在这四种查询方式中性能最慢， 也不至于不能忍受，如果对查询性能要求不是非常高， 而对查询准确度要求比较高的时候可以考虑这个】

　　DFS 是一个什么样的过程？

　　从 es 的官方网站我们可以发现， DFS 其实就是在进行真正的查询之前， 先把各个分片的词频率和文档频率收集一下， 然后进行词搜索的时候， 各分片依据全局的词频率和文档频率进行搜索和排名。 显然如果使用 DFS_QUERY_THEN_FETCH 这种查询方式， 5效率是最低的，因为一个搜索， 可能要请求 3 次分片。 但， 使用 DFS 方法， 搜索精度是最高的。
  
  - Elasticsearch在数据量很大的情况下（数十亿级别）如何提高搜索性能?

    (1) 善于利用OS Cache

    如果Elasticsearch的每次搜索都要落盘, 那搜索性能肯定很差, 将达到秒级. 但**如果ES集群中的数据量等于OS Cache的容量, 那每次搜索都会直接走OS Cache, 这样性能就会很高, 达到毫秒级.**

    ES集群中的数据量最好不要超过OS Cache的容量, 最低要求也不能超过OS Cache的两倍. 比如我们ES集群有3台机器, 每台机器64G内存, 为每个节点的ES JVM Heap分配32G内存, 最终集群的OS Cache为 32G * 3 = 96G内存. 我们ES集群中的数据量最优情况是不超过96G, 最低要求的情况是不超过192G.

    (2) 数据建模

    从上文"善于利用OS Cache"中我们知道, 我们要保证ES集群中的数据量不超过OS Cache的容量, 那么我们在数据建模的时候就要注意两点:

    - **不要将MySQL表中的所有字段都写入ES, 只写入一部分会被搜索的字段.**
    - **对于MySQL中具有关联关系的表, 我们直接将关联字段写入ES中或在应用端处理关联关系, 禁止在ES中处理关联关系.**

    (3) 数据预热

    如果我们无法做到让ES集群中的数据量不超过OS Cache的容量, **那我们做一个缓存预热子系统, 定时搜索"热数据", 让其进入OS Cache.**

    (4) 冷热分离

    在数据预热的基础上我们还可以进行冷热数据分离, 比如我们有6台机器, 创建两个索引, 每个索引3个分片, **一个索引放热数据, 一个索引放冷数据**. 热数据量一般只占总数据量的10%, 这样我们就能保证热数据都在OS Cache中. 而冷数据虽然占总数据的90%, 但却只有10%的用户访问, 性能差点是可以接受的.

    (5) 分页性能优化

    **深度分页的性能是很差的, 我们要防止出现深度分页的情况, 用滚动翻页来代替深度分页.**

    - search after
    - scroll

  - ES分页

    Elasticsearch分页api有三种:

    - from/size（深度分页。当我们进行一个分页查询from=990, size=10时:首先在每个分片上先都获取 1000 个文档，通过 Coordinating Node 聚合所有结果，再通过排序选取前 1000 个文档。页数越深，占用内存就越多。）
    - search after（用来实时的获取下一页文档信息, 它不支持指定页数(from), 只能往下翻.）
    - scroll（用来处理大数据量的分页搜索, 不适用于实时的分页搜索. scroll分页搜索每次都会创建一个快照, 新数据写入只能影响到后续的分页搜索.）

  - Elasticsearch生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？

    (1) ES生产集群我们部署了5台机器, 每台机器是6核64G的, 集群总内存是320G.

    (2) 我们ES集群的日增量数据大概是2000万条, 500MB左右; 每月增量数据大概是6亿条, 15G左右. 目前系统已经运行了几个月, 现在ES集群里数据总量大概是100G左右.

    (3) 目前线上有5个索引（这个结合你们自己业务来, 看看自己有哪些数据可以放ES的）, 每个索引的数据量大概是20G, 所以这个数据量之内, 我们每个索引分配的是8个shard, 比默认的5个shard多了3个shard.
  
  - 常用命令

    创建索引模板 PUT _template/...
      settings: 分片数、副本数
      mappings: properties 字段类型
    创建索引 PUT ...
    查询 GET _search
      query: match_all, term (精确查找), match(模糊匹配), range (范围查找), [bool: filter, should (或), must (与)]
    java中的写法：jsonbuilder，client发送请求；类似JPA

12. SOA

  > [通俗易懂地解释什么是SOA](https://www.zhihu.com/question/42061683)
  
  把系统按照实际业务，拆分成刚刚好大小的、合适的、独立部署的模块，每个模块之间相互独立。
  
  当服务越来越多，调用方也越来越多的时候，它们之间的关系就变得非常混乱，需要对这些关系进行管理。
  
  所以这个时候就需要能进行服务治理的框架，比如dubbo+zookeeper，比如SpringCloud，有了服务治理功能，我们就能清晰地看到服务被谁谁谁调用，谁谁谁调用了哪些服务，哪些服务是热点服务需要配置服务器集群，而对这个服务集群的负载均衡也是服务治理可以完成的重要功能之一。

  当然，还可以更进一步，加上服务监控跟踪等等等等之类的。
  
  > [Dubbo](https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/dubbo)
  
  什么是分布式?

  分布式或者说 SOA 分布式重要的就是面向服务，说简单的分布式就是我们把整个系统拆分成不同的服务然后将这些服务放在不同的服务器上减轻单体服务的压力提高并发量和性能。比如电商系统可以简单地拆分成订单系统、商品系统、登录系统等等，拆分之后的每个服务可以部署在不同的机器上，如果某一个服务的访问量比较大的话也可以将这个服务同时部署在多台机器上。

  为什么要分布式?
  
  从开发角度来讲单体应用的代码都集中在一起，而分布式系统的代码根据业务被拆分。所以，每个团队可以负责一个服务的开发，这样提升了开发效率。另外，代码根据业务拆分之后更加便于维护和扩展。

  另外，我觉得将系统拆分成分布式之后不光便于系统扩展和维护，更能提高整个系统的性能。你想一想嘛？把整个系统拆分成不同的服务/系统，然后每个服务/系统 单独部署在一台服务器上，是不是很大程度上提高了系统性能呢？

12. RPC

  > [什么是 RPC?RPC原理是什么?](https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/why-use-rpc)
  
  RPC（Remote Procedure Call）—远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。比如两个不同的服务 A、B 部署在两台不同的机器上，那么服务 A 如果想要调用服务 B 中的某个方法该怎么办呢？使用 HTTP请求 当然可以，但是可能会比较慢而且一些优化做的并不好。 RPC 的出现就是为了解决这个问题。
  
  RPC原理是什么？
  
  1. 服务消费方（client）调用以本地调用方式调用服务；
  2. client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；
  3. client stub找到服务地址，并将消息发送到服务端；
  4. server stub收到消息后进行解码；
  5. server stub根据解码结果调用本地的服务；
  6. 本地服务执行并将结果返回给server stub；
  7. server stub将返回结果打包成消息并发送至消费方；
  8. client stub接收到消息，并进行解码；
  9. 服务消费方得到最终结果。
  
  RPC 解决了什么问题？
  
  从上面对 RPC 介绍的内容中，概括来讲RPC 主要解决了：让分布式或者微服务系统中不同服务之间的调用像本地调用一样简单。
  
  常见的 RPC 框架总结?
  
  - RMI（JDK自带）： JDK自带的RPC，有很多局限性，不推荐使用。

  - Dubbo: Dubbo是 阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。目前 Dubbo 已经成为 Spring Cloud Alibaba 中的官方组件。

  - gRPC ：gRPC是可以在任何环境中运行的现代开源高性能RPC框架。它可以通过可插拔的支持来有效地连接数据中心内和跨数据中心的服务，以实现负载平衡，跟踪，运行状况检查和身份验证。它也适用于分布式计算的最后一英里，以将设备，移动应用程序和浏览器连接到后端服务。

  - Hessian： Hessian是一个轻量级的remotingonhttp工具，使用简单的方法提供了RMI的功能。 相比WebService，Hessian更简单、快捷。采用的是二进制RPC协议，因为采用的是二进制协议，所以它很适合于发送二进制数据。

  - Thrift： Apache Thrift是Facebook开源的跨语言的RPC通信框架，目前已经捐献给Apache基金会管理，由于其跨语言特性和出色的性能，在很多互联网公司得到应用，有能力的公司甚至会基于thrift研发一套分布式服务框架，增加诸如服务注册、服务发现等功能。
  
  既有 HTTP ,为啥用 RPC 进行服务调用?

  RPC 只是一种概念、一种设计，就是为了解决 不同服务之间的调用问题, 它一般会包含有 传输协议 和 序列化协议 这两个。

  但是，HTTP 是一种协议，RPC框架可以使用 HTTP协议作为传输协议或者直接使用TCP作为传输协议，使用不同的协议一般也是为了适应不同的场景。
  
  RPC框架功能更齐全：成熟的 RPC框架还提供好了“服务自动注册与发现”、"智能负载均衡"、“可视化的服务治理和运维”、“运行期流量调度”等等功能，这些也算是选择 RPC 进行服务注册和发现的一方面原因吧！

12. Dubbo

  > [dubbo](https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/dubbo)
  
  Apache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC 框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。简单来说 Dubbo 是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。
  
  Dubbo 的诞生和 SOA 分布式架构的流行有着莫大的关系。SOA 面向服务的架构（Service Oriented Architecture），也就是把工程按照业务逻辑拆分成服务层、表现层两个工程。服务层中包含业务逻辑，只需要对外提供服务即可。表现层只需要处理和页面的交互，业务逻辑都是调用服务层的服务来实现。SOA架构中有两个主要角色：服务提供者（Provider）和服务使用者（Consumer）。
  
  Dubbo的架构
  
  节点简单说明：

  - Provider： 暴露服务的服务提供方
  - Consumer： 调用远程服务的服务消费方
  - Registry： 服务注册与发现的注册中心
  - Monitor： 统计服务的调用次数和调用时间的监控中心
  - Container： 服务运行容器
  
  调用关系说明：

  - 服务容器负责启动，加载，运行服务提供者。
  - 服务提供者在启动时，向注册中心注册自己提供的服务。
  - 服务消费者在启动时，向注册中心订阅自己所需的服务。
  - 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
  - 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
  - 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。

  重要知识点总结：

  - 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小
  - 监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示
  - 注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外
  - 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者
  - 注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表
  - 注册中心和监控中心都是可选的，服务消费者可以直连服务提供者
  - 服务提供者无状态，任意一台宕掉后，不影响使用
  - 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复
  
  从下至上分为十层，各层均为单向依赖，右边的黑色箭头代表层之间的依赖关系，每一层都可以剥离上层被复用，其中，Service 和 Config 层为 API，其它各层均为 SPI。

  各层说明：

  - 第一层：service层，接口层，给服务提供者和消费者来实现的
  - 第二层：config层，配置层，主要是对dubbo进行各种配置的
  - 第三层：proxy层，服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton
  - 第四层：registry层，服务注册层，负责服务的注册与发现
  - 第五层：cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务
  - 第六层：monitor层，监控层，对rpc接口的调用次数和调用时间进行监控
  - 第七层：protocol层，远程调用层，封装rpc调用
  - 第八层：exchange层，信息交换层，封装请求响应模式，同步转异步
  - 第九层：transport层，网络传输层，抽象mina和netty为统一接口
  - 第十层：serialize层，数据序列化层，网络传输需要
  
  Dubbo 提供的负载均衡策略
  
  - Random LoadBalance：默认，基于权重的随机负载均衡机制
  - RoundRobin LoadBalance：不推荐，基于权重的轮询负载均衡机制
  - LeastActive LoadBalance：最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。
  - ConsistentHash LoadBalance：一致性 Hash，相同参数的请求总是发到同一提供者。
  
  zookeeper宕机与dubbo直连的情况
  
  在实际生产中，假如zookeeper注册中心宕掉，一段时间内服务消费方还是能够调用提供方的服务的，实际上它使用的本地缓存进行通讯，这只是dubbo健壮性的一种体现。

  dubbo的健壮性表现：

  - 监控中心宕掉不影响使用，只是丢失部分采样数据
  - 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务
  - 注册中心对等集群，任意一台宕掉后，将自动切换到另一台
  - 注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯
  - 服务提供者无状态，任意一台宕掉后，不影响使用
  - 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复
  
  我们前面提到过：注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。所以，我们可以完全可以绕过注册中心——采用 dubbo 直连 ，即在服务消费方配置服务提供方的位置信息。

12. Thrift

  > [Thrift RPC详解](https://blog.csdn.net/kesonyk/article/details/50924489)
 
  > [Thrift RPC详解](https://www.jianshu.com/p/15dbc8665648)
  
  为了实现RPC步骤，许多RPC工具被研发出来。这些RPC工具大多使用“接口描述语言” —— interface description language (IDL) 来提供跨平台跨语言的服务调用。现在生产中用的最多的IDL是Google开源的protobuf。

  在日常开发中通常有两种形式来使用RPC，一种是团队内部完全实现上述RPC的6个步骤，自己序列化数据，然后自己利用socket或者http传输数据，最常见的就是游戏开发了。另一种就是利用现成的RPC工具，这些RPC工具实现了底层的数据通信，开发人员只需要利用IDL定义实现自己的服务即可而不用关心数据是如何通信的，最常见的RPC工具是Facebook开源的Thrift RPC框架。本文将重点讲解Thrift RPC。
  
  Thrift实际上是实现了C/S模式，通过代码生成工具将接口定义文件生成服务器端和客户端代码（可以为不同语言），从而实现服务端和客户端跨语言的支持。用户在Thirft描述文件中声明自己的服务，这些服务经过编译后会生成相应语言的代码文件，然后用户实现服务（客户端调用服务，服务器端提服务）便可以了。其中protocol（协议层, 定义数据传输格式，可以为二进制或者XML等）和transport（传输层，定义数据传输方式，可以为TCP/IP传输，内存共享或者文件共享等）被用作运行时库。
  
  Thrift的协议栈如下图所示：
 
  ![img](https://upload-images.jianshu.io/upload_images/6302559-75e0caadd951d14d.png?imageMogr2/auto-orient/strip|imageView2/2/w/424/format/webp)
 
  在Client和Server的最顶层都是用户自定义的处理逻辑，也就是说用户只需要编写用户逻辑，就可以完成整套的RPC调用流程。用户逻辑的下一层是Thrift自动生成的代码，这些代码主要用于结构化数据的解析,发送和接收，同时服务器端的自动生成代码中还包含了RPC请求的转发（Client的A调用转发到Server A函数进行处理）。

  协议栈的其他模块都是Thrift的运行时模块：

  - 底层IO模块，负责实际的数据传输，包括Socket，文件，或者压缩数据流等。

  - TTransport负责以字节流方式发送和接收Message，是底层IO模块在Thrift框架中的实现，每一个底层IO模块都会有一个对应TTransport来负责Thrift的字节流(Byte Stream)数据在该IO模块上的传输。例如TSocket对应Socket传输，TFileTransport对应文件传输。

  - TProtocol主要负责结构化数据组装成Message，或者从Message结构中读出结构化数据。TProtocol将一个有类型的数据转化为字节流以交给TTransport进行传输，或者从TTransport中读取一定长度的字节数据转化为特定类型的数据。如int32会被TBinaryProtocol Encode为一个四字节的字节数据，或者TBinaryProtocol从TTransport中取出四个字节的数据Decode为int32。

  - TServer负责接收Client的请求，并将请求转发到Processor进行处理。TServer主要任务就是高效的接受Client的请求，特别是在高并发请求的情况下快速完成请求。

  - Processor(或者TProcessor)负责对Client的请求做出相应，包括RPC请求转发，调用参数解析和用户逻辑调用，返回值写回等处理步骤。Processor是服务器端从Thrift框架转入用户逻辑的关键流程。Processor同时也负责向Message结构中写入数据或者读出数据。

  利用Thrift用户只需要做三件事：

  (1). 利用IDL定义数据结构及服务
  (2). 利用代码生成工具将(1)中的IDL编译成对应语言（如C++、JAVA），编译后得到基本的框架代码
  (3). 在(2)中框架代码基础上完成完整代码（纯C++代码、JAVA代码等）

  数据类型

  - Base Types（基本类型）
  - Structs（结构体）
  - enum(枚举）
  - Containers（容器）
  - Exceptions（异常）
  - Services（服务）

13. protobuf为什么快

  > [protobuf为什么那么快](https://www.jianshu.com/p/72108f0aefca)

14. Databus

  读数据：读缓存，读数据库，写缓存

  写数据：淘汰缓存，写数据库，（写缓存）

  问题：写数据库后，写缓存失败怎么办？读数据后写缓存时，数据库又更新了怎么办？

  解决：Databus，强一致协议（比如两阶段提交，paxos等）

15. 秒杀

  - 超卖

    https://blog.csdn.net/glamour2015/article/details/105179738/

    https://hacpai.com/article/1536335417613

    https://www.jianshu.com/p/39b3a95240c4

## 网络

1. OSI七层模型：物理层、数据链路层、网络层、传输层、会话层（会话管理）、表示层（数据格式转换）、应用层

2. ARP协议（网络层）：IP地址->MAC地址

    每个主机都设有一个ARP高速缓存，先查ARP表，如果没有就通过使用目的MAC地址为FF-FF-FF-FF-FF-FF的帧来封装并广播ARP请求分组。

3. TCP和UDP

    TCP提供可靠的面向连接的服务，增加了开销，用于文件传输、发送和接收邮件、远程登录等场景。

    UDP不建立连接，不提供可靠服务，用于语音、视频。

4. TCP为什么可靠一些

    TCP连接管理：三次握手、四次挥手

    TCP可靠传输：累计确认、超时和冗余ACK

    TCP流量控制：发送窗口的实际大小是接受窗口和拥塞窗口的最小值

    TCP拥塞控制：慢开始（指数规模增长）、拥塞避免（加法增大）、快恢复（乘法减小）

5. 滑动窗口的作用

    - 滑动窗口实现面向流的可靠性，只有在收到ACK确认的情况下移动左边界

    - 滑动窗口的流控特性

6. TCP连接和释放过程

    三次握手

    1. 客户机到服务器：SYN
    2. 服务器到客户机：SYN/ACK
    3. 客户机到服务器：ACK

    四次挥手

    1. 客户机到服务器：FIN
    2. 服务器到客户机：ACK
    
        CLOSE_WAIT

    3. 服务器到客户机：FIN/ACK

        TIME_WAIT
    
    4. 客户机到服务器：ACK

    - 为什么A还要发送一次确认呢？

      防止已经失效的连接请求报文段突然又传到了B，因而产生错误，浪费B的资源。
    
    - CLOSE_WAIT：半关闭状态，即A已经没有数据要发送了，但B若发送数据，A仍要接受。

    - TIME_WAIT：为什么A在TIME_WAIT状态必须等待2MSL（最长报文段寿命，建议为2min）？

      1. 为了保证A发送的最后一个ACK报文段能够到达B
      2. 防止已失效的连接请求报文段出现在本连接中
    
7. DNS的寻址过程

    1. 浏览器缓存、DNS缓存
    2. hosts文件
    3. 本地域名服务器分别请求根域名服务器、顶级域名服务器、权限域名服务器
    
        递归查询（比较少用）、迭代查询
    
8. 在浏览器输入url到显示主页的过程：DNS解析、TCP连接、发送HTTP请求、服务器解析渲染页面

9. 状态码

    1XX：信息性状态码

    2XX：成功状态码

    3XX：重定向状态码

    4XX：客户端错误状态码

    5XX：服务端错误状态码

    - **200 OK**：表示从客户端发来的请求在服务端被正常处理了。
    - 201 Created：请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。
    - **202 Accepted**：服务器已接受请求，但尚未处理。正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。
    - **204 No Content**：代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。
    - **206 Partial Content**：表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求。

    - **301 Moved Permanently**：永久性重定向。表示请求的资源已被分配了新的URL，以后应使用资源现在所指的URL。
    - **302 Found**：临时性重定向。表示请求的资源已被分配了新的URL，希望用户能使用新的URL访问。和301状态码相似，但302状态码代表资源不是被永久移动，只是临时性质的。
    - 304 Not Modified：表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回304.

    - **400 Bad Request**：表示请求报文中存在语法错误。
    - **401 Unauthorized**：表示发送的请求需要有通过HTTP认证的认证信息。
    - **403 Forbidden**：对请求资源的访问被服务器拒绝了。
    - **404 Not Found**：表明服务器上无法找到请求的资源。

    - **500 Internal Server Error**：表示服务器端在执行请求时发生了错误。
    - **503 Service Unavailable**：表明服务器暂时处于超负荷或正在进行停机维护，现在无法处理请求。

10. HTTP/1.1默认使用长连接，在响应头加入Connection: keep-alive。在使用长连接的情况下，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭。

11. HTTPS过程

  客户端向服务端发送HTTPS请求，服务端将自己的公钥发送给客户端，客户端利用公钥加密密钥，发起第二个HTTPS请求，将加密之后的密钥发送给服务端，服务端用私钥解密密钥，将加密后的密文发送给客户端，客户端利用密钥解密。

12. HTTP 2.0

  多个请求可同时在一个连接上并行执行。

13. HTTPS与HTTP的区别

  - 传输信息安全性不同
  - 连接方式不同：HTTPS由SSL+HTTP协议构建
  - 端口不同：HTTP 80, HTTPS 443
  - 证书申请方式不同：HTTPS需要到CA申请证书

14. 请求报文的结构

  - 请求行：请求方法GET/POST、URL、协议版本HTTP1.0/HTTP1.1
  - 请求首部：图解HTTP P80
  - 请求主体

  通用首部字段

  - Cache-Control：控制缓存的行为
  - Connection：逐跳首部、连接的管理

  请求首部字段

  - Accept：用户代理可处理的媒体类型
  - Accept-Charset：优先的字符集
  - Accept-Encoding：优先的内容编码
  - Accept-Language：优先的语言（自然语言）
  - Host：请求资源所在服务器
  - Range：实体的字节范围请求
  - Referer：对请求中URL的原始获取方
  - User-Agent：HTTP客户端程序的信息

  响应首部字段

  实体首部字段

  - Content-Encoding：实体主体适用的编码方式
  - Content-Language：实体主体的自然语言
  - Content-Length：实体主体的大小
  - Content-Type：实体主体的媒体类型
  
  非HTTP/1.1首部字段

  - Cookie
  - Set-Cookie

15. GET请求和POST请求

  - GET请求参数在URL中，POST请求在请求主体中
  - GET请求具有幂等性，多次调用和一次调用是一样的，没有副作用

## 设计模式

1. 面对对象

- 封装：对象包含它能操作所需的所有信息，包括变量和方法，好处是减少耦合，内部可以自由修改，具有清晰的对外接口。
- 继承：is-a的关系，父类变子类不得不变，强耦合。
- 多态：子类以父类的身份出现，调用父类的方法，使用的是子类的实现。

2. 原则

- 单一职责原则：就一个类而言，应该仅有一个引起它变化的原因。
- 开放封闭原则：软件实体对于扩展是开放的，对于更改是封闭的。
- 依赖倒转原则：A.高层模块不应该依赖低层模块，两个都应该依赖抽象。B. 抽象不应该依赖细节，细节应该依赖抽象。
- 里氏替换原则：子类型必须能够替换掉它们的父类型。
- 合成/聚合复用原则：尽量使用合成/聚合，尽量不要使用继承。

3. 设计模式

- 简单工厂模式
- 工程方法模式：产品接口、工厂接口、具体产品、具体工厂，一个具体工厂生产一个具体产品。
- 抽象工厂模式：一个具体工厂创建一组具体工厂。
- 策略模式：上下文类（维护一个对策略的引用），策略类，具体策略类
- 代理模式：主体类（定义真是主体类和代理类的共同接口），真实主体类，代理类（保存一个引用是的代理可以访问真实主体）
- 观察者模式（发布-订阅模式）：主体类（可以增加和删除观察者对象）、观察者（再得到主体的通知时更新自己）、具体主体、具体观察者
- 适配器模式：将一个类的接口转换成客户希望的另一个接口
- 桥接模式：实现系统可能有多角度分类，每一种分类都有可能变化，那么就把这种多角度分离出来让它们独立变化，减少它们之间的耦合。
- 单例模式

  ```java
  public class Singleton {
      private volatile static Sinleton uniqueInstance;
      private Singleton() {}
      public static SIngleton getInstance() {
          if (uniqueInstance == null) {
	            synchronized (Singleton.class) {
	                if (uniqueInstance == null) {
		                  uniqueInstance = new Singleton();
		              }
              }
	        }
      }
  }
  ```

4. DDD(Domain-driven Design - 领域驱动设计)

  > [设计思想--开发模式](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3--%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F)

  - 《浅谈我对DDD领域驱动设计的理解》

    - 概念：DDD 主要对传统软件开发流程(分析-设计-编码)中各阶段的割裂问题而提出，避免由于一开始分析不明或在软件开发过程中的信息流转不一致而造成软件无法交付（和需求方设想不一致）的问题。DDD 强调一切以领域（Domain）为中心，强调领域专家（Domain Expert）的作用，强调先定义好领域模型之后在进行开发，并且领域模型可以指导开发（所谓的驱动）。
    - 过程：理解领域、拆分领域、细化领域，模型的准确性取决于模型的理解深度。
    - 设计：DDD 中提出了建模工具，比如聚合、实体、值对象、工厂、仓储、领域服务、领域事件来帮助领域建模。
  
  - 《领域驱动设计的基础知识总结》

    - 领域（Doamin）本质上就是问题域，比如一个电商系统，一个论坛系统等。
    - 界限上下文（Bounded Context）：阐述子域之间的关系，可以简单理解成一个子系统或组件模块。
    - 领域模型（Domain Model）：DDD的核心是建立（用通用描述语言、工具—领域通用语言）正确的领域模型；反应业务需求的- 本质，包括实体和过程；其贯穿软件分析、设计、开发 的整个过程；常用表达领域模型的方式：图、代码或文字；
    - 领域通用语言：领域专家、开发设计人员都能立即的语言或工具。
    - 经典分层架构：用户界面/展示层、应用层、领域层、基础设施层，是四层架构模式。
    - 使用的模式：
      - 关联尽量少，尽量单项，尽量降低整体复杂度。
      - 实体（Entity）：领域中的唯一标示，一个实体的属性尽量少，少则清晰。
      - 值对象（Value Object）：没有唯一标识，且属性值不可变，小二简单的对象，比如Date。
      - 领域服务（Domain Service）： 协调多个领域对象，只有方法没有状态(不存数据)；可以分为应用层服务，领域层服务、基础层服务。
      - 聚合及聚合根（Aggregate，Aggregate Root）：聚合定义了一组具有内聚关系的相关对象的集合；聚合根是对聚合引用的唯一元素；当修改一个聚合时，必须在事务级别；大部分领域模型中，有70%的聚合通常只有一个实体，30%只有2~3个实体；如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，那么我们可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互；
      - 工厂（Factory）：类似于设计模式中的工厂模式。
      - 仓储（Repository）：持久化到DB，管理对象，且只对聚合设计仓储。
  
  - 《领域驱动设计(DDD)实现之路》

    - 聚合：比如一辆汽车（Car）包含了引擎（Engine）、车轮（Wheel）和油箱（Tank）等组件，缺一不可。
  
  - 《领域驱动设计系列（2）浅析VO、DTO、DO、PO的概念、区别和用处》

    > [VO、DTO、DO、PO](https://www.cnblogs.com/ooo0/p/10499463.html)
    
    领域模型中的实体类可细分为4种类型：VO、DTO、DO、PO。
    
    - VO（View Ob-ject）：视图对象，用于展示层视图状态对应的对象
    - DTO（Data Transfer Object）：数据传输对象，原来的目的是为EJB的分布式应用提供粗粒度的数据实体，以降低分布式调用的次数，提高分布式调用的性能，后来一般泛指用于展示层与服务层之间的数据传输对象，因此可以将DTO看成一个组合版的DO
    - DO（Domain Object）：领域对象，即业务实体对象
    - PO（Persistent Object）：持久化对象，表示持久层的数据结构（如数据库表）
    
    从分层角度来说，PO、DO/DTO、VO分别属于持久层、服务层和展现层。
    
    对于简单模块来说，有时PO、DO和VO并没有什么区别，这时就没有必要分别定义DO和VO了，直接复用PO即可。

## 数据库

## Java 

1. 简单类型8种：short, int, long, float, double, boolean, byte, char

2. NIO：非阻塞IO，调用者不用一直等着结果返回。线程控制选择器，选择不同的通道来读取缓存区。

3. Linux的5中IO模型：阻塞、非阻塞、异步、IO复用、信号驱动IO

4. select, poll, epoll的区别

  - select需要把文件描述符(fd)集合从用户态拷贝到内核态，并在内核态遍历文件描述符。
  - poll与select类似，文件描述符集合的描述结构不同。
  - epoll会在注册时把所有文件描述符拷贝进内核，每个文件描述符只会拷贝一次，挂到等待队列上。

5. Object类方法：hashCode(), equals(), notify(), wait(), toString(), clone(), getClass(), finalize()

6. 接口和抽象类的区别：方法在接口中不能有实现；一个类可以实现多个接口，但只能继承一个抽象类。

7. String：不可变
StringBuffer：可变，线程安全synchronized
StringBuilder：可变，线程不安全

8. final

  - 修饰变量：值再初始化后不能更改
  - 修饰类：类不能被继承，所有成员方法都会被隐式指定为final

9. static

  - 修饰成员变量和方法
  - 静态代码块
  - 静态内部类（不能引用外部非static成员变量和方法）

10. 通配符?用于实例化泛型对象，T用于定义泛型类

11. List, Set, Map

  - List: ArrayList, Vector, LinkedList
  - Set, Map: HashMap, HashTable, LinkedHashMap, TreeMap

12. HashMap

  - hash = h ^ (h >>> 16)，高16位和低16位都反映到低位上，使hash更均匀
  - 到table[(n-1)&hash]取值（取hash的低位）
  - 扩容：新数组newTable为原数组的2倍；如果节点是TreeNode，分成2棵树；如果是节点，hash&oldCap==0放在原索引，否则原索引+oldCap.
  - JDK 8前，并发扩容产生循环链表，get时死循环。JDK 8不会死循环，但仍然会产生数据丢失。

13. ==和equals()的区别

  - ==判断2个对象的地址是否相等
  - equals()没有重写时等价于==，可以重写

14. hashCode()和equals()

  - HashMap比较key是否相同时，先判断hashCode是否相同，再比较equals()是否相同。
  - 2个对象相等，散列码相同。
  - equals()重写过，hashCode()也要重写，否则有可能2个对象相同散列码不同，散列到不同的散列桶中找不到key

15. 重写equals()的约定

    (1) 使用==操作符检查参数是否时这个对象的引用

    (2) 使用instance检查是否为正确的类型

    (3) 把参数转换成正确的类型

    (4) 比较每个关键域是否匹配

    (5) 思考equals()方法是否满足自反性、对称性、传递性、一致性、非空性

16. 重写hashCode

    (1) int result = 17;

    (2) 对于每个关键域：

    a. 计算关键域int类型的散列码c，float, double转成int, long, long: (int) (f^(f>>>32))
    
    b. result=31*result+c

17. TreeMap的底层实现是红黑树，AVL树是严格平衡，红黑树是弱平衡

18. 红黑树性质

    (1) 每个节点要么是红色，要么是黑色

    (2) 根节点永远是黑色的

    (3) 叶结点是空节点，并且是黑色的

    (4) 每个红色节点的2个子节点都是黑色的
    
    (5)从任一节点到其子树的每个叶结点都包含相同数量的黑色节点

19. Java 8

  - lambda表达式
  - 方法引用
  - 接口的默认方法
  - stream()
  - Optional

## 并发

1. 并发执行有可能比串行慢，因为线程有创建和上下文切换的开销

2. 使用Lmbench测量上下文切换时长，vmstat测量上下文切换的次数

3. 如何减少上下文切换

  - CAS算法，不用加锁
  - 使用最少线程
  - 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换

4. synchronized

  - 3种形式
  
    - 对于普通的同步方法，锁的是当前实例对象
    - 对于静态同步方法，锁的是当前类的Class对象
    - 对于同步方法块，锁的是synchronized括号里配置的对象
  
  - JVM基于进入和退出Monitor对象来实现方法同步和代码块同步。代码块同步是使用monitorenter和monitorexit指令实现的，而方法同步时使用ACC_SYNCHRONIZED标志位实现的。

5. Java对象头的Mark Word中存储对象的hashCode、分代年龄和锁标记位。

  - 偏向锁：Mark Word中存储指向当前线程的偏向锁。
  - 轻量级锁：线程尝试使用CAS将对象头中的MarkWord替换为指向锁记录的指针。
  - 重量级锁

6. CAS的三大问题

  (1) ABA问题
  (2) 循环时间长开销大
  (3) 只能保证一个共享变量的原子操作

7. JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本。

  如果线程A要和B通信，必须要经历下面2个步骤：
  
  (1) 线程A把本地内存A中更新过的共享变量刷新到主内存中去。
  (2) 线程B到主内存中去读取线程A之前已经更新过的共享变量。

8. 为什么要使用多线程（主要原因是IO阻塞和多CPU）

  - 单核时代提高CPU和IO的综合利用率
  - 多核时代提高CPU利用率
  - 业务更快的响应时间

9. 设置线程优先级时，针对频繁阻塞的线程需设置较高的优先级，而偏重计算的线程设置较低的优先级，确保处理器不会被独占。

10. 线程的状态

  - NEW
  - TERMINATED
  - RUNNABLE：运行中，包括就绪和运行
  - BLOCKED：阻塞于锁
  - WAITING：等待其他线程通知
  - TIME_WAITING：超时等待，可以在指定时间自行返回

11. 当一个Java虚拟机中不存在非Daemon线程时，Java虚拟机将会退出。

12. 线程通过方法isInterrupted()来判断是否被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标志位进行复位。

13. 除了中断以外，还可以利用一个boolean变量来控制是否需要停止任务并终止该线程。

14. suspend()调用后不会释放已经占有的资源（比如锁），而是占有着资源进入睡眠状态。

  stop()终结一个线程时不会保证线程资源正常释放
  
  yield()方法会临时暂停正在执行的线程，来让有同样优先级的线程有机会执行。yield()方法不保证当前的线程会暂停或停止，但是可以保证当前线程调用yield方法时会放弃CPU。

15. 线程间通信

  - wait/notify
  - volatile/synchronized
  - join
  - countdownlatch/cyclicbarrier
  - semaphore

16. Fork/Join框架

  Fork就是把一个大任务切分成若干子任务，Join就是合并这些子任务的执行结果。
  
  工作窃取算法是指某个线程从其他队列中窃取任务来执行。充分利用线程进行并行计算，减少了线程的竞争。

17. AtomicInteger

  ```java
  public final int getAndIncrement() {
      for (;;) {
          int current = get();
          int next = current + 1;
          if (compareAndSet(current, next)) {
              return current;
          }
      }
  }
 
  public final boolean compareAndSet(int expect, int update) {
      return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
  }
  ```

18. 线程池的好处

  - 降低资源消耗
  - 提高响应速度
  - 提高线程的可管理性
   
19. 线程池的参数

  (1) corePoolSize：核心线程数

  (2) runnableTaskQueue：任务队列

  ArrayBockingQueue：有界

  LinkedBlockingQueue：有界，默认Integer.MAX_VALUE

  SynchronousQueue：不存储元素

  PriorityBlockingQueue：具有优先级、无限

  (3) maxPoolSize：线程池的最大数量

  (4) ThreadFactory：创建线程的工厂

  (5) RejectExxcutionHandler 饱和策略

  AbortPolicy 直接抛出异常

  CallerRunPolicy 调用者所用线程

  DiscardOldestPolicy 丢弃最早

  DiscardPolicy 丢弃

  (6) keepAliveTime 线程池工作线程空闲后，保持存活的时间

20. 线程池提交任务

  execute()提交不需要返回值的任务，输入Runnable类实例

  submit()提交需要返回值的任务，输入Runnale或Callable，返回一个future对象，future的get()方法会阻塞到任务完成并返回返回值

21. 关闭线程池

  RUNNING

  SHUTDOWN(shutdown) 继续处理等待队列

  STOP(shutdownNow) 不再处理等待队列，中断正在执行的线程

22. CPU密集型任务应配置尽可能小的线程，如N_CPU+1; IO密集型任务线程并不是一直在执行任务，应配置尽可能多的线程，如2N_CPU.

23. Executor

  (1) FixedThreadPool
  (2) SingleThreadExecutor
  (3) CachedThreadExecutor
  (4) ScheduledThreadExecutor

24. Future接口和实现Future接口的FutureTask类用来表示异步计算的结果。

25. Runnable接口不会返回结果，而Callable接口可以返回结果。

26. CopyOnWriteArrayList：修改时，复制原有数据，将修改内容写入副本。写完后再去替换原来的数据。

27. java.util.comncurrent并发包

  并发容器 concurrentHashMap, copyOnWriteArrayList

  原子变量 AtomicInteger

  显式锁 lock

  同步工具 semaphore, countdownlatch, cyclicbarrier

	线程池

28. 可重入锁独有的功能

	- 指定公平锁还是非公平锁
	- Condition条件类，分组唤醒需要唤醒的线程
	- 中断等待锁

29. ThreadLocal内存泄漏

	key为弱引用，value为强引用，key被清理掉，value未被清理

30. 强引用：不会被清理

  弱引用：生存到下一次垃圾收集发生之前
	
	软引用：系统将要内存溢出异常前回收

	虚引用：唯一目的就是被回收前收到一个系统通知

31. CountDownLatch: countDown()计数减1，计数为0时释放等待线程，一等多

  CyclicBarrier: await()计数减1，计数为0时释放等待线程，多个线程互相等待

32. 创建线程的方法

	- 继承Thread类
	- 实现Runnable接口，传进Thread
	- 实现Callable接口，传进Thread
	- 线程池

33. 线程同步的方法

  - synchronized
	- volatile
	- 重入锁
	- ThreadLocal
	- 阻塞队列
	- 原子变量

34. 重入：获取锁的操作粒度是线程而不是调用，一个线程如果获取了锁之后那么也可以再次获取这个锁。

35. AQS

  > [AQS](https://snailclimb.gitee.io/javaguide/#/docs/java/Multithread/AQS)
  
  AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
  
  CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。
  
  AQS 使用一个 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。

  AQS 定义两种资源共享方式

  1)Exclusive（独占）

  只有一个线程能执行，如 ReentrantLock。又可分为公平锁和非公平锁,ReentrantLock 同时支持两种锁,下面以 ReentrantLock 对这两种锁的定义做介绍：

  - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
  - 非公平锁：当线程要获取锁时，先通过两次 CAS 操作去抢锁，如果没抢到，当前线程再加入到队列中等待唤醒。
  
  2)Share（共享）

  多个线程可同时执行，如 Semaphore/CountDownLatch。
  
  AQS 底层使用了模板方法模式

  同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：

  使用者继承 AbstractQueuedSynchronizer 并重写指定的方法。（这些重写方法很简单，无非是对于共享资源 state 的获取和释放）

  将 AQS 组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。

  这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用，下面简单的给大家介绍一下模板方法模式，模板方法模式是一个很容易理解的设计模式之一。

  模板方法模式是基于”继承“的，主要是为了在不改变模板结构的前提下在子类中重新定义模板中的内容以实现复用代码。举个很简单的例子假如我们要去一个地方的步骤是：购票buyTicket()->安检securityCheck()->乘坐某某工具回家ride()->到达目的地arrive()。我们可能乘坐不同的交通工具回家比如飞机或者火车，所以除了ride()方法，其他方法的实现几乎相同。我们可以定义一个包含了这些方法的抽象类，然后用户根据自己的需要继承该抽象类然后修改 ride()方法。

## JVM

1. 双亲委派模型

  如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器完成。只有当父类加载器自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子类加载器才会尝试自己去加载。
  
2. 三种系统提供的类加载器

  - 启动类加载器
  - 扩展类加载器
  - 应用程序类加载器

3. 破坏双亲委派模型

  - ClassLoader.loadClass()方法
  - 线程上下文加载器
  - 用户对程序的动态性要求

4. 双亲委派模型的好处

  - 避免类的重复加载
  - Java的核心API不被篡改

5. 线程的实现

  - 内核线程，一对一线程模型
  - 用户线程，一对多线程模型

6. Amdahl定律：并行化来压榨计算机运算能力

7. 类加载的过程

 - 加载
 - 连接：验证、准备、解析
 - 初始化

8. volatile

  - 第一个语义：保证此变量对所有线程的可见性
  - volatile变量的运算再并发下一样时不安全的
  - 第二个语义：禁止指令重排序优化

9. happends-before先行发生

  happens-before是Java内存模型中定义的2项操作之间的偏序关系。如果说操作A先行发生于操作B，其实就是说发生操作B之前，操作A产生的影响能被B观察到。

  程序次序规则、volatile变量规则

10. JVM运行时数据区域

  线程私有的：程序计数器、虚拟机栈、本地方法栈
  
  线程共享的：堆、方法区

  JDK 8中用元数据去代替永久代实现方法区，并把字符串常量池和类静态变量迁移到堆中存放。

  为什么要用元数据区代替永久代？
  
  (1) 字符串存在永久代，容易出现性能问题
  
  (2) 类信息比较难确定大小，永久代空间分配困难

11. 垃圾回收GC

   - 根搜索算法：GC Roots向下搜索，判断是否可达
   
     GC Roots包括下面几种：
   
     1. 虚拟机栈中引用的对象
     2. 本地方法栈中引用的对象
     3. 方法区中的的常量变量引用的对象
     4. 方法区中的类静态变量引用的对象

   - 分代收集算法
   
     Eden: From Survivor: To Survivor = 8:1:1
     
     Eden区和From Survivor区中还存活的对象移动到To Survivor区，对象优先在Eden区分配，大对象直接进入老年代，长期存活的对象将进入老年代（15岁），老年代分配担保
   
   - Minor GC的触发条件：Eden区满
   
   - Full GC的触发条件
   
     1. 调用System.gc时建议执行Full GC
     2. 老年代空间不足
     3. 方法区空间不足
     4. 老年代担保空间不足
   
   - 新生代的收集器：Serial（串行）、ParNew（并行）、Parallel（高吞吐量），使用复制算法
   
   - 老年代的收集器有Serial Old、Parallel Old，使用标记-整理算法
   
   - CMS收集器基于标记-清楚算法，步骤分为初始标记、并发标记、重新标记、并发清除
   
   - G1收集器将Java堆划分为多个大小相等的独立区域（Region），相关引用记录在Region对应的Remembered Set中。从整体看基于标记-整理算法，从局部（2个Region之间）看基于复制算法。步骤分为初始标记、比并发标记、最终标记、筛选回收。

12. OOM、CPU占用过高排查

  - jsp：列出正在运行的虚拟机进程
  - jstat：统计信息，包括分区占用情况
  - **jmap：内存映像**
  - **jstack：堆栈跟踪**
  - VisualVM：生成浏览堆转储快照、分析CPU、内存性能
  - top ps

## Spring

> [spring](https://github.com/hanggegreat/CS-Tree/blob/master/Java/Spring/Spring.md)

> [mybatis interview](https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/mybatis/mybatis-interview)

> [mybatis缓存机制详解](https://www.cnblogs.com/winclpt/articles/7511672.html)

- #{}和${}的区别是什么？

  ${}是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如${driver}会被静态替换为com.mysql.jdbc.Driver。

  #{}是 sql 的参数占位符，Mybatis 会将 sql 中的#{}替换为?号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的?号占位符设置参数值，比如 ps.setInt(0, parameterValue)，#{item.name} 的取值方式为使用反射从参数对象中获取 item 对象的 name 属性值，相当于 param.getItem().getName()。

- mybatis缓存

  mybatis提供了缓存机制减轻数据库压力，提高数据库性能

  mybatis的缓存分为两级：一级缓存、二级缓存

  一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效

  二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的

- Xml 映射文件中，除了常见的 select|insert|updae|delete 标签之外，还有哪些标签？

  还有很多其他的标签，<resultMap>、<parameterMap>、<sql>、<include>、<selectKey>，加上动态 sql 的 9 个标签，trim|where|set|foreach|if|choose|when|otherwise|bind等，其中为 sql 片段标签，通过<include>标签引入 sql 片段，<selectKey>为不支持自增的主键生成策略标签。

- 最佳实践中，通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应，请问，这个 Dao 接口的工作原理是什么？Dao 接口里的方法，参数不同时，方法能重载吗？

  Dao 接口，就是人们常说的 Mapper接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中MappedStatement的 id 值，接口方法内的参数，就是传递给 sql 的参数。Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到 namespace 为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement。在 Mybatis 中，每一个<select>、<insert>、<update>、<delete>标签，都会被解析为一个MappedStatement对象。

  Dao 接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。

  Dao 接口的工作原理是 JDK 动态代理，Mybatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行MappedStatement所代表的 sql，然后将 sql 执行结果返回。

- mybatis和hibernate, jdbc的区别；mybatis解决了什么问题，mybatis有什么缺点

  > [JDBC、MyBatis、Hibernate的区别](https://www.cnblogs.com/kingofjava/p/10651093.html)

  JDBC

  1.使用JDBC编程需要链接数据库，注册驱动和数据库信息。

  2.操作Connection，打开Statement对象。

  3.通过Statement执行SQL语句，返回结果放到ResultSet对象。

  4.使用ResultSet读取数据。

  5.关闭数据库相关的资源。

  JDBC缺点：

  工作量比较大，需要连接，然后处理jdbc底层事务，处理数据类型，还需要操作Connection，Statement对象和ResultSet对象去拿数据并关闭他们

  没有使用框架的时候 sql语句是和java语句一起写在dao层 耦合度高，维护不易而且实际开发中sql是会变的，需要频繁修改 当你要替换某个sql代码的时候

  ，需要对整个项目 进行操作，极不方便。

  JDBC优点：

  接近底层，理论上效率最高

  MyBatis

  半自动化的持久层框架 半自动 轻量级 

  1.SQLSessionFactoryBuilder(构造器):它会根据配置信息或者代码生成SqlSessionFactory。

  2.SqlSessionFactory(工厂接口)：依靠工厂生成SqlSession。

  3.SqlSession(会话)：是一个既可以发送SQL去执行并且返回结果，也可以获取Mapper接口。

  4.SQL Mapper:是由一个JAVA接口和XML文件(或注解)构成，需要给出对应的SQL和映射规则。SQL是由Mapper发送出去，并且返回结果。

  Mybatis的优点：

  1、易于上手和掌握，提供了数据库查询的自动对象绑定功能，而且延续了很好的SQL使用经验，对于没有那么高的对象模型要求的项目来说，相当完美。

  2、sql写在xml里，便于统一管理和优化， 解除sql与程序代码的耦合。

  3、提供映射标签，支持对象与数据库的orm字段关系映射

  4、 提供对象关系映射标签，支持对象关系组建维护

  5、提供xml标签，支持编写动态sql。

  6、速度相对于Hibernate的速度较快

  Mybatis的缺点：

  1、关联表多时，字段多的时候，sql工作量很大。

  2、sql依赖于数据库，导致数据库移植性差。

  3、由于xml里标签id必须唯一，导致DAO中方法不支持方法重载。

  4、对象关系映射标签和字段映射标签仅仅是对映射关系的描述，具体实现仍然依赖于sql。

  5、DAO层过于简单，对象组装的工作量较大。

  6、不支持级联更新、级联删除。

  7、Mybatis的日志除了基本记录功能外，其它功能薄弱很多。

  8、编写动态sql时,不方便调试，尤其逻辑复杂时。

  9、提供的写动态sql的xml标签功能简单，编写动态sql仍然受限，且可读性低。

  Hibernate

  Hibernate的优点：

  1、hibernate是全自动，hibernate完全可以通过对象关系模型实现对数据库的操作，拥有完整的JavaBean对象与数据库的映射结构来自动生成sql。

  2、功能强大，数据库无关性好，O/R映射能力强，需要写的代码很少，开发速度很快。

  3、有更好的二级缓存机制，可以使用第三方缓存。

  4、数据库移植性良好。

  5、hibernate拥有完整的日志系统，hibernate日志系统非常健全，涉及广泛，包括sql记录、关系异常、优化警告、缓存提示、脏数据警告等

  Hibernate的缺点：

  1、学习门槛高，精通门槛更高，程序员如何设计O/R映射，在性能和对象模型之间如何取得平衡，以及怎样用好Hibernate方面需要的经验和能力都很强才行

  2、hibernate的sql很多都是自动生成的，无法直接维护sql；虽然有hql查询，但功能还是不及sql强大，见到报表等变态需求时，hql查询要虚，也就是说hql查询是有局限的；hibernate虽然也支持原生sql查询，但开发模式上却与orm不同，需要转换思维，因此使用上有些不方便。总之写sql的灵活度上hibernate不及mybatis。

- mapper中的sql语句怎么转化成代码中的sql的

## 操作系统

> [操作系统](https://snailclimb.gitee.io/javaguide/#/docs/operating-system/basis?id=_11-%e4%bb%80%e4%b9%88%e6%98%af%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f%ef%bc%9f)

1. 死锁

  - 死锁预防：互斥、不剥夺、请求保持（一次申请完所需的全部资源）、循环等待（顺序资源分配法）
  - 死锁避免：银行家算法
  - 死锁检测与解除：资源分配图、死锁定理

2. 页式存储

  - 页号根据页表查到块号，与页内偏移量拼接，得到物理地址
  - 连续的逻辑地址->不连续的物理地址

3. 缺页中断

  在请求分页系统中，每当所要访问的页面不在内存时，便产生一个缺页中断，请求操作系统将所缺页调入内存。
	
4. 页面置换算法

  OPT, FIFO, LRU, CLOCK
