---
layout:     post
title:      "知识点整理"
subtitle:   ""
date:       2020-03-5 12:00:00
author:     "盈盈冲哥"
header-img: "img/fleabag.jpg"
mathjax: true
catalog: true
tags:
    - 学习
---

## 目录

- [基础](#基础)
- [容器](#容器)
- [并发容器](#并发容器)
- [并发](#并发)
- [JVM](#jvm)
- [Java8](#java8)
- [数据结构](#数据结构)
- [网络](#网络)
- [操作系统](#操作系统)
- [数据库](#数据库)
- [设计模式](#设计模式)
- [项目](#项目)
- [面经](#面经)
- [面试](#面试)

## 基础

- Java简单类型

  - byte：8位，最大存储数据量是255，存放的数据范围是-128~127之间。
  - short：16位，最大数据存储量是65536，数据范围是-32768~32767之间。
  - int：32位，最大数据存储容量是2的32次方减1，数据范围是负的2的31次方到正的2的31次方减1。
  - long：64位，最大数据存储容量是2的64次方减1，数据范围为负的2的63次方到正的2的63次方减1。
  - float：32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。
  - double：64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。
  - boolean：只有true和false两个取值。
  - char：16位，存储Unicode码，用单引号赋值。

- Java中的I/O流

  - BIO、NIO、AIO

    - **BIO (Blocking I/O):** 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。
    - **NIO (New I/O):** NIO是一种同步非阻塞的I/O模型。NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。
    - **AIO (Asynchronous I/O):** AIO 也就是 NIO 2，是异步非阻塞的IO模型。

    > [https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/BIO-NIO-AIO.md](https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/BIO-NIO-AIO.md)

    **同步与异步**

    同步： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。

    异步： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。

    同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。

    **阻塞和非阻塞**

    阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。

    非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。

    举个生活中简单的例子，你妈妈让你烧水，小时候你比较笨啊，在那里傻等着水开（同步阻塞）。等你稍微再长大一点，你知道每次烧水的空隙可以去干点其他事，然后只需要时不时来看看水开了没有（同步非阻塞）。后来，你们家用上了水开了会发出声音的壶，这样你就只需要听到响声后就知道水开了，在这期间你可以随便干自己的事情，你需要去倒水了（异步非阻塞）。

- NIO

  线程控制选择器，选择不同的通道来读取缓存区。

  > [https://www.jianshu.com/p/362b365e1bcc](https://www.jianshu.com/p/362b365e1bcc)

  IO和NIO的区别

  原有的 IO 是面向流的、阻塞的，NIO 则是面向块的、非阻塞的。

  怎么理解IO是面向流的、阻塞的
  java1.4以前的io模型，一连接对一个线程。

  原始的IO是面向流的，不存在缓存的概念。Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区

  Java IO的各种流是阻塞的，这意味着当一个线程调用read或 write方法时，该线程被阻塞，直到有一些数据被读取，或数据完全写入，该线程在此期间不能再干任何事情了。

  怎么理解NIO是面向块的、非阻塞的

  NIO是面向缓冲区的。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性。

  Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。

  通俗理解：NIO是可以做到用一个线程来处理多个操作的。假设有10000个请求过来,根据实际情况，可以分配50或者100个线程来处理。不像之前的阻塞IO那样，非得分配10000个。

- linux五种IO模型

  > [https://juejin.im/post/5c725dbe51882575e37ef9ed](https://juejin.im/post/5c725dbe51882575e37ef9ed)

  Linux下主要有以下五种I/O模型：

  1. 阻塞I/O（blocking IO）
  2. 非阻塞I/O (nonblocking I/O)
  3. I/O 复用 (I/O multiplexing)
  4. 信号驱动I/O (signal driven I/O (SIGIO))
  5. 异步I/O (asynchronous I/O)

- select、poll、eopll的区别

  > [https://www.cnblogs.com/anker/p/3265058.html](https://www.cnblogs.com/anker/p/3265058.html)
  
  > [https://segmentfault.com/a/1190000003063859](https://segmentfault.com/a/1190000003063859)

  select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但**select，poll，epoll本质上都是同步I/O**，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

  **select**
  
  select的几大缺点：

  （1）每次调用select，**都需要把fd集合从用户态拷贝到内核态**，这个开销在fd很多时会很大

  （2）同时每次调用select**都需要在内核遍历传递进来的所有fd**，这个开销在fd很多时也很大

  （3）select支持的文件描述符数量太小了，默认是1024

  **poll**
  
  poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构。

  **epoll**
  
  epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。

  对于第一个缺点，epoll的解决方案**在epoll_ctl函数中**。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），**会把所有的fd拷贝进内核**，而不是在epoll_wait的时候重复拷贝。**epoll保证了每个fd在整个过程中只会拷贝一次。**

  对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，**当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表**）。**epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd**（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。

  对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。

  **总结**
  
  （1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。

  （2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而**epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次**（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。

- Object类的方法

  > [https://fangjian0423.github.io/2016/03/12/java-Object-method/](<https://fangjian0423.github.io/2016/03/12/java-Object-method/>)

  - getClass()
  - **hashCode()**
  - **equals()**
  - clone()
  - **toString()**
  - **notify()**: 唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果所有的线程都在此对象上等待，那么只会选择一个线程。
  - notifyAll(): 跟notify一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。
  - **wait**(long timeout) throws InterruptedException: wait方法会让当前线程等待直到另外一个线程调用对象的notify或notifyAll方法，或者超过参数设置的timeout超时时间。
  - wait(long timeout, int nanos) throws InterruptedException: 跟wait(long timeout)方法类似，多了一个nanos参数，这个参数表示额外时间（以毫微秒为单位，范围是 0-999999）。 所以超时的时间还需要加上nanos毫秒。
  - wait() throws InterruptedException: 跟之前的2个wait方法一样，只不过该方法一直等待，没有超时时间这个概念。
  - finalize()的作用是实例被垃圾回收器回收的时候触发的操作，就好比 “死前的最后一波挣扎”。

- **接口**和**抽象类**的区别

  - **方法在接口中不能有实现**，而抽象类可以有非抽象方法。
  - 接口中除了static、final变量，不能有其他变量。
  - **一个类可以实现多个接口，但只能实现一个抽象类**。接口可以通过extends关键字扩展多个接口。
  - 接口方法默认是public，抽象方法可以有public、protected、default（不能使用private）。
  - 抽象类是对类的抽象，接口是对行为的抽象。

---

- 面对对象语言的特点：**封装**、**继承**、**多态**（指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。（发送消息就是函数调用））（引用变量指向哪个类的实例对象，引用对象发出的方法调用哪个类中的实现的方法，在程序运行期间才能确定）。

- JVM、JDK、JRE

  - **Java虚拟机(JVM)**实现**平台无关性**，是运行**Java字节码**（.class文件）的虚拟机。
  - .java源代码（通过JDK中的javac编译）.class字节码（通过JVM）机器码。
  - **JDK包括JRE**、javac、jdb等，能够创建和**编译程序**；**JRE**是**Java运行环境**，用于运行已编译的Java程序，包括JVM等。

- Java与C++的区别

  - Java**没有指针来直接访问内存**，访问内存更安全。
  - 有**自动内存管理机制**，不需要手动释放内存。
  - Java的类是**单继承**的，接口可以多继承，C++支持多继承。
  - Java字符串没有\0，因为Java里**一切都是对象**，可以确定长度。

- Java的接口和C++的虚类的相同和不同处

  - 由于Java不支持多继承，而有可能某个类或对象要使用分别在几个类或对象里面的方法或属性，现有的单继承机制就不能满足要求。
  - 与继承相比，接口有更高的灵活性，因为接口中没有任何实现代码。当一个类实现了接口以后，该类要实现接口里面所有的方法和属性。

  > [https://blog.csdn.net/chwshuang/article/details/46943711](<https://blog.csdn.net/chwshuang/article/details/46943711>)

  - C++虚类相当于java中的抽象类，一个子类只能继承一个抽象类（虚类），但能实现多个接口
  - 一个抽象类可以有构造方法，接口没有构造方法
  - 一个抽象类中的方法不一定是抽象方法，即其中的方法可以有实现（有方法体），接口中的方法都是抽象方法，不能有方法体，只有声明
  - 一个抽象类可以是public、private、protected、default，接口只有public
  - 一个抽象类中的方法可以是public、private、protected、default，接口中的方法只能是public和default
  - 相同之处是：都不能实例化。

- **构造器（private方法）**不能**重写**（override），但是可以**重载**（overload），一个类中可以有多个构造器。

- **重写**（override）和**重载**（overload）的区别

  - 方法的重写和重载都是实现多态的方式，区别在于前者实现的是运行的多态性，而后者实现的是编译时的多态性。

  - 重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，不能比父类被重写方法声明更多的异常（里氏代换原则）

  - 重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载。

  - 重载是否区分返回值类型？重载不根据返回类型进行区分。

  - Overloaded的方法是否可以改变返回值的类型？

    > [https://blog.csdn.net/singit/article/details/47722047](https://blog.csdn.net/singit/article/details/47722047)

    这个题目很模糊。如果几个Overloaded的方法的参数列表不一样，它们的返回者类型当然也可以不一样。但我估计你想问的问题是：如果两个方法的参数列表完全一样，是否可以让它们的返回值不同来实现重载Overload。这是不行的。

    我们可以用反证法来说明这个问题，因为我们有时候调用一个方法时也可以不定义返回结果变量，即不要关心其返回结果，例如，我们调用map.remove(key)方法时，虽然remove方法有返回值，但是我们通常都不会定义接收返回结果的变量，这时候假设该类中有两个名称和参数列表完全相同的方法，仅仅是返回类型不同，java就无法确定编程者倒底是想调用哪个方法了，因为它无法通过返回结果类型来判断。

- String、Stringbuffer、StringBuilder

  - **String**类中使用**final**关键字修饰字符数组来保存字符串，对象**不可变**，**线程安全**。
  - StringBuffer和StringBuilder构造方法调用父类AbstractStringBuffer实现，是**可变**的。
  - **StringBuffer**对方法加了**同步锁**，是**线程安全**的；**StringBuilder**没有加同步锁，非线程安全。
  - 底层实现上的话，StringBuffer其实就是比StringBuilder多了Synchronized修饰符。

- **装箱**：基本类型用对应的引用类型包装起来。

  **拆箱**：包装类型转换为基本数据类型。

- 静态方法内不能调用非静态成员，因为静态方法可以不通过对象进行调用。

- 不做事且没有参数的构造方法的作用：子类中没有用super()方法来调用父类特定的构造方法，**会调用父类中没有参数的构造方法**。

- **成员变量**和**局部变量**的区别

  - 成员变量属于类，局部变量是在方法中定义的变量或方法的参数；成员变量可以被public、private、static等修饰符修饰，局部变量不能被访问控制符及static所修饰；成员变量和局部变量都能被final修饰。
  - 成员变量如果使用static修饰属于类，否则属于实例。对象存在堆中，局部变量存在栈中，**静态变量存在方法区**。
  - 成员变量是对象的一部分，随着对象的创建而存在；局部变量随着方法的调用而自动消失。
  - 成员变量如果没有赋初值会自动赋默认值，局部变量不会自动赋值。

- 构造方法

  - 名字于类名相同。
  - 没有返回值，不能用void声明构造函数。
  - 生成类的对象时自动执行，无需调用。如果没有声明构造方法，会有默认的不带参数的构造函数。
  - 作用时完成堆类对象的初始化工作。

- **静态方法**和**实例方法**的区别

  - 在外部调用静态方法：类名.方法名、对象名.方法名；实例方法：对象名.方法名。
  - 静态方法在访问本类成员时，只允许访问静态成员（静态成员变量、静态方法），不允许访问实例成员变量和实例方法。

- 为什么**Java中只有值传递**

  - 例1

    ```java
    public static void main(String[] args) {
    	int[] arr = { 1, 2, 3, 4, 5 };
    	System.out.println(arr[0]);
    	change(arr);
    	System.out.println(arr[0]);
    }
    
    public static void change(int[] array) {
    	// 将数组的第一个元素变为0
    	array[0] = 0;
    }
    ```

    结果

    ```
    1
    0
    ```

    解析：**方法得到的是对象引用的拷贝，对象引用及对象引用的拷贝同时引用同一个对象**。

    ![example 2](https://camo.githubusercontent.com/b7bad9506150c29bb8d7debd3905bd7a71cd6611/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d32372f333832353230342e6a7067)

  - 例2

    ```java
    public class Test {
    
    	public static void main(String[] args) {
    		// TODO Auto-generated method stub
    		Student s1 = new Student("小张");
    		Student s2 = new Student("小李");
    		Test.swap(s1, s2);
    		System.out.println("s1:" + s1.getName());
    		System.out.println("s2:" + s2.getName());
    	}
    
    	public static void swap(Student x, Student y) {
    		Student temp = x;
    		x = y;
    		y = temp;
    		System.out.println("x:" + x.getName());
    		System.out.println("y:" + y.getName());
    	}
    }
    ```

    结果

    ```
    x:小李
    y:小张
    s1:小张
    s2:小李
    ```

    解析

    交换之前：

    ![img](https://camo.githubusercontent.com/9d6dd0313695d309280675cd3251b47432a28814/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d32372f38383732393831382e6a7067)

    交换之后：

    ![img](https://camo.githubusercontent.com/6bea9b0ed65609d699207ab787f631f7ba0a9246/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d32372f33343338343431342e6a7067)

    方法并没有改变存储在变量s1和s2中的对象引用。

  - 总结

    **Java中对对象采用的不是引用调用，对象引用是按值传递的**，因此一个方法不能让对象参数引用一个新的对象。

- Java中的异常处理

  - 异常类层次结构

    ![Java异常类层次结构图](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-2/Exception.png)

    **Throwable类**分为两个子类：**Exception（异常）**和**Error（错误）**。

    **Error是程序无法处理的错误**。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题。例如，Java虚拟机运行错误（Virtual MachineError），当 JVM 不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。

    **Exception是程序本身可以处理的异常**。Exception 类有一个重要的子类 **RuntimeException**。RuntimeException 异常由Java虚拟机抛出。**NullPointerException**（要访问的变量没有引用任何对象时，抛出该异常）、**ArithmeticException**（算术运算异常，一个整数除以0时，抛出该异常）和 **ArrayIndexOutOfBoundsException** （下标越界异常）。

  - 异常处理总结

    - **try 块：** 用于捕获异常。其后可接零个或多个catch块，如果没有catch块，则必须跟一个finally块。

    - **catch 块：** 用于处理try捕获到的异常。

    - **finally 块：** 无论是否捕获或处理异常，finally块里的语句都会被执行。当在try块或catch块中遇到return 语句时，finally语句块将在方法返回之前被执行。

    - **注意：** 当try语句和finally语句中都有return语句时，在方法返回之前，finally语句的内容将被执行，并且finally语句的返回值将会覆盖原始的返回值。以下代码如果调用 `f(2)`，返回值将是0，因为finally语句的返回值覆盖了try语句块的返回值。

      ```java
      public static int f(int value) {
          try {
              return value * value;
          } finally {
              if (value == 2) {
                  return 0;
              }
          }
      }
      ```

  - 请说明JAVA语言如何进行异常处理，关键字：throws,throw,try,catch,finally分别代表什么意义？在try块中可以抛出异常吗？

    - throw：用来明确地抛出一个“异常”。

    - throws：标明一个成员函数可能抛出的各种“异常”。
    - 可以在try里手动抛出异常，不过比较少见；也可以在try里嵌套try。

- transient关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复。transient只能修饰变量，不能修饰类和方法。

- 获取用键盘输入的方法

  - 通过 Scanner

    ```java
    Scanner input = new Scanner(System.in);
    String s  = input.nextLine();
    input.close();
    ```

  - 通过 BufferedReader

    ```java
    BufferedReader input = new BufferedReader(new InputStreamReader(System.in)); 
    String s = input.readLine(); 
    ```

- static、final

  - **final**关键字
    - **对于一个final变量，如果是基本数据类型的变量，其数值在初始化后不能更改；如果是引用类型的变量，在对其初始化之后不能再让它指向另一个对象。**
    - **用final修饰一个类时，表示这个类不能被继承。final类的所有成员方法都会被隐式指定final方法。**
    - 使用final方法有两个原因。
      - 把方法锁定，以防任何继承类修改它的含义。
      - 效率。在早期的Java实现版本中，会将final方法转为内嵌调用。类中的所有private方法都隐式地指定为final。
  - **static**关键字
    - **修饰成员变量和成员方法:** 被 static 修饰的成员属于类，不属于单个这个类的某个对象，被类中所有对象共享，可以并且建议通过类名调用。被static 声明的成员变量属于静态成员变量，**静态变量 存放在 Java 内存区域的方法区**。调用格式：`类名.静态变量名` `类名.静态方法名()`
    - **静态代码块:** 静态代码块定义在类中方法外, 静态代码块在非静态代码块之前执行(静态代码块—>非静态代码块—>构造方法)。 该类不管创建多少对象，静态代码块只执行一次.
    - **静态内部类（static修饰类的话只能修饰内部类）：** 静态内部类与非静态内部类之间存在一个最大的区别: 非静态内部类在编译完成之后会隐含地保存着一个引用，该引用是指向创建它的外围类，但是静态内部类却没有。没有这个引用就意味着：1. 它的创建是不需要依赖外围类的创建。2. 它不能使用任何外围类的非static成员变量和方法。
    - **静态导包(用来导入类中的静态资源，1.5之后的新特性):** 格式为：`import static` 这两个关键字连用可以指定导入某个类中的指定静态资源，并且不需要使用类名调用类中静态成员，可以直接使用类中静态成员变量和成员方法。

- 深拷贝、浅拷贝

  - **浅拷贝**：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝。
  - **深拷贝**：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容。

- Java和PHP/JavaScript、Python的区别

  > [https://www.zhihu.com/question/20377398](<https://www.zhihu.com/question/20377398>)
  >
  > [https://www.zhihu.com/question/19913979](<https://www.zhihu.com/question/19913979>)
  >
  > [https://www.zhihu.com/question/19918532](<https://www.zhihu.com/question/19918532>)
  >
  > [https://www.zhihu.com/question/20491745](<https://www.zhihu.com/question/20491745>)

  - Java 属于**强类型**（所有程序都是well behaved），是**静态类型**语言（在编译时拒绝ill behaved）。

  - PHP/JavaScript属于弱类型（不需要定义变量的类型），是动态类型语言（在运行时拒绝ill behaved）。
  - PHP/JavaScript数组的功能强大，可以当作map和list来用。
  - PHP主要用于服务器端，JavaScript主要用于网页端。
  - Java和Python的区别是静态类型和动态类型，**静态类型必须先声明再使用，动态则不需要声明**。
  - Python也是强类型。**强弱类型不是指是否需要定义，而是是一旦类型决定了，是否能随便转换。**

- 如何跳出多重循环

  - loop and a half
  - break

- 内部类可以引用他包含类的成员吗，如果可以，有没有什么限制吗？

  - 一个内部类对象可以访问创建它的外部类对象的内容。内部类如果不是static的，那么它可以访问创建它的外部类对象的所有属性内部类；如果是satic的，即为nested class，那么它只可以访问创建它的外部类对象的所有static属性

  - 完全可以。如果不是静态内部类，那没有什么限制！
    如果你把静态嵌套类当作内部类的一种特例，那在这种情况下不可以访问外部类的普通成员变量，而只能访问外部类中的静态成员。

- Static Nested Class 和 Inner Class的不同

  > [https://blog.csdn.net/zzy7075/article/details/50378366](<https://blog.csdn.net/zzy7075/article/details/50378366>)

  Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。而通常的内部类需要在外部类实例化后才能实例化。

- final, finally, finalize的区别

  - final 用于声明属性，方法和类，分别表示属性不可变，方法不可覆盖，类不可继承。
  - finally是异常处理语句结构的一部分，表示总是执行。
  - finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。

- extends 和super 泛型限定符

  > [https://blog.csdn.net/qq_40395278/article/details/88603655](<https://blog.csdn.net/qq_40395278/article/details/88603655>)

  - 在java泛型中，**？ 表示通配符，代表未知类型，< ? extends Object>表示上边界限定通配符，< ? super Object>表示下边界限定通配符。**

  - 通配符 与 T 的区别

    - **T：作用于模板上，用于将数据类型进行参数化**，不能用于实例化对象。 
    - **?：在实例化对象的时候，不确定泛型参数的具体类型时，可以使用通配符进行对象定义。**
    - < T > 等同于 < T extends Object>
    - < ? > 等同于 < ? extends Object>

  - 例一：**定义泛型类**，将key，value的数据类型进行< K, V >参数化，而不可以使用通配符。

    ```java
    public class Container<K, V> {
    	private K key;
    	private V value;
    
    	public Container(K k, V v) {
    		key = k;
    		value = v;
    	}
    }
    ```

  - 例二：**实例化泛型对象**，我们不能够确定eList存储的数据类型是Integer还是Long，因此我们使用List<? extends Number>定义变量的类型。

    ```java
    List<? extends Number> eList = null;
    eList = new ArrayList<Integer>();
    eList = new ArrayList<Long>();
    ```

    上界类型通配符（? extends）

    ```java
    List<? extends Number> eList = null;
    eList = new ArrayList<Integer>();
    Number numObject = eList.get(0); //语句1，正确
     
    //Type mismatch: cannot convert from capture#3-of ? extends Number to Integer
    Integer intObject = eList.get(0); //语句2，错误
     
    //The method add(capture#3-of ? extends Number) in the type List<capture#3-of ? extends Number> is not applicable for the arguments (Integer)
    eList.add(new Integer(1)); //语句3，错误
    ```

- 泛型

  泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。

- Query接口的list方法和iterate方法有什么区别？

  > [https://www.nowcoder.com/questionTerminal/e0f929dfaf6e46e4900b538b9c2134ea?orderByHotValue=1&page=1&onlyReference=false](<https://www.nowcoder.com/questionTerminal/e0f929dfaf6e46e4900b538b9c2134ea?orderByHotValue=1&page=1&onlyReference=false>)

  1. 返回的类型不一样，list返回List，iterate返回iterator

  1. 查询策略不同。获取数据的方式不一样，list会直接查询数据库，iterate会先到数据库中把id取出来，然后真正要遍历某个对象的时候先到缓存中找，如果找不到，以id为条件再发一条sql到数据库，这样如果缓存中没有数据，则查询数据库的次数为n+1 

  1. iterate会查询2级缓存，list只会缓存，但不会使用缓存（除非结合查询缓存）。  

  1. list中返回的list中每个对象都是原本的对象，iterate中返回的对象中仅包含了主键值

- 汉字能用char类型来表示吗，一个汉字占多少字节？

  char固定占用2个字节，用来储存Unicode字符。范围在065536。unicode编码字符集中包含了汉字，所以，char型变量中可以存储汉字。不过，如果某个特殊的汉字没有被包含在unicode编码字符集中，那么，这个char型变量中就不能存储这个特殊汉字。

  > [https://www.cnblogs.com/kingcat/archive/2012/10/16/2726334.html](https://www.cnblogs.com/kingcat/archive/2012/10/16/2726334.html)

  UTF-8 与UTF-16的区别

  UTF-16比较好理解,就是任何字符对应的数字都用两个字节来保存.我们通常对Unicode的误解就是把Unicode与UTF-16等同了.但是很显然如果都是英文字母这做有点浪费.明明用一个字节能表示一个字符为啥整两个啊.

  于是又有个UTF-8,这里的8非常容易误导人,8不是指一个字节,难道一个字节表示一个字符?实际上不是.当用UTF-8时表示一个字符是可变的,有可能是用一个字节表示一个字符,也可能是两个,三个.当然最多不能超过3个字节了.反正是根据字符对应的数字大小来确定.

## 容器

- List、Set、Map的区别

  - List：有序的多个对象。
    - **Arraylist：** Object数组
    - **Vector：** Object数组
    - **LinkedList：** 双向链表
  - Set：不允许重复的集合。
    - **HashSet（无序，唯一）:** 基于 HashMap 实现的，底层采用 HashMap 来保存元素
    - **LinkedHashSet：** LinkedHashSet 继承于 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 HashMap 实现一样，不过还是有一点点区别的
    - **TreeSet（有序，唯一）：** 红黑树(自平衡的排序二叉树)
  - Map：使用键值对存储。
  - Set和Map容器都有基于哈希存储和排序树的两种实现版本，基于哈希存储的版本理论存取时间复杂度为O(1)，而基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。

- Array和ArrayList的区别

  - Array可以包含基本类型和对象类型，ArrayList只能包含对象类型。
  - Array大小是固定的，ArrayList的大小是动态变化的。
  - ArrayList提供了更多的方法和特性，比如：addAll()，removeAll()，iterator()等等。

- ArrayList和LinkedList的区别

  - 都不保证线程安全。
  - 底层数据结构：**ArrayList底层使用的Object数组，LinkedList底层使用的是双向链表结构。**
  - 时间复杂度：ArrayList插入删除元素的时间复杂度为**O(n)**，取第 i 元素的时间复杂度为**O(1)**；LinkedList插入和删除的时间复杂度为**O(1)**，如果是要在指定位置i插入和删除元素的话，时间复杂度近似为**O(n)**因为需要先移动到指定位置再插入。
  - 是否支持快速随机访问：LinkedList不支持高效的随机元素访问，而 ArrayList 支持。
  - 内存空间占用： ArrayList的空 间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。

- ArrayList和Vector的区别

  - Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。
  - Arraylist不是同步的，所以在不需要保证线程安全时建议使用Arraylist。

- Map的分类

  - Map有4个实现类，HashMap、HashTable、LinkedHashMap、TreeMap。
  - Hashmap 是一个最常用的Map，它根据键的HashCode值存储数据,根据键可以直接获取它的值，具有**很快的访问速度**，遍历时，取得数据的顺序是完全随机的。 **HashMap最多只允许一条记录的键为Null；允许多条记录的值为 Null；HashMap不支持线程的同步**，即任一时刻可以有多个线程同时写HashMap；可能会导致数据的不一致。
  - **Hashtable**与 HashMap类似，它继承自Dictionary类，不同的是：**它不允许记录的键或者值为空；它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了 Hashtable在写入时会比较慢。**
  - LinkedHashMap 是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的.也可以在构造时用带参数，按照应用次数排序。
  - TreeMap实现SortMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。
  - 一般情况下，我们用的最多的是HashJDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）Map，在Map 中插入、删除和定位元素，HashMap 是最好的选择。但如果您要按**自然顺序**或自定义顺序遍历键，那么**TreeMap**会更好。如果需要**输出的顺序和输入的相同**，那么用**LinkedHashMap**可以实现,它还可以按读取顺序来排列.

- HashMap源码学习

  JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间。

  ```java
  public V put(K key, V value) {
      return putVal(hash(key), key, value, false, true);
  }

  final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                    boolean evict) {
      Node<K,V>[] tab; Node<K,V> p; int n, i;
      // table未初始化或者长度为0，进行扩容
      if ((tab = table) == null || (n = tab.length) == 0)
          n = (tab = resize()).length;
      // (n - 1) & hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)
      if ((p = tab[i = (n - 1) & hash]) == null)
          tab[i] = newNode(hash, key, value, null);
      // 桶中已经存在元素
      else {
          Node<K,V> e; K k;
          // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等
          if (p.hash == hash &&
              ((k = p.key) == key || (key != null && key.equals(k))))
                  // 将第一个元素赋值给e，用e来记录
                  e = p;
          // hash值不相等，即key不相等；为红黑树结点
          else if (p instanceof TreeNode)
              // 放入树中
              e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
          // 为链表结点
          else {
              // 在链表最末插入结点
              for (int binCount = 0; ; ++binCount) {
                  // 到达链表的尾部
                  if ((e = p.next) == null) {
                      // 在尾部插入新结点
                      p.next = newNode(hash, key, value, null);
                      // 结点数量达到阈值，转化为红黑树
                      if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                          treeifyBin(tab, hash);
                      // 跳出循环
                      break;
                  }
                  // 判断链表中结点的key值与插入的元素的key值是否相等
                  if (e.hash == hash &&
                      ((k = e.key) == key || (key != null && key.equals(k))))
                      // 相等，跳出循环
                      break;
                  // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表
                  p = e;
              }
          }
          // 表示在桶中找到key值、hash值与插入元素相等的结点
          if (e != null) { 
              // 记录e的value
              V oldValue = e.value;
              // onlyIfAbsent为false或者旧值为null
              if (!onlyIfAbsent || oldValue == null)
                  //用新值替换旧值
                  e.value = value;
              // 访问后回调
              afterNodeAccess(e);
              // 返回旧值
              return oldValue;
          }
      }
      // 结构性修改
      ++modCount;
      // 实际大小大于阈值则扩容
      if (++size > threshold)
          resize();
      // 插入后回调
      afterNodeInsertion(evict);
      return null;
  } 
  ```

  ```java
  public V get(Object key) {
      Node<K,V> e;
      return (e = getNode(hash(key), key)) == null ? null : e.value;
  }

  final Node<K,V> getNode(int hash, Object key) {
      Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
      if ((tab = table) != null && (n = tab.length) > 0 &&
          (first = tab[(n - 1) & hash]) != null) {
          // 数组元素相等
          if (first.hash == hash && // always check first node
              ((k = first.key) == key || (key != null && key.equals(k))))
              return first;
          // 桶中不止一个节点
          if ((e = first.next) != null) {
              // 在树中get
              if (first instanceof TreeNode)
                  return ((TreeNode<K,V>)first).getTreeNode(hash, key);
              // 在链表中get
              do {
                  if (e.hash == hash &&
                      ((k = e.key) == key || (key != null && key.equals(k))))
                      return e;
              } while ((e = e.next) != null);
          }
      }
      return null;
  }
  ```

  ```java
  final Node<K,V>[] resize() {
      Node<K,V>[] oldTab = table;
      int oldCap = (oldTab == null) ? 0 : oldTab.length;
      int oldThr = threshold;
      int newCap, newThr = 0;
      if (oldCap > 0) {
          // 超过最大值就不再扩充了，就只好随你碰撞去吧
          if (oldCap >= MAXIMUM_CAPACITY) {
              threshold = Integer.MAX_VALUE;
              return oldTab;
          }
          // 没超过最大值，就扩充为原来的2倍
          else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY && oldCap >= DEFAULT_INITIAL_CAPACITY)
              newThr = oldThr << 1; // double threshold
      }
      else if (oldThr > 0) // initial capacity was placed in threshold
          newCap = oldThr;
      else { 
          // signifies using defaults
          newCap = DEFAULT_INITIAL_CAPACITY;
          newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
      }
      // 计算新的resize上限
      if (newThr == 0) {
          float ft = (float)newCap * loadFactor;
          newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);
      }
      threshold = newThr;
      @SuppressWarnings({"rawtypes","unchecked"})
          Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
      table = newTab;
      if (oldTab != null) {
          // 把每个bucket都移动到新的buckets中
          for (int j = 0; j < oldCap; ++j) {
              Node<K,V> e;
              if ((e = oldTab[j]) != null) {
                  oldTab[j] = null;
                  if (e.next == null)
                      newTab[e.hash & (newCap - 1)] = e;
                  else if (e instanceof TreeNode)
                      ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                  else { 
                      Node<K,V> loHead = null, loTail = null;
                      Node<K,V> hiHead = null, hiTail = null;
                      Node<K,V> next;
                      do {
                          next = e.next;
                          // 原索引
                          if ((e.hash & oldCap) == 0) {
                              if (loTail == null)
                                  loHead = e;
                              else
                                  loTail.next = e;
                              loTail = e;
                          }
                          // 原索引+oldCap
                          else {
                              if (hiTail == null)
                                  hiHead = e;
                              else
                                  hiTail.next = e;
                              hiTail = e;
                          }
                      } while ((e = next) != null);
                      // 原索引放到bucket里
                      if (loTail != null) {
                          loTail.next = null;
                          newTab[j] = loHead;
                      }
                      // 原索引+oldCap放到bucket里
                      if (hiTail != null) {
                          hiTail.next = null;
                          newTab[j + oldCap] = hiHead;
                      }
                  }
              }
          }
      }
      return newTab;
  }
  ```

- HashMap的容量为什么是2的n次幂？

  > [https://blog.csdn.net/sybnfkn040601/article/details/73194613](https://blog.csdn.net/sybnfkn040601/article/details/73194613)

  用`h & (length - 1)`取代` h % length`，位运算取低位速度快。

- hashmap hash算法的具体实现，巧妙之处

  1. hashmap规定长度必定为2的n次方、如果指定的capacity不为2的n次方，会将其转换为>capacity的最小的2的次方数

  2. hash算法 hash = h ^ (h >>> 16)，保证了capacity较小时，能够将高16位和低16位的变化都反应到低位上，在计算下标时，高位和地位同时参与，使hash更加均匀分散，降低hash碰撞的概率

  3. put的时候会put到table[(n-1)&hash]，因为n为2的n次方，所以n-1导致低位全是1，便可以保证hash与上n-1得到的数组下标一定在0~n-1之间

  4. get的时候依然是直接用table[(n-1)&hash]

  所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。

  ```java
  static final int hash(Object key) {
      int h;
      // key.hashCode()：返回散列值也就是hashcode
      // ^ ：按位异或
      // >>>:无符号右移，忽略符号位，空位都以0补齐
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
  ```

- hashmap扩容resize怎么实现

  1、首先建立新数组newTable、为原数组的两倍

  2、将原数组hash到新数组中，hash & (newLength-1) ，

  3、如果原数组节点只有一个头节点，则hash到新数组直接放入

  4、如果原数组e是树节点，则将其split（保持顺序分裂成两个树节点TreeNode list、list过长则转化成树，不然则彻底转成node list）
  
  5、如果是链表，则保持原数组中链表的顺序，hash到新数组中

  > [https://segmentfault.com/a/1190000015812438?utm_source=tag-newest](https://segmentfault.com/a/1190000015812438?utm_source=tag-newest)

- hashmap扩容时每个entry需要再计算一次hash吗？

  > [https://blog.csdn.net/qq_27093465/article/details/52270519](https://blog.csdn.net/qq_27093465/article/details/52270519)

  还是原来的hash，`hash & oldCap`如果是0的话就是原索引，如果是1的话是原索引+oldCap

- jdk1.8之前并发操作hashmap时为什么会有死循环的问题

  > [https://juejin.im/post/5a66a08d5188253dc3321da0](https://juejin.im/post/5a66a08d5188253dc3321da0)

  在并发的情况，发生扩容时，可能会产生循环链表，在执行get的时候，会触发死循环，引起CPU的100%问题，所以一定要避免在并发环境下使用HashMap。

  > [https://blog.csdn.net/wthfeng/article/details/88972137](https://blog.csdn.net/wthfeng/article/details/88972137)

  Java 8虽然修复了死循环的BUG，但是HashMap 还是非线程安全类，仍然会产生数据丢失等问题。

- hashmap一个写，多个读并发会有线程安全问题吗，引申出fail-fast和iterator

  1、会导致数据读写不一致的问题、因为JMM(java内存模型)里线程只能先与自己的工作内存交互，之后才能与共享内存交互

  2、会导致fail-fast问题（这是java集合的一个错误检测机制）

  fail-fast：如果在集合迭代的过程中，iterator（迭代器）不知道集合发生了修改（add/remove）操作，就会报错

  如何实现遍历集合的同时进行修改：让iterator知道，即用iterator自带的remove方法：iterator.remove();

  modCount是集合通用的属性，只要集合发生了修改操作，modCount就会++，在获取迭代器的时候会将modCount赋值给ExpectedModCount，此时两者肯定相等，但是如果执行了修改操作，modCound就会++，两者不等，就会报错。

  1. 场景1：写线程唯一、读线程不确定，没有迭代操作。使用hashmap不会存在程序不安全，最多就是发生数据不一致性的问题。
  2. 场景2：写线程唯一、读线程不确定，有迭代操作，此时不能使用hashmap，会存在fastfail问题
  3. 场景3: 读写线程是同一个，且唯一，有迭代操作，此时注意不能通过集合方法remove或者add更改，只能通过iterator内方法来更新。不然会存在fastfail问题。

- **==**和**equals()**的区别

  - ==：判断两个对象的地址是不是相等。
  - equals()
    - 情况1：类没有覆盖equals()方法时，等价于==。
    - 情况2：覆盖类equals()方法，来比较两个对象的内容是否相等。

- **hashCode()**和**equals()**的区别

  - hashCode()的作用：获取散列码，实际上是一个int整数。
  - 为什么要有散列码？以“HashSet”如何检查重复为例：**当把对象加入HashSet时，HashSet会先计算散列码，如果没有相符的散列码，HashSet会假设对象没有重复出现，如果发现有相同散列码的对象，会调用equals()方法来检查对象是否真的相同。如果两者相同，HashSet就不会让它加入，否则就会重新散列到其他位置。这样就大大减少equals()的次数，提高执行速度。**
  - 相关规定
    - **如果两个对象相等，则散列码相同。**
    - 如果两个对象相等，则两个对象分别调用equals()方法都返回true。
    - 两个对象有相同的散列码，它们也不一定是相等的。
    - **equals()方法被覆盖过，则hashCode()方法也必须被覆盖**。
    - hashCode()的默认行为是对堆上的对象产生独特值，如果没有重写hashcode()，则同一个类的两个对象无论如何不会相等。

- 重写equals()是否需要重写hashcode()，不重写会有什么后果

  > [https://blog.csdn.net/xyh269/article/details/69171545](https://blog.csdn.net/xyh269/article/details/69171545)
  
  需要，不重写有可能两个对象相等但是hashcode不相等，HashMap中存在重复的键。

- HashMap的key可以是可变的对象吗

  > [https://www.cnblogs.com/0201zcr/p/4810813.html](https://www.cnblogs.com/0201zcr/p/4810813.html)

  运行时可能会出现找不到key的问题。

- 如果hashMap的key是一个自定义的类，怎么办？

  使用HashMap，如果key是自定义的类，就必须重写hashcode()和equals()。

- 覆盖equals是请遵守通用约定

  实现高质量equals方法的诀窍：

  1. 使用==操作符检查“参数是否为这个对象的引用”
  1. 使用instanceof操作符检查“参数是否为正确的类型”
  1. 把参数转换成正确的类型
  1. 对于该类中的每个“关键”域，检查参数中的域是否域该对象中对应的域相匹配（域的比较顺序可能会影响到equals方法的性能。为了获得最佳的性能，应该先比较最优可能不一致的域，或者是开销最低的域）
  1. 当你完成了equals方法之后，应该问自己三个问题：它是否是对称的、传递的、一致的？（**自反性、对称性、传递性、一致性、非空性**）

  告诫：

  - 覆盖equals时总要覆盖hashCode
  - 不要将equals声明中的Object对象替换为其他的类型

- 覆盖equals时总要覆盖hashCode

  如果equals时不覆盖hashCode：equals时hashCode不同，散列到不同的散列桶中找不到key

  简单的解决方法：

  1. 把某个非零的常数值，比如17，保存在一个名为result的int类型的变量中。

  2. 对于对象中每个关键域f（指equals方法中涉及的每个域），完成以下步骤：

    a. 为该域计算int类型的散列码c：

    i.boolean类型: `f?1:0`

    ii.byte, char, short, int: `(int)f`

    iii. long: `(int)(f^(f>>>32))`

    iv. float: `Float.floatToIntBits(f)`

    v. double: `Double.doubleToLongBits(f)`，然后按照步骤2.a.iii为得到的long类型值计算散列值

    vi. 对象引用：递归调用hashCode

    vii. 数组：把每一个元素当作单独的域来处理

    b. 按照公式把步骤2.a中计算得到的散列码c合并到result中：
    
    `result=31*result+c`

    注意：
    
    - 如果一个类是不可变的，并且计算散列码的开销也比较大，就应该开率把散列码缓存在对象内部。
    - 不要试图从散列码计算中排除掉一个对象的关键部分来提高性能。

- TreeMap的底层实现

  - TreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树，这样就可以保证当需要快速检索指定节点。

    红黑树的插入、删除、遍历时间复杂度都为O(lgN)，所以性能上低于哈希表。但是哈希表无法提供键值对的有序输出，红黑树因为是排序插入的，可以按照键的值的大小有序输出。

  - 红黑树性质：

    性质1：每个节点要么是红色，要么是黑色。

    性质2：根节点永远是黑色的。

    性质3：所有的叶节点都是空节点（即 null），并且是黑色的。

    性质4：每个红色节点的两个子节点都是黑色。（从每个叶子到根的路径上不会有两个连续的红色节点）

    性质5：从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点。

- 红黑树和平衡二叉树的区别、java中哪种数据结构实现了红黑树

  BST：二叉搜索树、不确保平衡、性能无法确保

  AVL：平衡二叉树，**严格平衡（每个节点的左右子树的高度差不超过1）**，搜索性能可以一直确保最佳，但是一旦有插入删除操作，就必须
  要进行旋转，来维持树的严格平衡，而旋转操作是非常耗时的。所以AVL使用于搜索操作多，而插入删除操作少的场景
  
  RBT：红黑树，**弱平衡（红黑树确保没有一条路径会比其他路径长出两倍）**，这样子的话一旦有插入删除操作，用于维持RBT规则的旋转操作次数就会很少。用非严格的平衡来换取增删节点时候旋转次数的降低。所以RBT适用于插入删除操作多的场景

  所以简单说，搜索的次数远远大于插入和删除，那么选择AVL树，如果搜索，插入删除次数几乎差不多，应该选择RB树

  java的TreeMap实现了红黑树

---

- ArrayList如何扩容和缩容

  1、扩容：直接是采用底层的System.copyOf()，创建一个新的大数组，将原来的数组内容copy到新数组中，然后返回新数组的引用

  2、缩容：trimToSize（）。如果实际size<数组长度，在内存紧张的情况下，会将数组缩小，采用的依然是System.copyOf()

- 如何用LinkedHashMap实现LRU？

  > [https://www.jianshu.com/p/d76a78086c3a](https://www.jianshu.com/p/d76a78086c3a)

  LinkedHashMap重写removeEldestEntry()方法，当前size()大于了cacheSize便删掉头部的元素
  
- 如何用TreeMap实现一致性hash？

  > 什么是一致性hash
  >
  > [https://zhuanlan.zhihu.com/p/34985026](https://zhuanlan.zhihu.com/p/34985026)

  > 自己实现一个一致性 Hash 算法
  >
  > [https://juejin.im/post/5abf8f3851882555731c42d1](https://juejin.im/post/5abf8f3851882555731c42d1)

  - 内部没有使用数组，而是使用了有序 Map。
  - put 方法中，对象如果没有落到缓存节点上，就找比他小的节点且离他最近的。这里我们使用了 TreeMap 的 tailMap 方法，具体 API 可以看文档。
  - get 方法中，和 put 步骤相同，否则是取不到对象的。

- HashMap和HashSet的区别

  - HashSet 底层就是基于 HashMap 实现的。

  - | HashMap                          | HashSet                                                      |
    | -------------------------------- | ------------------------------------------------------------ |
    | 实现了Map接口                    | 实现Set接口                                                  |
    | 存储键值对                       | 仅存储对象                                                   |
    | 调用 `put()`向map中添加元素      | 调用 `add()`方法向Set中添加元素                              |
    | HashMap使用键（Key）计算Hashcode | HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性 |

## 并发容器

- 并发容器

  **JDK 提供的并发容器总结**

  - ConcurrentHashMap: 线程安全的 HashMap
  - CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector.
  - ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。
  - BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。
  - ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。

  **CopyOnWriteArrayList**

  在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问 List 的内部数据，毕竟读取操作是安全的。

  这和我们之前在多线程章节讲过 ReentrantReadWriteLock 读写锁的思想非常类似，也就是读读共享、写写互斥、读写互斥、写读互斥。JDK 中提供了 CopyOnWriteArrayList 类比相比于在读写锁的思想又更进一步。为了将读取的性能发挥到极致，CopyOnWriteArrayList 读取是完全不用加锁的，并且更厉害的是：写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待。这样一来，读操作的性能就会大幅度提升。那它是怎么做的呢？

  CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。**当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。**

  从 CopyOnWriteArrayList 的名字就能看出CopyOnWriteArrayList 是满足CopyOnWrite 的 ArrayList，所谓CopyOnWrite 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。

  **读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。**

  CopyOnWriteArrayList **写入操作 add() 方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。**

  **ConcurrentLinkedQueue**

  Java 提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。

  从名字可以看出，ConcurrentLinkedQueue这个队列使用链表作为其数据结构．ConcurrentLinkedQueue 应该算是在高并发环境中性能最好的队列了。它之所有能有很好的性能，是因为其内部复杂的实现。

  ConcurrentLinkedQueue 内部代码我们就不分析了，大家知道 **ConcurrentLinkedQueue 主要使用 CAS 非阻塞算法**来实现线程安全就好了。

  ConcurrentLinkedQueue 适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 ConcurrentLinkedQueue 来替代。

  **BlockingQueue**

  上面我们己经提到了 ConcurrentLinkedQueue 作为高性能的非阻塞队列。下面我们要讲到的是阻塞队列——BlockingQueue。阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是 BlockingQueue 提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。

  BlockingQueue 是一个接口，继承自 Queue，所以其实现类也可以作为 Queue 的实现来使用，而 Queue 又继承自 Collection 接口。

  下面主要介绍一下:ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue，这三个 BlockingQueue 的实现类。

  - ArrayBlockingQueue

    ArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。ArrayBlockingQueue 一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。

    ArrayBlockingQueue 默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 ArrayBlockingQueue。而非公平性则是指访问 ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当 ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到 ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。

  - LinkedBlockingQueue

    LinkedBlockingQueue 底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE。

  - PriorityBlockingQueue

    PriorityBlockingQueue 是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 compareTo() 方法来指定元素排序规则，或者初始化时通过构造器参数 Comparator 来指定排序规则。

    PriorityBlockingQueue 并发控制采用的是 ReentrantLock，队列为无界队列（ArrayBlockingQueue 是有界队列，LinkedBlockingQueue 也可以通过在构造函数中传入 capacity 指定队列最大的容量，但是 PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。

    简单地说，它就是 PriorityQueue 的线程安全版本。不可以插入 null 值，同时，插入队列的对象必须是可比较大小的（comparable），否则报 ClassCastException 异常。它的插入操作 put 方法不会 block，因为它是无界队列（take 方法在队列为空的时候会阻塞）。
  
  **ConcurrentSkipListMap**

  使用跳表实现 Map 和使用哈希算法实现 Map 的另外一个不同之处是：哈希并不会保存元素的顺序，而跳表内所有的元素都是排序的。因此在对跳表进行遍历时，你会得到一个有序的结果。所以，如果你的应用需要有序性，那么跳表就是你不二的选择。JDK 中实现这一数据结构的类是 ConcurrentSkipListMap。

- 如何线程安全地遍历List：Vector、CopyOnWriteArrayList

  > [https://blog.csdn.net/xiao__gui/article/details/51050793](https://blog.csdn.net/xiao__gui/article/details/51050793)

  **Vector**

  Vector和ArrayList类似，是长度可变的数组，与ArrayList不同的是，Vector是线程安全的，它给几乎所有的public方法都加上了synchronized关键字。由于加锁导致性能降低，在不需要并发访问同一对象时，这种强制性的同步机制就显得多余，所以现在Vector已被弃用。

  **HashTable**
  
  HashTable和HashMap类似，不同点是HashTable是线程安全的，它给几乎所有public方法都加上了synchronized关键字，还有一个不同点是HashTable的K，V都不能是null，但HashMap可以，它现在也因为性能原因被弃用了。

  **Collections包装方法**
  
  Vector和HashTable被弃用后，它们被ArrayList和HashMap代替，但它们不是线程安全的，所以Collections工具类中提供了相应的包装方法把它们包装成线程安全的集合。

  ```java
  List<E> synArrayList = Collections.synchronizedList(new ArrayList<E>());

  Set<E> synHashSet = Collections.synchronizedSet(new HashSet<E>());

  Map<K,V> synHashMap = Collections.synchronizedMap(new HashMap<K,V>());
  ```

  Collections针对每种集合都声明了一个线程安全的包装类，在原集合的基础上添加了锁对象，集合中的每个方法都通过这个锁对象实现同步。

  **ConcurrentHashMap**
  
  ConcurrentHashMap和HashTable都是线程安全的集合，它们的不同主要是加锁粒度上的不同。HashTable的加锁方法是给每个方法加上synchronized关键字，这样锁住的是整个Table对象。而ConcurrentHashMap是更细粒度的加锁。

  在JDK1.8之前，ConcurrentHashMap加的是分段锁，也就是Segment锁，每个Segment含有整个table的一部分，这样不同分段之间的并发操作就互不影响。

  JDK1.8对此做了进一步的改进，它取消了Segment字段，直接在table元素上加锁，实现对每一行进行加锁，进一步减小了并发冲突的概率。

  **CopyOnWriteArrayList和CopyOnWriteArraySet**

  它们是加了写锁的ArrayList和ArraySet，锁住的是整个对象，但读操作可以并发执行

  除此之外还有ConcurrentSkipListMap、ConcurrentSkipListSet、ConcurrentLinkedQueue、ConcurrentLinkedDeque等，至于为什么没有ConcurrentArrayList，原因是无法设计一个通用的而且可以规避ArrayList的并发瓶颈的线程安全的集合类，只能锁住整个list，这用Collections里的包装类就能办到。

- 为什么java.util.concurrent 包里没有并发的ArrayList实现？

  > [http://ifeve.com/why-is-there-not-concurrent-arraylist-in-java-util-concurrent-package/](http://ifeve.com/why-is-there-not-concurrent-arraylist-in-java-util-concurrent-package/)

  在java.util.concurrent包中没有加入并发的ArrayList实现的主要原因是：**很难去开发一个通用并且没有并发瓶颈的线程安全的List。**

  **像ConcurrentHashMap这样的类的真正价值（The real point / value of classes）并不是它们保证了线程安全。而在于它们在保证线程安全的同时不存在并发瓶颈。举个例子，ConcurrentHashMap采用了锁分段技术和弱一致性的Map迭代器去规避并发瓶颈。**

  所以问题在于，像“Array List”这样的数据结构，你不知道如何去规避并发的瓶颈。**拿contains() 这样一个操作来说，当你进行搜索的时候如何避免锁住整个list？**

  另一方面，Queue 和Deque (基于Linked List)有并发的实现是因为他们的接口相比List的接口有更多的限制，这些限制使得实现并发成为可能。

  CopyOnWriteArrayList是一个有趣的例子，它规避了只读操作（如get/contains）并发的瓶颈，但是它为了做到这点，在修改操作中做了很多工作和修改可见性规则。 此外，修改操作还会锁住整个List，因此这也是一个并发瓶颈。所以从理论上来说，CopyOnWriteArrayList并不算是一个通用的并发List。

- ConcurrentHashMap和HashTable的区别

  - **底层数据结构：** JDK1.7的 ConcurrentHashMap 底层采用 **分段的数组+链表** 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。HasTable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 **数组+链表** 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；

  - **实现线程安全的方式（重要）：** 

    ① **在JDK1.7的时候，ConcurrentHashMap（分段锁）** 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 

    > ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。HashEntry 用来封装散列映射表中的键值对。**在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。**
    >
    >  在ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。**由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。**

    **到了 JDK1.8 的时候已经摒弃了Segment的概念，则是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化）** 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；

    ② **HashTable(同一把锁)** :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。

  - HashTable

    ![HashTable全表锁](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/HashTable%E5%85%A8%E8%A1%A8%E9%94%81.png)

  - JDK1.7的ConcurrentHashMap

    ![JDK1.7的ConcurrentHashMap](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ConcurrentHashMap%E5%88%86%E6%AE%B5%E9%94%81.jpg)

  - JDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）

    ![JDK1.8的ConcurrentHashMap](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JDK1.8-ConcurrentHashMap-Structure.jpg)

- ConcurrentHashmap读操作加锁吗，不加锁volatile修饰共享变量，为什么volatile能实现读操作线程安全

  不加锁，volatile能够保证内存可见性。

  当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。

  当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，线程接下来将从主内存中读取共享变量。

- ConcurrentHashMap如何做到get操作不加锁？

  get方法中将要使用的共享变量都定义成volatile类型，定义成volatile的变量，只能被单线程写，但能被多个线程同时读，在线程之间保持可见性，保证不会读到过期的值。在get操作中只需要读不需要写共享变量get和value，所以可以不用加锁，之所以不会读到过期的值，是因为JMM的happen before规则，对volatile字段的写先于读。

- **ConcurrentHashMap如何在resize中并发的插入、删除和查找**

  利用CAS+synchronized实现node节点粒度的并发

  resize的时候单线程构建一个nextTable（2倍原容量）、多线程扩容
  
  put的时候如果检测到需要插入的位置被forward节点占有，就帮助扩容、如果检测到的节点非空且不是forward节点，对节点加syn锁，进行节点插入
  
  get的时候不加锁，可多线程查找
  
  remove的时候如果检测到需要删除的位置被forward节点占有，就帮助扩容、如果不是，则对节点加syn锁，进行节点删除

- concurrentHashmap的size实现

  > [https://juejin.im/post/5ae75584f265da0b873a4810](https://juejin.im/post/5ae75584f265da0b873a4810)
  
  JDK 8 推荐使用mappingCount 方法，因为这个方法的返回值是 long 类型，不会因为 size 方法是 int 类型限制最大值（size 方法是接口定义的，不能修改）。

  在没有并发的情况下，使用一个 baseCount volatile 变量就足够了，当并发的时候，CAS 修改 baseCount 失败后，就会使用 CounterCell 类了，会创建一个这个对象，通常对象的 volatile value 属性是 1。在计算 size 的时候，会将 baseCount 和 CounterCell 数组中的元素的 value 累加，得到总的大小，但这个数字仍旧可能是不准确的。

- 快速失败(fail-fast)和安全失败(fail-safe)的区别

  > [https://blog.csdn.net/qq_31780525/article/details/77431970](<https://blog.csdn.net/qq_31780525/article/details/77431970>)

  - **在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。**

    - 原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。

    - 注意：这里异常的抛出条件是检测到 modCount!=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。

    - 场景：**java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。**

  - **采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。**

    - 原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。

    - 缺点：**基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。**

    - 场景：**java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。**

  - 快速失败和安全失败是对迭代器而言的。 

    - 快速失败：当在迭代一个集合的时候，如果有另外一个线程在修改这个集合，就会抛出ConcurrentModification异常，java.util下都是快速失败。
    - 安全失败：在迭代时候会在集合二层做一个拷贝，所以在修改集合上层元素不会影响下层。在java.util.concurrent下都是安全失败

---

- List、Set、Map是否继承自Collection接口？

  List、Set 是，Map 不是。Map是键值对映射容器，与List和Set有明显的区别，而Set存储的零散的元素且不允许有重复元素（数学中的集合也是如此），List是线性结构的容器，适用于按数值索引访问元素的情形。

- 常用集合类以及主要方法

  > [https://blog.csdn.net/zhj870975587/article/details/50996811](<https://blog.csdn.net/zhj870975587/article/details/50996811>)

  > 若要检查Collection中的元素，可以使用foreach进行遍历，也可以使用迭代器，Collection支持iterator()方法，通过该方法可以访问Collection中的每一个元素。Set和List是由Collection派生的两个接口。

  - **Collection接口**
    - **List接口**：LinkedList类、ArrayList类
    - Vector类
    - Stack类
    - **Set接口**：HashSet类、TreeSet类
    - Queue类

  - **Map接口**：HashTable类、HashMap类、TreeMap类、LinkedHashMap类

- Collection 和 Collections的区别

  - Collection是集合类的上级接口，继承与他的接口主要有Set 和List.
  - Collections是针对集合类的一个帮助类，他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。

- Iterator和ListIterator的区别

  - Iterator可用来遍历Set和List集合，但是ListIterator只能用来遍历List。Iterator对集合只能是前向遍历，ListIterator既可以前向也可以后向。
  - ListIterator实现了Iterator接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引，等等。

- 什么是迭代器？

  - Iterator提供了统一遍历操作集合元素的统一接口，Collection接口实现Iterable接口，每个集合都通过实现Iterable接口中iterator()方法返回Iterator接口的实例，然后对集合的元素进行迭代操作.
  - 有一点需要注意的是：在迭代元素的时候不能通过集合的方法删除元素，否则会抛出ConcurrentModificationException 异常. 但是可以通过Iterator接口中的remove()方法进行删除.

- 为什么集合类没有实现Cloneable和Serializable接口？

  - 克隆(cloning)或者是序列化(serialization)的语义和含义是跟具体的实现相关的。因此，应该由集合类的具体实现来决定如何被克隆或者是序列化。
  - 实现Serializable序列化的作用：将对象的状态保存在存储媒体中以便可以在以后重写创建出完全相同的副本；按值将对象从一个从一个应用程序域发向另一个应用程序域。
    实现 Serializable接口的作用就是可以把对象存到字节流，然后可以恢复。所以你想如果你的对象没有序列化，怎么才能进行网络传输呢？要网络传输就得转为字节流，所以在分布式应用中，你就得实现序列化。如果你不需要分布式应用，那就没必要实现实现序列化。

## 并发

- 多线程和java.util.concurrent并发包总结

  > [https://blog.csdn.net/jiyiqinlovexx/article/details/51175975](https://blog.csdn.net/jiyiqinlovexx/article/details/51175975)

  一、描述线程的类：Runable和Thread都属于java.lang包

  二、内置锁synchronized属于jvm关键字，内置条件队列操作接口Object.wait()/notify()/notifyAll()属于java.lang包

  二、提供内存可见性和防止指令重排的volatile属于jvm关键字

  四、而java.util.concurrent包(J.U.C)中包含的是java并发编程中有用的一些工具类，包括几个部分：

  1、collections部分：散落在java.util.concurrent包中，提供并发容器相关功能；

  2、atomic部分：包含在java.util.concurrent.atomic包中，提供原子变量类相关的功能，是构建非阻塞算法的基础；
  
  3、locks部分：包含在java.util.concurrent.locks包中，提供显式锁(互斥锁和速写锁)相关功能；

  4、tools部分：散落在java.util.concurrent包中，提供同步工具类，如信号量、闭锁、栅栏等功能；

  5、executor部分：散落在java.util.concurrent包中，提供线程池相关的功能；

- synchronized关键字

  - 说一说自己对于 synchronized 关键字的了解

    synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

    另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

  - 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗

    synchronized关键字最主要的三种使用方式：

    **修饰实例方法**: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁

    **修饰静态方法**: 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，**因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。**

    **修饰代码块**: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

    总结： **synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。**尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！

  - 讲一下 synchronized 关键字的底层原理

    synchronized 关键字底层原理属于 JVM 层面。

    ① synchronized 同步语句块的情况

    ```java
    public class SynchronizedDemo {
        public void method() {
            synchronized (this) {
                System.out.println("synchronized 代码块");
            }
        }
    }
    ```

    synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

    ② synchronized 修饰方法的的情况

    ```java
    public class SynchronizedDemo2 {
        public synchronized void method() {
            System.out.println("synchronized 方法");
        }
    }
    ```

    synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

  - 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗

    JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。

    锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

  - 谈谈 synchronized和ReentrantLock 的区别

    ① 两者都是可重入锁

    两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

    ② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API

    synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。

    ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。

    ③ ReentrantLock 比 synchronized 增加了一些高级功能

    相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）

    ReentrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。

    ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 

    ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。

    synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，**比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。** 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。

    如果你想使用上述功能，那么选择ReentrantLock是一个不错的选择。

    ④ 性能已不是选择标准

  - synchronized与java.util.concurrent.locks.Lock的相同之处和不同之处

    > [https://blog.csdn.net/qq838642798/article/details/65441415](<https://blog.csdn.net/qq838642798/article/details/65441415>)

    ReenTrantLock可重入锁（和synchronized的区别）总结

    **可重入性：**

    从名字上理解，ReenTrantLock的字面意思就是再进入的锁，其实synchronized关键字所使用的锁也是可重入的，两者关于这个的区别不大。两者都是同一个线程每进入一次，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

    **锁的实现：**

    **Synchronized是依赖于JVM实现的，而ReenTrantLock是JDK实现的**，有什么区别，说白了就类似于操作系统来控制实现和用户自己敲代码实现的区别。前者的实现是比较难见到的，后者有直接的源码可供阅读。

    **性能的区别：**

    在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。

    **功能区别：**

    便利性：很明显**Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放，而ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。**

    锁的细粒度和灵活度：很明显ReenTrantLock优于Synchronized

    **ReenTrantLock独有的能力：**

    1. **ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。**

    1. **ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的诸线程，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。**

    1. ReenTrantLock提供了一种能够**中断等待锁**的线程的机制，通过lock.lockInterruptibly()来实现这个机制。

    **ReenTrantLock实现的原理：**

    在网上看到相关的源码分析，本来这块应该是本文的核心，但是感觉比较复杂就不一一详解了，简单来说，ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。**想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。**

    **什么情况下使用ReenTrantLock：**

    答案是，如果你需要实现ReenTrantLock的三个独有功能时。

- volatile关键字

  **讲一下Java内存模型**

  在 JDK1.2 之前，Java的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4.png)

  要解决这个问题，就需要把变量声明为volatile，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。

  说白了， volatile 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%8F%AF%E8%A7%81%E6%80%A7.png)

  **说说 synchronized 关键字和 volatile 关键字的区别**

  synchronized关键字和volatile关键字比较

  volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。

  多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞。

  volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。

  volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。

- ThreadLocal

  **ThreadLocal简介**

  通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK中提供的ThreadLocal类正是为了解决这样的问题。 ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。

  如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get() 和 set() 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。

  再举个简单的例子：

  比如有两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来避免这两个线程竞争的。

  **ThreadLocal原理**

  最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。 ThrealLocal 类中可以通过Thread.currentThread()获取到当前线程对象后，直接通过getMap(Thread t)可以访问到该线程的ThreadLocalMap对象。

  每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为key的键值对。 比如我们在同一个线程中声明了两个 ThreadLocal 对象的话，会使用 Thread内部都是使用仅有那个ThreadLocalMap 存放数据的，**ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值。**

  **ThreadLocal 内存泄露问题**

  ThreadLocalMap 中使用的 **key 为 ThreadLocal 的弱引用,而 value 是强引用**。所以，**如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉**。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法。

  **弱引用介绍**

  如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。

  弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。

  **Java的四种引用类型**

  上面的分析可知，无论是通过引用计数还是可达性分析的判断都用到了引用，那么引用是否可以被回收就至关重要了，如果一个引用要么可以被回收，要么就不能被回收，那对于一些“可回收”的对象就无能无力了，jdk1.2之后扩充了引用的概念，将引用分为强引用（Strong Reference），软引用（Soft Reference），弱引用（Weak Reference），虚引用（Phantom Reference），四种引用引用的强度依次逐渐减弱。

  **强引用**：程序中的普通对象赋值就是强引用，只要引用还在垃圾回收器就永远不会回收被引用的对象。

  **软引用**：描述还有用但并非必须的对象，在系统将要发生内存溢出异常之前，将会把这些对象放入回收范围内进行二次回收，如果还没有足够内存，才抛出异常。

  **弱引用**：也是用来描述非必须对象，强度更弱，弱引用关联的对象只能生存到下一次垃圾收集发生之前，无论内存是否足够都会被回收掉。

  **虚引用**：一个对象是否有虚引用的存在，不会对其生存时间产生任何影响，也无法通过虚引用获取对象实例，虚引用的唯一一个目的就是能在对象被回收时收到一个系统通知。

- 线程池

  - 使用线程池的好处

    池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。

    线程池提供了一种限制和管理资源（包括执行一个任务）。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。

    这里借用《Java 并发编程的艺术》提到的来说一下使用线程池的好处：

    - **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
    - **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
    - **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

  - Executors 返回线程池对象的弊端如下：

    - FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。
    - CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。

  - 内存足够的情况下，线程池里的线程越多越好吗

    也不是线程越多，程序的性能就越好，因为线程之间的调度和切换也会浪费CPU时间。

  - 核心线程池ThreadPoolExecutor内部参数

    ThreadPoolExecutor 3 个最重要的参数：

    - **corePoolSize : 核心线程数定义了最小可以同时运行的线程数量。**
    - **maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。**
    - **workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，信任就会被存放在队列中。**

    ThreadPoolExecutor其他常见参数:

    - **keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；**
    - unit : keepAliveTime 参数的时间单位。
    - threadFactory :executor 创建新线程的时候会用到。
    - **handler :饱和策略。**

    ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%90%84%E4%B8%AA%E5%8F%82%E6%95%B0%E7%9A%84%E5%85%B3%E7%B3%BB.jpg)

    ThreadPoolExecutor 饱和策略定义:

    **如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了时，ThreadPoolTaskExecutor 定义一些策略:**

    - **ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。**
    - ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。
    - **ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。**
    - **ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。**

  - 线程池的运行流程，使用参数以及方法策略

    ![img](/img/post/线程池.jpg)

    ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png)

    > [https://blog.csdn.net/u011240877/article/details/73440993](https://blog.csdn.net/u011240877/article/details/73440993)

    1. 当前池中线程比核心数少，新建一个线程执行任务

    2. 核心池已满，但任务队列未满，添加到队列中

    3. 核心池已满，队列已满，试着创建一个新线程

  - 实现Runnable接口和Callable接口的区别

    Runnable自Java 1.0以来一直存在，但Callable仅在Java 1.5中引入,目的就是为了来处理Runnable不支持的用例。**Runnable 接口不会返回结果或抛出检查异常，但是Callable 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口，这样代码看起来会更加简洁。**

    工具类 Executors 可以实现 Runnable 对象和 Callable 对象之间的相互转换。（Executors.callable（Runnable task）或 Executors.callable（Runnable task，Object resule））。

  - 执行execute()方法和submit()方法的区别是什么呢？

    1. **execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否**；
    2. **submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功**，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

  - 线程池都有哪些状态

    1.**RUNNING**：这是最正常的状态，接受新的任务，处理等待队列中的任务。线程池的初始化状态是RUNNING。线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0。

    2.**SHUTDOWN**：不接受新的任务提交，但是会**继续处理等待队列中的任务**。**调用线程池的shutdown()方法时，线程池由RUNNING -> SHUTDOWN。**

    3.**STOP**：不接受新的任务提交，**不再处理等待队列中的任务，中断正在执行任务的线程**。**调用线程池的shutdownNow()方法时，线程池由(RUNNING or SHUTDOWN ) -> STOP。**

    4.**TIDYING**：所有的任务都销毁了，workCount 为 0，线程池的状态在转换为 TIDYING 状态时，会执行钩子方法 terminated()。因为terminated()在ThreadPoolExecutor类中是空的，所以用户想在线程池变为TIDYING时进行相应的处理；可以通过重载terminated()函数来实现。 

        当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -> TIDYING。

        当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -> TIDYING。

    5.**TERMINATED**：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -> TERMINATED。

- Atomic 原子类

  - 介绍一下Atomic 原子类

    Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

    所以，所谓原子类说简单点就是具有原子/原子操作特征的类。

  - JUC 包中的原子类是哪4类?

    **基本类型**

    使用原子的方式更新基本类型

    - AtomicInteger：整形原子类
    - AtomicLong：长整型原子类
    - AtomicBoolean：布尔型原子类
    
    **数组类型**

    使用原子的方式更新数组里的某个元素

    - AtomicIntegerArray：整形数组原子类
    - AtomicLongArray：长整形数组原子类
    - AtomicReferenceArray：引用类型数组原子类
    
    **引用类型**

    - AtomicReference：引用类型原子类
    - AtomicStampedReference：原子更新引用类型里的字段原子类
    - AtomicMarkableReference ：原子更新带有标记位的引用类型
    
    **对象的属性修改类型**

    - AtomicIntegerFieldUpdater：原子更新整形字段的更新器
    - AtomicLongFieldUpdater：原子更新长整形字段的更新器
    - AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

  - 能不能给我简单介绍一下 AtomicInteger 类的原理

    AtomicInteger 线程安全原理简单分析

    AtomicInteger 类的部分源码：

    ```java
    // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;

    static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
    }

    private volatile int value;
    ```
    
    AtomicInteger 类主要利用 **CAS (compare and swap) + volatile** 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

    **CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。**另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。

- AQS

  **AQS介绍**
  
  AQS 的全称为（AbstractQueuedSynchronizer），这个类在 java.util.concurrent.locks 包下面。

  AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask(jdk1.7) 等等皆是基于 AQS 的。当然，我们自己也能利用 AQS 非常轻松容易地构造出符合我们自己需求的同步器。

  **AQS原理**

  AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/Java%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%EF%BC%9A%E5%B9%B6%E5%8F%91%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93/CLH.png)

  **AQS 定义两种资源共享方式**

  1)Exclusive（独占）

  只有一个线程能执行，如 **ReentrantLock**。又可分为公平锁和非公平锁,ReentrantLock 同时支持两种锁,下面以 ReentrantLock 对这两种锁的定义做介绍：

  - **公平锁：按照线程在队列中的排队顺序，先到者先拿到锁**
  - **非公平锁：当线程要获取锁时，先通过两次 CAS 操作去抢锁，如果没抢到，当前线程再加入到队列中等待唤醒。**

  公平锁和非公平锁只有两处不同：

  1. 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。
  2. 非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。

  公平锁和非公平锁就这两点区别，如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。

  相对来说，非公平锁会有更好的性能，因为它的吞吐量比较大。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。

  2)Share（共享）

  多个线程可同时执行，如 Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。

  ReentrantReadWriteLock 可以看成是组合式，因为 ReentrantReadWriteLock 也就是读写锁允许多个线程同时对某一资源进行读。

  不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS 已经在上层已经帮我们实现好了。

  **Semaphore(信号量)-允许多个线程同时访问**

  synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。

  执行 acquire 方法阻塞，直到有一个许可证可以获得然后拿走一个许可证；每个 release 方法增加一个许可证，这可能会释放一个阻塞的 acquire 方法。然而，其实并没有实际的许可证这个对象，Semaphore 只是维持了一个可获得许可证的数量。 Semaphore 经常用于限制获取某种资源的线程数量。

  Semaphore 有两种模式，公平模式和非公平模式。

  - 公平模式： 调用 acquire 的顺序就是获取许可证的顺序，遵循 FIFO；
  - 非公平模式： 抢占式的。

  **CountDownLatch （倒计时器）**

  CountDownLatch 是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。在 Java 并发中，countdownlatch 的概念是一个常见的面试题，所以一定要确保你很好的理解了它。

  - CountDownLatch 的三种典型用法

    ① 某一线程在开始运行前等待 n 个线程执行完毕。将 CountDownLatch 的计数器初始化为 n ：new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减 1 countdownlatch.countDown()，当计数器的值变为 0 时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。

    ② 实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 ：new CountDownLatch(1)，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。

    ③ 死锁检测：一个非常方便的使用场景是，你可以使用 n 个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。
  
  - CountDownLatch 的不足

    CountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。
  
  **CyclicBarrier(循环栅栏)**

  CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。

  CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。

  CyclicBarrier 的应用场景

  CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个 Excel 保存了用户所有银行流水，每个 Sheet 保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个 sheet 里的银行流水，都执行完之后，得到每个 sheet 的日均银行流水，最后，再用 barrierAction 用这些线程的计算结果，计算出整个 Excel 的日均银行流水。

  **CyclicBarrier 和 CountDownLatch 的区别**

  下面这个是国外一个大佬的回答：

  CountDownLatch 是计数器，只能使用一次，而 CyclicBarrier 的计数器提供 reset 功能，可以多次使用。但是我不那么认为它们之间的区别仅仅就是这么简单的一点。我们来从 jdk 作者设计的目的来看，javadoc 是这么描述它们的：

  > CountDownLatch: A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.(**CountDownLatch: 一个或者多个线程，等待其他多个线程完成某件事情之后才能执行；**) CyclicBarrier : A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.(**CyclicBarrier : 多个线程互相等待，直到到达同一个同步点，再继续一起执行。**)

  对于 CountDownLatch 来说，重点是“一个线程（多个线程）等待”，而其他的 N 个线程在完成“某件事情”之后，可以终止，也可以等待。而对于 CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。

  CountDownLatch 是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而 CyclicBarrier 更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。

  **ReentrantLock 和 ReentrantReadWriteLock**

  ReentrantLock 和 synchronized 的区别在上面已经讲过了这里就不多做讲解。另外，需要注意的是：读写锁 ReentrantReadWriteLock 可以保证多个线程可以同时读，所以在读操作远大于写操作的时候，读写锁就非常有用了。

  **CyclicBarrier和CountDownLatch区别**

  > [https://blog.csdn.net/tolcf/article/details/50925145](<https://blog.csdn.net/tolcf/article/details/50925145>)

  | CountDownLatch                                               | CyclicBarrier                                                |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | 减计数方式                                                   | 加计数方式                                                   |
  | 计算为0时释放所有等待的线程                                  | 计数达到指定值时释放所有等待线程                             |
  | 计数为0时，无法重置                                          | 计数达到指定值时，计数置为0重新开始                          |
  | **调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响** | **调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞** |
  | 不可重复利用                                                 | 可重复利用                                                   |

  **如何让多个执行速度不同的线程跑到一个点上（同步）**

  **CyclicBarrier**

  **用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行**
  
  和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。

  CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它
  才叫做循环屏障。

  **CountDownLatch**

  **用来控制一个线程等待多个线程。**

  维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。

  **Semaphore**

  Semaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。

- 悲观锁和乐观锁

  > [https://snailclimb.gitee.io/javaguide/#/docs/essential-content-for-interview/%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E4%B9%8B%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81?id=2-cas%e7%ae%97%e6%b3%95](https://snailclimb.gitee.io/javaguide/#/docs/essential-content-for-interview/%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E4%B9%8B%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81?id=2-cas%e7%ae%97%e6%b3%95)

  **悲观锁**

  **总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁**（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之su前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

  **乐观锁**

  **总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁**，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用**版本号机制和CAS算法**实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.**atomic**包下面的**原子变量类**就是使用了乐观锁的一种实现方式**CAS**实现的。

  **两种锁的使用场景**

  从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，**像乐观锁适用于写比较少的情况下（多读场景）**，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以**一般多写的场景下用悲观锁就比较合适**。

  **乐观锁常见的两种实现方式**

  > 乐观锁一般会使用版本号机制或CAS算法实现。

  1. 版本号机制

      一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

      举一个简单的例子： 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。

      1. 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。
      2. 在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。
      3. 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
      4. 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。

      这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。

  2. CAS算法

      即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数

      - 需要读写的内存值 V
      - 进行比较的值 A
      - 拟写入的新值 B
      
      当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。

      > [https://blog.csdn.net/qq_34337272/article/details/81252853](https://blog.csdn.net/qq_34337272/article/details/81252853)
      
      自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。

      ```java
      public class SpinLock {
          private AtomicReference<Thread> cas = new AtomicReference<Thread>();
          public void lock() {
              Thread current = Thread.currentThread();
              // 利用CAS
              while (!cas.compareAndSet(null, current)) {
                  // DO nothing
              }
          }
          public void unlock() {
              Thread current = Thread.currentThread();
              cas.compareAndSet(current, null);
          }
      }
      ```

      > [https://blog.csdn.net/bohu83/article/details/51124065](https://blog.csdn.net/bohu83/article/details/51124065)

      ```java
      /** 
      * Atomically sets the value to the given updated value 
      * if the current value {@code ==} the expected value. 
      * 
      * @param expect the expected value 
      * @param update the new value 
      * @return true if successful. False return indicates that 
      * the actual value was not equal to the expected value. 
      */  
      public final boolean compareAndSet(int expect, int update) {  
          return unsafe.compareAndSwapInt(this, valueOffset, expect, update);  
      } 
      ```

  **乐观锁的缺点**

  > ABA 问题是乐观锁一个常见的问题

  1. **ABA 问题**

      如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。

      JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

  2. **循环时间长开销大**

      **自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。** 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

  3. 只能保证一个共享变量的原子操作

      CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。
  
  **CAS与synchronized的使用情景**

  > **简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多）**

  1. 对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。
  2. 对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。

  补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。

- 多线程

  - 什么是线程和进程?

    **何为进程?**

    进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

    在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。

    **何为线程?**
    
    线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

  - 程序计数器为什么是私有的?

    程序计数器主要有下面两个作用：

    字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。

    在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

    需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。

    所以，程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。

  - 虚拟机栈和本地方法栈为什么是私有的?

    虚拟机栈： 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。

    本地方法栈： 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

    所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。

  - 为什么要使用多线程呢?

    先从总体上来说：

    从计算机底层来说： 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。

    从当代互联网发展趋势来说： 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。

    再深入到计算机底层来探讨：

    单核时代： 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。

    多核时代: 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。

  - 线程的生命周期和状态

    **Java线程的状态：新建New（线程被构建）、可运行Runnable（运行中Running、就绪Ready）、阻塞Blocked（线程阻塞于锁）、等待Waiting（当前线程需要等待其他线程的消息）、超时等待TimeWaiting（在等待状态的基础上增加了超时限制，在指定时间自动回到Runnable）、终止Terminated**

    ![Java线程的状态](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png)

    ![Java线程状态变迁](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%20%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E8%BF%81.png)

    由上图可以看出：线程创建之后它将处于 NEW（新建） 状态，调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 RUNNING（运行） 状态。

    > 操作系统隐藏 Java 虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态，所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。

    当线程执行 wait()方法之后，线程进入 WAITING（等待） 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。
  
  - 什么是上下文切换?

    多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。

    概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换。**

    上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。

    Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。

  - 说说 sleep() 方法和 wait() 方法区别和共同点?

    两者最主要的区别在于：**sleep 方法没有释放锁，而 wait 方法释放了锁**。
    两者都可以暂停线程的执行。

    Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。

    wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。
    
  - 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

    new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

    总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。

- 创建线程有几种不同的方式？你喜欢哪一种？为什么？

  > [https://blog.csdn.net/u012973218/article/details/51280044](<https://blog.csdn.net/u012973218/article/details/51280044>)

  1. 继承Thread类创建线程类

     ```java
     public class FirstThreadTest extends Thread {  
         int i = 0;  
         //重写run方法，run方法的方法体就是现场执行体  
         public void run() {  
             for(;i<100;i++) {  
                 System.out.println(getName()+"  "+i);  
             }  
         }  
         public static void main(String[] args) {  
             for(int i = 0;i< 100;i++) {  
                 System.out.println(Thread.currentThread().getName()+"  : "+i);  
                 if(i==20) {  
                     new FirstThreadTest().run();  
                     new FirstThreadTest().run();  
                 }  
             }  
         }   
     }
     ```

  2. 通过Runable接口创建线程类

     ```java
     public class RunnableThreadTest implements Runnable {  
         private int i;  
         public void run() {  
             for(i = 0;i <100;i++) {  
                 System.out.println(Thread.currentThread().getName()+" "+i);  
             }  
         }  
         public static void main(String[] args) {  
             for(int i = 0;i < 100;i++) {  
                 System.out.println(Thread.currentThread().getName()+" "+i);  
                 if(i==20) {  
                     RunnableThreadTest rtt = new RunnableThreadTest();  
                     new Thread(rtt,"新线程1").start();  
                     new Thread(rtt,"新线程2").start();  
                 }  
             }  
         }  
     }
     ```

  3. 通过Callable接口和FutureTask对象创建线程

     a. 创建Callable接口的实现类，并实现call()方法；

     b. 创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callback对象的call()方法的返回值；

     c. 使用FutureTask对象作为Thread对象的target创建并启动新线程；

     d. 调用FutureTask对象的get()方法来获得子线程执行结束后的返回值。

     ```java
     import java.util.concurrent.Callable;  
     import java.util.concurrent.ExecutionException;  
     import java.util.concurrent.FutureTask;  
       
     public class CallableThreadTest implements Callable<Integer> {  
       
         public static void main(String[] args) {  
             CallableThreadTest ctt = new CallableThreadTest();  
             FutureTask<Integer> ft = new FutureTask<Integer>(ctt);  
     //        Thread thread = new Thread(ft,"有返回值的线程");
     //        thread.start();
             for(int i = 0;i < 100;i++) {  
                 System.out.println(Thread.currentThread().getName()+" 的循环变量i的值"+i);  
                 if(i==20) {  
                     new Thread(ft,"有返回值的线程").start();  
                 }  
             }  
             try {  
                 System.out.println("子线程的返回值："+ft.get());  
             } catch (InterruptedException e) {  
                 e.printStackTrace();  
             } catch (ExecutionException e) {  
                 e.printStackTrace();  
             }  
         }  
       
         @Override  
         public Integer call() throws Exception {  
             int i = 0;  
             for(;i<100;i++) {  
                 System.out.println(Thread.currentThread().getName()+" "+i);  
             }  
             return i;  
         }  
     } 
     ```

  4. 通过线程池创建线程

     ```java
     import java.util.concurrent.ExecutorService;
     import java.util.concurrent.Executors;
     
     public class ThreadPool {
     	/* POOL_NUM */
     	private static int POOL_NUM = 10;
     	
     	/**
     	 * Main function
     	 */
     	public static void main(String[] args) {
     		ExecutorService executorService = Executors.newFixedThreadPool(5);
     		for(int i = 0; i<POOL_NUM; i++) {
     			RunnableThread thread = new RunnableThread();
     			executorService.execute(thread);
     		}
     	}
     }
      
     class RunnableThread implements Runnable {
     	private int THREAD_NUM = 10;
     	public void run() {
     		for(int i = 0; i<THREAD_NUM; i++) {
     			System.out.println("线程" + Thread.currentThread() + " " + i);
     		} 
     	}
     }
     ```

- Java多线程回调是什么意思？

  > [https://blog.csdn.net/wenzhi20102321/article/details/52512536](<https://blog.csdn.net/wenzhi20102321/article/details/52512536>)

  所谓回调，就是客户程序C调用服务程序S中的某个方法A，然后S又在某个时候反过来调用C中的某个方法B，对于C来说，这个B便叫做回调方法。

  - 回答者(S)

  ```java
  package com.xykj.thread;
  public class XiaoZhang extends Thread {
      // 回答1+1，很简单的问题不需要线程
      public int add(int num1, int num2) {
         return num1 + num2;
      }
   
      // 重写run方法
      @Override
      public void run() {
         // 回答地球为什么是圆的
         askquestion();
         super.run();
      }
   
      // 回调接口的创建，里面要有一个回调方法
      //回调接口什么时候用呢？这个思路是最重要的   
      public static interface CallPhone {
         public void call(String question);
      }
   
      // 回调接口的对象
      CallPhone callPhone;
   
      // 回答地球为什么是圆的
      private void askquestion() {
         System.err.println("开始查找资料！");
         try {
             sleep(3000);// 思考3天
         } catch (InterruptedException e) {
             e.printStackTrace();
         }
         // 把答案返回到回调接口的call方法里面
         if (callPhone!=null) {//提问者实例化callPhone对象，相当于提问者已经告诉我，我到时用什么方式回复答案
             //这个接口的方法实现是在提问者的类里面
             callPhone.call("知道了，！！！~~~~百度有啊");
         }     
      }
  }
  ```

  - 提问者(C)

  ```java
  package com.xykj.thread;
  import com.xykj.thread.XiaoZhang.CallPhone;
  public class MainClass {
      /**
       * java回调方法的使用
       * 实际操作时的步骤：（以本实例解释）
       * 1.在回答者的类内创建回调的接口
       * 2.在回答者的类内创建回调接口的对象，
       * 3.在提问者类里面实例化接口对象，重写接口方法
       * 2.-3.这个点很重要，回调对象的实例化，要在提问者的类内实例化，然后重写接口的方法
       * 相当于提问者先把一个联络方式给回答者，回答者找到答案后，通过固定的联络方式，来告诉提问者答案。
       * 4.调用开始新线程的start方法
       * 5.原来的提问者还可以做自己的事
       * */
      public static void main(String[] args) {
         // 小王问小张1+1=？，线程同步
         XiaoZhang xiaoZhang = new XiaoZhang();
         int i = xiaoZhang.add(1, 1);//回答1+1的答案
   
         // 问小张地球为什么是圆的？回调方法的使用
         //这相当于先定好一个返答案的方式，再来执行实际操作
        
         // 实例化回调接口的对象
         CallPhone phone = new CallPhone() {
             @Override
             public void call(String question) {
                //回答问题者，回答后，才能输出答案
                System.err.println(question);
             }
         };
        
         //把回调对象赋值给回答者的回调对象，回答问题者的回调对象才能回答问题
         xiaoZhang.callPhone = phone;
        
         System.out.println("交代完毕！");
         //相关交代完毕之后再执行查询操作
         xiaoZhang.start();
        
         //小王做自己的事！
         System.out.println("小王做自己的事！");
      }
   
  }
  ```

- java中**线程通信**协作有哪些方式

  1、synchronized加锁的线程的Object类的wait、notify方法

  2、lock加锁的Condition条件类的await、signal方法

  3、Thread中的join方法

  4、while条件轮询（类似自旋锁）

  5、管道通信（字节流、字符流）

  > [https://blog.csdn.net/do168/article/details/51745441](https://blog.csdn.net/do168/article/details/51745441)

  - 管道、消息队列、共享内存
  - **sychronized加锁的线程中Object类的wait、notify方法**
  - **Thread类中的join方法**
  - CAS
  - **countdownlatch, cyclicbarrier, semaphore**

- 协程

  > [https://www.cnblogs.com/lxmhhy/p/6041001.html](https://www.cnblogs.com/lxmhhy/p/6041001.html)

  **协程是一种用户态的轻量级线程，协程的调度完全由用户控制。**协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

- 当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？

  不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的synchronized修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。

- 线程同步和线程调度的相关方法

  - wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；
  - sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理InterruptedException异常；
  - notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关；
  - notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；
  - 通过Lock接口提供了显式的锁机制（explicit lock），增强了灵活性以及对线程的协调。Lock接口中定义了加锁（lock()）和解锁（unlock()）的方法，同时还提供了newCondition()方法来产生用于线程之间通信的Condition对象；此外，Java 5还提供了信号量机制（semaphore），信号量可以用来限制对某个共享资源进行访问的线程的数量。在对资源进行访问之前，线程必须得到信号量的许可（调用Semaphore对象的acquire()方法）；在完成对资源的访问后，线程必须向信号量归还许可（调用Semaphore对象的release()方法）。

- 线程的sleep()方法和yield()方法有什么区别？

  ① sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会；

  ② 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态；

  ③ sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常；

  ④ sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性。

  > [https://www.jianshu.com/p/25e959037eed](<https://www.jianshu.com/p/25e959037eed>)

  Java中wait、sleep的区别或者Java中sleep、yield的区别是Java面试或者多线程面试中最常问的问题之一。在这3个在Java中能够用来暂停线程的方法中，sleep()和yield()方法是定义在Thread类中，而wait()方法是定义在Object类中的， 这也是面试中常问的一个问题。

  wait()和sleep()的关键的区别在于，**wait()是用于线程间通信的，而sleep()是用于短时间暂停当前线程。**更加明显的一个区别在于，**当一个线程调用wait()方法的时候，会释放它锁持有的对象的管程和锁，但是调用sleep()方法的时候，不会释放他所持有的管程。**

  回到**yield()方法**上来，与wait()和sleep()方法有一些区别，它**仅仅释放线程所占有的CPU资源，从而让其他线程有机会运行，但是并不能保证某个特定的线程能够获得CPU资源。谁能获得CPU完全取决于调度器，在有些情况下调用yield方法的线程甚至会再次得到CPU资源。所以，依赖于yield方法是不可靠的，它只能尽力而为。**

  - Java中wait和sleep的区别

    wait和sleep的主要区别是调用wait方法时，线程在等待的时候会释放掉它所获得的monitor，但是调用Thread.sleep()方法时，线程在等待的时候仍然会持有monitor或者锁。另外，Java中的wait方法应在同步代码块中调用，但是sleep方法不需要。
    **另一个区别是Thread.sleep()方法是一个静态方法，作用在当前线程上；但是wait方法是一个实例方法，并且只能在其他线程调用本实例的notify()方法时被唤醒。**另外，使用sleep方法时，被暂停的线程在被唤醒之后会立即进入就绪态（Runnable state)，但是使用wait方法的时候，被暂停的线程会首先获得锁（译者注：阻塞态），然后再进入就绪态。所以，根据你的需求，如果你需要暂定你的线程一段特定的时间就使用sleep()方法，如果你想要实现线程间通信就使用wait()方法。
    下面列出Java中wait和sleep方法的区别：

    1. wait只能在同步（synchronize）环境中被调用，而sleep不需要。详见[Why to wait and notify needs to call from synchronized method](https://link.jianshu.com/?t=http%3A%2F%2Fjavarevisited.blogspot.com%2F2011%2F05%2Fwait-notify-and-notifyall-in-java.html)
    2. 进入wait状态的线程能够被notify和notifyAll线程唤醒，但是进入sleeping状态的线程不能被notify方法唤醒。
    3. wait通常有条件地执行，线程会一直处于wait状态，直到某个条件变为真。但是sleep仅仅让你的线程进入睡眠状态。
    4. wait方法在进入wait状态的时候会释放对象的锁，但是sleep方法不会。
    5. wait方法是针对一个被同步代码块加锁的对象，而sleep是针对一个线程。更详细的讲解可以参考《Java核心技术卷1》，里面介绍了如何使用wait和notify方法。

  - yield和sleep的区别

    yield和sleep的区别主要是，**yield方法会临时暂停当前正在执行的线程，来让有同样优先级的正在等待的线程有机会执行。如果没有正在等待的线程，或者所有正在等待的线程的优先级都比较低，那么该线程会继续运行。**执行了yield方法的线程什么时候会继续运行由线程调度器来决定，不同的厂商可能有不同的行为。**yield方法不保证当前的线程会暂停或者停止，但是可以保证当前线程在调用yield方法时会放弃CPU。**
    在Java中Sleep方法有两个， 一个只有一个毫秒参数，另一个有毫秒和纳秒两个参数。

    ```java
    sleep(long millis)
    ```

    or

    ```java
    sleep(long millis, int nanos)
    ```

    会让当前执行的线程sleep指定的时间。

    下面这张图很好地展示了在调用wait、sleep、yield方法的时候，线程状态如何转换。

    ![img](https://upload-images.jianshu.io/upload_images/66827-780462c52b8f5a83.png?imageMogr2/auto-orient/strip\|imageView2/2/w/1100/format/webp)

    Java中sleep方法的几个注意点：

    1. Thread.sleep()方法用来暂停线程的执行，将CPU放给线程调度器。
    2. Thread.sleep()方法是一个静态方法，它暂停的是当前执行的线程。
    3. Java有两种sleep方法，一个只有一个毫秒参数，另一个有毫秒和纳秒两个参数。
    4. 与wait方法不同，sleep方法不会释放锁
    5. 如果其他的线程中断了一个休眠的线程，sleep方法会抛出Interrupted Exception。
    6. 休眠的线程在唤醒之后不保证能获取到CPU，它会先进入就绪态，与其他线程竞争CPU。
    7. 有一个易错的地方，当调用t.sleep()的时候，会暂停线程t。这是不对的，因为Thread.sleep是一个静态方法，它会使当前线程而不是线程t进入休眠状态。

    这就是java中的sleep方法。我们已经看到了java中sleep、wait以及yield方法的区别。总之，记住sleep和yield作用于当前线程。

- 第一个 问题：Java中有几种方法可以实现一个线程？

  第二个问题：用什么关键字修饰同步方法?  

  第三个问题：stop()和suspend()方法为何不推荐使用，请说明原因？

  > [https://blog.csdn.net/Amen_Wu/article/details/54025804](<https://blog.csdn.net/Amen_Wu/article/details/54025804>)

  - **多线程有两种实现方法，分别是继承Thread类与实现Runnable接口。**

  - **用synchronized关键字修饰同步方法。（同步的实现方面有两种，分别是synchronized, wait与notify.）**

  - **反对使用stop()，是因为它不安全。它会解除由线程获取的所有锁定**，而且如果对象处于一种不连贯状态，那么其他线程能在那种状态下检查和修改它们。结果很难检查出真正的问题所在。

    **suspend()方法容易发生死锁。调用suspend()的时候，目标线程会停下来，但却仍然持有在这之前获得的锁定。**此时，其他任何线程都不能访问锁定的资源，除非被”挂起”的线程恢复运行。对任何线程来说，如果它们想恢复目标线程，同时又试图使用任何一个锁定的资源，就会造成死锁。

    所以不应该使用suspend()，而应在自己的Thread类中置入一个标志，指出线程应该活动还是挂起。若标志指出线程应该挂起，便用 wait()命其进入等待状态。若标志指出线程应当恢复，则用一个notify()重新启动线程。

- 启动一个线程是用run()还是start()?

  > [https://blog.csdn.net/wang_xing1993/article/details/70257475](<https://blog.csdn.net/wang_xing1993/article/details/70257475>)

  启动线程肯定要用start()方法。当用start()开始一个线程后，线程就进入就绪状态，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM调度并执行。这并不意味着线程就会立即运行。当cpu分配给它时间时，才开始执行run()方法(如果有的话)。start()是方法,它调用run()方法.而run()方法是你必须重写的. run()方法中包含的是线程的主体。

- 在监视器(Monitor)内部，是如何做到线程同步的？在程序又应该做哪种级别的同步呢？

  > [https://www.nowcoder.com/questionTerminal/26fc16a2a85e49a5bd5fc2b5759dbbc2](https://www.nowcoder.com/questionTerminal/26fc16a2a85e49a5bd5fc2b5759dbbc2)

  在 java 虚拟机中, 每个对象( Object 和 class )通过某种逻辑关联监视器,每个监视器和一个对象引用相关联, 为了实现监视器的互斥功能, 每个对象都关联着一把锁。
 
  一旦方法或者代码块被 synchronized 修饰, 那么这个部分就放入了监视器的监视区域, 确保一次只能有一个线程执行该部分的代码, 线程在获取锁之前不允许执行该部分的代码。
  
  另外 java 还提供了显式监视器( Lock )和隐式监视器( synchronized )两种锁方案。

- 同步方法和同步代码块的区别是什么？

  同步方法默认用this或者当前类class对象作为锁；
  同步代码块可以选择以什么来加锁，比同步方法要更细颗粒度，我们可以选择只同步会发生同步问题的部分代码而不是整个方法。

- 什么是生产者消费者模式？

  ![img](https://uploadfiles.nowcoder.com/images/20180925/308572_1537880635592_7142B8354CA8A352B2B805F997C71549)

  生产者消费者问题是线程模型中的经典问题：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者取走数据。

- 线程安全有哪些实现方式

  1、同步方案：互斥同步（阻塞同步）：**synchronized和lock**

  非阻塞同步（乐观锁）：**CAS**

  2、无同步方案：不可变对象（本身就是线程安全的，因为不能修改。比如final、String、enum（枚举））

  栈封闭（多线程访问一个方法的局部变量，不会有问题，因为虚拟机栈是线程私有的）

  线程本地存储（**ThreadLocal**，线程局部变量）

  可重入代码（纯代码，可以在代码执行的任何时刻中断，转而去执行其他代码，返回之后，不会出现程序错误）

  （特征：不依赖堆等共享资源，用到的状态变量全部由参数传入，不调用不可重入的代码）

- 实现多线程同步的方法

  > [https://www.cnblogs.com/xhjt/p/3897440.html](<https://www.cnblogs.com/xhjt/p/3897440.html>)

  1. **同步方法**

     即有synchronized关键字修饰的方法。由于java的每个对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

     代码如：

     ```java
     public synchronized void save(){}
     ```

     注： synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类

  2. **同步代码块**

     即有synchronized关键字修饰的语句块。被该关键字修饰的语句块会自动被加上内置锁，从而实现同步。

     代码如：

     ```java
     synchronized(object){}
     ```

     注：同步是一种高开销的操作，因此应该尽量减少同步的内容。通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可。

     代码实例：

     ```java
     package com.xhj.thread;
     
     /**
       * 线程同步的运用
       */
     public class SynchronizedThread {
     
         class Bank {
     
             private int account = 100;
     
             public int getAccount() {
                 return account;
             }
     
             /**
               * 用同步方法实现
               * 
               * @param money
               */
             public synchronized void save(int money) {
                 account += money;
             }
     
             /**
               * 用同步代码块实现
               * 
               * @param money
               */
             public void save1(int money) {
                 synchronized (this) {
                     account += money;
                 }
             }
         }
     
         class NewThread implements Runnable {
             private Bank bank;
     
             public NewThread(Bank bank) {
                 this.bank = bank;
             }
     
             @Override
             public void run() {
                 for (int i = 0; i < 10; i++) {
                     // bank.save1(10);
                     bank.save(10);
                     System.out.println(i + "账户余额为：" + bank.getAccount());
                 }
             }
     
         }
     
         /**
           * 建立线程，调用内部类
           */
         public void useThread() {
             Bank bank = new Bank();
             NewThread new_thread = new NewThread(bank);
             System.out.println("线程1");
             Thread thread1 = new Thread(new_thread);
             thread1.start();
             System.out.println("线程2");
             Thread thread2 = new Thread(new_thread);
             thread2.start();
         }
     
         public static void main(String[] args) {
             SynchronizedThread st = new SynchronizedThread();
             st.useThread();
         }
     
     }
     ```

  3. 使用特殊域变量(**volatile**)实现线程同步

     a.volatile关键字为域变量的访问提供了一种免锁机制，

     b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新，

     c.因此每次使用该域就要重新计算，而不是使用寄存器中的值

     d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量

     例如：在上面的例子当中，只需在account前面加上volatile修饰，即可实现线程同步。

     代码实例：

     ```java
     //只给出要修改的代码，其余代码与上同
     class Bank {
         //需要同步的变量加上volatile
         private volatile int account = 100;
     
         public int getAccount() {
             return account;
         }
         //这里不再需要synchronized 
         public void save(int money) {
             account += money;
         }
     }
     ```

     注：多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法。用final域，有锁保护的域和volatile域可以避免非同步的问题。

  4. 使用**重入锁**实现线程同步

     在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。ReentrantLock类是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。

     **ReentrantLock类**的常用方法有：

     - ReentrantLock() : 创建一个ReentrantLock实例
     - lock() : 获得锁
     - unlock() : 释放锁

     注：ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用。

     例如：在上面例子基础上，修改后的代码为：

     代码实例：

     ```java
     //只给出要修改的代码，其余代码与上同
     class Bank {
     
         private int account = 100;
         //需要声明这个锁
         private Lock lock = new ReentrantLock();
         public int getAccount() {
             return account;
         }
         //这里不再需要synchronized 
         public void save(int money) {
             lock.lock();
             try{
                 account += money;
             }finally{
                 lock.unlock();
             }
         }
     }
     ```

     注：关于Lock对象和synchronized关键字的选择：

     a.最好两个都不用，使用一种java.util.concurrent包提供的机制，能够帮助用户处理所有与锁相关的代码。

     b.如果synchronized关键字能满足用户的需求，就用synchronized，因为它能简化代码

     c.如果需要更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally代码释放锁

  5. 使用局部变量实现线程同步

     **如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。**

     **ThreadLocal 类**的常用方法

     - ThreadLocal() : 创建一个线程本地变量
     - get() : 返回此线程局部变量的当前线程副本中的值
     - initialValue() : 返回此线程局部变量的当前线程的"初始值"
     - set(T value) : 将此线程局部变量的当前线程副本中的值设置为value

     例如：在上面例子基础上，修改后的代码为：

     代码实例：

     ```java
     //只改Bank类，其余代码与上同
     public class Bank{
         //使用ThreadLocal类管理共享变量account
         private static ThreadLocal<Integer> account = new ThreadLocal<Integer>(){
             @Override
             protected Integer initialValue(){
                 return 100;
             }
         };
         public void save(int money){
             account.set(account.get()+money);
         }
         public int getAccount(){
             return account.get();
         }
     }
     ```

     注：ThreadLocal与同步机制

     a.**ThreadLocal**与**同步机制**都是为了解决多线程中相同变量的访问冲突问题。

     b.前者采用以"**空间换时间**"的方法，后者采用以"**时间换空间**"的方式

  6. 使用**阻塞队列**实现线程同步

     前面5种同步方式都是在底层实现的线程同步，但是我们在实际开发当中，应当尽量远离底层结构。 
     使用javaSE5.0版本中新增的java.util.concurrent包将有助于简化开发。 

     本小节主要是使用**LinkedBlockingQueue<E>**来实现线程的同步 。LinkedBlockingQueue<E>是一个基于已连接节点的，范围任意的blocking queue。 队列是先进先出的顺序（FIFO），关于队列以后会详细讲解~ 

     **LinkedBlockingQueue 类常用方法** 

     - LinkedBlockingQueue() : 创建一个容量为Integer.MAX_VALUE的LinkedBlockingQueue 
     - put(E e) : 在队尾添加一个元素，如果队列满则阻塞 
     - size() : 返回队列中的元素个数 
     - take() : 移除并返回队头元素，如果队列空则阻塞 

     **代码实例：** 实现商家生产商品和买卖商品的同步

     ```java
     package com.xhj.thread;
     
     import java.util.Random;
     import java.util.concurrent.LinkedBlockingQueue;
     
     /**
      * 用阻塞队列实现线程同步 LinkedBlockingQueue的使用
      */
     public class BlockingSynchronizedThread {
         /**
          * 定义一个阻塞队列用来存储生产出来的商品
          */
         private LinkedBlockingQueue<Integer> queue = new LinkedBlockingQueue<Integer>();
         /**
          * 定义生产商品个数
          */
         private static final int size = 10;
         /**
          * 定义启动线程的标志，为0时，启动生产商品的线程；为1时，启动消费商品的线程
          */
         private int flag = 0;
     
         private class LinkBlockThread implements Runnable {
             @Override
             public void run() {
                 int new_flag = flag++;
                 System.out.println("启动线程 " + new_flag);
                 if (new_flag == 0) {
                     for (int i = 0; i < size; i++) {
                         int b = new Random().nextInt(255);
                         System.out.println("生产商品：" + b + "号");
                         try {
                             queue.put(b);
                         } catch (InterruptedException e) {
                             // TODO Auto-generated catch block
                             e.printStackTrace();
                         }
                         System.out.println("仓库中还有商品：" + queue.size() + "个");
                         try {
                             Thread.sleep(100);
                         } catch (InterruptedException e) {
                             // TODO Auto-generated catch block
                             e.printStackTrace();
                         }
                     }
                 } else {
                     for (int i = 0; i < size / 2; i++) {
                         try {
                             int n = queue.take();
                             System.out.println("消费者买去了" + n + "号商品");
                         } catch (InterruptedException e) {
                             // TODO Auto-generated catch block
                             e.printStackTrace();
                         }
                         System.out.println("仓库中还有商品：" + queue.size() + "个");
                         try {
                             Thread.sleep(100);
                         } catch (Exception e) {
                             // TODO: handle exception
                         }
                     }
                 }
             }
         }
     
         public static void main(String[] args) {
             BlockingSynchronizedThread bst = new BlockingSynchronizedThread();
             LinkBlockThread lbt = bst.new LinkBlockThread();
             Thread thread1 = new Thread(lbt);
             Thread thread2 = new Thread(lbt);
             thread1.start();
             thread2.start();
         }
     }
     ```

     注：BlockingQueue<E>定义了阻塞队列的常用方法，尤其是三种添加元素的方法，我们要多加注意，当队列满时：add()方法会抛出异常，offer()方法返回false，put()方法会阻塞。

  7. 使用**原子变量**实现线程同步

     需要使用线程同步的根本原因在于对普通变量的操作不是原子的。那么什么是原子操作呢？原子操作就是指将读取变量值、修改变量值、保存变量值看成一个整体来操作，即-这几种行为要么同时完成，要么都不完成。在java的**util.concurrent.atomic包中提供了创建了原子类型变量的工具类**，使用该类可以简化线程同步。其中**AtomicInteger** 表可以用原子方式更新int的值，可用在应用程序中(如以原子方式增加的计数器)，但不能用于替换Integer；可扩展Number，允许那些处理机遇数字类的工具和实用工具进行统一访问。

     **AtomicInteger类常用方法：**

     - AtomicInteger(int initialValue) : 创建具有给定初始值的新的AtomicInteger
     - addAddGet(int dalta) : 以原子方式将给定值与当前值相加
     - get() : 获取当前值

     **代码实例：**只改Bank类，其余代码与上面第一个例子同

     ```java
     class Bank {
         private AtomicInteger account = new AtomicInteger(100);
     
         public AtomicInteger getAccount() {
             return account;
         }
     
         public void save(int money) {
             account.addAndGet(money);
         }
     }
     ```

     **补充--原子操作主要有：**

     对于引用变量和大多数原始变量(long和double除外)的读写操作；

     对于所有使用volatile修饰的变量(包括long和double)的读写操作。

- 什么是线程安全

  如果一段代码可以保证多个线程访问的时候正确操作共享数据，那么它是线程安全的

- 多线程中的i++线程安全吗？请简述一下原因？

  不安全。i++不是原子性操作。i++分为读取i值，对i值加一，再赋值给i++，执行期中任何一步都是有可能被其他线程抢占的。

- synchronized的可重入怎么实现

  > 《Java并发编程实践》

  **“重入”意味这获取锁的操作的粒度是“线程”，而不是“调用”。**重入的一种**实现方法**是，为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程持有。当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1. 如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减。当计数值为0时，这个锁将被释放。

  > [https://www.jianshu.com/p/5379356c648f](<https://www.jianshu.com/p/5379356c648f>)

  若一个程序或子程序可以“**在任意时刻被中断然后操作系统调度执行另外一段代码，这段代码又调用了该子程序不会出错**”，则称其为可重入（reentrant或re-entrant）的。即**当该子程序正在运行时，执行线程可以再次进入并执行它**，仍然获得符合设计时预期的结果。与多线程并发执行的线程安全不同，可重入强调对单个线程执行时重新进入同一个子程序仍然是安全的。

- 《Java并发编程实战》摘录

  - 第二章 线程安全性

    - **安全性**的含义是“**永远不发生糟糕的事情**”，而**活跃性**则关注于另一个目标，即“**某件正确的事情最终会发生**”。

    - **当多个线程访问某个类时**，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，**这个类都能表现出正确的行为**，那么就称**这个类是线程安全的**。

    - 无状态对象一定是线程安全的。

    - 当某个计算的正确性取决于多个线程的交替执行时序时，就会发生**竞争条件**(race condition)。换句话说，就是正确的结果要取决于运气。最常见的竞争条件类型就是“**先检查后执行**(check-then-act)”操作，即通过一个可能失效的观测结果来决定下一步的动作。

    - 假定有两个操作A和B，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说时**原子的**。原子操作是指，对于访问同一个状态的所有操作（包括该操作本身）来说，这个操作是一个以原子方式执行的操作。

    - 在java.util.concurrent.atomic包中包含了一些原子变量类，用于实现在数值和对象引用上的原子状态转换。通过用AtomicLong来代替long类型的计数器，能够确保所有对计数器状态的访问操作都是原子的。

    - 要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。

    - **“重入”意味这获取锁的操作的粒度是“线程”，而不是“调用”。**重入的一种**实现方法**是，为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程持有。当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1. 如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减。当计数值为0时，这个锁将被释放。

      在以下代码中，子类改写了父类的synchronized方法，然后调用父类的方法，此时如果没有可重入的锁，那么这段代码将产生死锁。

      ```java
      public class Widget {
          public synchronized void doSomething() {
              ...
          }
      }
      
      public class LoggingWiget extends Widget {
          public synchronized void doSomething() {
              System.out.println(toString() + ": calling doSomething");
              super.doSomething();
          }
      }
      ```

    - 一种常见的错误是认为，只有在写入共享变量时才需要使用同步，然而事实并非如此。

    - 对于可能被多个线程同时访问的可变状态变量，在访问它时都需要持有同一个锁，在这种情况下，我们称状态是由这个锁保护的。**每个共享的和可变的变量都应该只由一个锁来保护，从而使维护人员知道是哪一个锁。对于包含多个变量的不变性条件，其中涉及的所有变量都需要由同一个锁来保护。**

    - Servlet中一个同步代码块负责保护判断是否只需返回缓存结果的“先检查后执行”操作序列，另一个同步代码块则负责确保对缓存的数值和引述分解结果进行同步更新。

      ```java
      @ThreadSafe
      public class CacheFactorizer implments Servlet {
          @GuardedBy("this") private BigInteger lastNumber;
          @GuardedBy("this") private BigInteger[] lastFactors;
          @GuardedBy("this") private long hits;
          @GuardedBy("this") private long cacheHits;
          
          public synchronized long getHits() { return hits; }
          public synchronized double getCacheHitRatio() {
              return (double) cacheHits / (double) hits;
          }
          
          public void service(ServletRequest req, ServletResponse resq) {
              BigInteger i = extractFromRequest(req);
              BigInteger[] factors = null;
              synchronized (this) {
                  ++hits;
                  if (i.equals(lastNumber)) {
                      ++cacheHits;
                      factors = lastFactors.clone();
                  }
              }
              if (factors == null) {
                  factors = factor(i);
                  synchronized (this) {
                      lastNumber = i;
                      lastFactors = factors.clone();
                  }
              }
              encodeIntResponse(resp, factors);
          }
      }
      ```

      在简单性与性能之间存在着相互制约因素。

      **当执行时间较长的计算或者可能无法快速完成的操作时（例如，网络I/O或控制台I/O），一定不要持有锁。**

  - 第三章 对象的共享

    - 在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意向不到的调整。在缺乏足够同步的多线程程序中，要想对内存操作的执行顺序进行判断，几乎无法得出正确的结论。在缺乏同步的程序中可能产生错误结果的一种情况是**失效数据**。仅对set方法进行同步是不够的，调用get的线程仍然会看到失效值。

    - 当线程在没有同步的情况下读取变量时，可能会得到一个失效值，但至少这个值是由之前某个线程设置的值，而不是一个随机值。这种安全性保证也被称为最低安全性(out-of-thin-air safety)。最低安全性适用于绝大多数变量，但是存在一个例外：非volatile类型的64位数值变量（double和long）。Java内存模型要求，变量的读取操作和写入操作都必须时原子操作，但对于非volatile类型的long和double变量，JVM允许将64位读操作或写操作分解为两个32位的操作。当读取一个非volatile类型的long时，如果对该变量的读操作和写操作在不同的线程中执行，那么很可能会读取到某个值的高32位和另一个值的低32位。

    - 在访问某个共享且可变的变量时要求所有线程在同一个锁上同步，就是为了确保某个线程写入该变量的值对于其他线程来说时可见的。**加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。**

    - **Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保变量的更新操作通知到其他线程。在读取volatile类型的变量时总会返回最新写入的值。在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。**

    - volatile变量对可见性的影响比volatile变量本身更为重要。当线程A首先写入一个volatile变量并且线程B随后读取该变量时，在写入volatile变量之前对A可见的所有变量的值，在B读取了volatile变量后，对B也是可见的。因此，从内存可见性的角度来看，写入volatile变量相当于退出同步代码块，而读取volatile变量就相当于进入同步代码块。

    - **加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。**虽然volatile变量很方便，但也存在一些局限性，在使用时要非常小心。例如，volatile的语义不足以确保递增操作(count++)的原子性，除非你能确保只有一个线程对变量执行写操作。

    - 当且仅当满足以下所有条件时，才应该使用volatile变量：

      - 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。
      - 该变量不会与其他状态一起纳入不变性条件中。
      - 在访问变量时不需要加锁。

    - volatile变量的典型用法：检查某个状态标记以判断是否退出循环。为了使这个示例能正确执行，asleep必须为volatile变量。否则，当asleep被另一个线程修改时，执行判断的线程却发现不了。

      ```java
      volatile boolean asleep;
      ...
          while (!asleep)
              countSomeSheep();
      ```

## JVM

- JVM加载class文件的原理

  > [https://www.cnblogs.com/Qian123/p/5707562.html](<https://www.cnblogs.com/Qian123/p/5707562.html>)

   Java中的所有类，都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，像是反射，就需要显式的加载所需要的类。

  类装载方式，有两种 

  1. 隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中，
  2. 显式装载， 通过class.forname()等方法，显式加载需要的类 

  隐式加载与显式加载的区别：两者本质是一样? 

  Java类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载。这当然就是为了节省内存开销。

  Java的类加载器有三个，对应Java的三种类:（java中的类大致分为三种：   1.系统类   2.扩展类 3.由程序员自定义的类 ）

  ```​
       Bootstrap Loader  // 负责加载**系统类** (指的是内置类，像是String，对应于C#中的System类和C/C++标准库中的类)
  ​            | 
  ​          \- - ExtClassLoader   // 负责加载**扩展类**(就是继承类和实现类)
  ​                          | 
  ​                      \- - AppClassLoader   // 负责加载**应用类**(程序员自定义的类)
  ```

  三个加载器各自完成自己的工作，但它们是如何协调工作呢？哪一个类该由哪个类加载器完成呢？为了解决这个问题，Java采用了**委托模型机制**。

  **委托模型机制的工作原理很简单：当类加载器需要加载类的时候，先请示其Parent(即上一层加载器)在其搜索路径载入，如果找不到，才在自己的搜索路径搜索该类。这样的顺序其实就是加载器层次上自顶而下的搜索，因为加载器必须保证基础类的加载。** 之所以是这种机制，还有一个安全上的考虑：如果某人将一个恶意的基础类加载到jvm，委托模型机制会搜索其父类加载器，显然是不可能找到的，自然就不会将该类加载进来。

  我们可以通过这样的代码来获取类加载器:

  ```java
  ClassLoader loader = ClassName.class.getClassLoader();
  ClassLoader ParentLoader = loader.getParent();
  ```

  注意一个很重要的问题，就是Java在逻辑上并不存在BootstrapLoader的实体！因为它是用C++编写的，所以打印其内容将会得到null。

  前面是对类加载器的简单介绍，它的原理机制非常简单，就是下面几个步骤:

  1. **加载**:查找和导入**class文件**;

  2. **连接**:

     (1)**验证**:检查**载入的class文件数据的正确性**;

     (2)**准备**:**为类的静态变量分配存储空间**;

     (3)**解析**:**将符号引用转换成直接引用**(这一步是可选的)

  3. **初始化**:**初始化静态变量**，静态代码块。

  这样的过程在程序调用类的静态成员的时候开始执行，所以静态方法main()才会成为一般程序的入口方法。类的构造器也会引发该动作。

  ![img](https://uploadfiles.nowcoder.com/images/20180926/308572_1537962641528_95106A90F455887E4A4B298735A4641B)

  > 《深入理解JVM》P191 双亲委派模型

  绝大部分Java程序都会使用到以下三种系统提供的类加载器：

  - 启动类加载器(Bootstrap ClassLoader): 这个类加载器负责将存放在`<JAVA_HOME>\lib`目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接使用。
  - 扩展类加载器(Extension ClassLoader)：这个加载器由`sun.misc.Launcher$ExtClassLoader`实现，它负责加载`<Java_HOME>\lib\ext`目录中的，或者被`java.ext.dirs`系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。
  - 应用程序类加载器(Application ClassLoader)：这个类加载器由`sun.misc.Launcher$AppClassLoader`来实现。由于这个类加载器是ClassLoader中的`getSystemClassLoader()`方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径(ClassPath)上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有定义过自己的类加载器，一般情况下这个就是程序中的默认的类加载器。

  我们的应用程序都是由者三种类加载器互相配合进行加载的，如果有必要，还可以加入自己定义的类加载器。

  **双亲委派模型**的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载器请求最终都应该传送到顶层的启动类加载器中，只有当父加载器自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。

  > 《深入理解JVM》P194 破坏双亲委派模型

  双亲委派模型主要出现过三次较大规模的“被破坏”情况。

  第一次出现在双亲委派模型出现之前————即JDK1.2发布之前。由于双亲委派模型在JDK1.0时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协。为了向前兼容，JDK1.2之后的java.lang.ClassLoader添加了一个新的protected方法findClass()，在次之前，用户继承**java.lang.ClassLoader的唯一目的就是重写loadClass()方法**。

  **JDK1.2之后已不提倡用户再去覆盖loadClass()方法，而应该把自己的类加载逻辑写到findClass()方法中，在loadClass()方法的逻辑里如果父类加载失败，则会调用自己的findClass()方法来完成加载**，这样就可以保证新写出来的类加载器时符合双亲委派规则的。

  第二次是**由这个模型的自身的缺陷所导致**的，基础类之所以被称为“基础”，是因为它们总是作为被用户代码调用的API，但如果**基础类又要调用回用户的代码**，那该怎么办？

  **JNDI服务由启动类加载器去加载**，但启动类加载器不可能“认识”这些代码啊！为了解决这个困境，Java设计团队只好引入了一个不太优雅的设计：**线程上下文类加载器**。JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码，也就是**父类加载器请求子类加载器去完成类加载器**的动作，这种行为实际上就是打通了双亲委派模型的层次结构来你想使用类加载器。

  第三次是由于**用户对程序动态性的追求**而导致的，这里所说的“动态性”指的是当前一些非常“热”门的名词：代码热替换、模块热部署等，说白了就是希望应用程序能像我们的电脑外设那样，插上鼠标或U盘，不用重启机器就能立即使用，鼠标有问题或要升级就换个鼠标，不用停机也不用重启。

  > [https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8](https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8)

  双亲委派模型的好处
  
  双亲委派模型保证了Java程序的稳定运行，**可以避免类的重复加载**（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），**也保证了 Java 的核心 API 不被篡改**。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类。

- OOM、CPU占用过高排查

  - jps列出正在运行的虚拟机进程
  - **jstat统计信息，包括分区占用情况**
  - **jmap内存映像**
  - **jstack堆栈跟踪**
  - **VisualVM：生成浏览堆转储快照、分析CPU、内存性能**
  - top ps

- JVM是如何实现线程的？

  > 《深入理解JVM》P333 Java与线程
  
  > [https://blog.csdn.net/qq_33938256/article/details/52615257](<https://blog.csdn.net/qq_33938256/article/details/52615257>)

  并发不一定要依赖多线程（如PHP中很常见的多进程并发），但是在Java里面谈论并发，大多数都与线程脱不开关系。

  - 线程的实现

    线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的**资源分配**和**执行调度**分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度（线程是CPU调度的最基本单位）。

    主流的操作系统都提供了线程实现，Java语言则提供了在不同硬件和操作系统平台下对线程操作的同一处理，每个java.lang.Thread类的实例就代表了一个线程。**Thread类的关键方法，都声明为Native**。这意味着这个方法无法或没有使用平台无关的手段来实现，也可能是为了执行效率。

    实现线程主要有三种方式：使用内核线程实现，使用用户线程实现，使用用户线程加轻量级进程混合实现。

    1. **使用内核线程实现**

       内核线程就是直接由操作系统内核支持的线程。

       - **由内核来完成线程切换**
       - 内核通过调度器Scheduler调度线程，并将线程的任务映射到各个CPU上
       - 程序使用**内核线程的高级接口**，**轻量级进程**(Light Weight Process,LWP)–>(!!!名字是进程，实际是线程)
       - **用户态和内核态切换消耗内核资源**
       - 轻量级进程与内核线程之间的1:1关系称为**一对一线程模型**

    2. **使用用户线程实现**

       - **系统内核不能感知线程存在的实现**
       - **用户线程的建立、同步、销毁和调度完全在用户态中完成**
       - 所有线程操作需要用户程序自己处理，复杂度高
       - 这种进程与线程之间1:N的关系称为**一对多的线程模型**

    3. **混合实现**

       - 轻量级进程作为用户线程和内核线程之间的桥梁
       - 混合模式中，用户线程与轻量级进程的数量比是不定的，是M:N的关系，称为**多对多关系**

    4. Java线程的实现

       对于Sun JDK来说，它的Windows版与Linux版都是使用一对一的线程模型来实现的，一条Java线程就映射到一条轻量级进程之中，因为Windows和Linux系统系统提供的线程模型就是一对一的。

  - Java线程调度

    线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同式线程调度和抢占式线程调度。

    - 协同式调度：线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上去。

      优点：实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。

      缺点：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。

    - 抢占式调度：每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定。

      在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。

    虽然说Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配一点执行时间，另外的一些线程则可以少分配一点——这项操作可以通过设置线程优先级来完成。Java语言一共设置了10个级别的线程优先级。

    不过，线程优先级并不是太靠谱，原因是Java的线程是被映射到系统原生线程上来实现的，所以线程调度最终还是有操作系统说了算，虽然现在很多操作系统都提供线程优先级的概念，但是并不见得能与Java线程的优先级一一对应。Windows只有7中优先级，比Java线程优先级少，不得不出现几个优先级相同的情况。还有其他情况让我们不能太依赖优先级：优先级可能会被系统自行改变。例如在Windows系统中存在一个名为“优先级推进器”的功能，它的大致作用就是当系统发现一个线程被执行得特别“勤奋努力”的话，可能会越过线程优先级去为它分配执行时间。

  > 王道操作系统 P34

  - 线程的实现方式

    线程的实现可以分为两类，**用户级线程**和**内核级线程**。

    **在用户级线程中，有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。**通常，应用程序从单线程起始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。

    **在内核级线程中，线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。**内核为进程及其内部的每个线程维护上下文信息，调度也是在内核基于线程架构的基础上完成。

    在一些系统中，使用**组合方式**的多线程实现。线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行，一个应用程序中的多个用户级线程被映射到一些内核级线程上。

  - 多线程模型

    有的系统同时支持用户线程和内核线程，由此产生了不同的多线程模型。

    1. **多对一模型**。**将多个用户级线程映射到一个内核级线程**，线程管理在用户空间完成。

       优点：线程管理是在用户空间进行的，因此效率比较高。

       缺点：当一个线程在使用内核服务被阻塞，那么整个进程都会被阻塞；多个线程不能并行地运行在多处理器上。

    2. **一对一模型**。将每个用户及线程映射到一个内核级线程。

       优点：当一个线程被阻塞后允许另一个线程继续执行，所以并发能力较强。

       缺点：每创建一个用户及线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。

    3. **多对多模型**。将$n$个用户及线程映射到$m$个内核级线程上，要求$m\le n$。

- 什么是Java内存模型？

  > 《深入理解JVM》P318

  Java虚拟机规范中试图定义一种Java内存模型(JMM)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果。

  Java内存模型规定了所有的变量都存储在主内存中。每个线程还有自己的工作内存，线程的工作内存中给保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读取主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。

  > [https://blog.csdn.net/suifeng3051/article/details/52611310](<https://blog.csdn.net/suifeng3051/article/details/52611310>)

  Java内存模型(简称JMM)。**JMM决定一个线程对共享变量的写入何时对另一个线程可见**。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：**线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本**。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。

  ![这里写图片描述](https://img-blog.csdn.net/20160921182337904)

  从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤：

  1. 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。
  2. 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。 

  下面通过示意图来说明这两个步骤：

  ![这里写图片描述](https://img-blog.csdn.net/20160921182748551)

  如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。

  从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。

- JVM运行时数据区域

  > [https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F?id=%e5%86%99%e5%9c%a8%e5%89%8d%e9%9d%a2-%e5%b8%b8%e8%a7%81%e9%9d%a2%e8%af%95%e9%a2%98](<https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F?id=%e5%86%99%e5%9c%a8%e5%89%8d%e9%9d%a2-%e5%b8%b8%e8%a7%81%e9%9d%a2%e8%af%95%e9%a2%98>)

  **线程私有的：**

  - **程序计数器**
  - **虚拟机栈**
  - **本地方法栈**

  **线程共享的：**

  - **堆**
  - **方法区**
  - 直接内存 (非运行时数据区的一部分)

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F.png)

  > 《深入理解JVM》P25 运行时数据区域

  Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。

  - 程序计数器

    程序计数器是一块较小的内存空间，它的作用可以看作是当前线程所执行的字节码的行号指示器。**字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。**

    另外，**为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。**

    **注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。**

  - Java虚拟机栈

    **与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。**

    **Java 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。** （实际上，Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。）

    **局部变量表主要存放了编译器可知的各种数据类型**（boolean、byte、char、short、int、float、long、double）、**对象引用**（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。

    **Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。**

    - **StackOverFlowError：** 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。
    - **OutOfMemoryError：** 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 错误。

    Java 虚拟机栈也是线程私有的，每个线程都有各自的 Java 虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。

  - 本地方法栈

    和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。** 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

    本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。

    方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。

    > [https://blog.csdn.net/wike163/article/details/6635321](https://blog.csdn.net/wike163/article/details/6635321)

    > 一个Native Method是这样一个java的方法：该方法的实现由非java语言实现，比如C。

  - Java堆

    Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都是在这里分配内存。

    Java堆是垃圾收集器管理的主要区域，因此很多时候也被称作“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老生代，再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。

    根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。

  - 方法区

    方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的**类信息、常量、静态变量**、即时编译器编译后的代码等数据。虽然 **Java 虚拟机规范把方法区描述为堆的一个逻辑部分**，但是它却有一个别名叫做 **Non-Heap（非堆）**，目的应该是与 Java 堆区分开来。

    《Java 虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 **方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。** 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法。

    根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。

  - 运行时常量池

    运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项时常量池信息，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。

    既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。

  - 直接内存

    **直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。**

    JDK1.4 中新加入的 **NIO(New Input/Output) 类**，引入了一种基于**通道（Channel）** 与**缓存区（Buffer）** 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为**避免了在 Java 堆和 Native 堆之间来回复制数据**。

    本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。
  
  - jdk1.8：**用元数据区替代永久代，实现方法区，并把字符串常量池和类静态变量迁移到堆中存放。**

    ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3Java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9FJDK1.8.png)

    元数据区直接存放在本地内存中，不在java虚拟机中，因此加载多少类的内存限制由系统实际的可用空间控制。

    为什么要用元数据区（metadata）代替永久代

    1、字符串存放在永久代，容易出现性能和内存溢出的问题

    2、类信息比较难确定其大小，永久代空间分配困难
    
    3、永久代为垃圾回收带来了不必要的复杂度，并且回收效率低

    > **整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。**

- GC中如何判断对象是否需要被回收？

  > 《深入理解JVM》P44 对象已死？
  >
  > [https://blog.csdn.net/u010126792/article/details/82855265](<https://blog.csdn.net/u010126792/article/details/82855265>) 判断一个对象是否可用（存活，可回收），GC回收对象的过程方式，finilized函数了解吗，调用了finilized函数的对象一定会被回收吗，可以主动调用finilized函数吗？

  - 判断对象是否需要被回收

    - 引用计数算法

      给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时候计数器都为0的对象就是不可能再被使用的。

      Java语言中没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间的相互循环引用的问题。但是它们的引用计数可能都不为0，计数引用算法无法通知GC收集器回收它们。

    - 根搜索算法

      在主流的商用程序语言中，都是使用**根搜索算法**判断对象是否存活。这个算法的基本思路就是通过一系列的名为"GC Roots"的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（用凸轮的话来说就是从GC Roots到这个对象不可达）时，则证明此对象时不可用的。

      在Java语言中，可作为GC Roots的对象包括下面几种：

      1. **虚拟机栈**（栈帧中的本地变量表）中引用的对象
      2. **方法区中的类静态变量**引用的对象
      3. **方法区中的常量**引用的对象
      4. **本地方法栈中JNI**（即一般说的Native方法）的引用的变量

  - finalize()方法

    在根搜索算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行根搜索后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。

    如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程区执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，**如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）复制给某个类变量或对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合**；如果对象这时候还没有逃脱，那它就真的离死不远了。

    并不鼓励使用finalize()方法来拯救对象，因为它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。finalize()能做的所有工作，使用try-finally或其他方式都可以做得更好。

- Eden区和Survivor区的含义以及工作原理？

  目前主流的虚拟机实现都采用了分代收集的思想，把整个堆区划分为新生代和老年代；新生代又被划分成Eden 空间、 From Survivor 和 To Survivor 三块区域。

  我们把Eden : From Survivor : To Survivor 空间大小设成 8 : 1 : 1 ，对象总是在 Eden 区出生， From Survivor 保存当前的幸存对象， To Survivor 为空。一次 gc 发生后： 1）Eden 区活着的对象 ＋ From Survivor 存储的对象被复制到 To Survivor ；2) 清空 Eden 和 From Survivor ； 3) 颠倒 From Survivor 和 To Survivor 的逻辑关系： From 变 To ， To 变 From 。可以看出，只有在 Eden 空间快满的时候才会触发 Minor GC 。而 Eden 空间占新生代的绝大部分，所以 Minor GC 的频率得以降低。当然，使用两个 Survivor 这种方式我们也付出了一定的代价，如 10% 的空间浪费、复制对象的开销等。

  > 《深入理解JVM》P51 垃圾收集算法

  - 标记-清除算法

    算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。

    它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量布莱纳许的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。

  - 复制算法

    为了解决效率问题，一种称为“复制”的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这块用完了，就将还活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样是的每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价时将内存缩小为原来的一半，未免太高了一点。

    现在的商业虚拟机都采用这种收集算法来回收新生代，新生代中的对象98%是朝生夕死的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地拷贝到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor的空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%(80%+10%)，只有10%的内存是会被“浪费”的。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够时，需要依赖其他内存（这里指老年代）进行分配担保。

  - 标记-整理算法

    根据老年代的特点，有人提出了另外一种“标记-整理”算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象对象进行清理，而是所有存活的对象都向一端移动，然后直接清理掉段边界以外的内存。

  - **分代收集算法**

    当前商业虚拟机的垃圾收集都采用“分代收集”算法，这种算法并没有什么新的思想，只是根据对象的存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少了存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。

- JVM的回收算法以及它的回收器是什么？CMS采用哪种回收算法？使用CMS怎样解决内存碎片的问题呢？

  > 《深入理解JVM》P55 垃圾收集器
  >
  > [https://crowhawk.github.io/2017/08/15/jvm_3/](<https://crowhawk.github.io/2017/08/15/jvm_3/>)

  **如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。**Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。接下来讨论的收集器基于JDK1.7 Update 14 之后的HotSpot虚拟机（在此版本中正式提供了商用的G1收集器，之前G1仍处于实验状态），该虚拟机包含的所有收集器如下图所示：

  ![img](https://pic.yupoo.com/crowhawk/56a02e55/3b3c42d2.jpg)

  上图展示了7种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。Hotspot实现了如此多的收集器，正是因为目前并无完美的收集器出现，只是选择对具体应用最适合的收集器。

  - 相关概念

    - 并行和并发

      - **并行（Parallel）**：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。
      - **并发（Concurrent）**：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行。而垃圾收集程序运行在另一个CPU上。

    - 吞吐量（Throughput）

      吞吐量就是**CPU用于运行用户代码的时间**与**CPU总消耗时间**的比值，即

      **吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）。**

      假设虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。

    - Minor GC 和 Full GC
      - **新生代GC（Minor GC）**：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。具体原理见上一篇文章。
      - **老年代GC（Major GC / Full GC）**：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。

  - 新生代收集器

    - Serial收集器

      **Serial（串行）**收集器是最基本、发展历史最悠久的收集器，它是采用**复制算法**的**新生代收集器**，曾经（JDK 1.3.1之前）是虚拟机**新生代**收集的唯一选择。它是一个单线程收集器，只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是**它在进行垃圾收集时，必须暂停其他所有的工作线程，直至Serial收集器收集结束为止（“Stop The World”）**。这项工作是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说是难以接收的。

      下图展示了Serial 收集器（老年代采用Serial Old收集器）的运行过程：

      ![img](https://pic.yupoo.com/crowhawk/6b90388c/6c281cf0.png)

      为了消除或减少工作线程因内存回收而导致的停顿，HotSpot虚拟机开发团队在JDK 1.3之后的Java发展历程中研发出了各种其他的优秀收集器，这些将在稍后介绍。但是这些收集器的诞生并不意味着Serial收集器已经“老而无用”，实际上到现在为止，它依然是**HotSpot虚拟机运行在Client模式下的默认的新生代收集器**。它也有着优于其他收集器的地方：**简单而高效（与其他收集器的单线程相比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得更高的单线程收集效率。**

      在用户的桌面应用场景中，分配给虚拟机管理的内存一般不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本不会再大了），停顿时间完全可以控制在几十毫秒最多一百毫秒以内，只要不频繁发生，这点停顿时间可以接收。所以，Serial收集器对于运行在Client模式下的虚拟机来说是一个很好的选择。

    - ParNew 收集器

      **ParNew**收集器就是Serial收集器的多线程版本，它也是一个**新生代收集器**。除了使用多线程进行垃圾收集外，其余行为包括Serial收集器可用的所有控制参数、收集算法（复制算法）、Stop The World、对象分配规则、回收策略等与Serial收集器完全相同，两者共用了相当多的代码。

      ParNew收集器的工作过程如下图（老年代采用Serial Old收集器）：

      ![img](https://pic.yupoo.com/crowhawk/605f57b5/75122b84.png)

      ParNew收集器除了使用多线程收集外，其他与Serial收集器相比并无太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关的重要原因是，**除了Serial收集器外，目前只有它能和CMS收集器（Concurrent Mark Sweep）配合工作**，CMS收集器是JDK 1.5推出的一个具有划时代意义的收集器，具体内容将在稍后进行介绍。

      ParNew 收集器在**单CPU的环境**中绝对不会有比Serial收集器有更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越。在**多CPU环境**下，随着CPU的数量增加，它对于GC时系统资源的有效利用是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多的情况下可使用**-XX:ParallerGCThreads**参数设置。

    - Parallel Scavenge 收集器

      **Parallel Scavenge**收集器也是一个**并行**的**多线程新生代**收集器，它也使用**复制算法**。Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是**达到一个可控制的吞吐量（Throughput）**。

      **停顿时间越短就越适合需要与用户交互的程序**，良好的响应速度能提升用户体验。而**高吞吐量**则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合**在后台运算而不需要太多交互的任务**。

      Parallel Scavenge收集器除了会显而易见地提供可以精确控制吞吐量的参数，还提供了一个参数**-XX:+UseAdaptiveSizePolicy**，这是一个开关参数，打开参数后，就不需要手工指定新生代的大小（-Xmn）、Eden和Survivor区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为**GC自适应的调节策略（GC Ergonomics）**。自适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。

      另外值得注意的一点是，Parallel Scavenge收集器无法与CMS收集器配合使用，所以在JDK 1.6推出Parallel Old之前，如果新生代选择Parallel Scavenge收集器，老年代只有Serial Old收集器能与之配合使用。

  - 老年代收集器

    - Serial Old收集器

      Serial Old 是 Serial收集器的老年代版本，它同样是一个**单线程收集器**，使用**“标记-整理”（Mark-Compact）**算法。

      此收集器的主要意义也是在于给Client模式下的虚拟机使用。如果在Server模式下，它还有两大用途：

      - 在JDK1.5 以及之前版本（Parallel Old诞生以前）中与Parallel Scavenge收集器搭配使用。
      - 作为CMS收集器的后备预案，在并发收集发生**Concurrent Mode Failure**时使用。

      它的工作流程与Serial收集器相同，这里再次给出Serial/Serial Old配合使用的工作流程图：

      ![img](https://pic.yupoo.com/crowhawk/6b90388c/6c281cf0.png)

    - Parallel Old收集器

      Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用**多线程**和**“标记-整理”**算法。前面已经提到过，这个收集器是在JDK 1.6中才开始提供的，在此之前，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old以外别无选择，所以在Parallel Old诞生以后，**“吞吐量优先”收集器**终于有了比较名副其实的应用组合，在**注重吞吐量**以及**CPU资源敏感**的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。Parallel Old收集器的工作流程与Parallel Scavenge相同，这里给出Parallel Scavenge/Parallel Old收集器配合使用的流程图：

      ![img](https://pic.yupoo.com/crowhawk/9a6b1249/b1800d45.png)

    - CMS收集器

      **CMS（Concurrent Mark Sweep）**收集器是一种以**获取最短回收停顿时间**为目标的收集器，它非常符合那些集中在互联网站或者B/S系统的服务端上的Java应用，这些应用都非常重视服务的响应速度。从名字上（“Mark Sweep”）就可以看出它是基于**“标记-清除”**算法实现的。

      CMS收集器工作的整个流程分为以下4个步骤：

      - **初始标记（CMS initial mark）**：仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。
      - **并发标记（CMS concurrent mark）**：进行**GC Roots Tracing**的过程，在整个过程中耗时最长。
      - **重新标记（CMS remark）**：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要“Stop The World”。
      - **并发清除（CMS concurrent sweep）**

      由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。通过下图可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间：

      ![img](https://pic.yupoo.com/crowhawk/fffcf9a2/f60599b2.png)

      **优点**

      CMS是一款优秀的收集器，它的主要**优点**在名字上已经体现出来了：**并发收集**、**低停顿**，因此CMS收集器也被称为**并发低停顿收集器（Concurrent Low Pause Collector）**。

      **缺点**

      - **对CPU资源非常敏感** 其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。**CMS默认启动的回收线程数是（CPU数量+3）/4**，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是**当CPU不足4个时（比如2个），CMS对用户程序的影响就可能变得很大**，如果本来CPU负载就比较大，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。
      - **无法处理浮动垃圾（Floating Garbage）** 可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。**由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。**这一部分垃圾出现在标记过程之后，CMS无法再当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就被称为**“浮动垃圾”**。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。
      - **标记-清除算法导致的空间碎片** CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次Full GC。为了解决这个问题，CMS收集器提供了一个-XX:+UseCMSCompactAtFullCollection开关参数，用于在“享受”完Full GC服务之后额外免费附送一个碎片整理过程，内存整理的过程是无法并发的。空间碎片问题没有了，但停顿时间不得不变长了。虚拟机设计者还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction，这个参数用于设置在执行多少次不压缩的Full GC后，跟着来一次带压缩的。

    - G1收集器

      **G1（Garbage-First）**收集器是当今收集器技术发展最前沿的成果之一，它是一款**面向服务端应用**的垃圾收集器，HotSpot开发团队赋予它的使命是（在比较长期的）未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点：

      - **并行与并发** G1 能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。
      - **分代收集** 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。
      - **空间整合** G1从整体来看是基于**“标记-整理”**算法实现的收集器，从局部（两个Region之间）上来看是基于**“复制”**算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。
      - **可预测的停顿** 这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。

      **横跨整个堆内存**

      在G1之前的其他收集器进行收集的范围都是整个新生代或者老生代，而G1不再是这样。G1在使用时，Java堆的内存布局与其他收集器有很大区别，它**将整个Java堆划分为多个大小相等的独立区域（Region）**，虽然还保留新生代和老年代的概念，但**新生代和老年代不再是物理隔离的了，而都是一部分Region（不需要连续）的集合**。

      **建立可预测的时间模型**

      G1收集器之所以能建立可预测的停顿时间模型，是因为它可以**有计划地避免在整个Java堆中进行全区域的垃圾收集**。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），**在后台维护一个优先列表**，每次根据允许的收集时间，**优先回收价值最大的Region（这也就是Garbage-First名称的来由）**。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。

      **避免全堆扫描——Remembered Set**

      G1把Java堆分为多个Region，就是“化整为零”。但是Region不可能是孤立的，一个对象分配在某个Region中，可以与整个Java堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个Java堆才能保证准确性，这显然是对GC效率的极大伤害。

      为了避免全堆扫描的发生，虚拟机**为G1中每个Region维护了一个与之对应的Remembered Set**。虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable**把相关引用信息记录到被引用对象所属的Region的Remembered Set之中**。当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。

      ------

      如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤：

      - **初始标记（Initial Marking）** 仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改**TAMS（Nest Top Mark Start）**的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要**停顿线程**，但耗时很短。
      - **并发标记（Concurrent Marking）** 从GC Root 开始对堆中对象进行**可达性分析**，找到存活对象，此阶段耗时较长，但**可与用户程序并发执行**。
      - **最终标记（Final Marking）** 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在**线程的Remembered Set Logs**里面，最终标记阶段需要**把Remembered Set Logs的数据合并到Remembered Set中**，这阶段需要**停顿线程**，但是**可并行执行**。
      - **筛选回收（Live Data Counting and Evacuation）** 首先对各个Region中的回收价值和成本进行排序，根据用户所期望的GC 停顿是时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。

      通过下图可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段（Safepoint处）：

      ![img](https://pic.yupoo.com/crowhawk/53b7a589/0bce1667.png)

  - 总结

    **新生代的收集器有Serial、ParNew、Parallel Scavenge。Serial收集器是串行、单线程的收集器，在收集垃圾时需要暂停其他所有的工作，stop the world，使用复制算法。ParNew收集器是Serial的并行、多线程版本，可以配合CMS使用。Parallel Scavenge收集器目标是达到高吞吐量，可以配合Parallel Old使用。**

    **老年代的收集器有Serail Old、Parallel Old、CMS、G1算法。Serial Old收集器是Serial收集器的老年代版本，使用标记-整理算法。Parallel Old收集器是Parallel Scavenge的老年代版本，使用多线程和标记-整理算法。**
    
    **CMS收集器的目标是低停顿、高响应速度，基于标记-清除算法，步骤分为初始标记（标记GC Roots能关联到的对象，速度很快，需要stop the world）、并发标记（GC Root Tracing，耗时最长）、重新标记（修复并发标记期间改动的标记，需要stop the world）、并发清除。**

    **G1收集器使命是在未来替代CMS。G1将整个Java堆划分为多个大小相等的独立区域（Region），每个Region维护了一个与之对应的Remembered Set，把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。从整体来看基于标记-整理算法，从局部（两个Region之间）来看基于复制算法。步骤分为：初始标记、并发标记、最终标记（将变动合并到Remember Set中）、筛选回收（回收一部分Region）。**

    | 收集器                | 串行、并行or并发 | 新生代/老年代 | 算法               | 目标             | 适用场景                                  |
    | --------------------- | ---------------- | ------------- | ------------------ | ---------------- | ----------------------------------------- |
    | **Serial**            | **串行**         | 新生代        | 复制算法           | 响应速度优先     | 单CPU环境下的Client模式                   |
    | **ParNew**            | **并行**         | 新生代        | 复制算法           | 响应速度优先     | 多CPU环境时在Server模式下**与CMS配合**    |
    | **Parallel Scavenge** | 并行             | 新生代        | 复制算法           | **吞吐量优先**   | 在后台运算而不需要太多交互的任务          |
    | **Serial Old**        | 串行             | 老年代        | 标记-整理          | 响应速度优先     | 单CPU环境下的Client模式、CMS的后备预案    |
    | **Parallel Old**      | 并行             | 老年代        | 标记-整理          | 吞吐量优先       | 在后台运算而不需要太多交互的任务          |
    | **CMS**               | **并发**         | 老年代        | **标记-清除**      | **响应速度优先** | 集中在互联网站或B/S系统服务端上的Java应用 |
    | **G1**                | 并发             | both          | 标记-整理+复制算法 | 响应速度优先     | 面向服务端应用，将来替换CMS               |
  
- Minor GC和Full GC触发条件

  Minor GC触发条件：当**Eden区满时**，触发Minor GC。

  Full GC触发条件：
  - **调用System.gc时，系统建议执行Full GC，但是不必然执行**
  - **老年代空间不足**
  - **方法区空间不足**
  - 通过Minor GC后进入老年代的平均大小大于老年代的可用内存
  - **由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小**

- 什么时候触发MinorGC?什么时候触发FullGC?

  > [https://www.cnblogs.com/williamjie/p/9516367.html](https://www.cnblogs.com/williamjie/p/9516367.html)

  **触发MinorGC(Young GC)**

  虚拟机在进行minorGC之前会判断老年代最大的可用连续空间是否大于新生代的所有对象总空间

  1、如果大于的话，直接执行minorGC

  2、如果小于，判断是否开启HandlerPromotionFailure，没有开启直接FullGC

  3、如果开启了HanlerPromotionFailure, JVM会判断老年代的最大连续内存空间是否大于历次晋升的大小，如果小于直接执行FullGC

  4、如果大于的话，执行minorGC

  **触发FullGC**

  - 老年代空间不足

    如果创建一个大对象，Eden区域当中放不下这个大对象，会直接保存在老年代当中，如果老年代空间也不足，就会触发Full GC。为了避免这种情况，最好就是不要创建太大的对象。

  - 持久代空间不足

    如果有持久代空间的话，系统当中需要加载的类，调用的方法很多，同时持久代当中没有足够的空间，就出触发一次Full GC
  
  - YGC出现promotion failure
  
    promotion failure发生在Young GC, 如果Survivor区当中存活对象的年龄达到了设定值，会就将Survivor区当中的对象拷贝到老年代，如果老年代的空间不足，就会发生promotion failure， 接下去就会发生Full GC.
  
  - 统计YGC发生时晋升到老年代的平均总大小大于老年代的空闲空间
  
    在发生YGC是会判断，是否安全，这里的安全指的是，当前老年代空间可以容纳YGC晋升的对象的平均大小，如果不安全，就不会执行YGC,转而执行Full GC。
  
  - 显示调用System.gc

- 什么原因会导致minor gc运行频繁？同样的，什么原因又会导致minor gc运行很慢？

  > [https://www.nowcoder.com/questionTerminal/b3cd86f89d6c4b1ab54252b49a6bff57](<https://www.nowcoder.com/questionTerminal/b3cd86f89d6c4b1ab54252b49a6bff57>)

  什么原因会导致minor gc运行频繁？

  1. **产生了太多朝生夕灭的对象导致需要频繁minor gc**

  2. **新生代空间设置的比较小**

  什么原因会导致minor gc运行很慢？

  1. **新生代空间设置过大。**

  2. **对象引用链较长，进行可达性分析时间较长。**

  3. 新生代survivor区设置的比较小，清理后剩余的对象不能装进去需要移动到老年代，造成移动开销。

  4. 内存分配担保失败，由minor gc转化为full gc

  5. **采用的垃圾收集器效率较低，比如新生代使用serial收集器**

  > 《深入理解JVM》P65 内存分配与回收策略

  - **对象优先在Eden分配**

    大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够的空间进行分配时，虚拟机将发起一次Minor GC。

  - **大对象直接进入老年代**

    大对象对虚拟机的内存分配来说是个坏消息，经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。

  - **长期存活的对象将进入老年代**

    虚拟机既然采用了分代收集的思想来管理内存，那内存回收时就必须能识别哪些对象应该放在新生代，哪些对象应该放在老年代。为了做到这点，虚拟机给每个对象定义了一个对象年龄计数器。如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor区中每熬过一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁）时，就会被晋升到老年代中。对象今生老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold来设置。

  - **动态对象年龄判定**

    为了能更好地适应不同程序的内存状况，虚拟机并不总是要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代，**如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代**，无需等到MaxTenuringThreshold中要求的年龄。

  - **空间分配担保**

    在发生Minor GC时，虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小，如果大于，则改为直接进行一次Full GC。如果小于，则查看HandlePromotionFailure设置是否允许担保失败；如果允许，那只会进行Minor GC；如果不允许，则也要改为进行一次Full GC。

    前面提到过，新生代使用复制收集算法，但为了内存利用率，**只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况时（最极端就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，让Survivor无法容纳的对象直接进入老年代。**与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的空间，一共有多少对象会活下来，在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。

    取平均值进行比较其实仍然是一种动态概率的手段，也就是说如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁。

- java.lang.String写个一模一样的可以运行吗，会报错吗

  > 《深入理解JVM》P193

  使用双亲委派模型来组织类和加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如`Java.lang.Object`，它存放在`rt.jar`之中，无论哪一个类加载器要加载这个类，最终都是委派给启动类加载器进行加载，因此Object类在程序的各种累加器环境中都是同一个类。相反，如果没有使用双亲委派模型，由各个类加载器自行区加载的话，如果用户自己写了一个名为`Java.lang.Object`的类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无从保证，应用程序也将会变得一片混乱。可以尝试区写一个与`rt.jar`类库中已有类重名的Java类，将会发现可以正常编译，但永远无法被加载运行。（即使自定义了自己的加载器，强行用defineClass()方法去加载一个以`Java.lang`开头的类也不会成功。如果读者尝试这样做的话，将会收到一个由虚拟机自己抛出的`java.lang.SecurityException: Prohibited package name: java.lang`异常。）

  > [https://blog.csdn.net/tang9140/article/details/42738433](https://blog.csdn.net/tang9140/article/details/42738433)

---

- 什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？

  > [https://www.nowcoder.com/questionTerminal/a90230b35b5f4a7287f779ecdd88841d](<https://www.nowcoder.com/questionTerminal/a90230b35b5f4a7287f779ecdd88841d>)

  java的跨平台不是java源程序的跨平台 ，如果是这样，那么所有语言都是跨平台的， java源程序先经过javac编译器编译成二进制的.class字节码文件（java的跨平台指的就是.class字节码文件的跨平台，.class字节码文件是与平台无关的），.class文件再运行在jvm上，java解释器（jvm的一部分）会将其解释成对应平台的机器码执行，所以java所谓的跨平台就是在不同平台上安装了不同的jvm，而在不同平台上生成的.class文件都是一样的，而.class文件再由对应平台的jvm解释成对应平台的机器码执行。 

  最后解释下机器码和字节码的区别: 

  一，机器码，完全依附硬件而存在～并且不同硬件由于内嵌指令集不同，即使相同的0 1代码 意思也可能是不同的～换句话说，根本不存在跨平台性～比如～不同型号的CPU,你给他个指令10001101，他们可能会解析为不同的结果～ 

  二，我们知道JAVA是跨平台的，为什么呢？因为他有一个jvm,不论哪种硬件，只要你装有jvm,那么他就认识这个JAVA字节码～～～～至于底层的机器码，咱不用管，有jvm搞定，他会把字节码再翻译成所在机器认识的机器码～～～

- JVM最大内存限制多少？

  > [https://blog.csdn.net/lengyuhong/article/details/6044894](<https://blog.csdn.net/lengyuhong/article/details/6044894>)

  没想到第一个实验的程序，跑了几个小时，就遇到了Out of Memory Exception了。看看自己的虚拟机设置，我设置的是-Xms512M -Xmx1024M。想都没想，直接改成-Xms512M -Xmx2048M，结果直接就Could not reserve enough space for object heap。程序都起不来了。这才发现原来最大内存还有限制。上网搜了一下，发现很多讨论这个问题的文章。最终在BEA的DEV2DEV论坛发现了最有用的一篇

  这里的版主YuLimin 做了[测试](http://softtest.chinaitlab.com/)，得出结论：

  　　公司 JVM版本                  最大内存(兆)client    最大内存(兆)server

  　　SUN 1.5.x                          1492                            1520

  　　SUN 1.5.5(Linux)             2634                            2660

  　　SUN 1.4.2                          1564                            1564

  　　SUN 1.4.2(Linux)             1900                            1260

  　　IBM 1.4.2(Linux)             2047                             N/A

  　　BEA JRockit 1.5 (U3)      1909                             1902

  >[https://www.nowcoder.com/questionTerminal/855006adab6b45afb9fe98e3c72b90d6](<https://www.nowcoder.com/questionTerminal/855006adab6b45afb9fe98e3c72b90d6>)

  首先JVM内存限制于实际的最大物理内存了 假设物理内存无限大的话 JVM内存的最大值跟操作系统有很大的关系 简单的说就32位处理器虽然可控内存空间有4GB,但是具体的操作系统会给一个限制，这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G Linux系统 下为2G-3G） 而64bit以上的处理器就不会有限制了

- 假设一个场景，要求stop the world时间非常短，你会怎么设计垃圾回收机制？

  ParNew + CMS

- 垃圾回收器的基本原理是什么？垃圾回收器可以马上回收内存吗？并且有什么办法可以主动通知虚拟机进行垃圾回收呢？

  对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。通常，GC采用有向图的方式记录和管理堆(heap)中的所有对象。通过这种方式确定哪些对象是”可达的”，哪些对象是”不可达的”。当GC确定一些对象为”不可达”时，GC就有责任回收这些内存空间。可以。程序员可以手动执行System.gc()，通知GC运行，但是Java语言规范并不保证GC一定会执行。

- 在java中会存在内存泄漏吗？

  > [https://blog.csdn.net/m0_37204491/article/details/64500151](<https://blog.csdn.net/m0_37204491/article/details/64500151>)

  **内存泄露**就是指一个不再被程序使用的对象或变量一直被占据在内存中。java中有垃圾回收机制，它可以保证一对象不再被引用的时候，即对象变成了孤儿的时候，对象将自动被垃圾回收器从内存中清除掉。由于Java 使用有向图的方式进行垃圾回收管理，可以消除引用循环的问题，例如有两个对象，相互引用，只要它们和根进程不可达的，那么GC也是可以回收它们的。

  **java中的内存泄露的情况**：

  1. 长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄露的发生场景，通俗地说，就是**程序员可能创建了一个对象，以后一直不再使用这个对象，这个对象却一直被引用，即这个对象无用但是却无法被垃圾回收器回收的**，这就是java中可能出现内存泄露的情况，例如，缓存系统，我们加载了一个对象放在缓存中(例如放在一个全局map对象中)，然后一直不再使用它，这个对象一直被缓存引用，但却不再被使用。

     检查java中的内存泄露，一定要让程序将各种分支情况都完整执行到程序结束，然后看某个对象是否被使用过，如果没有，则才能判定这个对象属于内存泄露。

  2. 如果一个外部类的实例对象的方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持久外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄露。

  3. 当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄露。

- 垃圾回收的优点以及原理

  Java 语言中一个显著的特点就是引入了垃圾回收机制，使c++程序员最头疼的内存管理的问题迎刃而解，它使得Java程序员在编写程序的时候不再需要考虑内存管理。由于有个垃圾回收机制，Java中的对象不再有"作用域"的概念，只有对象的引用才有"作用域"。垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低级别的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清楚和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。回收机制有分代复制垃圾回收和标记垃圾回收，增量垃圾回收。

## Java8

> [https://snailclimb.gitee.io/javaguide/#/docs/java/What's%20New%20in%20JDK8/Java8Tutorial](https://snailclimb.gitee.io/javaguide/#/docs/java/What's%20New%20in%20JDK8/Java8Tutorial)

- **Lambda 表达式：Lambda允许把函数作为一个方法的参数**

  首先看看在老版本的Java中是如何排列字符串的：

  ```java
  List<String> names = Arrays.asList("peter", "anna", "mike", "xenia");

  Collections.sort(names, new Comparator<String>() {
      @Override
      public int compare(String a, String b) {
          return b.compareTo(a);
      }
  });
  ```

  只需要给静态方法Collections.sort 传入一个 List 对象以及一个比较器来按指定顺序排列。通常做法都是**创建一个匿名的比较器对象**然后将其传递给 sort 方法。

  在Java 8 中你就没必要使用这种传统的匿名对象的方式了，Java 8提供了更简洁的语法，lambda表达式：

  ```java
  Collections.sort(names, (String a, String b) -> {
      return b.compareTo(a);
  });
  ```

  可以看出，代码变得更段且更具有可读性，但是实际上还可以写得更短：

  ```java
  Collections.sort(names, (String a, String b) -> b.compareTo(a));
  ```

  对于函数体只有一行代码的，你可以去掉大括号{}以及return关键字，但是你还可以写得更短点：

  ```java
  names.sort((a, b) -> b.compareTo(a));
  ```

  List 类本身就有一个 sort 方法。并且Java编译器可以自动推导出参数类型，所以你可以不用再写一次类型。

- **方法和构造函数引用**

  ```java
  Converter<String, Integer> converter = Integer::valueOf;
  Integer converted = converter.convert("123");
  System.out.println(converted.getClass());   //class java.lang.Integer
  ```

  Java 8允许您**通过::关键字传递方法或构造函数的引用。** 上面的示例显示了如何引用静态方法。 但我们也可以引用对象方法：

  ```java
  class Something {
      String startsWith(String s) {
          return String.valueOf(s.charAt(0));
      }
  }
  ```

  ```java
  Something something = new Something();
  Converter<String, String> converter = something::startsWith;
  String converted = converter.convert("Java");
  System.out.println(converted);    // "J"
  ```

  接下来看看构造函数是如何使用::关键字来引用的，首先我们定义一个包含多个构造函数的简单类：

  ```java
  class Person {
      String firstName;
      String lastName;

      Person() {}

      Person(String firstName, String lastName) {
          this.firstName = firstName;
          this.lastName = lastName;
      }
  }
  ```

  接下来我们指定一个用来创建Person对象的对象工厂接口：

  ```java
  interface PersonFactory<P extends Person> {
      P create(String firstName, String lastName);
  }
  ```

  这里我们使用构造函数引用来将他们关联起来，而不是手动实现一个完整的工厂：

  ```java
  PersonFactory<Person> personFactory = Person::new;
  Person person = personFactory.create("Peter", "Parker");
  ```

  我们只需要使用 Person::new 来获取Person类构造函数的引用，Java编译器会自动根据PersonFactory.create方法的参数类型来选择合适的构造函数。

## 数据结构

#### 散列

- 选择散列函数

  - Division method

    - $h(k)=k \mod m$

  - Multiplication method

    - $m=2^r$，计算机有$w$位词

    - $h(k)=(A\cdot k\mod 2^w)\rm{rsh}(w-r)$
    - 模块轮 (Modular wheel)：将轮子旋转$k$个$A$，然后舍弃最后几位

  > [http://www.alloyteam.com/2017/05/hash-functions-introduction/](http://www.alloyteam.com/2017/05/hash-functions-introduction/)

  加法、位运算、乘法、除法、查表、混合

  一个好的哈希函数应该具备以下三点：
  1. 抗碰撞性，尽量避免冲突。
  2. 抗篡改性，只要改动一个字节，其哈希值也会很大不同。
  3. 查找效率。

- 处理冲突

  - 拉链法  

    填装因子$\alpha=表中记录数（键数）n/散列表长度（槽数）m$

    **不成功**搜索的期望时间$=\Theta(1+\alpha)$

  - 开放定址法：线性探查法、平方探查法、再散列法、伪随机序列法

    假设均匀散列，每个键等可能地将$m!$种排序之一作为其探查序列。

    定理：不成功搜索的期望探查次数 $E[$#$probes]\le1/(1-\alpha)$

#### B树和B+树

> 王道数据结构P243 B树和B+树

- B树

  一棵$m$阶B树或为空树，或为满足如下特征的$m$叉树：

  1. **树中每个结点至多有$m$棵子树**（即至多含有$m-1$个关键字）。

  2. **若根节点不是终端结点，则至少有2棵子树。**

  3. **除根结点外的所有非叶结点至少有$\lceil m/2\rceil$棵子树**（即至少含有$\lceil m/2\rceil-1$个关键字）

  4. 所有的非叶结点的结构：$n,P_0,K_1,P_1,K_2,P_2,...,K_n,P_n$. 其中$K_i$为结点的关键字，且满足$K_1\lt K_2\lt...\lt K_n$; $P_i$所指子树中所有结点的关键字均大于$K_i$, $n$为结点中关键字的个数。

  5. 所有的叶节点都出现再同一层次上，并且不带信息。

  B树的插入：定位（找到最底层的某个非叶结点），插入（分裂上移）

  B树的删除：不在终端结点删除（删除合并），在终端结点删除（兄弟够借，兄弟不够借）

- B+树

  $m$阶B+树与$m$阶B树的主要差异在于：

  1. 在B+树中，具有$n$个关键字的结点只含有$n$棵子树，即每个关键字对应一棵子树；而在B树中，具有$n$个关键字的结点含有$(n+1)$棵子树。

  2. 在B+树中，每个结点（非根内部结点）关键字个数$n$的范围时$\lceil m/2\rceil \le n \le m$（根结点：$1\le n\le m-1$）；在B树中，每个结点（非根内部结点）关键字个数$n$的范围是$\lceil m/2\rceil-1 \le n \le m-1$（根结点：$1\le n\le m-1$）。

  3. 在B+树中，叶结点包含信息，所有非叶节点仅起到索引作用，非叶结点中的每个索引项只含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。

  4. 在B+树中，叶结点包含了全部关键字，即在非叶结点中出现的关键字也会出现在叶结点中；而在B树中，叶结点包含的关键字和其他结点包含的关键字是不重复的。

#### 布隆过滤器

**什么是布隆过滤器**

布隆过滤器（Bloom Filter）是一个叫做 Bloom 的老哥于1970年提出的。我们可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。

**布隆过滤器的原理**

当一个元素加入布隆过滤器中的时候，会进行如下操作：

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-hash%E8%BF%90%E7%AE%97.png)

**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

**布隆过滤器使用场景**

1. **判断给定数据是否存在**：**比如判断一个数字是否在于包含大量数字的数字集中**（数字集很大，5亿以上！）、 **防止缓存穿透（判断请求的数据是否有效避免直接绕过缓存请求数据库）**、邮箱的垃圾邮件过滤、黑名单功能等等。
2. 去重：比如爬给定网址的时候对已经爬取过的 URL 去重。

> [https://www.zhihu.com/question/38573286](https://www.zhihu.com/question/38573286)

- 海量数据的TopK问题

  > [https://www.cnblogs.com/itxiaok/p/10385676.html](https://www.cnblogs.com/itxiaok/p/10385676.html)

  - 找重复最多的TopK：散列成多个小数据集再统计
  - 找最大TopK：外排、优先队列、分治找最大
  - 去重：布隆过滤器

- 跳表

  [https://blog.csdn.net/lusic01/article/details/92001898](https://blog.csdn.net/lusic01/article/details/92001898)

## 网络

#### 网络概述

- TCP协议、IP协议、HTTP协议分别在哪一层？
  
  运输层，网络层，应用层。

  ![img](https://uploadfiles.nowcoder.com/images/20190814/980266035_1565787665824_1ABB2DC3D76311944FFDBE9980FBAADD)

  > 王道网络P15 ISO/OSI参考模型和TCP/IP模型
  
  OSI参考模型：**物理层、数据链路层、网络层、运输层、会话层（会话管理）、表示层（数据格式转换）、应用层**

  TCP/IP模型：网络接口层、网际层、传输层、应用层

  学习计算机网络：物理层、数据链路层、网络层、传输层、应用层

  > [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)

  **物理层**

  在物理层上所传送的数据单位是比特。 **物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。** 使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。

  **数据链路层**

  数据链路层(data link layer)通常简称为链路层。**两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。** 在两个相邻节点之间传送数据时，**数据链路层将网络层交下来的 IP 数据报组装成帧**，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。

  在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。 控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。

  **网络层**

  **在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。** 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。

  这里要注意：不要把运输层的“用户数据报 UDP ”和网络层的“ IP 数据报”弄混。另外，无论是哪一层的数据单元，都可笼统地用“分组”来表示。

  这里强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称.

  互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Protocol）和许多路由选择协议，因此互联网的网络层也叫做网际层或IP层。

  **运输层**

  **运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。** 应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。

  运输层主要使用以下两种协议:

  传输控制协议 TCP（Transmission Control Protocol）--提供面向连接的，可靠的数据传输服务。

  用户数据协议 UDP（User Datagram Protocol）--提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。
  
  **应用层**

  **应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。** 应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如**域名系统DNS**，支持万维网应用的 **HTTP协议**，支持电子邮件的 **SMTP协议** 等等。我们把应用层交互的数据单元称为报文。

#### 网络层

- arp协议和arp攻击

  地址解析协议。
  
  > [https://blog.csdn.net/wy_bk/article/details/78823573](https://blog.csdn.net/wy_bk/article/details/78823573)

  **ARP协议**

  ARP协议是一个年代相当“久远”的网络协议。ARP协议制定于1982年11月，英文全称：Address Resolution Protocol，即“地址解析协议”。

  我们知道，虽然终端设备想要上网必须具有公有IP地址，但是在Internet的TCP/IP协议中，IP地址的作用是标识一台主机或路由器与一条链路的接口，也就是说IP地址指明了数据由一个网络传输到另一个网络的路径，但是我们知道，为了节约IP地址，通常情况下，在一个内部网络中，主机常常使用RFC规定的三种私有IP地址作为局域网中主机的IP地址，而且主机的IP地址是由该网络的路由器动态分配的，如果数据的传输仅仅依赖于IP地址，那么当数据到达一个内部网络中时就可能因为目标主机的IP地址发生改变而将数据传输到了错误的目标主机。但是不同设备的物理地址（MAC）是全网唯一的，而且一般也不会被改变（MAC地址是写入网卡的，固定的），因此使用MAC地址作为信息的标识，定位目标网络设备就可以保证信息能够正确抵达目标主机。而通过目标设备的IP地址查找目标设备的MAC地址就是ARP协议的基本功能。

  **ARP协议的工作过程**

  由于内部网络中主机的IP地址往往是动态分配的，因此，在主机中是有ARP缓存的，记录着本网络中IP地址与MAC地址的对应关系。那么，这个ARP缓存是怎么生成的呢？首先，当网络中的主机A需要向主机B发送信息时，会将包含目标IP地址的ARP请求广播到该网络中的所有主机上，网络中的其他主机在收到主机A的ARP请求后可以自主的发送ARP应答报文，应答中包含自己的IP和自己的MAC地址，主机B也会发送这样的应答报文给主机A。这样主机A就知道了主机B的MAC地址与IP地址了。

  ARP协议的工作是建立在网络中各个主机之间相互信任的基础上的，一台主机在收到其他主机的ARP应答报文时并不会采取措施校验该报文的真实性，而是直接就记录到了自己的ARP缓存中以备下次使用。

  **ARP攻击**

  ARP攻击的第一步就是ARP欺骗。由上述“ARP协议的工作过程”我们知道，ARP协议基本没有对网络的安全性做任何思考，当时人们考虑的重点是如何保证网络通信能够正确和快速的完成——ARP协议工作的前提是默认了其所在的网络是一个善良的网络，每台主机在向网络中发送应答信号时都是使用的真实身份。不过后来，人们发现ARP应答中的IP地址和MAC地址中的信息是可以伪造的，并不一定是自己的真实IP地址和MAC地址，由此，ARP欺骗就产生了。

  **ARP欺骗**

  ARP的应答报文是可以伪造的。假设一个网络中有3台主机，分别为A、B和C。当主机A向网络中发送了ARP请求时，用于攻击的主机C可以假装是B，然后向主机A发送一个伪造的ARP应答报文，由于A并不会采取措施验证该报文真伪，而是直接存入自己的ARP缓存并在需要时使用（ARP缓存分两种，一种是静态ARP缓存，该类缓存只要主机不关机就一直存在。另一类是动态ARP缓存，该类缓存是有时效限制的，一般ARP动态缓存的最长生命周期是10分钟，如果一个动态缓存项目在2分钟内没有被使用，则删除，如果在两分钟内被使用了，则增加两分钟的生命周期，直到达到10分钟的最长生命周期后进行更新），由此，C就成功的欺骗了A。那么来自主机B的正确的应答报文去哪了？如果A收到了来自B的正确的应答报文，更新了自己的ARP缓存，那么C的ARP欺骗不就失败了吗？确实会发生这种情况，但是如果C不断的向网络中的各台主机大量发送伪造的ARP应答报文，直到同时欺骗了A和B，C就成功的对主机A和B进行了ARP欺骗。接下来C就可以监听A和B之间的流量，伪造A和B的通信内容或者阻止A和B的通信。

  > 王道网络P149 地址解析协议ARP

  无论网络层使用什么协议，在实际网络的链路上传送数据帧时，最终必须使用硬件地址。所以需要一种方法来完成IP地址到MAC地址的映射，这就是地址解析协议ARP。每个主机都设有一个ARP高速缓存，存放本局域网上各主机和路由器的IP地址到MAC地址的映射表，称ARP表，使用ARP协议来动态维护此ARP表。

  ARP工作在网络层，其工作原理：当主机A欲向本局域网上的某个主机B发送IP数据报时，就先在其ARP高速缓存中查看有无主机B的IP地址。如有，就可查出其对应的硬件地址，再将此硬件地址写入MAC帧，然后通过局域网将该MAC帧发往此硬件地址。如果没有，就通过使用目的MAC地址为FF-FF-FF-FF-FF-FF的帧来封装并广播ARP请求分组，可以使同一个局域网里的所有主机收到ARP请求。当主机B收到该ARP请求后，就会向主机A发出响应ARP分组，分组中包含主机B的IP与MAC地址的映射关系，主机A再收到后将此映射写入ARP缓存中，然后按查询到的硬件地址发送MAC帧。

- 什么是icmp协议，它的作用是什么？

  它是TCP/IP协议族的一个子协议，**用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息**。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。

  > 王道网络P151 网络控制报文协议ICMP

  为了提高IP数据报交付成功的机会，**在网络层使用了网际控制报文协议(ICMP)来允许主机或路由器报告差错和异常情况**。ICMP协议是IP层协议。ICMP报文的种类有两种，即ICMP差错报告报文（包括源点抑制）和ICMP询问报文。

- DHCP协议

  > 王道网络P150 动态主机配置协议DHCP

  动态主机配置协议(DHCP)常用于**给主机动态地分配IP地址**，它提供了即插即用联网的机制，这种机制允许一台计算机加入新的网络和获取IP地址而不用手工参与。DHCP是应用层协议，它是基于UDP的。

- 路由器和交换机的区别

  1、工作层次不同：交换机比路由器更简单，路由器比交换器能获取更多信息

  交换机工作在数据链路层，而路由器工作在网络层

  2、数据转发所依据的对象不同

  交换机的数据转发依据是利用物理地址或者说MAC地址来确定转发数据的目的地址

  而路由器是依据ip地址进行工作的

  3、传统的交换机只能分割冲突域，不能分割广播域；而路由器可以分割广播域

#### 传输层

- 为什么tcp为什么要建立连接？

  保证可靠传输。

- 解释一下TCP为什么可靠一些

  三次握手，超时重传，滑动窗口，拥塞控制。

  > 王道网络P218

  **TCP连接管理**：三次握手、四次挥手
  
  **TCP可靠传输**：累计确认、超时和冗余ACK重传
  
  **TCP流量控制**：接收端控制发送端速率（发送窗口的实际大小是接受窗口和拥塞窗口的最小值）
  
  **TCP拥塞控制**：慢开始（指数规律增长）、拥塞避免（加法增大）、快恢复（j，乘法减小）

  > [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)
  
  **TCP 协议如何保证可靠传输**

  1. 应用数据被分割成 TCP 认为最适合发送的数据块。
  2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
  3. 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
  4. TCP 的接收端会丢弃重复的数据。
  5. 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
  6. 拥塞控制： 当网络拥塞时，减少数据的发送。
  7. ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
  8. 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

- 哪种应用场景会使用TCP协议，使用它的意义

  当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议

- TCP,UDP 协议的区别

  > [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/tcp-vs-udp.jpg)
  
  UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等

  TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

- TCP的连接和释放过程

  三次握手的过程

  1）主机A向主机B发送TCP连接请求数据包，其中包含主机A的初始序列号seq(A)=x。（其中报文中同步标志位SYN=1，ACK=0，表示这是一个TCP连接请求数据报文；序号seq=x，表明传输数据时的第一个数据字节的序号是x）；

  2）主机B收到请求后，会发回连接确认数据包。（其中确认报文段中，标识位SYN=1，ACK=1，表示这是一个TCP连接响应数据报文，并含主机B的初始序列号seq(B)=y，以及主机B对主机A初始序列号的确认号ack(B)=seq(A)+1=x+1）

  3）第三次，主机A收到主机B的确认报文后，还需作出确认，即发送一个序列号seq(A)=x+1；确认号为ack(A)=y+1的报文；

  四次挥手过程

  假设主机A为客户端，主机B为服务器，其释放TCP连接的过程如下：
  1） 关闭客户端到服务器的连接：首先客户端A发送一个FIN，用来关闭客户到服务器的数据传送，然后等待服务器的确认。其中终止标志位FIN=1，序列号seq=u。
  2） 服务器收到这个FIN，它发回一个ACK，确认号ack为收到的序号加1。
  3） 关闭服务器到客户端的连接：也是发送一个FIN给客户端。

  4） 客户段收到FIN后，并发回一个ACK报文确认，并将确认序号seq设置为收到序号加1。 首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。

  > 王道网络P213 TCP协议

  **TCP连接的建立**

  ![img](https://uploadfiles.nowcoder.com/images/20180927/308572_1538027722640_EBFE71FE6E03CBB1AAE38A25DC56AFB2)

  连接的建立经历以下3个步骤，通常称为“三次握手”。

  第一步：客户机的TCP首先向服务器的TCP发送一个连接请求报文段。这个特殊的报文段重不含应用层数据，起首部中的SYN标志位被置为1。另外，客户机会随机选择一个起始序号seq=x（连接请求报文不携带数据，但要消耗掉一个序号）

  第二步：服务器的TCP收到连接请求报文段后，如同意连接，就像客户机发回确认，并为该TCP连接分配TCP缓存和变量。在确认报文段中，SYN和ACK位都被置为1，确认号字段的值为x+1，并且服务器随机产生其实序号seq=y（确认报文不携带数据，但也要消耗掉一个序号）。确认报文段同样不包含应用层数据。

  第三步：当客户机收到确认报文段后，还要向服务器给出确认，并且也要给该连接分配缓存和变量。这个报文段的ACK标志位被置为1，序号字段为x+1，确认号字段ack=y+1。该报文段可以携带数据，如果不携带数据则不消耗序号。

  **TCP连接的释放**

  ![img](https://uploadfiles.nowcoder.com/images/20180927/308572_1538027843891_F17231DF387BA79A4CCC2E7CDD1C110E)

  TCP连接释放的过程通常称为“四次挥手”。

  第一步：客户机打算关闭连接，就向其TCP发送一个连接释放报文段，并停止再发送数据，主动关闭TCP连接，该报文段的FIN标志位被置为1，seq=u，它等于前面已传送过的数据的最后一个字节的序号加1（FIN报文段即使不携带数据，也要消耗一个序号）。TCP是全双工的，即可以想象成是一条TCP连接上有两条数据通路。当发送FIN报文时，发送FIN的一端就不能再发送数据，也就是关闭了其中一条数据通路，但对方好可以发送数据。

  第二步：服务器收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等于它前面已传送过的数据的最后一个字节的序号加1。此时，从客户机到服务器这个方向的连接就释放了，TCP连接处于半关闭状态。但服务器若发送数据，客户机仍要接收，即从服务器到客户机这个方向的连接并未关闭。

  第三步：若服务器已经没有要向客户机发送的数据，就通知TCP释放连接，此时它发出FIN=1的连接释放报文段。

  第四步：客户机收到连接释放报文段后，必须发出确认。在确认报文段中，ACK字段被置为1，确认号ack=w+1，序号seq=u+1。此时TCP连接还没有释放掉，必须经过时间等待计时器设置的时间2MSS后，A才进入到连接关闭状态。

  > [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)

  **为什么要三次握手**

  **三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

  第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

  第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

  第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

  所以三次握手就能确认双发收发功能都正常，缺一不可。

  **为什么要传回 SYN**

  接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。

  > SYN 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement[汉译：确认字符 ,在数据通信传输中，接收站发给发送站的一种传输控制字符。它表示确认发来的数据已经接受无误。 ]）消息响应。这样在客户机和服务器之间才能建立起可靠的TCP连接，数据才可以在客户机和服务器之间传递。

  **传了 SYN,为啥还要传 ACK**

  双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。

  **为什么要四次挥手**

  任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。

  举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

- 滑动窗口的作用

  [https://www.zhihu.com/question/32255109](https://www.zhihu.com/question/32255109)

  **滑动窗口实现面向流的可靠性**

  1）最基本的传输可靠性来源于“确认重传”机制。

  2）TCP的滑动窗口的可靠性也是建立在“确认重传”基础上的。

  3）发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，m 左边界。

  4）接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。

  **滑动窗口的流控特性**

  TCP的滑动窗口是动态的，我们可以想象成小学常见的一个数学题，一个水池，体积V，每小时进水量V1，出水量V2。当水池满了就不允许再注入了，如果有个液压系统控制水池大小，那么就可以控制水的注入速率和量。这样的水池就类似TCP的窗口。应用根据自身的处理能力变化，通过本端TCP接收窗口大小控制来对对对端的发送窗口流量限制。

  应用程序在需要（如内存不足）时，通过API通知TCP协议栈缩小TCP的接收窗口。然后TCP协议栈在下个段发送时包含新的窗口大小通知给对端，对端按通知的窗口来改变发送窗口，以此达到减缓发送速率的目的。

- TIME_WAIT和CLOSE_WAIT

  > [https://www.jianshu.com/p/394cafc91d18](https://www.jianshu.com/p/394cafc91d18)

  > [https://zhuanlan.zhihu.com/p/60382685](https://zhuanlan.zhihu.com/p/60382685)

#### 应用层

- SSL四次握手的过程

- 负载均衡 反向代理模式的优点、缺点

- DNS的寻址过程

  > 王道网络P242 DNS系统

  域名系统DNS是因特网使用的命名系统，用来把便于人们记忆的含有特定含义的主机名转换为便于机器处理的IP地址。DNS系统采用客户/服务器模型，其协议运行在UDP之上，使用53号端口。

  递归查询（比较少用）、迭代查询
  
  本地域名服务器分别请求根域名服务器、顶级域名服务器、权限域名服务器

> [https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C](https://snailclimb.gitee.io/javaguide/#/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C)

- 在浏览器中输入url地址 ->> 显示主页的过程(面试常客)

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/url%E8%BE%93%E5%85%A5%E5%88%B0%E5%B1%95%E7%A4%BA%E5%87%BA%E6%9D%A5%E7%9A%84%E8%BF%87%E7%A8%8B.jpg)

  总体来说分为以下几个过程:

  1. DNS解析
  2. TCP连接
  3. 发送HTTP请求
  4. 服务器处理请求并返回HTTP报文
  5. 浏览器解析渲染页面
  6. 连接结束

- 各种协议与HTTP协议之间的关系

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E5%90%84%E7%A7%8D%E5%8D%8F%E8%AE%AE%E4%B8%8EHTTP%E5%8D%8F%E8%AE%AE%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.png)

- 状态码

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E7%8A%B6%E6%80%81%E7%A0%81.png)

- HTTP是不保存状态的协议,如何保存用户状态?

  HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个Session）。

  在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

  Cookie 被禁用怎么办?

  最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。

- Cookie的作用是什么?和Session有什么区别？

  Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。

  Cookie 一般用来保存用户信息 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

  Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。

  Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

- session原理

  > [https://www.cnblogs.com/saysmy/p/8535571.html](https://www.cnblogs.com/saysmy/p/8535571.html)

  为了记录session，在客户端和服务器端都要保存数据，客户端记录一个标记，服务器端不但存储了这个标记同时还存储了这个标记映射的数据。好吧，还是说点白话吧，在客户端记录的其实是一个sessionid，在服务器端记录的是一个key-value形式的数据结构，这里的key肯定是指sessionid了，value就代表session的详细内容。用户在做http请求的时候，总是会把sessionid传递给服务器，然后服务器根据这个sessionid来查询session的内容（也就是上面说到的value）。
  
  现在我们重点关注一下sessionid，他是今天问题的关键所在。sessionid在客户端（http的客户端一般就是指浏览器了）是存储在cookie中，当然也有例外（书本上肯定会提到也有保存在url中的，我做程序员这么多年也没有见过这种方式，这难道就是现实和实际的差距吗，好残酷）。

- session 生命周期

  > [https://blog.csdn.net/bylhjcsmmd/article/details/53158898](https://blog.csdn.net/bylhjcsmmd/article/details/53158898)

- HTTP长连接,短连接

  在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

  而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：

  Connection:keep-alive

  在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

  HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。

- HTTP 1.0和HTTP 1.1的主要区别是什么?

  HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：

  长连接 : 在HTTP/1.0中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP 1.1起，默认使用长连接 ,默认开启Connection： keep-alive。 HTTP/1.1的持续连接有非流水线方式和流水线方式 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。

  错误状态响应码 :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

  缓存处理 :在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。

  带宽优化及网络连接的使用 :HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

- URI和URL的区别是什么?

  URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。

  URL(Uniform Resource Location) 是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

  URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

- HTTP 和 HTTPS 的区别？

  端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。

  安全性和资源消耗： HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。**所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。**所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

  **对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等；**

  **非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。**

- HTTPS原理和流程

  HTTPS通信过程

  HTTPS协议 = HTTP协议 + SSL/TLS协议，在HTTPS数据传输的过程中，需要用SSL/TLS对数据进行加密和解密，需要用HTTP对加密后的数据进行传输，由此可以看出HTTPS是由HTTP和SSL/TLS一起合作完成的。

  SSL的全称是Secure Sockets Layer，即安全套接层协议，是为网络通信提供安全及数据完整性的一种安全协议。SSL协议在1994年被Netscape发明，后来各个浏览器均支持SSL，其最新的版本是3.0

  TLS的全称是Transport Layer Security，即安全传输层协议，最新版本的TLS（Transport Layer Security，传输层安全协议）是IETF（Internet Engineering Task Force，Internet工程任务组）制定的一种新的协议，它建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本。在TLS与SSL3.0之间存在着显著的差别，主要是它们所支持的加密算法不同，所以TLS与SSL3.0不能互操作。虽然TLS与SSL3.0在加密算法上不同，但是在我们理解HTTPS的过程中，我们可以把SSL和TLS看做是同一个协议。

  HTTPS为了兼顾安全与效率，同时使用了对称加密和非对称加密。数据是被对称加密传输的，对称加密过程需要客户端的一个密钥，为了确保能把该密钥安全传输到服务器端，采用非对称加密对该密钥进行加密传输，总的来说，对数据进行对称加密，对称加密所要使用的密钥通过非对称加密传输。

  HTTPS在传输的过程中会涉及到三个密钥：

  服务器端的公钥和私钥，用来进行非对称加密

  客户端生成的随机密钥，用来进行对称加密

  一个HTTPS请求实际上包含了两次HTTP传输，可以细分为8步。

  1. **客户端向服务器发起HTTPS请求**，连接到服务器的443端口

  2. 服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人。

  3. **服务器将自己的公钥发送给客户端。**

  4. 客户端收到服务器端的公钥之后，会对公钥进行检查，验证其合法性，如果发现发现公钥有问题，那么HTTPS传输就无法继续。严格的说，这里应该是验证服务器发送的数字证书的合法性，关于客户端如何验证数字证书的合法性，下文会进行说明。如果公钥合格，那么**客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，我们将该密钥称之为client key，即客户端密钥**，这样在概念上和服务器端的密钥容易进行区分。**然后用服务器的公钥对客户端密钥进行非对称加密，这样客户端密钥就变成密文了**，至此，HTTPS中的第一次HTTP请求结束。

  5. **客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端密钥发送给服务器。**

  6. **服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密**，解密之后的明文就是客户端密钥，**然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。**

  7. 然后**服务器将加密后的密文发送给客户端。**

  8. **客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密**，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成。

- XML和JSON优缺点

  > https://www.cnblogs.com/sanmaospace/p/3139186.html

  (1).XML的优缺点

  <1>.XML的优点

  　　A.格式统一，符合标准；

  　　B.容易与其他系统进行远程交互，数据共享比较方便。

  <2>.XML的缺点

  　　A.XML文件庞大，文件格式复杂，传输占带宽；

  　　B.服务器端和客户端都需要花费大量代码来解析XML，导致服务器端和客户端代码变得异常复杂且不易维护；

  　　C.客户端不同浏览器之间解析XML的方式不一致，需要重复编写很多代码；

  　　D.服务器端和客户端解析XML花费较多的资源和时间。

  (2).JSON的优缺点

  <1>.JSON的优点：

  　　A.数据格式比较简单，易于读写，格式都是压缩的，占用带宽小；

  　　B.易于解析，客户端JavaScript可以简单的通过eval()进行JSON数据的读取；

  　　C.支持多种语言，包括ActionScript, C, C#, ColdFusion, Java, JavaScript, Perl, PHP, Python, Ruby等服务器端语言，便于服务器端的解析；

  　　D.在PHP世界，已经有PHP-JSON和JSON-PHP出现了，偏于PHP序列化后的程序直接调用，PHP服务器端的对象、数组等能直接生成JSON格式，便于客户端的访问提取；

  　　E.因为JSON格式能直接为服务器端代码使用，大大简化了服务器端和客户端的代码开发量，且完成任务不变，并且易于维护。

  <2>.JSON的缺点

  　　A.没有XML格式这么推广的深入人心和喜用广泛，没有XML那么通用性；

  　　B.JSON格式目前在Web Service中推广还属于初级阶段。

- HTTP 2.0

  > [https://www.cnblogs.com/heluan/p/8620312.html](https://www.cnblogs.com/heluan/p/8620312.html)

- HTTP请求/响应报文结构

  > [https://www.cnblogs.com/ldq2016/p/9055933.html](https://www.cnblogs.com/ldq2016/p/9055933.html)

  字符编码集、语言、内容长度、服务器的域名和端口号

  > [https://blog.csdn.net/sdb5858874/article/details/80535348](https://blog.csdn.net/sdb5858874/article/details/80535348)

  一、请求报文的结构：

  - 请求行：**请求方法GET/POST**、**URL**、**协议版本HTTP1.0/HTTP1.1**
  - 请求头部
  - 请求主体

  1.请求报文中方法的介绍：
  GET  请求获取一个Web页面
  POST 主要作用是执行操作，比如向服务器提交一个表单
  DELETE  请求删除一个Web界面
  MOVE 请求移动某个页面到指定位置
  HEAD 与GET方法类似区别在于获取Web页面首部，不获取主体
             也就是说只获得一个页面的Head部分，而不获得BODY主体
  PUT 请求向服务器上传指定资源。
  TRACE  用于测试，要求服务器返回收到的请求
  OPTION请求服务器支持哪些方法

  2.请求消息头
  字段名               说明

  **Host**         消息头用于指定出现在被访问的完整URL中的主机名称  （被访问的完整URL主机名，也就是目的地址）

  **User-Agent**   这个消息头用于提供与浏览器或生成请求的客户端软件有关的消息

  Accept  这个消息头用于告诉服务器客户端接收那些内容，如图片类型，办公文档格式等

  Accept-Language 用于声明服务器，浏览器支持哪些语言

  Accept-Encoding 这个消息头用于告诉服务器 客户端接受那些内容编码

  **Referer**  这个消息头用于指示提出当前请求的原始URL

  **Cookie**

  Connection  通知通信的另一方，是否在完成HTTP传输后关闭TCP连接


  二、响应报文的结构

  - 响应行：**版本**、**状态码**、短语
  - 响应头部
  - 响应主体

  1.有关状态码的介绍
  状态码是响应报文状态行中包含的一个三位数字  指明请求是否被满足，如果没有被满足，原因是什么，状态码可以分为以下五大类

  状态码         含义                          例子
  1XX        表示请求已被接收，继续处理            100：服务器正在处理客户请求
  2XX        表示请求已被成功接收，理解，接受          200：请求成功
  3XX        客户端被重定向到其他资源                301：表示本网页永久性跳转到另一个地址
                                                                         302：重定向，浏览器自动跳转到新连接
                                                                         304：上次文档已经缓存，还可以继续使用
  4XX         请求有语法错误或请求无法实现         400：请求有语法错误
                                                                          403：拒绝提供服务
                                                                          404：请求资源不存在
  5XX          服务器执行请求时遇到错误。            500：服务器错误
                                                                          503：服务器不能处理，请稍后再试

  2.响应头部字段说明
  date     响应返回的时间，GMT代表格林威治时间（北京位于东八区，所以北京时间要加8小时）
  server   这个消息头提供所使用的Web服务器软件的相关信息
  set-Cookie  这个消息头用于向浏览器发布Cookie，浏览器会在随后的请求中将其返回给服务器
  Content-type  这个消息头用于规定消息主题的内容类型 例如html文档的类型为：text/html，
  Content-Length  这个消息头用于规定消息主体的字节长度
  Connection  通知通信的另一方，是否在完成HTTP传输后关闭TCP连接

- get请求和post请求的区别

  GET请求把参数包含在URL中，将请求信息放在URL后面，POST请求通过request body传递参数，将请求信息放置在报文体中。

  > [https://www.zhihu.com/question/28586791](https://www.zhihu.com/question/28586791)

  **GET**
  
  “读取“一个资源。比如Get到一个html文件。反复读取不应该对访问的数据有副作用。比如”GET一下，用户就下单了，返回订单已受理“，这是不可接受的。没有副作用被称为“幂等“（Idempotent)。
  
  因为GET因为是读取，就可以对GET请求的数据做缓存。这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），或者做到server端（用Etag，至少可以减少带宽消耗）

  **POST**

  在页面里<form> 标签会定义一个表单。点击其中的submit元素会发出一个POST请求让服务器做一件事。这件事往往是有副作用的，不幂等的。

  不幂等也就意味着不能随意多次执行。因此也就不能缓存。比如通过POST下一个单，服务器创建了新的订单，然后返回订单成功的界面。这个页面不能被缓存。试想一下，如果POST请求被浏览器缓存了，那么下单请求就可以不向服务器发请求，而直接返回本地缓存的“下单成功界面”，却又没有真的在服务器下单。那是一件多么滑稽的事情。

  GET和POST携带数据的格式也有区别。当浏览器发出一个GET请求时，就意味着要么是用户自己在浏览器的地址栏输入，要不就是点击了html里a标签的href中的url。所以其实并不是GET只能用url，而是浏览器直接发出的GET只能由一个url触发。所以没办法，GET上要在url之外带一些参数就只能依靠url上附带querystring。但是HTTP协议本身并没有这个限制。

  浏览器的POST请求都来自表单提交。每次提交，表单的数据被浏览器用编码到HTTP请求的body里。浏览器发出的POST请求的body主要有有两种格式，一种是application/x-www-form-urlencoded用来传输简单的数据，大概就是"key1=value1&key2=value2"这样的格式。另外一种是传文件，会采用multipart/form-data格式。采用后者是因为application/x-www-form-urlencoded的编码方式对于文件这种二进制的数据非常低效。

  浏览器在POST一个表单时，url上也可以带参数，只要<form action="url" >里的url带querystring就行。只不过表单里面的那些用<input> 等标签经过用户操作产生的数据都在会在body里。

  因此我们一般会泛泛的说“GET请求没有body，只有url，请求数据放在url的querystring中；POST请求的数据在body中“。但这种情况仅限于浏览器发请求的场景。

- HTTP GET、DELETE、PUT、POST四种主要方法的幂等性的理解

  - GET:GET请求是幂等的，多次的GET请求，不应该修改数据状态，只是查询。
  - DELETE：Delete请求也具有幂等性，执行一次请求，删除id=1的记录，多次请求与一次请求的结果应该是一样的，最终的结果都是把id=1的记录删除。
　- PUT：Put意为修改记录，也具有幂等性，执行一次请求，将记录修改为特定状态，多次请求结果也应该是一样的。
　- POST：Post请求不具有幂等性，通常为增加记录。没执行一次请求，都会增加一条记录。

- DNS的寻址过程

  1、在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。

  2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。

  3、如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。

  4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。

  5、如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。

  6、如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。

  从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。

  > [https://www.cnblogs.com/WindSun/p/11489356.html](https://www.cnblogs.com/WindSun/p/11489356.html)

  DNS解析（域名解析服务器）
  a）首先会搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存）

  b）如果浏览器自身的缓存里面没有找到，那么浏览器会搜索系统自身的DNS缓存

  c）如果还没有找到，那么尝试从 hosts文件里面去找

  d）在前面三个过程都没获取到的情况下，就递归地去域名服务器去查找，具体过程如下

  ![https://ask.qcloudimg.com/draft/6064128/5rxqugj8dh.png](https://ask.qcloudimg.com/draft/6064128/5rxqugj8dh.png)

  DNS优化两个方面：DNS缓存、DNS负载均衡

- 请你简单讲解一下，负载均衡 反向代理模式的优点、缺点

  （1）反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。

  （2）反向代理负载均衡技术是把将来自internet上的连接请求以反向代理的方式动态地转发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。

  （3）反向代理负载均衡能以软件方式来实现，如apache mod_proxy、netscape proxy等，也可以在高速缓存器、负载均衡器等硬件设备上实现。反向代理负载均衡可以将优化的负载均衡策略和代理服务器的高速缓存技术结合在一起，提升静态网页的访问速度，提供有益的性能；由于网络外部用户不能直接访问真实的服务器，具备额外的安全性（同理，NAT负载均衡技术也有此优点）。

  （4）其缺点主要表现在以下两个方面

  反向代理是处于OSI参考模型第七层应用的，所以就必须为每一种应用服务专门开发一个反向代理服务器，这样就限制了反向代理负载均衡技术的应用范围，现在一般都用于对web服务器的负载均衡。

  针对每一次代理，代理服务器就必须打开两个连接，一个对外，一个对内，因此在并发连接请求数量非常大的时候，代理服务器的负载也就非常大了，在最后代理服务器本身会成为服务的瓶颈。

  一般来讲，可以用它来对连接数量不是特别大，但每次连接都需要消耗大量处理资源的站点进行负载均衡，如search等。

## 操作系统

- 什么是死锁？

  > 王道操作系统P114

  **死锁是指多个进程因竞争资源而造成一种僵局（互相等待）**，若无外力作用，这些进程都无法向前推进。

  例如，某计算机系统只有一台答应及和一台输入设备，进程P1正占用输入设备，同时又提出使用答应及的请求，但此时打印机正被进程P2所占用，而P2在未释放打印机之前，又提出请求使用正被P1占用着的输入设备。这样两个进程相互无休止地进行下去，均无法继续执行，此时两个进程陷入死锁状态。

  - 死锁预防：破坏死锁产生的四个必要条件，只要其中任一条件不成立，死锁就不会发生。

    - **互斥条件**：进程要求对锁分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占用。此时若有其他进程请求该资源，则请求进程只能等待。

    - **不剥夺条件**：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放）。

    - **请求和保持条件**：进程已经保持了至少一个资源，但由提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。

      为了破坏请求和保持条件，采用预先静态分配方法，即进程在运行前**一次申请完它所需要的全部资源**，在它的资源未满足前，不把它投入运行。

    - **循环等待条件**：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被链中下一个进程所请求。

      为了破坏循环等待条件，采用**顺序资源分配法**。首先给系统中的资源编号，规定**每个进程必须按编号递增的顺序请求资源**，同类资源一次申请完。

  - 死锁避免：银行家算法

  - 死锁检测与解除：资源分配图、死锁定理

- JAVA中如何确保N个线程可以访问N个资源，但同时又不导致死锁？

  > [https://www.nowcoder.com/questionTerminal/7192c9454277483d8711a7b4237a0bbe](<https://www.nowcoder.com/questionTerminal/7192c9454277483d8711a7b4237a0bbe>)

  多线程产生死锁需要四个条件，分别是互斥性，保持和请求，不可剥夺性还有要形成闭环，这四个条件缺一不可，只要破坏了其中一个条件就可以破坏死锁，其中最简单的方法就是线程都是以同样的顺序加锁和释放锁，也就是破坏了第四个条件。

- 怎么理解操作系统里的内存碎片，有什么解决办法？

  内存碎片分为：内部碎片和外部碎片。

  内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；

  内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。

  单道连续分配只有内部碎片。多道固定连续分配既有内部碎片，又有外部碎片。

  外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。

  外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。

  使用伙伴系统算法。

  > 王道操作系统P144 连续分配管理方式

  固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干个固定的区域，每个分区只装入一道作业。当程序小于固定分区大小时，也占用了一个完整的内存分区空间，这样分区内部有空间浪费，这种现象称为内部碎片。

  动态分区分配不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。动态分区在开始分配时是很好的，但是之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片，这些小的内存碎片称为外部碎片。克服外部碎片可以通过紧凑技术来解决。

- 什么是页式存储？

  > 王道操作系统 P147 非连续分配管理方式
  
  **基本分页存储管理方式**

  分页存储管理的逻辑地址结构：页号P、页内偏移量W
  
  页表项：页号P、块号b

  页号根据页表查到块号，与页内偏移量拼接，得到物理地址。

  **基本分段存储管理方式**

  分段系统中的逻辑地址结构：段号S、段内偏移量W

  段表项：段号S、段长C、基址b

  段号根据段表查到基址，加上段内偏移量，得到物理地址。

  **段页式管理方式**

  段页式系统的逻辑地址结构：段号S、页号P、页内偏移量W

  段号根据段表查到页表的起始地址。页号根据页表查到块号，与页内偏移量拼接，得到物理地址。

- 页面置换算法

  > 王道操作系统P176 页面置换算法

  - 最佳(OPT)置换算法

    最佳置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。

  - 先进先出(FIFO)置换算法

    优先淘汰最早进入内存的页面，亦即在内存中驻留时间最久的页面。

    FIFO算法会产生党所分配的物理块数增大而页故障数不增反减的异常现象，称为Belady异常。只有FIFO算法可能出现Belady异常，而LRU和OPT算法永远不会出现Belady异常。

  - 最近最久未使用(LRU)置换算法

    它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法未每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。

  - 时钟(CLOCK)置换算法

    又称为最近未用(NRU)算法。给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为1；当该页随后再被访问到时，它的使用位也被置为1。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。当遇到一个使用位为1的帧时，操作系统就将该位重新置为0。

## 数据库

#### MySQL

- 内连接、左外连接、右外连接、全连接

  > [https://blog.csdn.net/plg17/article/details/78758593](https://blog.csdn.net/plg17/article/details/78758593)

- MySQL 七大约束

  > [https://blog.csdn.net/apt1203jn/article/details/80314605](https://blog.csdn.net/apt1203jn/article/details/80314605)

  - **not null** 不允许为空
  - **default** 默认值
  - comment 列描述
  - zerofill 在数据前面自动填充0
  - **primary key** 主键不能为空，不能重复，一张表有且只能有一个主键，可以是复合主键
  - **auto_increment** 自增长
  - **unique** 唯一键允许为空，但是不能重复

- MyISAM和InnoDB区别

  MyISAM是MySQL的默认数据库引擎（5.5版之前）。虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但MyISAM不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。不过，5.5版本之后，MySQL引入了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。

  大多数时候我们使用的都是 InnoDB 存储引擎，但是在某些情况下使用 MyISAM 也是合适的比如读密集的情况下。（如果你不介意 MyISAM 崩溃恢复问题的话）。

  两者的对比：

  1. **是否支持行级锁** : MyISAM 只有表级锁(table-level locking)，而InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。
  2. **是否支持事务和崩溃后的安全恢复**： MyISAM 强调的是性能，每次查询具有原子性,其执行速度比InnoDB类型更快，但是不提供事务支持。但是InnoDB 提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。
  3. **是否支持外键**： MyISAM不支持，而InnoDB支持。
  4. **是否支持MVCC** ：仅 InnoDB 支持。应对高并发事务, MVCC比单纯的加锁更高效;MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作;MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统一。推荐阅读：MySQL-InnoDB-MVCC多版本并发控制
  5. ......
  
  《MySQL高性能》上面有一句话这样写到:

  > 不要轻易相信“MyISAM比InnoDB快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。

  一般情况下我们选择 InnoDB 都是没有问题的，但是某些情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择MyISAM也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。

- 字符集及校对规则

  字符集指的是一种从二进制编码到某类字符符号的映射。校对规则则是指某种字符集下的排序规则。MySQL中每一种字符集都会对应一系列的校对规则。

  MySQL采用的是类似继承的方式指定字符集的默认值，每个数据库以及每张数据表都有自己的默认值，他们逐层继承。比如：某个库中所有表的默认字符集将是该数据库所指定的字符集（这些表在没有指定字符集的情况下，才会采用默认字符集）

- 索引

  MySQL索引使用的数据结构主要有**BTree索引** 和 **哈希索引** 。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。

  MySQL的BTree索引使用的是B树中的B+Tree，但对于主要的两种存储引擎的实现方式是不同的。

  - **MyISAM**: B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则**取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录**。这被称为“**非聚簇索引**”。
  
  - **InnoDB**: 其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，**树的叶节点data域保存了完整的数据记录**。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“**聚簇索引（或聚集索引）**”。而其余的索引都作为辅助索引，**辅助索引的data域存储相应记录主键的值而不是地址**，这也是和MyISAM不同的地方。**在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。**

  > [https://www.kancloud.cn/kancloud/theory-of-mysql-index/41852](https://www.kancloud.cn/kancloud/theory-of-mysql-index/41852)

- 查询缓存的使用

  > 执行查询语句的时候，会先查询缓存。不过，MySQL 8.0 版本后移除，因为这个功能不太实用。

  my.cnf加入以下配置，重启MySQL开启查询缓存

  ```properties
  query_cache_type=1
  query_cache_size=600000
  ```
  MySQL执行以下命令也可以开启查询缓存

  ```properties
  set global  query_cache_type=1;
  set global  query_cache_size=600000;
  ```
  如上，**开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果。** 这里的查询条件包括查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息。因此任何两个查询在任何字符上的不同都会导致缓存不命中。此外，如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果也不会被缓存。

  缓存建立之后，MySQL的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。

  **缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。** 因此，开启缓存查询要谨慎，尤其对于写密集的应用来说更是如此。如果开启，要注意合理控制缓存空间大小，一般来说其大小设置为几十MB比较合适。此外，**还可以通过sql_cache和sql_no_cache来控制某个查询语句是否需要缓存：**

  ```sql
  select sql_no_cache count(*) from usr;
  ```

- 什么是事务?

  **事务是逻辑上的一组操作，要么都执行，要么都不执行。**

  事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。

  事务的四大特性(ACID)

  1. **原子性（Atomicity）**： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
  2. **一致性（Consistency）**： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
  3. **隔离性（Isolation）**： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
  4. **持久性（Durability）**： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

  > [https://blog.csdn.net/chosen0ne/article/details/10036775](https://blog.csdn.net/chosen0ne/article/details/10036775)

  **一致性（Consistency）**

  一致性是指事务使得系统从一个一致的状态转换到另一个一致状态。事务的一致性决定了一个系统设计和实现的复杂度。事务可以不同程度的一致性：

  - 强一致性：读操作可以立即读到提交的更新操作。

  - 弱一致性：提交的更新操作，不一定立即会被读操作读到，此种情况会存在一个不一致窗口，指的是读操作可以读到最新值的一段时间。

  - 最终一致性：是弱一致性的特例。事务更新一份数据，最终一致性保证在没有其他事务更新同样的值的话，最终所有的事务都会读到之前事务更新的最新值。如果没有错误发生，不一致窗口的大小依赖于：通信延迟，系统负载等。

  > [https://www.zhihu.com/question/31346392](https://www.zhihu.com/question/31346392)

  数据库一致性

  ACID里的AID都是数据库的特征,也就是依赖数据库的具体实现.而唯独这个C,实际上它依赖于应用层,也就是依赖于开发者.这里的一致性是指系统从一个正确的状态,迁移到另一个正确的状态.什么叫正确的状态呢?就是当前的状态满足预定的约束就叫做正确的状态.而事务具备ACID里C的特性是说通过事务的AID来保证我们的一致性.

  例子：A要向B支付100元,而A的账户中只有90元,并且我们给定账户余额这一列的约束是,不能小于0.那么很明显这条事务执行会失败,因为90-100=-10,小于我们给定的约束了.

- **并发事务带来哪些问题?**

  在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。

  - **脏读（Dirty read）**: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
  - **丢失修改（Lost to modify）**: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。
  - **不可重复读（Unrepeatableread）**: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
  - **幻读（Phantom read）**: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
  
  **不可重复读和幻读区别：**

  不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。

- **事务隔离级别有哪些?MySQL的默认隔离级别是?**

  SQL 标准定义了四个隔离级别：

  - READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，**允许读取尚未提交的数据变更**，可能会导致脏读、幻读或不可重复读。
  - READ-COMMITTED(读取已提交)： **允许读取并发事务已经提交的数据**，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
  - REPEATABLE-READ(可重复读)： **对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改**，可以阻止脏读和不可重复读，但幻读仍有可能发生。
  - SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。**所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰**，也就是说，该级别可以防止脏读、不可重复读以及幻读。

  | 隔离级别 | 脏读 | 不可重复读 | 幻影读 |
  | - | - | - | - |
  | 读取未提交(READ-UNCOMMITTED) | √ | √ | √ |
  | 读取已提交(READ-COMMITTED) | × | √ | √ |
  | 可重复读(REPEATABLE-READ) | × |	× | √ |
  | 可串行化(SERIALIZABLE) | × | × | × |

  MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。

  这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server) 是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化) 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读） 并不会有任何性能损失。

  InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。

- **锁机制与InnoDB锁算法**

  MyISAM和InnoDB存储引擎使用的锁：

  - MyISAM采用表级锁(table-level locking)。
  - InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁
  
  表级锁和行级锁对比：

  - 表级锁： MySQL中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。
  - 行级锁： MySQL中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

  InnoDB存储引擎的锁的算法有三种：

  - Record lock：单个行记录上的锁
  - Gap lock：间隙锁，锁定一个范围，不包括记录本身
  - Next-key lock：record+gap 锁定一个范围，包含记录本身
  
  相关知识点：

  1. innodb对于行的查询使用next-key lock
  2. Next-locking keying为了解决Phantom Problem幻读问题
  3. 当查询的索引含有唯一属性时，将next-key lock降级为record key
  4. Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
  5. 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1

- 大表优化

  当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：

  1. 限定数据的范围

      务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；

  2. 读/写分离

      经典的数据库拆分方案，主库负责写，从库负责读；

  3. 垂直分区

      根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

      简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 如下图所示，这样来说大家应该就更容易理解了。

      ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9E%82%E7%9B%B4%E5%88%86%E5%8C%BA.png)
    
      - 垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。

      - 垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；
  
  4. 水平分区

      保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。

      水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。

      ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%B0%B4%E5%B9%B3%E6%8B%86%E5%88%86.png)

      水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。

      水平拆分能够 支持非常大的数据量存储，应用端改造也少，但 分片事务难以解决 ，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度 ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

  下面补充一下数据库分片的两种常见方案：

  - 客户端代理： 分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。 当当网的 Sharding-JDBC 、阿里的TDDL是两种比较常用的实现。
  - 中间件代理： 在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。 我们现在谈的 Mycat 、360的Atlas、网易的DDB等等都是这种架构的实现。

- 解释一下什么是池化设计思想。什么是数据库连接池?为什么需要数据库连接池?

  池化设计应该不是一个新名词。我们常见的如java线程池、jdbc连接池、redis连接池等就是这类设计的代表实现。这种设计会初始预设资源，解决的问题就是抵消每次获取资源的消耗，如创建线程的开销，获取远程连接的开销等。就好比你去食堂打饭，打饭的大妈会先把饭盛好几份放那里，你来了就直接拿着饭盒加菜即可，不用再临时又盛饭又打菜，效率就高了。除了初始化资源，池化设计还包括如下这些特征：池子的初始值、池子的活跃值、池子的最大值等，这些特征可以直接映射到java线程池和数据库连接池的成员属性中。

  数据库连接本质就是一个 socket 的连接。数据库服务端还要维护一些缓存和用户权限信息之类的 所以占用了一些内存。我们可以把数据库连接池是看做是维护的数据库连接的缓存，以便将来需要对数据库的请求时可以重用这些连接。为每个用户打开和维护数据库连接，尤其是对动态数据库驱动的网站应用程序的请求，既昂贵又浪费资源。**在连接池中，创建连接后，将其放置在池中，并再次使用它，因此不必建立新的连接。如果使用了所有连接，则会建立一个新连接并将其添加到池中。** 连接池还减少了用户必须等待建立与数据库的连接的时间。

- 分库分表之后,id 主键如何处理？

  因为要是分成多个表之后，每个表都是从 1 开始累加，这样是不对的，我们需要一个全局唯一的 id 来支持。

  生成全局 id 有下面这几种方式：

  - UUID：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。
  - 数据库自增 id : 两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。这种方式生成的 id 有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。
  - 利用 redis 生成 id : 性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。
  - Twitter的snowflake算法 ：Github 地址：https://github.com/twitter-archive/snowflake。
  - 美团的Leaf分布式ID生成系统 ：Leaf 是美团开源的分布式ID生成器，能保证全局唯一性、趋势递增、单调递增、信息安全，里面也提到了几种分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件。感觉还不错。美团技术团队的一篇文章：https://tech.meituan.com/2017/04/21/mt-leaf.html 。
  - ......

- 高性能优化规范建议

  **索引设计规范**
  
  1. 限制每张表上的索引数量,建议单张表索引不超过 5 个

      索引并不是越多越好！索引可以提高效率同样可以降低效率。

      索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。

      因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。
  
  2. 禁止给表中的每一列都建立单独的索引

      5.6 版本之前，一个 sql 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好。

  3. 每个 Innodb 表必须有个主键
  
      Innodb 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。

      Innodb 是按照主键索引的顺序来组织表的

      **不要使用更新频繁的列作为主键**，不适用多列主键（相当于联合索引）
  
      **不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长）**
  
      **主键建议使用自增 ID 值**
  
  4. 常见索引列建议
  
      出现在 SELECT、UPDATE、DELETE 语句的 **WHERE 从句中的列**
  
      **包含在 ORDER BY、GROUP BY、DISTINCT 中的字段**
  
      并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好
      
      **多表 join 的关联列**
  
  5. 如何选择索引列的顺序
  
      建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。

      **区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）**
  
      **尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）**
  
      使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）
  
  6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）
  
      重复索引示例：primary key(id)、index(id)、unique index(id)
  
      冗余索引示例：index(a,b,c)、index(a,b)、index(a)
  
  7. 对于频繁的查询优先考虑使用覆盖索引
  
      覆盖索引：就是包含了所有查询字段 (where,select,ordery by,group by 包含的字段) 的索引

      覆盖索引的好处：

      避免 Innodb 表进行索引的二次查询: Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。
  
      可以把随机 IO 变成顺序 IO 加快查询效率: 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。
  
  8. 索引 SET 规范
  
      尽量避免使用外键约束

      不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引
  
      外键可用于保证数据的参照完整性，但建议在业务端实现
  
      外键会影响父表和子表的写操作从而降低性能

- 数据库索引总结

  **为什么要使用索引**

  - 通过创建唯一性索引，可以保证数据库每一行数据的唯一性。
  - 可以大大加快数据的检索速度（大大减少的检索的数据量），这也是创建索引的最主要的原因。

  **索引有这么多优点，为什么不对表中的每一个列创建一个索引呢**

  - 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。
  - 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还有占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。
  - 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。

  **使用索引的注意事项**

  - **在经常使用在WHERE子句中的列上面创建索引**，加快条件的判断速度。
  - **在经常需要排序的列上创建索引**，因为索引已经排序，这样查询可以利用索引的排序，加快排序时间。
  - 对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引。
  - **在经常用在连接的列上，这些列主要是一些外键**，可以加快连接速度。
  - 避免where子句中对字段施加函数，这会造成无法命中索引。
  - **将打算加索引的列设置为NOT NULL，否则讲导致引擎放弃使用索引而进行全表扫描。**
  - 在使用limit offset查询缓慢时，可以借助索引来提高性能。

  **覆盖索引介绍**

  - 什么是覆盖索引

    如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。我们知道在InnoDB存储引擎中，如果不是主键索引，叶子结点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次，这样就会比较慢。覆盖索引就是要查询出的列和索引是对应的，不做回表操作。
  
  - 覆盖索引使用实例

    现在我创建了索引(username, age)，在查询数据的时候：`select username, age from user where username = 'Java' and age = 22`，要查询出的列在叶子结点都存在，所以就不用回表。
  
  **选择索引和编写利用这些索引的查询的3个原则**

  1. 单个访问时很慢的。如果服务器从存储中读取一个数据块知识为了获取其中一行，那么就浪费了很多工作。最好读取的块中能包含尽可能多所需要的行。使用索引可以创建位置引，用以提高效率。

  2. 按顺序访问范围数据是很快的，这有两个原因。第一，顺序I/O不需要多次磁盘寻道，所以比随机I/O要快很多。第二，如果服务器能够按需要顺序读取数据，那么就不再需要额外的排序操作，并且GROUPBY查询也无需再做排序和将行按组进行聚合计算了。

  3. 索引覆盖查询是很快的。如果一个索引包含了查询需要的所有列，那么查询引擎就不需要再回表查找行。这避免了大量的单行访问，而上面的第1点已经写明单行访问时很慢的。

> [https://www.nowcoder.com/discuss/356120](https://www.nowcoder.com/discuss/356120)

- Mysql(innondb 下同) 有哪几种事务隔离级别？

  读取未提交、读取已提交、可重复读、可串行化

- 不同事务隔离级别分别会加哪些锁？

  **读取已提交级别：读取不加锁，写入、修改、删除加行锁。** 读（快照读）存在不可重复读的问题，解决方法是读取数据后，将这些数据加行锁。写（当前读）存在幻读的问题，解决方法是使用next-key锁。

  **可重复读级别：next-key锁=gap锁+行锁。** 行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。

  **可串行化：读加共享锁，写加排他锁，读写互斥。并发能力非常差。**

  > [https://tech.meituan.com/2014/08/20/innodb-lock.html](https://tech.meituan.com/2014/08/20/innodb-lock.html)

  - 读取已提交 Read Committed

    在RC级别中，数据的读取都是不加锁的，但是数据的写入、修改和删除是需要加锁的。

    |事务A | 事务B |
    |--|--|
    |begin;	|begin;|
    |update class_teacher set class_name=‘初三二班’ where teacher_id=1;	|update class_teacher set class_name=‘初三三班’ where teacher_id=1;|
    |commit;||

    为了防止并发过程中的修改冲突，事务A中MySQL给teacher_id=1的数据行加锁，并一直不commit（释放锁），那么事务B也就一直拿不到该行锁，wait直到超时。

    这时我们要注意到，teacher_id是有索引的，如果是没有索引的class_name呢？update class_teacher set teacher_id=3 where class_name = ‘初三一班’; 那么MySQL会给整张表的所有数据行的加行锁。这里听起来有点不可思议，但是当sql运行的过程中，MySQL并不知道哪些数据行是 class_name = ‘初三一班’的（没有索引嘛），如果一个条件无法通过索引快速过滤，存储引擎层面就会将所有记录加锁后返回，再由MySQL Server层进行过滤。

    但在实际使用过程当中，MySQL做了一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。可见即使是MySQL，为了效率也是会违反规范的。（参见《高性能MySQL》中文第三版p181）

    这种情况同样适用于MySQL的默认隔离级别RR。所以对一个数据量很大的表做批量修改的时候，如果无法使用相应的索引，MySQL Server过滤数据的的时候特别慢，就会出现虽然没有修改某些行的数据，但是它们还是被锁住了的现象。

  - 可重复读 Repeatable Read

    这是MySQL中InnoDB默认的隔离级别。我们姑且分“读”和“写”两个模块来讲解。

    **读**

    RC（不可重读）模式下的展现

    | 事务A                                                        | 事务B                                                      |
    | ------------------------------------------------------------ | ---------------------------------------------------------- |
    | begin;                                                       | begin;                                                     |
    | select id,class_name,teacher_id from class_teacher where teacher_id=1; ① |                                                            |
    |                                                              | update class_teacher set class_name='初三三班' where id=1; |
    |                                                              | commit;                                                    |
    | select id,class_name,teacher_id from class_teacher where teacher_id=1; ② |                                                            |
    | commit;                                                      |                                                            |

    ①
    | id | class_name | teacher_id |
    | -- | -- | -- |
    | 1 | 初三二班 | 1 |
    | 2 | 初三一班 | 1 |

    ②
    | id | class_name | teacher_id |
    | -- | -- | -- |
    | 1 | 初三三班 | 1 |
    | 2 | 初三一班 | 1 |

    读到了事务B修改的数据，和第一次查询的结果不一样，是不可重读的。

    我们注意到，当teacher_id=1时，事务A先做了一次读取，事务B中间修改了id=1的数据，并commit之后，事务A第二次读到的数据和第一次完全相同。所以说它是可重读的。那么MySQL是怎么做到的呢？

    > 不可重复读和幻读的区别
    >
    > 很多人容易搞混不可重复读和幻读，确实这两者有些相似。但不可重复读重点在于update和delete，而幻读的重点在于insert。
    >
    > 如果使用锁机制来实现这两种隔离级别，在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。
    >
    > 所以说不可重复读和幻读最大的区别，就在于如何通过锁机制来解决他们产生的问题。

    **写**

    > 对于读取历史数据的方式，我们叫它快照读 (snapshot read)，而读取数据库当前版本数据的方式，叫当前读 (current read)。
    > 
    > - 快照读：就是select
    >   - select * from table ….;
    > 
    > - 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。
    >   - select * from table where ? lock in share mode;
    >   - select * from table where ? for update;
    >   - insert;
    >   - update;
    >   - delete;
    
    事务的隔离级别中虽然只定义了读数据的要求，实际上这也可以说是写数据的要求。上文的“读”，实际是讲的快照读；而这里说的“写”就是当前读了。

    为了解决当前读中的幻读问题，MySQL事务使用了Next-Key锁。

    Next-Key锁是行锁和GAP（间隙锁）的合并，行锁上文已经介绍了，接下来说下GAP间隙锁。

    行锁可以防止不同事务版本的数据修改提交时造成数据冲突的情况。但如何避免别的事务插入数据就成了问题。我们可以看看RR级别和RC级别的对比

    RC级别：

    | 事务A                                                        | 事务B                                                        |
    | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | begin;                                                       | begin;                                                       |
    | select id,class_name,teacher_id from class_teacher where teacher_id=30; ① |                                                              |
    | update class_teacher set class_name='初三四班' where teacher_id=30; |                                                              |
    |                                                              | insert into class_teacher values (null,'初三二班',30);commit; |
    | select id,class_name,teacher_id from class_teacher where teacher_id=30; ② |                                                              |

    ① 

    |id|class_name|teacher_id|
    |-|-|-|
    |2|初三二班|30|

    ②

    |id|class_name|teacher_id|
    |-|-|-|
    |2|初三二班|30|
    |10|初三二班|30|

    RR级别：

    | 事务A                                                        | 事务B                                                        |
    | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | begin;                                                       | begin;                                                       |
    | select id,class_name,teacher_id from class_teacher where teacher_id=30; ① |                                                              |
    | update class_teacher set class_name='初三四班' where teacher_id=30; |                                                              |
    |                                                              | insert into class_teacher values (null,'初三二班',30);waiting.... |
    | select id,class_name,teacher_id from class_teacher where teacher_id=30; ② |                                                              |
    | commit;                                                      | 事务Acommit后，事务B的insert执行。                           |

    ①

    |id|class_name|teacher_id|
    |-|-|-|
    |2|初三二班|30|

    ②

    |id|class_name|teacher_id|
    |-|-|-|
    |2|初三二班|30|

    通过对比我们可以发现，在RC级别中，事务A修改了所有teacher_id=30的数据，但是当事务Binsert进新数据后，事务A发现莫名其妙多了一行teacher_id=30的数据，而且没有被之前的update语句所修改，这就是“当前读”的幻读。

    RR级别中，事务A在update后加锁，事务B无法插入新数据，这样事务A在update前后读的数据保持一致，避免了幻读。这个锁，就是Gap锁。

    MySQL是这么实现的：

    在class_teacher这张表中，teacher_id是个索引，那么它就会维护一套B+树的数据关系，为了简化，我们用链表结构来表达（实际上是个树形结构，但原理相同）

    ![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/b3b6a55f.png)

    如图所示，InnoDB使用的是聚集索引，teacher_id身为二级索引，就要维护一个索引字段和主键id的树状结构（这里用链表形式表现），并保持顺序排列。

    Innodb将这段数据分成几个个区间

    - (negative infinity, 5],
    - (5,30],
    - (30,positive infinity)；

    update class_teacher set class_name=‘初三四班’ where teacher_id=30;不仅用行锁，锁住了相应的数据行；同时也在两边的区间，（5,30]和（30，positive infinity），都加入了gap锁。这样事务B就无法在这个两个区间insert进新数据。

    受限于这种实现方式，Innodb很多时候会锁住不需要锁的区间。如下所示：

    | 事务A                                                        | 事务B                                                        | 事务C                                                  |
    | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------ |
    | begin;                                                       | begin;                                                       | begin;                                                 |
    | select id,class_name,teacher_id from class_teacher; ①        |                                                              |                                                        |
    | update class_teacher set class_name='初一一班' where teacher_id=20; |                                                              |                                                        |
    |                                                              | insert into class_teacher values (null,'初三五班',10);waiting ..... | insert into class_teacher values (null,'初三五班',40); |
    | commit;                                                      | 事务A commit之后，这条语句才插入成功                         | commit;                                                |
    |                                                              | commit;                                                      |                                                        |

    ①
    
    |id|class_name|teacher_id|
    |-|-|-|
    |1|初三一班|5|
    |2|初三二班|30|
    
    update的teacher_id=20是在(5，30]区间，即使没有修改任何数据，Innodb也会在这个区间加gap锁，而其它区间不会影响，事务C正常插入。

    如果使用的是没有索引的字段，比如update class_teacher set teacher_id=7 where class_name=‘初三八班（即使没有匹配到任何数据）’,那么会给全表加入gap锁。同时，它不能像上文中行锁一样经过MySQL Server过滤自动解除不满足条件的锁，因为没有索引，则这些字段也就没有排序，也就没有区间。除非该事务提交，否则其它事务无法插入任何数据。

    行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。

  - 可串行化 Serializable

    这个级别很简单，读加共享锁，写加排他锁，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差。如果你的业务并发的特别少或者没有并发，同时又要求数据及时可靠的话，可以使用这种模式。

- MVCC

  > [https://www.jianshu.com/p/8845ddca3b23](https://www.jianshu.com/p/8845ddca3b23)

  > [https://blog.csdn.net/nmjhehe/article/details/98470570](https://blog.csdn.net/nmjhehe/article/details/98470570)

  > [https://www.jianshu.com/p/57c510f4ec28](https://www.jianshu.com/p/57c510f4ec28)

- 快照读、当前读

  > [https://blog.csdn.net/silyvin/article/details/79280934](https://blog.csdn.net/silyvin/article/details/79280934)

  快照读：select ...

  在rr级别下，mvcc完全解决了重复读，但并不能真正的完全避免幻读，只是在部分场景下利用历史数据规避了幻读

  当前读：select ... lock in share mode (共享锁), select ... for update (排他锁), update, insert, delete

  要完全避免，需要手动加锁将快照读调整使用next-key完全避免了幻读

- mysql的行锁、表锁、间隙锁、意向锁分别是做什么的？

  > [https://blog.csdn.net/u010841296/article/details/84204701](https://blog.csdn.net/u010841296/article/details/84204701)

  - 共享锁Shared Locks（S锁）

    1、兼容性：加了S锁的记录，允许其他事务再加S锁，不允许其他事务再加X锁

    2、加锁方式：select…lock in share mode

  - 排他锁Exclusive Locks（X锁）

    1、兼容性：加了X锁的记录，不允许其他事务再加S锁或者X锁

    2、加锁方式：select…for update

  - 表锁：意向锁 Intention Locks，意向锁相互兼容

    1、表明“某个事务正在某些行持有了锁、或该事务准备去持有锁”

    2、意向锁的存在是为了协调行锁和表锁的关系，支持多粒度（表锁与行锁）的锁并存。

    3、**例子：事务A修改user表的记录r，会给记录r上一把行级的排他锁（X），同时会给user表上一把意向排他锁（IX），这时事务B要给user表上一个表级的排他锁就会被阻塞。意向锁通过这种方式实现了行锁和表锁共存且满足事务隔离性的要求。**

    4、
    
    1）**意向共享锁（IS锁）：事务在请求S锁前，要先获得IS锁**

    2）**意向排他锁（IX锁）：事务在请求X锁前，要先获得IX锁**

    q1：**为什么意向锁是表级锁呢？**

    当我们需要加一个排他锁时，需要根据意向锁去判断表中有没有数据行被锁定（行锁）：

    （1）如果意向锁是行锁，则需要遍历每一行数据去确认；

    （2）如果意向锁是表锁，则只需要判断一次即可知道有没数据行被锁定，提升性能。

    q2：**意向锁怎么支持表锁和行锁并存？**

    （1）首先明确并存的概念是指数据库同时支持表、行锁，而不是任何情况都支持一个表中同时有一个事务A持有行锁、又有一个事务B持有表锁，因为表一旦被上了一个表级的写锁，肯定不能再上一个行级的锁。

    （2）**如果事务A对某一行上锁，其他事务就不可能修改这一行。这与“事务B锁住整个表就能修改表中的任意一行”形成了冲突。所以，没有意向锁的时候，让行锁与表锁共存，就会带来很多问题。于是有了意向锁的出现，如q1的答案中，数据库不需要在检查每一行数据是否有锁，而是直接判断一次意向锁是否存在即可，能提升很多性能。**

  - 行锁：记录锁(Record Locks)

    （1）记录锁, 仅仅锁住索引记录的一行，在单条索引记录上加锁。

    （2）record lock锁住的永远是索引，而非记录本身，即使该表上没有任何索引，那么innodb会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。
    所以说当一条sql没有走任何索引时，那么将会在每一条聚合索引后面加X锁，这个类似于表锁，但原理上和表锁应该是完全不同的。

  - 行锁：间隙锁(Gap Locks)

    （1）区间锁, 仅仅锁住一个索引区间（开区间，不包括双端端点）。

    （2）在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身。比如在 1、2、3中，间隙锁的可能值有 (∞, 1)，(1, 2)，(2, ∞)。

    （3）间隙锁可用于防止幻读，保证索引间的不会被插入数据

  - 行锁：临键锁(Next-Key Locks)

    （1）record lock + gap lock, 左开右闭区间。

    （2）默认情况下，innodb使用next-key locks来锁定记录。select … for update

    （3）但当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。

    （4）Next-Key Lock在不同的场景中会退化:

    ![img](https://img-blog.csdnimg.cn/20181118210006461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA4NDEyOTY=,size_16,color_FFFFFF,t_70)

- 说说什么是最左匹配？

  > [https://segmentfault.com/a/1190000015416513](https://segmentfault.com/a/1190000015416513)

  **最左前缀匹配原则**

  在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，示例：
  对列col1、列col2和列col3建一个联合索引

  ```sql
  KEY test_col1_col2_col3 on test(col1,col2,col3);
  ```

  联合索引 test_col1_col2_col3 实际建立了(col1)、(col1,col2)、(col,col2,col3)三个索引。

  ```sql
  SELECT * FROM test WHERE col1=“1” AND clo2=“2” AND clo4=“4”
  ```

  上面这个查询语句执行时会依照最左前缀匹配原则，检索时会使用索引(col1,col2)进行数据匹配。

  **注意**

  索引的字段可以是任意顺序的，如：

  ```sql
  SELECT * FROM test WHERE col1=“1” AND clo2=“2”
  SELECT * FROM test WHERE col2=“2” AND clo1=“1”
  ```

  这两个查询语句都会用到索引(col1,col2)，mysql创建联合索引的规则是首先会对联合合索引的最左边的，也就是第一个字段col1的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个字段col2进行排序。其实就相当于实现了类似 order by col1 col2这样一种排序规则。

  有人会疑惑第二个查询语句不符合最左前缀匹配：首先可以肯定是两个查询语句都包含索引(col1,col2)中的col1、col2两个字段，只是顺序不一样，查询条件一样，最后所查询的结果肯定是一样的。既然结果是一样的，到底以何种顺序的查询方式最好呢？此时我们可以借助mysql查询优化器explain，explain会纠正sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。

  **为什么要使用联合索引**

  - 减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！
  - 覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。
  - 效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！

  > [https://segmentfault.com/a/1190000015416513](https://segmentfault.com/a/1190000015416513)

- 如何定位慢SQL

  > [https://blog.csdn.net/zzti_erlie/article/details/80534733](https://blog.csdn.net/zzti_erlie/article/details/80534733)

- 索引失效

  > [https://www.cnblogs.com/liehen2046/p/11052666.html](https://www.cnblogs.com/liehen2046/p/11052666.html)

  - 什么时候没用

    1.有or必全有索引;
    2.**复合索引未用左列字段;**
    3.**like以%开头;**
    4.**需要类型转换;**
    5.where中索引列有运算;
    6.**where中索引列使用了函数;**
    7.如果mysql觉得全表扫描更快时（数据少）;
  
  - 什么时候没必要用

    1.唯一性差;
    2.频繁更新的字段不用（更新索引消耗）;
    3.where中不用的字段;
    4.索引使用<>时，效果一般;

- explain

  > [https://blog.csdn.net/zzti_erlie/article/details/80534733](https://blog.csdn.net/zzti_erlie/article/details/80534733)

  - id
  - select_type: simple, [primary, subquery], [primary, derived (在from子句里)], [primary, union, union result]
  - type: eq_ref, ref, range, index, all
  - extra: using index, using where, using temporary

- MySQL 执行流程

  > [https://www.cnblogs.com/liyasong/p/mysql_zhixingguocheng.html](https://www.cnblogs.com/liyasong/p/mysql_zhixingguocheng.html)

　　mysql得到sql语句后，大概流程如下：

　　1.sql的解析器：负责解析和转发sql

　　2.预处理器：对解析后的sql树进行验证

　　3.查询优化器：得到一个执行计划

　　4.查询执行引擎：得到数据结果集

　　5.将数据放回给调用端。

- 如何优化慢查询？

  > [https://database.51cto.com/art/201809/583239.htm](https://database.51cto.com/art/201809/583239.htm)

  - **索引优化**

    索引类型

    - **普通索引**：是最基本的索引，它没有任何限制。
    - **唯一索引**：与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。
    - **组合索引**：指多个字段上创建的索引，只有在查询条件中使用了创建索引时的***个字段，索引才会被使用。
    - **主键索引**：是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引
    - **全文索引**：主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。它可以在create table，alter table ，create index使用，不过目前只有char、varchar，text 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多。
    
    优化原则
    
    - **只要列中含有NULL值，就不要在此例设置索引**，复合索引如果有NULL值，此列在使用时也不会使用索引
    - 尽量使用短索引，如果可以，应该制定一个前缀长度
    - **对于经常在where子句使用的列设置索引**，这样会加快查找速度
    - **对于有多个列where或者order by子句的，应该建立复合索引**
    - **对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引**
    - **尽量不要在列上进行运算（函数操作和表达式操作）**
    - 尽量不要使用not in和<>操作

  - **SQL语句优化**

    优化原则
    
    - 查询时，**能不要\*就不用\*，尽量写全字段名**
    - **大部分情况连接效率远大于子查询**
    - 多使用explain和profile分析查询语句
    - **查看慢查询日志，找出执行时间长的sql语句优化**
    - 多表连接时，尽量**小表驱动大表，即小表 join 大表**
    - **在分页时使用limit**
    - 对于经常使用的查询，可以开启缓存

  - **大表优化**

    数据表拆分：主要就是垂直拆分和水平拆分。

    - **水平切分**:将记录散列到不同的表中，各表的结构完全相同，每次从分表中查询, 提高效率。
    - **垂直切分**:将表中大字段单独拆分到另外一张表, 形成一对一的关系。

- mysql索引为什么用的是b+ tree而不是b tree、红黑树

  > [https://blog.csdn.net/qq_35923749/article/details/88068659](https://blog.csdn.net/qq_35923749/article/details/88068659)

  B-树、B+树、红黑树，都是平衡查找树，那么查询效率上讲，平均都是O(logn)。使用什么哪种数据结构，肯定是出于提高数据库的查询效率的考虑。

  **一、B+树做索引而不用B-树**

  那么Mysql如何衡量查询效率呢？– 磁盘IO次数。

  一般来说索引非常大，尤其是关系性数据库这种数据量大的索引能达到亿级别，所以为了减少内存的占用，索引也会被存储在磁盘上。B-树/B+树 的特点就是每层节点数目非常多，层数很少，目的就是为了减少磁盘IO次数，但是B-树的每个节点都有data域（指针），这无疑增大了节点大小，说白了增加了磁盘IO次数（磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO多耗时），而B+树除了叶子节点其它节点并不存储数据，节点小，磁盘IO次数就少。

  - 优点一： B+树只有叶节点存放数据，其余节点用来索引，而B-树是每个索引节点都会有Data域。

  - 优点二： B+树所有的Data域在叶子节点，并且所有叶子节点之间都有一个链指针。 这样遍历叶子节点就能获得全部数据，这样就能进行区间访问啦。在数据库中基于范围的查询是非常频繁的，而B树不支持这样的遍历操作。

  **二、B+树做索引而不用红黑树**

  AVL 树（平衡二叉树）和红黑树（二叉查找树）基本都是存储在内存中才会使用的数据结构。在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况。为什么会出现这样的情况，我们知道要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。根据磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树可以有多个子女，从几十到上千，可以降低树的高度。

  数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。

- 分库分表如何选择分表键

  > [https://github.com/Meituan-Dianping/Zebra/wiki/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%88%86%E8%A1%A8%E9%94%AE%EF%BC%8C%E8%B7%AF%E7%94%B1%E8%A7%84%E5%88%99%E5%8F%8A%E5%88%86%E7%89%87%E6%95%B0](https://github.com/Meituan-Dianping/Zebra/wiki/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%88%86%E8%A1%A8%E9%94%AE%EF%BC%8C%E8%B7%AF%E7%94%B1%E8%A7%84%E5%88%99%E5%8F%8A%E5%88%86%E7%89%87%E6%95%B0)

  **分表键即分库/分表字段，是在水平拆分过程中用于生成拆分规则的数据表字段。**

  数据表拆分的首要原则，就是要尽可能找到数据表中的数据在业务逻辑上的主体，并确定大部分（或核心的）数据库操作都是围绕这个主体的数据进行，然后可使用该主体对应的字段作为分表键，进行分库分表。

  业务逻辑上的主体，通常与业务的应用场景相关，下面的一些典型应用场景都有明确的业务逻辑主体，可用于分表键：

  - 面向用户的互联网应用，都是围绕用户维度来做各种操作，那么业务逻辑主体就是用户，可使用用户对应的字段作为分表键；
  - 侧重于卖家的电商应用，都是围绕卖家维度来进行各种操作，那么业务逻辑主体就是卖家，可使用卖家对应的字段作为分表键；

  以此类推，其它类型的应用场景，大多也能找到合适的业务逻辑主体作为分表键的选择。

  如果确实找不到合适的业务逻辑主体作为分表键，那么可以考虑下面的方法来选择分表键：

  - 根据数据分布和访问的均衡度来考虑分表键，尽量将数据表中的数据相对均匀地分布在不同的物理分库/分表中，适用于大量分析型查询的应用场景（查询并发度大部分能维持为1）；
  - 按照数字（字符串）类型与时间类型字段相结合作为分表键，进行分库和分表，适用于日志检索类的应用场景。

  注意：无论选择什么拆分键，采用何种拆分策略，都要注意拆分值是否存在热点的问题，尽量规避热点数据来选择拆分键。

  注意：不一定需要拿数据库主键当做分表键，也可以拿其他业务值当分表键。拿主键当分表键的好处是可以散列均衡，减少热点问题。

- 分库分表的情况下，查询时一般是如何做排序的？

  > [https://cloud.tencent.com/developer/article/1404798](https://cloud.tencent.com/developer/article/1404798)

  **Mysql分库分表方案**

  - **为什么要分表**

    当一张表的数据达到几千万时，你查询一次所花的时间会变多，如果有联合查询的话，我想有可能会死在那儿了。分表的目的就在于此，减小数据库的负担，缩短查询时间。

  - **大数据量并且访问频繁的表，将其分为若干个表**

    比如对于某网站平台的数据库表-公司表，数据量很大，这种能预估出来的大数据量表，我们就事先分出个N个表，这个N是多少，根据实际情况而定。

    某网站现在的数据量至多是5000万条，可以设计每张表容纳的数据量是500万条，也就是拆分成10张表。

    那么如何判断某张表的数据是否容量已满呢?可以在程序段对于要新增数据的表，在插入前先做统计表记录数量的操作，当<500万条数据，就直接插入，当已经到达阀值，可以在程序段新创建数据库表(或者已经事先创建好)，再执行插入操作。

  - **利用merge存储引擎来实现分表**

    如果要把已有的大数据量表分开比较痛苦，最痛苦的事就是改代码，因为程序里面的sql语句已经写好了。用merge存储引擎来实现分表, 这种方法比较适合。

  **数据库架构**

  1. 简单的MySQL主从复制

      MySQL的主从复制解决了数据库的读写分离，并很好的提升了读的性能，其图如下：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/fqy4a9b1um.jpeg?imageView2/2/w/1620)
      
      其主从复制的过程如下图所示：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/odg78hats0.jpeg?imageView2/2/w/1620)

      但是，主从复制也带来其他一系列性能瓶颈问题：

      - 写入无法扩展
      - 写入无法缓存
      - 复制延时
      - 锁表率上升
      - 表变大，缓存率下降

  2. MySQL垂直分区

      如果把业务切割得足够独立，那把不同业务的数据放到不同的数据库服务器将是一个不错的方案，而且万一其中一个业务崩溃了也不会影响其他业务的正常进行，并且也起到了负载分流的作用，大大提升了数据库的吞吐能力。经过垂直分区后的数据库架构图如下：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/eiuihqsrb2.jpeg?imageView2/2/w/1620)

      然而，尽管业务之间已经足够独立了，但是有些业务之间或多或少总会有点联系，如用户，基本上都会和每个业务相关联，况且这种分区方式，也不能解决单张表数据量暴涨的问题，因此为何不试试水平分割呢?

  3. MySQL水平分片(Sharding)

      这是一个非常好的思路，**将用户按一定规则（按id哈希）分组，并把该组用户的数据存储到一个数据库分片中，即一个sharding**，这样随着用户数量的增加，只要简单地配置一台服务器即可，原理图如下：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/gztxxds73x.jpeg?imageView2/2/w/1620)

      如何来确定某个用户所在的shard呢，可以建一张用户和shard对应的数据表，每次请求先从这张表找用户的shard id，再从对应shard中查询相关数据，如下图所示：

      ![img](https://ask.qcloudimg.com/http-save/yehe-4878700/eyqabomfoa.jpeg?imageView2/2/w/1620)

  **单库单表**

  单库单表是最常见的数据库设计，例如，有一张用户(user)表放在数据库db中，所有的用户都可以在db库中的user表中查到。

  **单库多表**

  随着用户数量的增加，user表的数据量会越来越大，当数据量达到一定程度的时候对user表的查询会渐渐的变慢，从而影响整个DB的性能。如果使用mysql, 还有一个更严重的问题是，当需要添加一列的时候，mysql会锁表，期间所有的读写操作只能等待。

  可以通过某种方式将user进行水平的切分，产生两个表结构完全一样的user_0000,user_0001等表，user_0000 + user_0001 + …的数据刚好是一份完整的数据。

  **多库多表**

  随着数据量增加也许单台DB的存储空间不够，随着查询量的增加单台数据库服务器已经没办法支撑。这个时候可以再对数据库进行水平区分。

  **分库分表规则**

  设计表的时候需要确定此表按照什么样的规则进行分库分表。例如，当有新用户时，程序得确定将此用户信息添加到哪个表中；同理，当登录的时候我们得通过用户的账号找到数据库中对应的记录，所有的这些都需要按照某一规则进行。 

  **路由** 

  通过分库分表规则查找到对应的表和库的过程。如分库分表的规则是user_id mod 4的方式，当用户新注册了一个账号，账号id的123,我们可以通过id mod 4的方式确定此账号应该保存到User_0003表中。当用户123登录的时候，我们通过123 mod 4后确定记录在User_0003中。

  **分库分表产生的问题，及注意事项** 

  1. 分库分表维度的问题 

      假如用户购买了商品,需要将交易记录保存取来，如果按照用户的维度分表，则每个用户的交易记录都保存在同一表中，所以很快很方便的查找到某用户的 购买情况，但是某商品被购买的情况则很有可能分布在多张表中，查找起来比较麻烦。反之，按照商品维度分表，可以很方便的查找到此商品的购买情况，但要查找 到买人的交易记录比较麻烦。 

      所以常见的解决方式有： 

      - 通过扫表的方式解决，此方法基本不可能，效率太低了。 
      - 记录两份数据，一份按照用户纬度分表，一份按照商品维度分表。 
      
      通过搜索引擎解决，但如果实时性要求很高，又得关系到实时搜索。 

  2. 联合查询的问题 

      联合查询基本不可能，因为关联的表有可能不在同一数据库中。 

  3. 避免跨库事务 

      避免在一个事务中修改db0中的表的时候同时修改db1中的表，一个是操作起来更复杂，效率也会有一定影响。 

  4. 尽量把同一组数据放到同一DB服务器上 

      例如将卖家a的商品和交易信息都放到db0中，当db1挂了的时候，卖家a相关的东西可以正常使用。也就是说避免数据库中的数据依赖另一数据库中的数据。 

- 如何设计数据库表

  > [https://blog.csdn.net/jiyiqinlovexx/article/details/44544325](https://blog.csdn.net/jiyiqinlovexx/article/details/44544325)

  > [https://www.jianshu.com/p/b3969c49dfaa](https://www.jianshu.com/p/b3969c49dfaa)

  E-R图：实体、关系

  一对一（外键）、一对多（多的一方加外键）、多对多（中间表，两列作为联合主键）

  > [https://www.cnblogs.com/wsg25/p/9615100.html](https://www.cnblogs.com/wsg25/p/9615100.html)

  三大范式

  - **第一范式（1NF）：要求数据库表的每一列都是不可分割的原子数据项。**

  - 第二范式（2NF）：在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）

    **第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。**

  - 第三范式（3NF）：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）

    **第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。**

- MySQL死锁

  > [https://www.cnblogs.com/zejin2008/p/5262751.html](https://www.cnblogs.com/zejin2008/p/5262751.html)

#### Redis

- redis性能为什么高?

  > [https://blog.csdn.net/xlgen157387/article/details/79470556](https://blog.csdn.net/xlgen157387/article/details/79470556)

  **Redis到底有多快**
  
  可以达到100000+的QPS（每秒内查询次数）。

  ![img](https://img-blog.csdn.net/2018030715491722?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDg3MDUxOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

  横轴是连接数，纵轴是QPS。
  
  **Redis为什么这么快**
  
  1、**完全基于内存**，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

  2、**数据结构简单**，对数据操作也简单，Redis中的数据结构是专门进行设计的；

  3、**采用单线程**，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

  4、使用**多路I/O复用模型**，非阻塞IO；

  5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

  以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨：

  多路 I/O 复用模型

  多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

  > [https://www.zhihu.com/question/28594409](https://www.zhihu.com/question/28594409)

  > 下面举一个例子，模拟一个tcp服务器处理30个客户socket。
  > 假设你是一个老师，让30个学生解答一道题目，然后检查学生做的是否正确，你有下面几个选择：
  >
  > 1. 第一种选择：**按顺序逐个检查**，先检查A，然后是B，之后是C、D。。。这中间如果有一个学生卡主，全班都会被耽误。
  >
  >     这种模式就好比，你用循环挨个处理socket，根本不具有并发能力。
  > 2. 第二种选择：你**创建30个分身**，每个分身检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个进程或者线程处理连接。
  > 3. 第三种选择，你**站在讲台上等，谁解答完谁举手**。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。
  >
  >     这种就是IO复用模型，Linux下的select、poll和epoll就是干这个的。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用**非阻塞模式**。
  >
  >     这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是**事件驱动**，所谓的reactor模式。

  **这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。** 采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。

- 单线程的redis如何利用多核cpu机器？

  > [https://blog.csdn.net/xlgen157387/article/details/79470556](https://blog.csdn.net/xlgen157387/article/details/79470556)

  我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。

  但是，我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！

- redis的缓存淘汰策略？

  > [https://blog.csdn.net/yangtuogege/article/details/77970896](https://blog.csdn.net/yangtuogege/article/details/77970896)

  redis 提供 6种数据淘汰策略：

  - volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
  - volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
  - volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
  - allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
  - allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
  - no-enviction（驱逐）：禁止驱逐数据

  上面提到的LRU（Least Recently Used）策略，实际上Redis实现的LRU并不是可靠的LRU，也就是名义上我们使用LRU算法淘汰键，但是实际上被淘汰的键并不一定是真正的最久没用的， 这里涉及到一个权衡的问题，如果需要在全部键空间内搜索最优解，则必然会增加系统的开销，Redis是单线程的， 也就是同一个实例在每一个时刻只能服务于一个客户端，所以耗时的操作一定要谨慎 。为了在一定成本内实现相对的LRU， 早期的Redis版本是基于采样的LRU，也就是放弃全部键空间内搜索解改为采样空间搜索最优解。自从Redis3.0版本之后， Redis作者对于基于采样的LRU进行了一些优化，目的是在一定的成本内让结果更靠近真实的LRU。

  **策略规则**

  如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru

  如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random

  volatile-lru策略和volatile-random策略适合我们将一个Redis实例既应用于缓存和又应用于持久化存储的时候，然而我们也可以通过使用两个Redis实例来达到相同的效果，将key设置过期时间实际上会消耗更多的内存，因此我们建议使用allkeys-lru策略从而更有效率的使用内存

  **失效的内部实现**

  消极方法（passive way），在主键被访问时如果发现它已经失效，那么就删除它

  积极方法（active way），周期性地从设置了失效时间的主键中选择一部分失效的主键删除

  主动删除：当前已用内存超过maxmemory限定时，触发主动清理策略，该策略由启动参数的配置决定

- redis如何持久化数据？

  > redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复)

  很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。

  Redis不同于Memcached的很重一点就是，Redis支持持久化，而且支持两种不同的持久化操作。**Redis的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file,AOF）。** 这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。

  **快照（snapshotting）持久化（RDB）**

  Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。

  快照持久化是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置：

  ```conf
  save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

  save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

  save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
  ```

  **AOF（append-only file）持久化**

  与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：

  ```conf
  appendonly yes
  ```

  开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。

  在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

  ```conf
  appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
  appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
  appendfsync no        #让操作系统决定何时进行同步
  ```

  为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

  **Redis 4.0 对于持久化机制的优化**

  Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。

  如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。

  **补充内容：AOF 重写**

  AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。

  AOF重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有AOF文件进行任何读入、分析或者写入操作。

  在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作。

- redis有哪几种数据结构？

  > redis 常见数据结构以及使用场景分析

  1.String

  > 常用命令: set,get,decr,incr,mget 等。

  String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。 常规key-value缓存应用； 常规计数：微博数，粉丝数等。

  2.Hash

  > 常用命令： hget,hset,hgetall 等。

  hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。比如下面我就用 hash 类型存放了我本人的一些信息：

  ```
  key=JavaUser293847
  value={
    “id”: 1,
    “name”: “SnailClimb”,
    “age”: 22,
    “location”: “Wuhan, Hubei”
  }
  ```

  3.List
  
  > 常用命令: lpush,rpush,lpop,rpop,lrange等

  list 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。

  Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

  另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。

  4.Set

  > 常用命令： sadd,spop,smembers,sunion 等

  set 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的。

  当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。

  比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：

  ```
  sinterstore key1 key2 key3     将交集存在key1内
  ```
  
  5.Sorted Set

  > 常用命令： zadd,zrange,zrem,zcard等

  和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。

  举例： 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 Sorted Set 结构进行存储。

- redis集群有哪几种形式？

  > [https://blog.csdn.net/wy0123/article/details/79583506](https://blog.csdn.net/wy0123/article/details/79583506)

  现在越来越多的项目都会利用到redis，多实例redis服务比单实例要复杂的多，这里面涉及到定位、容错、扩容等技术问题。我们常用sharding技术来对此进行管理，其集群模式主要有以下几种方式：

  1. 主从复制
  2. 哨兵模式
  3. Redis官方 Cluster集群模式（服务端sharding）
  4. Jedis sharding集群（客户端sharding）
  5. 利用中间件代理

  - **主从复制（Master-Slave Replication）**

    实现主从复制（Master-Slave Replication）的工作原理：Slave从节点服务启动并连接到Master之后，它将主动发送一个SYNC命令。Master服务主节点收到同步命令后将启动后台存盘进程，同时收集所有接收到的用于修改数据集的命令，在后台进程执行完毕后，Master将传送整个数据库文件到Slave，以完成一次完全同步。而Slave从节点服务在接收到数据库文件数据之后将其存盘并加载到内存中。此后，Master主节点继续将所有已经收集到的修改命令，和新的修改命令依次传送给Slaves，Slave将在本次执行这些数据修改命令，从而达到最终的数据同步。

    如果Master和Slave之间的链接出现断连现象，Slave可以自动重连Master，但是在连接成功之后，一次完全同步将被自动执行。

    **主从模式的优缺点**

    优点：

    - 同一个Master可以同步多个Slaves。
    - Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力。因此我们可以将Redis的Replication架构视为图结构。
    - Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求。
    - Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据
    - 为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成。即便如此，系统的伸缩性还是得到了很大的提高。
    - Master可以将数据保存操作交给Slaves完成，从而避免了在Master中要有独立的进程来完成此操作。
    - 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。
    
    缺点：

    - Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。
    - 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。
    - Redis的主从复制采用全量复制，复制过程中主机会fork出一个子进程对内存做一份快照，并将子进程的内存快照保存为文件发送给从机，这一过程需要确保主机有足够多的空余内存。若快照文件较大，对集群的服务能力会产生较大的影响，而且复制过程是在从机新加入集群或者从机和主机网络断开重连时都会进行，也就是网络波动都会造成主机和从机间的一次全量的数据复制，这对实际的系统运营造成了不小的麻烦。
    - Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。

    其实redis的主从模式很简单，在实际的生产环境中是很少使用的，我也不建议在实际的生产环境中使用主从模式来提供系统的高可用性，之所以不建议使用都是由它的缺点造成的，在数据量非常大的情况，或者对系统的高可用性要求很高的情况下，主从模式也是不稳定的。

  - **哨兵模式**

    该模式是从Redis的2.6版本开始提供的，但是当时这个版本的模式是不稳定的，直到Redis的2.8版本以后，这个哨兵模式才稳定下来，无论是主从模式，还是哨兵模式，这两个模式都有一个问题，不能水平扩容，并且这两个模式的高可用特性都会受到Master主节点内存的限制。

    Sentinel(哨兵)进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用。

    **Sentinel（哨兵）进程的作用**

    1. 监控(Monitoring): 哨兵(sentinel) 会不断地检查你的Master和Slave是否运作正常。
    2. 提醒(Notification)：当被监控的某个Redis节点出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知。
    3. 自动故障迁移(Automatic failover)：当一个Master不能正常工作时，哨兵(sentinel) 会开始一次自动故障迁移操作，它会将失效Master的其中一个Slave升级为新的Master, 并让失效Master的其他Slave改为复制新的Master；当客户端试图连接失效的Master时，集群也会向客户端返回新Master的地址，使得集群可以使用现在的Master替换失效Master。Master和Slave服务器切换后，Master的redis.conf、Slave的redis.conf和sentinel.conf的配置文件的内容都会发生相应的改变，即，Master主服务器的redis.conf配置文件中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换。

    **Sentinel（哨兵）进程的工作方式**

    1. 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
    2. 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
    3. 如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态
    4. 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）
    5. 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。
    6. 当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
    7. 若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。

    **哨兵模式的优缺点**

    优点:

    - 哨兵集群模式是基于主从模式的，所有主从的优点，哨兵模式同样具有。
    - 主从可以切换，故障可以转移，系统可用性更好。
    - 哨兵模式是主从模式的升级，系统更健壮，可用性更高。

    缺点:

    - Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。
    - 配置复杂
  
  - **Redis官方 Cluster集群模式**

    Redis Cluster是一种服务器Sharding技术，3.0版本开始正式提供。

    ![img](https://img-blog.csdn.net/20180319140642333?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3d5MDEyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    在这个图中，每一个蓝色的圈都代表着一个redis的服务器节点。它们任何两个节点之间都是相互连通的。客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点。对其进行存取和其他操作。

    **Redis集群数据分片**

    在redis的每一个节点上，都有这么两个东西，一个是插槽（slot）可以理解为是一个可以存储两个数值的一个变量这个变量的取值范围是：0-16383。还有一个就是cluster我个人把这个cluster理解为是一个集群管理的插件。当我们的存取的key到达的时候，redis会根据crc16的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。

    ![img](https://img-blog.csdn.net/20180319141211304?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3d5MDEyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    还有就是因为如果集群的话，是有好多个redis一起工作的，那么，就需要这个集群不是那么容易挂掉，所以呢，理论上就应该给集群中的每个节点至少一个备用的redis服务。这个备用的redis称为从节点（slave）。那么这个集群是如何判断是否有某个节点挂掉了呢？

    首先要说的是，每一个节点都存有这个集群所有主节点以及从节点的信息。

    它们之间通过互相的ping-pong判断是否节点可以连接上。如果有一半以上的节点去ping一个节点的时候没有回应，集群就认为这个节点宕机了，然后去连接它的备用节点。如果某个节点和所有从节点全部挂掉，我们集群就进入fail状态。还有就是如果有一半以上的主节点宕机，那么我们集群同样进入fail状态。这就是我们的redis的投票机制，具体原理如下图所示：

    ![img](https://img-blog.csdn.net/20180319141325659?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3d5MDEyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    Redis 3.0的集群方案有以下两个问题。

    1. 一个Redis实例具备了“数据存储”和“路由重定向”，完全去中心化的设计。这带来的好处是部署非常简单，直接部署Redis就行，不像Codis有那么多的组件和依赖。但带来的问题是很难对业务进行无痛的升级，如果哪天Redis集群出了什么严重的Bug，就只能回滚整个Redis集群。
    2. 对协议进行了较大的修改，对应的Redis客户端也需要升级。升级Redis客户端后谁能确保没有Bug？而且对于线上已经大规模运行的业务，升级代码中的Redis客户端也是一个很麻烦的事情。

    Redis Cluster是Redis 3.0以后才正式推出，时间较晚，目前能证明在大规模生产环境下成功的案例还不是很多，需要时间检验。

  - **Jedis sharding集群**

    Redis Sharding可以说是在Redis cluster出来之前业界普遍的采用方式，其主要思想是采用hash算法将存储数据的key进行hash散列，这样特定的key会被定为到特定的节点上。

    ![img](https://img-blog.csdn.net/20180319143624440?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3d5MDEyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    庆幸的是，Java Redis客户端驱动Jedis已支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool

    Jedis的Redis Sharding实现具有如下特点：

    1. 采用一致性哈希算法，将key和节点name同时hashing，然后进行映射匹配，采用的算法是MURMUR_HASH。采用一致性哈希而不是采用简单类似哈希求模映射的主要原因是当增加或减少节点时，不会产生由于重新匹配造成的rehashing。一致性哈希只影响相邻节点key分配，影响量小。
    2. 为了避免一致性哈希只影响相邻节点造成节点分配压力，ShardedJedis会对每个Redis节点根据名字(没有，Jedis会赋予缺省名字)会虚拟化出160个虚拟节点进行散列。根据权重weight，也可虚拟化出160倍数的虚拟节点。用虚拟节点做映射匹配，可以在增加或减少Redis节点时，key在各Redis节点移动再分配更均匀，而不是只有相邻节点受影响。
    3. ShardedJedis支持keyTagPattern模式，即抽取key的一部分keyTag做sharding，这样通过合理命名key，可以将一组相关联的key放入同一个Redis节点，这在避免跨节点访问相关数据时很重要。
  
    当然，Redis Sharding这种轻量灵活方式必然在集群其它能力方面做出妥协。比如扩容，当想要增加Redis节点时，尽管采用一致性哈希，毕竟还是会有key匹配不到而丢失，这时需要键值迁移。
  
    作为轻量级客户端sharding，处理Redis键值迁移是不现实的，这就要求应用层面允许Redis中数据丢失或从后端数据库重新加载数据。但有些时候，击穿缓存层，直接访问数据库层，会对系统访问造成很大压力。

  - **利用中间件代理**

    中间件的作用是将我们需要存入redis中的数据的key通过一套算法计算得出一个值。然后根据这个值找到对应的redis节点，将这些数据存在这个redis的节点中。

    常用的中间件有这几种

    - Twemproxy
    - Codis
    - nginx

- 有海量key和value都比较小的数据，在redis中如何存储才更省内存？

  > [https://zzyongx.github.io/blogs/redis-memory-optimization-when-store-small-data.html](https://zzyongx.github.io/blogs/redis-memory-optimization-when-store-small-data.html)

  - 使用二进制存储：**32位数转成16位数存储**

  - 使用SET和HSET混合的数据组织方式

    先看两个很有意思的配置，是专门为小Hash做准备（使用HSET），当Hash中的条目小于512，并且每个value小于64个字节时，Redis内部采用特殊的编码方式，可以使内存平均节省5倍。

    > https://www.jianshu.com/p/8764a3e7b090
    
    > 如果该 Map 的成员数比较少，则会采用类似一维线性的紧凑格式来存储该 Map，即省去了大量指针的内存开销

    ```
    hash-max-ziplist-entries 512
    hash-max-ziplist-value 64
    ```

    **我们可以把key-value的结构拆解成key-smallhash这样的结构来降低内存的使用**

- 如何保证redis和DB中的数据一致性？

  > 如何保证缓存与数据库双写时的数据一致性?

  > 一般情况下我们都是这样使用缓存的：先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。这种方式很明显会存在缓存和数据库的数据不一致的情况。

  你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？

  一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况

  串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。

  > [https://blog.csdn.net/qq_27384769/article/details/79499373](https://blog.csdn.net/qq_27384769/article/details/79499373)

  **数据一致性的原因**

  写流程：

  1）先淘汰cache

  2）再写db

  读流程：

  1）先读cache，如果数据命中hit则返回

  2）如果数据未命中miss则读db

  3）将db中读取出来的数据入缓存

  什么情况下可能出现缓存和数据库中数据不一致呢？

  ![img](https://github.com/csy512889371/learnDoc/raw/master/image/2018/redis/3.png)

  在分布式环境下，数据的读写都是并发的，上游有多个应用，通过一个服务的多个部署（为了保证可用性，一定是部署多份的），对同一个数据进行读写，在数据库层面并发的读写并不能保证完成顺序，也就是说后发出的读请求很可能先完成（读出脏数据）：

  a）发生了写请求A，A的第一步淘汰了cache（如上图中的1）

  b）A的第二步写数据库，发出修改请求（如上图中的2）

  c）发生了读请求B，B的第一步读取cache，发现cache中是空的（如上图中的步骤3）

  d）B的第二步读取数据库，发出读取请求，此时A的第二步写数据还没完成，读出了一个脏数据放入cache（如上图中的步骤4）

  即在数据库层面，后发出的请求4比先发出的请求2先完成了，读出了脏数据，脏数据又入了缓存，缓存与数据库中的数据不一致出现了

  **问题解决思路**

  能否做到先发出的请求一定先执行完成呢？常见的思路是“串行化” 

  ![img](https://github.com/csy512889371/learnDoc/raw/master/image/2018/redis/4.png)

  上图是一个service服务的上下游及服务内部详细展开，细节如下：

  1）service的上游是多个业务应用，上游发起请求对同一个数据并发的进行读写操作，上例中并发进行了一个uid=1的余额修改（写）操作与uid=1的余额查询（读）操作

  2）service的下游是数据库DB，假设只读写一个DB

  3）中间是服务层service，它又分为了这么几个部分

  3.1）最上层是任务队列

  3.2）中间是工作线程，每个工作线程完成实际的工作任务，典型的工作任务是通过数据库连接池读写数据库

  3.3）最下层是数据库连接池，所有的SQL语句都是通过数据库连接池发往数据库去执行的

- 如何解决缓存穿透和缓存雪崩？

  > 缓存雪崩和缓存穿透问题解决方案

  **缓存雪崩**

  什么是缓存雪崩？
  
  缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

  解决方法：

  - 事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。
  - 事中：本地ehcache缓存 + hystrix限流&降级，避免MySQL崩掉
  - 事后：利用 redis 持久化机制保存的数据尽快恢复缓存

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-25/6078367.jpg)

  **缓存穿透**

  什么是缓存穿透？

  缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。下面用图片展示一下(这两张图片不是我画的，为了省事直接在网上找的，这里说明一下)：

  正常缓存处理流程：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E6%AD%A3%E5%B8%B8%E7%BC%93%E5%AD%98%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-redis.png)

  缓存穿透情况处理流程：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-redis.png)

  一般MySQL 默认的最大连接数在 150 左右，这个可以通过 `show variables like '%max_connections%';`命令来查看。最大连接数一个还只是一个指标，cpu，内存，磁盘，网络等物理条件都是其运行指标，这些指标都会限制其并发能力！所以，一般 3000 个并发请求就能打死大部分数据库了。

  有哪些解决办法？

  最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。

  1）缓存无效 key : 如果缓存和数据库都查不到某个 key 的数据就写一个到 redis 中去并设置过期时间，具体命令如下：SET key value EX 10086。这种方式可以解决请求的 key 变化不频繁的情况，如何黑客恶意攻击，每次构建的不同的请求key，会导致 redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。

  另外，这里多说一嘴，一般情况下我们是这样设计 key 的： 表名:列名:主键名:主键值。

  如果用 Java 代码展示的话，差不多是下面这样的：

  ```java
  public Object getObjectInclNullById(Integer id) {
    // 从缓存中获取数据
    Object cacheValue = cache.get(id);
    // 缓存为空
    if (cacheValue == null) {
        // 从数据库中获取
        Object storageValue = storage.get(key);
        // 缓存空对象
        cache.set(key, storageValue);
        // 如果存储数据为空，需要设置一个过期时间(300秒)
        if (storageValue == null) {
            // 必须设置过期时间，否则有被攻击的风险
            cache.expire(key, 60 * 5);
        }
        return storageValue;
    }
    return cacheValue;
  }
  ```

  2）布隆过滤器：布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在与海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，我会先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。总结一下就是下面这张图(这张图片不是我画的，为了省事直接在网上找的)：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-redis.png)

- 如何用redis实现分布式锁？

  **什么是 RedLock**

  Redis 官方站这篇文章提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性：

  1. 安全特性：互斥访问，即永远只有一个 client 能拿到锁
  2. 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区
  3. 容错性：只要大部分 Redis 节点存活就可以正常提供服务

  **怎么在单节点上实现分布式锁**

  > SET resource_name my_random_value NX PX 30000

  主要依靠上述命令，该命令**仅当 Key 不存在时（NX保证）set 值**，并且**设置过期时间** 3000ms （PX保证），值 my_random_value 必须是所有 client 和所有锁请求发生期间唯一的，释放锁的逻辑是：

  ```lua
  if redis.call("get",KEYS[1]) == ARGV[1] then
      return redis.call("del",KEYS[1])
  else
      return 0
  end
  ```

  上述实现可以避免释放另一个client创建的锁，如果只有 del 命令的话，那么如果 client1 拿到 lock1 之后因为某些操作阻塞了很长时间，此时 Redis 端 lock1 已经过期了并且已经被重新分配给了 client2，那么 client1 此时再去释放这把锁就会造成 client2 原本获取到的锁被 client1 无故释放了，但现在为每个 client 分配一个 unique 的 string 值可以避免这个问题。至于如何去生成这个 unique string，方法很多随意选择一种就行了。

  **Redlock 算法**

  算法很易懂，起 5 个 master 节点，分布在不同的机房尽量保证可用性。为了获得锁，client 会进行如下操作：

  1. 得到当前的时间，微秒单位
  2. 尝试顺序地在 5 个实例上申请锁，当然需要使用相同的 key 和 random value，这里一个 client 需要合理设置与 master 节点沟通的 timeout 大小，避免长时间和一个 fail 了的节点浪费时间
  3. 当 client 在大于等于 3 个 master 上成功申请到锁的时候，且它会计算申请锁消耗了多少时间，这部分消耗的时间采用获得锁的当下时间减去第一步获得的时间戳得到，如果锁的持续时长（lock validity time）比流逝的时间多的话，那么锁就真正获取到了。
  4. 如果锁申请到了，那么锁真正的 lock validity time 应该是 origin（lock validity time） - 申请锁期间流逝的时间
  5. 如果 client 申请锁失败了，那么它就会在少部分申请成功锁的 master 节点上执行释放锁的操作，重置状态

  **失败重试**

  如果一个 client 申请锁失败了，那么它需要稍等一会在重试避免多个 client 同时申请锁的情况，最好的情况是一个 client 需要几乎同时向 5 个 master 发起锁申请。另外就是如果 client 申请锁失败了它需要尽快在它曾经申请到锁的 master 上执行 unlock 操作，便于其他 client 获得这把锁，避免这些锁过期造成的时间浪费，当然如果这时候网络分区使得 client 无法联系上这些 master，那么这种浪费就是不得不付出的代价了。

  **放锁**

  放锁操作很简单，就是依次释放所有节点上的锁就行了

  **性能、崩溃恢复和 fsync**

  如果我们的节点没有持久化机制，client 从 5 个 master 中的 3 个处获得了锁，然后其中一个重启了，这时注意 **整个环境中又出现了 3 个 master 可供另一个 client 申请同一把锁！** 违反了互斥性。如果我们开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在 server 挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。但是考虑断电之后呢，AOF部分命令没来得及刷回磁盘直接丢失了，除非我们配置刷回策略为 fsnyc = always，但这会损伤性能。解决这个问题的方法是，当一个节点重启之后，我们规定在 max TTL 期间它是不可用的，这样它就不会干扰原本已经申请到的锁，等到它 crash 前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作。

## 设计模式

> Java面试突击

> 设计模式比较常见的就是让你手写一个单例模式（注意单例模式的几种不同的实现方法）或者让你说一下某个常见的设计模式在你的项目中是如何使用的，另外面试官还有可能问你抽象工厂和工厂方法模式的区别、工厂模式的思想这样的问题。
>
> 建议把代理模式、观察者模式、（抽象）工厂模式好好看一下，这三个设计模式也很重要。

- Spring和JDK设计中用到的设计模式

  > [https://blog.csdn.net/TK_lTlei/article/details/101599074](https://blog.csdn.net/TK_lTlei/article/details/101599074)

  > [https://blog.csdn.net/wenjieyatou/article/details/80630685](https://blog.csdn.net/wenjieyatou/article/details/80630685)

  Spring中用到了那些设计模式

  - 简单工厂模式
  - 工厂方法
  - 单例模式
  - 代理模式
  - 观察者模式

  JDK中的设计模式

  - **Singleton（单例） Runtime**(https://www.cnblogs.com/fflower/p/10578437.html)
  - Factory（静态工厂） Class.forName
  - **Factory Method（工厂方法） Collection.iterator**
  - **Abstract Factory（抽象工厂） java.sql**
  - Prototype（原型） Object.clone
  - Adapter（适配器） java.io.InputStreamReader(InputStream)
  - **Proxy（代理） 动态代理**
  - Iterator（迭代器） Iterator
  - **Observer（观察者） Swing中的Listener**
  - Command（命令） Runnable

- Spring 框架中用到了哪些设计模式？

  - **工厂设计模式** : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。
  - **代理设计模式** : Spring AOP 功能的实现。
  - **单例设计模式** : Spring 中的 Bean 默认都是单例的。
  - 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。
  - 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。
  - **观察者模式**: Spring 事件驱动模型就是观察者模式很经典的一个应用。
  - 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。
  - ......

- 单例模式

  > [https://blog.csdn.net/qq_34337272/article/details/80455972](https://blog.csdn.net/qq_34337272/article/details/80455972)

  - 单例模式简介

    **为什么要用单例模式呢？**

    在我们的系统中，有一些对象其实我们只需要一个，比如说：线程池、缓存、对话框、注册表、日志对象、充当打印机、显卡等设备驱动程序的对象。事实上，这一类对象只能有一个实例，如果制造出多个实例就可能会导致一些问题的产生，比如：程序的行为异常、资源使用过量、或者不一致性的结果。

    简单来说使用单例模式可以带来下面几个好处:

    对于频繁使用的对象，可以省略创建对象所花费的时间，这对于那些重量级对象而言，是非常可观的一笔系统开销；
    由于 new 操作的次数减少，因而对系统内存的使用频率也会降低，这将减轻 GC 压力，缩短 GC 停顿时间。

    **为什么不使用全局变量确保一个类只有一个实例呢？**

    我们知道全局变量分为静态变量和实例变量，静态变量也可以保证该类的实例只存在一个。

    只要程序加载了类的字节码，不用创建任何实例对象，静态变量就会被分配空间，静态变量就可以被使用了。

    但是，如果说这个对象非常消耗资源，而且程序某次的执行中一直没用，这样就造成了资源的浪费。**利用单例模式的话，我们就可以实现在需要使用时才创建对象，这样就避免了不必要的资源浪费。** 不仅仅是因为这个原因，在程序中我们要尽量避免全局变量的使用，大量使用全局变量给程序的调试、维护等带来困难。

  - 单例的模式的实现

    通常单例模式在Java语言中，有两种构建方式：

    - **饿汉方式。指全局的单例实例在类装载时构建。**
    - **懒汉方式。指全局的单例实例在第一次被使用时构建。**
    
    不管是那种创建方式，它们通常都存在下面几点相似处：

    - 单例类**必须要有一个 private 访问级别的构造函数，只有这样，才能确保单例不会在系统中的其他代码内被实例化;**
    - **uniqueInstance 成员变量和 getInstance 方法必须是 static 的。**

    **饿汉方式(线程安全)**

    ```java
    public class Singleton {
        //在静态初始化器中创建单例实例，这段代码保证了线程安全
        private ， Singleton uniqueInstance = new Singleton();
        //Singleton类只有一个构造方法并且是被private修饰的，所以用户无法通过new方法创建该对象实例
        private Singleton(){}
        public static Singleton getInstance(){
            return uniqueInstance;
        }
    }
    ```

    所谓 “饿汉方式” 就是说JVM在加载这个类时就马上创建此唯一的单例实例，不管你用不用，先创建了再说，如果一直没有被使用，便浪费了空间，典型的空间换时间，每次调用的时候，就不需要再判断，节省了运行时间。

    **懒汉式（非线程安全和synchronized关键字线程安全版本 ）**

    ```java
    public class Singleton {  
        private static Singleton uniqueInstance;  
        private Singleton (){}   
        //没有加入synchronized关键字的版本是线程不安全的
        public static Singleton getInstance() {
            //判断当前单例是否已经存在，若存在则返回，不存在则再建立单例
            if (uniqueInstance == null) {  
                uniqueInstance = new Singleton();  
            }  
            return uniqueInstance;  
        }  
    }
    ```

    所谓 “ 懒汉式” 就是说单例实例在第一次被使用时构建，而不是在JVM在加载这个类时就马上创建此唯一的单例实例。

    但是上面这种方式很明显是线程不安全的，如果多个线程同时访问getInstance()方法时就会出现问题。如果想要保证线程安全，一种比较常见的方式就是在getInstance() 方法前加上synchronized关键字，如下：

    ```java
    public static synchronized Singleton getInstance() {  
	      if (instance == null) {  
	          uniqueInstance = new Singleton();  
	      }  
	      return uniqueInstance;  
    } 
    ```

    我们知道synchronized关键字偏重量级锁。虽然在JavaSE1.6之后synchronized关键字进行了主要包括：为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升。

    但是在程序中每次使用getInstance() 都要经过synchronized加锁这一层，这难免会增加getInstance()的方法的时间消费，而且还可能会发生阻塞。我们下面介绍到的 双重检查加锁版本 就是为了解决这个问题而存在的。

    **懒汉式(双重检查加锁版本)**

    利用双重检查加锁（double-checked locking），首先检查是否实例已经创建，如果尚未创建，“才”进行同步。这样以来，只有一次同步，这正是我们想要的效果。

    ```java
    public class Singleton {
        //volatile保证，当uniqueInstance变量被初始化成Singleton实例时，多个线程可以正确处理uniqueInstance变量
        private volatile static Singleton uniqueInstance;
        private Singleton() {}
        public static Singleton getInstance() {
            //检查实例，如果不存在，就进入同步代码块
            if (uniqueInstance == null) {
                //只有第一次才彻底执行这里的代码
                synchronized(Singleton.class) {
                    //进入同步代码块后，再检查一次，如果仍是null，才创建实例
                    if (uniqueInstance == null) {
                        uniqueInstance = new Singleton();
                    }
                }
            }
            return uniqueInstance;
        }
    }
    ```

    很明显，这种方式相比于使用synchronized关键字的方法，可以大大减少getInstance() 的时间消费。

    我们上面使用到了volatile关键字来保证数据的可见性。

    **懒汉式（登记式/静态内部类方式）**

    静态内部实现的单例是懒加载的且线程安全。

    只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 instance（只有第一次使用这个单例的实例的时候才加载，同时不会有线程安全问题）。

    ```java
    public class Singleton {  
        private static class SingletonHolder {  
            private static final Singleton INSTANCE = new Singleton();  
        }  
        private Singleton (){}  
        public static final Singleton getInstance() {  
            return SingletonHolder.INSTANCE;  
        }  
    }
    ```

    **饿汉式（枚举方式）**

    这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。 它更简洁，自动支持序列化机制，绝对防止多次实例化 （如果单例类实现了Serializable接口，默认情况下每次反序列化总会创建一个新的实例对象，关于单例与序列化的问题可以查看这一篇文章《单例与序列化的那些事儿》），同时这种方式也是《Effective Java 》以及《Java与模式》的作者推荐的方式。

    ```java
    public enum Singleton {
        //定义一个枚举的元素，它就是 Singleton 的一个实例
        INSTANCE;  
        
        public void doSomeThing() {  
          System.out.println("枚举方法实现单例");
        }  
    }
    ```

    使用方法：

    ```java
    public class ESTest {
        public static void main(String[] args) {
            Singleton singleton = Singleton.INSTANCE;
            singleton.doSomeThing();//output:枚举方法实现单例
        }
    }
    ```

    > 这种方法在功能上与公有域方法相近，但是它更加简洁，无偿提供了序列化机制，绝对防止多次实例化，即使是在面对复杂序列化或者反射攻击的时候。虽然这种方法还没有广泛采用，但是单元素的枚举类型已经成为实现Singleton的最佳方法。 —-《Effective Java 中文版 第二版》

- 工厂模式

  > [https://blog.csdn.net/qq_34337272/article/details/80472071](https://blog.csdn.net/qq_34337272/article/details/80472071)

  - 工厂模式介绍
  
    **工厂模式的定义**
    
    在基类中定义创建对象的一个接口，让子类决定实例化哪个类。工厂方法让一个类的实例化延迟到子类中进行。

    **工厂模式的分类**

    （1）简单工厂（Simple Factory）模式，又称静态工厂方法模式（Static Factory Method Pattern）。

    （2）工厂方法（Factory Method）模式，又称多态性工厂（Polymorphic Factory）模式或虚拟构造子（Virtual Constructor）模式；

    （3）抽象工厂（Abstract Factory）模式，又称工具箱（Kit 或Toolkit）模式。

    **工厂模式的例子**

    (1) Spring中通过getBean(“xxx”)获取Bean；

    (2) Java消息服务JMS中(下面以消息队列ActiveMQ为例子)

    ```java
    ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://192.168.25.155:61616");
    ```

    **为什么要用工厂模式**

    (1) 解耦 ：把对象的创建和使用的过程分开

    (2) 降低代码重复: 如果创建某个对象的过程都很复杂，需要一定的代码量，而且很多地方都要用到，那么就会有很多的重复代码。

    (3) 降低维护成本 ：由于创建过程都由工厂统一管理，所以发生业务逻辑变化，不需要找到所有需要创建对象的地方去逐个修正，只需要在工厂里修改即可，降低维护成本。

  - 简单工厂模式

    严格的说，简单工厂模式并不是23种常用的设计模式之一，它只算工厂模式的一个特殊实现。简单工厂模式在实际中的应用相对于其他2个工厂模式用的还是相对少得多，因为它只适应很多简单的情况。

    最重要的是它违背了我们在概述中说的 开放-封闭原则 （虽然可以通过反射的机制来避免，后面我们会介绍到） 。因为每次你要新添加一个功能，都需要在生switch-case 语句（或者if-else 语句）中去修改代码，添加分支条件。

  - 工厂方法模式

    工厂方法模式应该是在工厂模式家族中是用的最多模式，一般项目中存在最多的就是这个模式。

    工厂方法模式是简单工厂的进一步深化， **在工厂方法模式中，我们不再提供一个统一的工厂类来创建所有的对象，而是针对不同的对象提供不同的工厂。** 也就是说 每个对象都有一个与之对应的工厂 。

  - 抽象工厂模式

    在工厂方法模式中，其实我们有一个潜在意识的意识。那就是我们生产的都是同一类产品。**抽象工厂模式是工厂方法的仅一步深化，在这个模式中的工厂类不单单可以创建一种产品，而是可以创建一组产品。**

    抽象工厂是生产一整套有产品的（至少要生产两个产品)，这些产品必须相互是有关系或有依赖的，而工厂方法中的工厂是生产单一产品的工厂。

- 代理模式

  > [https://www.ibm.com/developerworks/cn/java/j-lo-proxy-pattern/index.html](https://www.ibm.com/developerworks/cn/java/j-lo-proxy-pattern/index.html)

- 观察者模式

  > [https://design-patterns.readthedocs.io/zh_CN/latest/behavioral_patterns/observer.html](https://design-patterns.readthedocs.io/zh_CN/latest/behavioral_patterns/observer.html)

## 项目

#### Spring

- 什么是 Spring 框架?

  Spring 是一种轻量级开发框架，旨在提高开发人员的开发效率以及系统的可维护性。Spring 官网：https://spring.io/。

  我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发。这些模块是：**核心容器、数据访问/集成、Web、AOP（面向切面编程）、工具、消息和测试模块**。比如：Core Container 中的 Core 组件是Spring 所有组件的核心，Beans 组件和 Context 组件是实现IOC和依赖注入的基础，AOP组件用来实现面向切面编程。

  Spring 官网列出的 Spring 的 6 个特征:

  核心技术 ：依赖注入(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。
  测试 ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。
  数据访问 ：事务，DAO支持，JDBC，ORM，编组XML。
  Web支持 : Spring MVC和Spring WebFlux Web框架。
  集成 ：远程处理，JMS，JCA，JMX，电子邮件，任务，调度，缓存。
  语言 ：Kotlin，Groovy，动态语言。

- 列举一些重要的Spring模块？

  下图对应的是 Spring4.x 版本。目前最新的5.x版本中 Web 模块的 Portlet 组件已经被废弃掉，同时增加了用于异步响应式处理的 WebFlux 组件。

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/Spring%E4%B8%BB%E8%A6%81%E6%A8%A1%E5%9D%97.png)

  - **Spring Core： 基础,可以说 Spring 其他所有的功能都需要依赖于该类库。主要提供 IoC 依赖注入功能。**
  - **Spring Aspects ： 该模块为与AspectJ的集成提供支持。**
  - **Spring AOP ：提供了面向切面的编程实现。**
  - **Spring JDBC : Java数据库连接。**
  - Spring JMS ：Java消息服务。
  - Spring ORM : 用于支持Hibernate等ORM工具。
  - **Spring Web : 为创建Web应用程序提供支持。**
  - Spring Test : 提供了对 JUnit 和 TestNG 测试的支持。

- @RestController vs @Controller

  **Controller 返回一个页面**

  单独使用 @Controller 不加 @ResponseBody的话一般使用在要返回一个视图的情况，这种情况属于比较传统的Spring MVC 的应用，对应于前后端不分离的情况。

  **@RestController 返回JSON 或 XML 形式数据**

  但@RestController只返回对象，对象数据直接以 JSON 或 XML 形式写入 HTTP 响应(Response)中，这种情况属于 RESTful Web服务，这也是目前日常开发所接触的最常用的情况（前后端分离）。

  **@Controller +@ResponseBody 返回JSON 或 XML 形式数据**

  如果你需要在Spring4之前开发 RESTful Web服务的话，你需要使用@Controller 并结合@ResponseBody注解，也就是说 **@Controller +@ResponseBody= @RestController**（Spring 4 之后新加的注解）。

  > @ResponseBody 注解的作用是将 Controller 的方法返回的对象通过适当的转换器转换为指定的格式之后，写入到HTTP 响应(Response)对象的 body 中，通常用来返回 JSON 或者 XML 数据，返回 JSON 数据的情况比较多。

- Spring IOC & AOP

  **谈谈自己对于 Spring IoC 和 AOP 的理解**

  **IoC**

  IoC（Inverse of Control:控制反转）是一种设计思想，就是 **将原本在程序中手动创建对象的控制权，交由Spring框架来管理**。 IoC 在其他语言中也有应用，并非 Spring 特有。 IoC 容器是 Spring 用来实现 IoC 的载体， **IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象**。

  将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。 IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。 在实际项目中一个 Service 类可能有几百甚至上千个类作为它的底层，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。

  **Spring 时代我们一般通过 XML 文件来配置 Bean，后来开发人员觉得 XML 文件来配置不太好，于是 SpringBoot 注解配置就慢慢开始流行起来。**

  > 什么是DI机制？
  >
  > 依赖注入（Dependecy Injection）和控制反转（Inversion of Control）是同一个概念，具体的讲：当某个角色 需要另外一个角色协助的时候，在传统的程序设计过程中，通常由调用者来创建被调用者的实例。但在spring中 创建被调用者的工作不再由调用者来完成，因此称为控制反转。创建被调用者的工作由spring来完成，然后注入调用者 因此也称为依赖注入。 
  >
  > 依赖注入可以通过setter方法注入（设值注入）、构造器注入和接口注入三种方式来实现，Spring支持**setter注入**和**构造器注入**，通常使用构造器注入来注入必须的依赖关系，对于可选的依赖关系，则setter注入是更好的选择，setter注入需要类提供无参构造器或者无参的静态工厂方法来创建对象。

  > ioc：控制反转、依赖注入（核心原理：反射机制）（优点：借助于第三方IOC容器实现对象之间的依赖关系解耦）
  >
  > aop：**分离应用的业务逻辑和系统级服务**（如日志、事务管理、安全权限等）（核心原理：代理模式（动态代理））
  >
  > 代理模式（静态代理、动态代理）：（在不修改被代理对象源码的基础上，进行功能增强）

  **AOP**

  AOP(Aspect-Oriented Programming:面向切面编程)能够**将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来**，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。

  **Spring AOP就是基于动态代理的，如果要代理的对象，实现了某个接口，那么Spring AOP会使用JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用Cglib ，这时候Spring AOP会使用 Cglib 生成一个被代理对象的子类来作为代理**，如下图所示：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/SpringAOPProcess.jpg)

  当然你也可以使用 AspectJ ,Spring AOP 已经集成了AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。

  使用 AOP 之后我们可以把一些通用功能抽象出来，在需要用到的地方直接使用即可，这样大大简化了代码量。我们需要增加新功能时也方便，这样也提高了系统扩展性。日志功能、事务管理等等场景都用到了 AOP 。

  **Spring AOP 和 AspectJ AOP 有什么区别？**

  **Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。**

  Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，

  如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比Spring AOP 快很多。

- Spring如何解决循环依赖（三级缓存）
  
  > [https://blog.csdn.net/github_38687585/article/details/82317674](https://blog.csdn.net/github_38687585/article/details/82317674)

  一、循环依赖的产生和解决的前提

  循环依赖的产生可能有很多种情况，例如：

  1. A的构造方法中依赖了B的实例对象，同时B的构造方法中依赖了A的实例对象
  2. A的构造方法中依赖了B的实例对象，同时B的某个field或者setter需要A的实例对象，以及反之
  3. A的某个field或者setter依赖了B的实例对象，同时B的某个field或者setter依赖了A的实例对象，以及反之

  Spring对于循环依赖的解决不是无条件的，首先前提条件是针对scope单例并且没有显式指明不需要解决循环依赖的对象，而且要求该对象没有被代理过。同时Spring解决循环依赖也不是万能，以上三种情况只能解决两种，第一种在构造方法中相互依赖的情况Spring也无力回天。

  二、Spring循环依赖的理论依据

  Spring循环依赖的理论依据其实是Java基于引用传递，当我们获取到对象的引用时，对象的field或者或属性是可以延后设置的。

  Spring单例对象的初始化其实可以分为三步：（实例化、填充属性、初始化）

  1. createBeanInstance， **实例化，实际上就是调用对应的构造方法构造对象，此时只是调用了构造方法，spring xml中指定的property并没有进**
  2. populate：populateBean，**填充属性，这步对spring xml中指定的property进行populate**
  3. initializeBean，调用spring xml中指定的init方法，或者AfterPropertiesSet方法

  会发生循环依赖的步骤集中在第一步和第二步。

  三、三级缓存

  对于单例对象来说，在Spring的整个容器的生命周期内，有且只存在一个对象，很容易想到这个对象应该存在Cache中，Spring大量运用了Cache的手段，在循环依赖问题的解决过程中甚至使用了“三级缓存”。

  “三级缓存”主要是指

  ```java
  /** Cache of singleton objects: bean name --> bean instance */
  private final Map<String, Object> singletonObjects = new ConcurrentHashMap<String, Object>(256);

  /** Cache of singleton factories: bean name --> ObjectFactory */
  private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<String, ObjectFactory<?>>(16);

  /** Cache of early singleton objects: bean name --> bean instance */
  private final Map<String, Object> earlySingletonObjects = new HashMap<String, Object>(16);
  ```

  从字面意思来说：**singletonObjects指单例对象的cache，singletonFactories指单例对象工厂的cache，earlySingletonObjects指提前曝光的单例对象的cache**。以上三个cache构成了三级缓存，Spring就用这三级缓存巧妙的解决了循环依赖问题。

  > **什么是三级缓存**
  > - 第一级缓存：单例缓存池**singletonObjects**。
  > - 第二级缓存：早期提前暴露的对象缓存**earlySingletonObjects**。（**属性还没有值，对象也没有被初始化**）
  > - 第三级缓存：**singletonFactories**单例对象工厂缓存。

  分析getSingleton的整个过程，**Spring首先从singletonObjects（一级缓存）中尝试获取，如果获取不到并且对象在创建中，则尝试从earlySingletonObjects(二级缓存)中获取，如果还是获取不到并且允许从singletonFactories通过getObject获取，则通过singletonFactory.getObject()(三级缓存)获取。如果获取到了则将singletonObject放入到earlySingletonObjects,也就是 将三级缓存提升到二级缓存中！**

- 你如何理解AOP中的连接点（Joinpoint）、切点（Pointcut）、增强（Advice）、引介（Introduction）、织入（Weaving）、切面（Aspect）这些概念？

  a. **连接点**（Joinpoint）：**程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。**Spring仅支持方法的连接点。

  b. **切点**（Pointcut）：**如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。**Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。

  c. **增强**（Advice）：**增强是织入到目标类连接点上的一段程序代码。**Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。*

  d. 引介（Introduction）：引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的为该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。

  e. 织入（Weaving）：织入是将增强添加到目标类具体连接点上的过程，AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。

  f. **切面**（Aspect）：**切面是由切点和增强（引介）组成的**，它包括了对横切关注功能的定义，也包括了对连接点的定义。

- AOP的原理是什么？
  
  > Java核心面试知识整理

  Spring 提供了两种方式来生成代理对象: JDKProxy 和Cglib，具体使用哪种方式生成由AopProxyFactory 根据AdvisedSupport 对象的配置来决定。**默认的策略是如果目标类是接口，则使用JDK 动态代理技术，否则使用Cglib 来生成代理。**

  - JDK动态接口代理

    JDK 动态代理主要涉及到java.lang.reflect 包中的两个类：Proxy 和InvocationHandler。InvocationHandler 是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编制在一起。Proxy 利用InvocationHandler 动态创建一个符合某一接口的实例，生成目标类的代理对象。
  
  - CGLib 动态代理

    CGLib 全称为Code Generation Library，是一个强大的高性能，高质量的代码生成类库，可以在运行期扩展Java 类与实现Java 接口，CGLib 封装了asm，可以再运行期动态生成新的class。和JDK 动态代理相比较：**JDK 创建代理有一个限制，就是只能为接口创建代理实例，而对于没有通过接口定义业务方法的类，则可以通过CGLib 创建动态代理。**

  > [https://juejin.im/post/5bf4fc84f265da611b57f906](<https://juejin.im/post/5bf4fc84f265da611b57f906>)

  **AOP简介**

  相信大家或多或少的了解过AOP，都知道它是面向切面编程，在网上搜索可以找到很多的解释。这里我用一句话来总结：AOP是能够让我们在不影响原有功能的前提下，为软件横向扩展功能。 那么横向扩展怎么理解呢，我们在WEB项目开发中，通常都遵守三层原则，包括控制层（Controller）->业务层（Service）->数据层（dao）,那么从这个结构下来的为纵向，它具体的某一层就是我们所说的横向。我们的AOP就是可以作用于这某一个横向模块当中的所有方法。

  我们在来看一下AOP和OOP的区别：AOP是OOP的补充，当我们需要为多个对象引入一个公共行为，比如日志，操作记录等，就需要在每个对象中引用公共行为，这样程序就产生了大量的重复代码，使用AOP可以完美解决这个问题。

  接下来介绍一下提到AOP就必须要了解的知识点：

  - 切面：拦截器类，其中会定义切点以及通知

  - 切点：具体拦截的某个业务点。

  - 通知：切面当中的方法，声明通知方法在目标业务层的执行位置，通知类型如下：

    1. 前置通知：@Before 在目标业务方法执行之前执行
    
    2. 后置通知：@After 在目标业务方法执行之后执行
    
    3. 返回通知：@AfterReturning 在目标业务方法返回结果之后执行
    
    4. 异常通知：@AfterThrowing 在目标业务方法抛出异常之后
    
    5. 环绕通知：@Around 功能强大，可代替以上四种通知，还可以控制目标业务方法是否执行以及何时执行

  **代码中实现举例**

  上面已经大概的介绍了AOP中需要了解的基本知识，也知道了AOP的好处，那怎么在代码中实现呢？给大家举个例子：我们现在有个学校管理系统，已经实现了对老师和学生的增删改，又新来个需求，说是对老师和学生的每次增删改做一个记录，到时候校长可以查看记录的列表。那么问题来了，怎么样处理是最好的解决办法呢？这里我罗列了三种解决办法，我们来看下他的优缺点。

  ![img](https://user-gold-cdn.xitu.io/2018/11/21/167357a2851d2cfc?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

  最简单的就是第一种方法，我们直接在每次的增删改的函数当中直接实现这个记录的方法，这样代码的重复度太高，耦合性太强，不建议使用。

  其次就是我们最长使用的，将记录这个方法抽离出来，其他的增删改调用这个记录函数即可，显然代码重复度降低，但是这样的调用还是没有降低耦合性。

  这个时候我们想一下AOP的定义，再想想我们的场景，其实我们就是要在不改变原来增删改的方法，给这个系统增加记录的方法，而且作用的也是一个层面的方法。这个时候我们就可以采用AOP来实现了。

  我们来看下代码的具体实现：

  1. 首先我定义了一个自定义注解作为切点
  ```java
  @Target(AnnotationTarget.FUNCTION)  //注解作用的范围，这里声明为函数
  @Order(Ordered.HIGHEST_PRECEDENCE)  //声明注解的优先级为最高，假设有多个注解，先执行这个
  annotation class Hanler(val handler: HandlerType)  //自定义注解类，HandlerType是一个枚举类型，里面定义的就是学生和老师的增删改操作，在这里就不展示具体内容了
  ```

  2. 接下来就是要定义切面类了
  ```java
  @Aspect   //该注解声明这个类为一个切面类
  @Component
  class HandlerAspect{
  
      @Autowired
      private lateinit var handlerService: HandlerService
  
      @AfterReturning("@annotation(handler)")   //当有函数注释了注解，将会在函数正常返回后在执行我们定义的方法
      fun hanler(hanler: Hanler) {
          handlerService.add(handler.operate.value)   //这里是真正执行记录的方法
      }
  }
  ```

  3. 最后就是我们本来的业务方法了
  ```java
  /**
  * 删除学生方法
  */
  @Handler(operate= Handler.STUDENT_DELETE)   //当执行到删除学生方法时，切面类就会起作用了,当学生正常删除后就会执行记录方法，我们就可以看到记录方法生成的数据
  fun delete(id：String) {
    studentService.delete(id)
  }
  ```

  **AOP实现原理**

  我们现在了解了代码中如何实现，那么AOP实现的原理是什么呢？之前看了一个博客说到，提到AOP大家都知道他的实现原理是动态代理，显然我之前就是不知道的，哈哈，但是相信阅读文章的你们一定是知道的。

  讲到动态代理就不得不说代理模式了， 代理模式的定义：给某一个对象提供一个代理，并由代理对象控制对原对象的引用。代理模式包含如下角色：subject：抽象主题角色，是一个接口。该接口是对象和它的代理共用的接口; RealSubject：真实主题角色，是实现抽象主题接口的类; Proxy:代理角色，内部含有对真实对象RealSubject的引用，从而可以操作真实对象。代理对象提供与真实对象相同的接口，以便代替真实对象。同时，代理对象可以在执行真实对象操作时，附加其他的操作，相当于对真实对象进行封装。如下图所示：

  ![img](https://user-gold-cdn.xitu.io/2018/11/22/1673a262814cef3e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

  ![img](https://user-gold-cdn.xitu.io/2018/11/22/1673a2653b02d775?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

  那么代理又分为静态代理和动态代理，这里写两个小的demo，动态代理采用的就是JDK代理。举个例子就是现在一个班上的学生需要交作业，现在由班长代理交作业，那么班长就是代理，学生就是被代理的对象。

  - 静态代理

    首先，我们创建一个Person接口。这个接口就是学生（被代理类），和班长（代理类）的公共接口，他们都有交作业的行为。这样，学生交作业就可以让班长来代理执行。

    ```java
    /**
    * Created by Mapei on 2018/11/7
    * 创建person接口
    */
    public interface Person {
        //交作业
        void giveTask();
    }
    ```

    Student类实现Person接口，Student可以具体实施交作业这个行为。

    ```java
    /**
    * Created by Mapei on 2018/11/7
    */
    public class Student implements Person {
        private String name;
        public Student(String name) {
            this.name = name;
        }

        public void giveTask() {
            System.out.println(name + "交语文作业");
        }
    }
    ```

    StudentsProxy类，这个类也实现了Person接口，但是还另外持有一个学生类对象，那么他可以代理学生类对象执行交作业的行为。

    ```java
    /**
    * Created by Mapei on 2018/11/7
    * 学生代理类，也实现了Person接口，保存一个学生实体，这样就可以代理学生产生行为
    */
    public class StudentsProxy implements Person{
        //被代理的学生
        Student stu;

        public StudentsProxy(Person stu) {
            // 只代理学生对象
            if(stu.getClass() == Student.class) {
                this.stu = (Student)stu;
            }
        }

        //代理交作业，调用被代理学生的交作业的行为
        public void giveTask() {
            stu.giveTask();
        }
    }
    ```

    下面测试一下，看代理模式如何使用：

    ```java
    /**
    * Created by Mapei on 2018/11/7
    */
    public class StaticProxyTest {
        public static void main(String[] args) {
            //被代理的学生林浅，他的作业上交有代理对象monitor完成
            Person linqian = new Student("林浅");

            //生成代理对象，并将林浅传给代理对象
            Person monitor = new StudentsProxy(linqian);

            //班长代理交作业
            monitor.giveTask();
        }
    }
    ```

    这里并没有直接通过林浅（被代理对象）来执行交作业的行为，而是通过班长（代理对象）来代理执行了。这就是代理模式。代理模式就是在访问实际对象时引入一定程度的间接性，这里的间接性就是指不直接调用实际对象的方法，那么我们在代理过程中就可以加上一些其他用途。比如班长在帮林浅交作业的时候想告诉老师最近林浅的进步很大，就可以轻松的通过代理模式办到。在代理类的交作业之前加入方法即可。这个优点就可以运用在spring中的AOP，我们能在一个切点之前执行一些操作，在一个切点之后执行一些操作，这个切点就是一个个方法。这些方法所在类肯定就是被代理了，在代理过程中切入了一些其他操作。

  - 动态代理

    动态代理和静态代理的区别是，**静态代理的的代理类是我们自己定义好的，在程序运行之前就已经编译完成，但是动态代理的代理类是在程序运行时创建的。** 相比于静态代理，动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。比如我们想在每个代理方法之前都加一个处理方法，我们上面的例子中只有一个代理方法，如果还有很多的代理方法，就太麻烦了，我们来看下动态代理是怎么去实现的。

    首先还是定义一个Person接口:

    ```java
    /**
    * Created by Mapei on 2018/11/7
    * 创建person接口
    */
    public interface Person {
        //交作业
        void giveTask();
    }
    ```

    接下来是创建需要被代理的实际类，也就是学生类：

    ```java
    /**
    * Created by Mapei on 2018/11/7
    */
    public class Student implements Person {
        private String name;
        public Student(String name) {
            this.name = name;
        }

        public void giveTask() {
            System.out.println(name + "交语文作业");
        }
    }
    ```

    创建StuInvocationHandler类，实现InvocationHandler接口，这个类中持有一个被代理对象的实例target。**InvocationHandler中有一个invoke方法，所有执行代理对象的方法都会被替换成执行invoke方法。**

    ```java
    /**
    * Created by Mapei on 2018/11/7
    */
    public class StuInvocationHandler<T> implements InvocationHandler {
        //invocationHandler持有的被代理对象
        T target;

        public StuInvocationHandler(T target) {
            this.target = target;
        }

        /**
        * proxy:代表动态代理对象
        * method：代表正在执行的方法
        * args：代表调用目标方法时传入的实参
        */
        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
            System.out.println("代理执行" +method.getName() + "方法");
            Object result = method.invoke(target, args);
            return result;
        }
    }
    ```

    那么接下来我们就可以具体的创建代理对象了。

    ```java
    /**
    * Created by Mapei on 2018/11/7
    * 代理类
    */
    public class ProxyTest {
        public static void main(String[] args) {

            //创建一个实例对象，这个对象是被代理的对象
            Person linqian = new Student("林浅");

            //创建一个与代理对象相关联的InvocationHandler
            InvocationHandler stuHandler = new StuInvocationHandler<Person>(linqian);

            //创建一个代理对象stuProxy来代理linqian，代理对象的每个执行方法都会替换执行Invocation中的invoke方法
            Person stuProxy = (Person) Proxy.newProxyInstance(Person.class.getClassLoader(), new Class<?>[]{Person.class}, stuHandler);

            //代理执行交作业的方法
            stuProxy.giveTask();
        }
    }
    ```

    我们执行代理测试类，**首先我们创建了一个需要被代理的学生林浅，将林浅传入stuHandler中，我们在创建代理对象stuProxy时，将stuHandler作为参数，那么所有执行代理对象的方法都会被替换成执行invoke方法**，也就是说，最后执行的是StuInvocationHandler中的invoke方法。所以在看到下面的运行结果也就理所当然了。

- aop的应用场景有哪些？

  > [https://zhuanlan.zhihu.com/p/83204146](https://zhuanlan.zhihu.com/p/83204146)

  **为什么会有面向切面编程（AOP）？**

  我们知道Java是一个面向对象（OOP）的语言，但它有一些弊端，比如当我们需要为多个不具有继承关系的对象引入一个公共行为，例如日志、权限验证、事务等功能时，只能在在每个对象里引用公共行为。这样做不便于维护，而且有大量重复代码。AOP的出现弥补了OOP的这点不足。

  **Spring AOP 中设计的一些核心知识，面试问题？**

  1、能说一下Spring AOP用的是哪种设计模式？

  回答：代理模式。

  2、 能简单聊一下你对代理模式的理解吗？

  记住一些贴近日常的示例方便理解，如买火车票，Windows 里面的快捷方式...

  3、 知道JDK代理和Cglib代理有什么区别？

  我们不需要创建代理类，JDK 在运行时为我们动态的来创建，JDK代理是接口

  若目标类不存在接口,则使用Cglib生成代理

  不管是JDK代理还是Cglib代理本质上都是对字节码进行操作

  4、让你实现一个JDK实现动态代理？你的思路是什么？

  Proxy: 定义一个自己的Proxy类

  InvocationHandler：定义一个自己的InvocationHandler类

  ClassLoad：自定义类加载器（方便加载我们自己指定的路径下面的类）

  **SpringAOP的在实际应用中场景有哪些？**

  1. **Authentication 权限**
  2. Caching 缓存
  3. Context passing 内容传递
  4. Error handling 错误处理
  5. Lazy loading 懒加载
  6. **Debugging 调试**
  7. logging，tracing，profiling and monitoring 记录跟踪 优化 校准
  8. Performance optimization 性能优化
  9. **Persistence 持久化**
  10. Resource pooling 资源池
  11. Synchronization 同步
  12. **Transactions 事务**
  13. **Logging 日志**

- Spring 中的 bean 的作用域有哪些?

  - singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。
  - prototype : 每次请求都会创建一个新的 bean 实例。

  Spring 2.x中针对WebApplicationContext新增了3个作用域

  - request : 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。
  - session : 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。
  - global-session： 全局session作用域，仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话

- Spring 中的单例 bean 的线程安全问题了解吗？

  大部分时候我们并没有在系统中使用多线程，所以很少有人会关注这个问题。**单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。**

  常见的有两种解决办法：

  1. 在Bean对象中尽量避免定义可变的成员变量（不太现实）。

  2. **在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中**（推荐的一种方式）。

- @Component 和 @Bean 的区别是什么？

  作用对象不同: **@Component 注解作用于类，而@Bean注解作用于方法。**

  **@Component通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了Spring这是某个类的示例，当我需要用它的时候还给我。**

  @Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。

  @Bean注解使用示例：

  ```java
  @Configuration
  public class AppConfig {
      @Bean
      public TransferService transferService() {
          return new TransferServiceImpl();
      }
  }
  ```

  上面的代码相当于下面的 xml 配置

  ```xml
  <beans>
      <bean id="transferService" class="com.acme.TransferServiceImpl"/>
  </beans>
  ```

  下面这个例子是通过 @Component 无法实现的。

  ```java
  @Bean
  public OneService getService(status) {
      case (status)  {
          when 1:
                  return new serviceImpl1();
          when 2:
                  return new serviceImpl2();
          when 3:
                  return new serviceImpl3();
      }
  }
  ```

- 在以前的学习中有使用过Spring里面的注解吗？如果有请谈一下autowired 和resource区别是什么？
  
  1、共同点

  两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。

  2、不同点

  （1）@Autowired

  @Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。

  **@Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。**

  （2）@Resource

  **@Resource默认按照ByName自动注入**，由J2EE提供，需要导入包javax.annotation.Resource。**@Resource有两个重要的属性：name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。**

  > [https://blog.csdn.net/u010648555/article/details/76299467](https://blog.csdn.net/u010648555/article/details/76299467)

  **Spring常用注解**

  **一： 组件类注解**

  @Component ：标准一个普通的spring Bean类。 
  
  @Repository：标注一个DAO组件类。 
  
  @Service：标注一个业务逻辑组件类。 
  
  @Controller：标注一个控制器组件类。

  @Component可以代替@Repository、@Service、@Controller，因为这三个注解是被@Component标注的。

  **二：装配bean时常用的注解**

  @Autowired：属于Spring 的org.springframework.beans.factory.annotation包下,可用于为类的属性、构造器、方法进行注值 
  
  @Resource：不属于spring的注解，而是来自于JSR-250位于java.annotation包下，使用该annotation为目标bean指定协作者Bean。 
  
  @PostConstruct 和 @PreDestroy 方法 实现初始化和销毁bean之前进行的操作

  相同点 
  
  @Resource的作用相当于@Autowired，均可标注在字段或属性的setter方法上。
  
  不同点

  a：提供方 

  @Autowired是Spring的注解，@Resource是javax.annotation注解，而是来自于JSR-250，J2EE提供，需要JDK1.6及以上。

  **b ：注入方式** 
  
  @Autowired只按照Type 注入；@Resource默认按Name自动注入，也提供按照Type 注入；

  **c：属性**

  @Autowired注解可用于为类的属性、构造器、方法进行注值。默认情况下，其依赖的对象必须存在（bean可用），如果需要改变这种默认方式，可以设置其required属性为false。
  还有一个比较重要的点就是，@Autowired注解默认按照类型装配，如果容器中包含多个同一类型的Bean，那么启动容器时会报找不到指定类型bean的异常，解决办法是结合**@Qualifier**注解进行限定，指定注入的bean名称。

  > **@Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。**
  
  @Resource有两个中重要的属性：name和type。name属性指定byName，如果没有指定name属性，当注解标注在字段上，即默认取字段的名称作为bean名称寻找依赖对象，当注解标注在属性的setter方法上，即默认取属性名作为bean名称寻找依赖对象。
  需要注意的是，@Resource如果没有指定name属性，并且按照默认的名称仍然找不到依赖对象时， @Resource注解会回退到按类型装配。但一旦指定了name属性，就只能按名称装配了。

  > **@Resource默认按照ByName自动注入**，由J2EE提供，需要导入包javax.annotation.Resource。**@Resource有两个重要的属性：name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。**

  d：
  
  @Resource注解的使用性更为灵活，可指定名称，也可以指定类型 ；@Autowired注解进行装配容易抛出异常，特别是装配的bean类型有多个的时候，而解决的办法是需要在增加@Qualifier进行限定。

  **三：@Component vs @Configuration and @Bean**

  @Component可以替代 @Configuration注解

  Bean注解主要用于方法上，有点类似于工厂方法，当使用了@Bean注解，我们可以连续使用多种定义bean时用到的注解，譬如用@Qualifier注解定义工厂方法的名称，用@Scope注解定义该bean的作用域范围，譬如是singleton还是prototype等。

  Spring 中新的 Java 配置支持的核心就是@Configuration 注解的类。这些类主要包括 @Bean 注解的方法来为 Spring 的 IoC 容器管理的对象定义实例，配置和初始化逻辑。

  使用@Configuration 来注解类表示类可以被 Spring 的 IoC 容器所使用，作为 bean 定义的资源。

  ```java
  @Configuration
  public class AppConfig {
      @Bean
      public MyService myService() {
          return new MyServiceImpl();
      }
  }
  ```

  这和 Spring 的 XML 文件中的非常类似

  ```xml
  <beans>
    <bean id="myService" class="com.acme.services.MyServiceImpl"/>
  </beans>
  ```

  **四：spring MVC模块注解**

  `@RestController` = `@Controller` + `@ResponseBody`
  
  `@RequestMapping`, `@PostMapping`, `@GetMapping`
  
  `@RequestBody`, `@RequestParam`, `@PathVariable`

  > [http://tengj.top/2016/04/28/javareflect/](http://tengj.top/2016/04/28/javareflect/)

  Java反射机制是指在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。
  
  用一句话总结就是**反射可以实现在运行时可以知道任意一个类的属性和方法。**
  
  **理解Class类和类类型**
  
  类是java.lang.Class类的实例对象，而Class是所有类的类。
  
  ```java
  Class c1 = Code.class;
  //这说明任何一个类都有一个隐含的静态成员变量class，这种方式是通过获取类的静态成员变量class得到的
  Class c2 = code1.getClass();
  //code1是Code的一个对象，这种方式是通过一个类的对象的getClass()方法获得的
  Class c3 = Class.forName("com.trigl.reflect.Code");
  //这种方法是Class类调用forName方法，通过一个类的全量限定名获得
  ```
  
  这里，c1、c2、c3都是Class的对象，他们是完全一样的，而且有个学名，叫做Code的类类型（class type）。

  **Java反射相关操作**

  获取成员方法Method

  ```java
  public Method getDeclaredMethod(String name, Class<?>... parameterTypes) // 得到该类所有的方法，不包括父类的
  public Method getMethod(String name, Class<?>... parameterTypes) // 得到该类所有的public方法，包括父类的
  ```

  获取成员变量Field

  ```java
  public Field getDeclaredField(String name) // 获得该类自身声明的所有变量，不包括其父类的变量
  public Field getField(String name) // 获得该类自所有的public成员变量，包括其父类变量
  ```
  
  获取构造函数Constructor
  ```java
  public Constructor<T> getDeclaredConstructor(Class<?>... parameterTypes) //  获得该类所有的构造器，不包括其父类的构造器
  public Constructor<T> getConstructor(Class<?>... parameterTypes) // 获得该类所以public构造器，包括父类
  ```

- Spring中自动装配的方式

  - no：不进行自动装配，手动设置Bean的依赖关系。
  - byName：根据Bean的名字进行自动装配。
  - byType：根据Bean的类型进行自动装配。
  - constructor：类似于byType，不过是应用于构造器的参数，如果正好有一个Bean与构造器的参数类型相同则可以自动装配，否则会导致错误。
  - autodetect：如果有默认的构造器，则通过constructor的方式进行自动装配，否则使用byType的方式进行自动装配。

- Spring 中的 bean 生命周期?

  **实例化bean、设置属性（依赖注入）、注入aware接口、执行postProcessBeforeInitialization() 方法、调用初始化方法、执行postProcessBeforeInitialization() 方法、调用销毁方法**

  - Bean 容器找到配置文件中 Spring Bean 的定义。
  - Bean 容器利用 Java Reflection API **创建一个Bean的实例**。
  - 如果涉及到一些属性值 利用 set()方法设置一些属性值。
  - 如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入Bean的名字。
  - 如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader对象的实例。
  - 与上面的类似，如果实现了其他 *.Aware接口，就调用相应的方法。
  - **如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法**
  - 如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。
  - 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。
  - **如果有和加载这个 Bean的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法**
  - 当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。
  - 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。

  > [https://www.zhihu.com/question/38597960](<https://www.zhihu.com/question/38597960>)

  对于普通的Java对象，当new的时候创建对象，当它没有任何引用的时候被垃圾回收机制回收。而由Spring IoC容器托管的对象，它们的生命周期完全由容器控制。Spring中每个Bean的生命周期如下：

  ![img](https://pic1.zhimg.com/80/v2-baaf7d50702f6d0935820b9415ff364c_hd.jpg)

  1. **实例化Bean**

      对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。

      对于ApplicationContext容器，当容器启动结束后，便实例化所有的bean。

      容器通过获取BeanDefinition对象中的信息进行实例化。并且这一步仅仅是简单的实例化，并未进行依赖注入。
      
      实例化对象被包装在BeanWrapper对象中，BeanWrapper提供了设置对象属性的接口，从而避免了使用反射机制设置属性。

  2. **设置对象属性（依赖注入）**

      实例化后的对象被封装在BeanWrapper对象中，并且此时对象仍然是一个原生的状态，并没有进行依赖注入。
    
      紧接着，Spring根据BeanDefinition中的信息进行依赖注入。
    
      并且通过BeanWrapper提供的设置属性的接口完成依赖注入。

  3. **注入Aware接口**

      紧接着，Spring会检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给bean。

  4. **BeanPostProcessor**

      当经过上述几个步骤后，bean对象已经被正确构造，但如果你想要对象被使用前再进行一些自定义的处理，就可以通过BeanPostProcessor接口实现。
    
      该接口提供了两个函数：

      - postProcessBeforeInitialzation( Object bean, String beanName )

        当前正在初始化的bean对象会被传递进来，我们就可以对这个bean作任何处理。

        这个函数会先于InitialzationBean执行，因此称为前置处理。
        所有Aware接口的注入就是在这一步完成的。

      - postProcessAfterInitialzation( Object bean, String beanName )

        当前正在初始化的bean对象会被传递进来，我们就可以对这个bean作任何处理。

        这个函数会在InitialzationBean完成后执行，因此称为后置处理。
  
  5. **InitializingBean与init-method**

      **当BeanPostProcessor的前置处理完成后就会进入本阶段。**
  
      InitializingBean接口只有一个函数：

      - afterPropertiesSet()

        这一阶段也可以在bean正式构造完成前增加我们自定义的逻辑，但它与前置处理不同，由于该函数并不会把当前bean对象传进来，因此在这一步没办法处理对象本身，只能增加一些额外的逻辑。
        若要使用它，我们需要让bean实现该接口，并把要增加的逻辑写在该函数中。然后Spring会在前置处理完成后检测当前bean是否实现了该接口，并执行afterPropertiesSet函数。

        当然，Spring为了降低对客户代码的侵入性，给bean的配置提供了init-method属性，该属性指定了在这一阶段需要执行的函数名。Spring便会在初始化阶段执行我们设置的函数。init-method本质上仍然使用了InitializingBean接口。

  6. **DisposableBean和destroy-method**

        和init-method一样，通过给destroy-method指定函数，就可以在bean销毁前执行指定的逻辑。

- Spring中BeanFactory和ApplicationContext的区别

  BeanFactory是Spring里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能。

  **ApplicationContext应用上下文，继承BeanFactory接口**，它是Spring的一各更高级的容器，提供了更多的有用的功能。如国际化，访问资源，**载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次**，消息发送、响应机制，**AOP**等。

  **BeanFactory在启动的时候不会去实例化Bean，中有从容器中拿Bean的时候才会去实例化。ApplicationContext在启动的时候就把所有的Bean全部实例化了。它还可以为Bean配置lazy-init=true来让Bean延迟实例化**
  
- Spring MVC

  **说说自己对于 Spring MVC 了解?**

  谈到这个问题，我们不得不提提之前 Model1 和 Model2 这两个没有 Spring MVC 的时代。

  Model1 时代 : 很多学 Java 后端比较晚的朋友可能并没有接触过 Model1 模式下的 JavaWeb 应用开发。在 Model1 模式下，整个 Web 应用几乎全部用 JSP 页面组成，只用少量的 JavaBean 来处理数据库连接、访问等操作。这个模式下 JSP 即是控制层又是表现层。显而易见，这种模式存在很多问题。比如①将控制逻辑和表现逻辑混杂在一起，导致代码重用率极低；②前端和后端相互依赖，难以进行测试并且开发效率极低；

  Model2 时代 ：学过 Servlet 并做过相关 Demo 的朋友应该了解“Java Bean(Model)+ JSP（View）+Servlet（Controller） ”这种开发模式,这就是早期的 JavaWeb MVC 开发模式。Model:系统涉及的数据，也就是 dao 和 bean。View：展示模型中的数据，只是用来展示。Controller：处理用户请求都发送给 ，返回数据给 JSP 并展示给用户。

  Model2 模式下还存在很多问题，Model2的抽象和封装程度还远远不够，使用Model2进行开发时不可避免地会重复造轮子，这就大大降低了程序的可维护性和复用性。于是很多JavaWeb开发相关的 MVC 框架应运而生比如Struts2，但是 Struts2 比较笨重。随着 Spring 轻量级开发框架的流行，Spring 生态圈出现了 Spring MVC 框架， Spring MVC 是当前最优秀的 MVC 框架。相比于 Struts2 ， Spring MVC 使用更加简单和方便，开发效率更高，并且 Spring MVC 运行速度更快。

  MVC 是一种设计模式,Spring MVC 是一款很优秀的 MVC 框架。Spring MVC 可以帮助我们进行更简洁的Web层的开发，并且它天生与 Spring 框架集成。Spring MVC 下我们一般把后端项目分为 Service层（处理业务）、Dao层（数据库操作）、Entity层（实体类）、Controller层(控制层，返回数据给前台页面)。

  Spring MVC 的简单原理图如下：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-11/60679444.jpg)

  **SpringMVC 工作原理了解吗?**
  
  原理如下图所示：

  ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-11/49790288.jpg)

  上图的一个笔误的小问题：Spring MVC 的入口函数也就是前端控制器 DispatcherServlet 的作用是接收请求，响应结果。

  流程说明（重要）：

  1. 客户端（浏览器）发送请求，直接请求到 DispatcherServlet（前端控制器）。
  2. DispatcherServlet（前端控制器） 根据请求信息调用 HandlerMapping（处理器映射器），解析请求对应的 Handler。
  3. 解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理。
  4. HandlerAdapter（处理器适配器） 会根据 Handler来调用真正的处理器开处理请求，并处理相应的业务逻辑。
  5. 处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。
  6. ViewResolver（视图解析器） 会根据逻辑 View 查找实际的 View。
  7. DispaterServlet（前端控制器） 把返回的 Model 传给 View（视图渲染）。
  8. 把 View 返回给请求者（浏览器）

  > **浏览器请求DispatcherServlet，DispatcherSevlet根据请求调用HandlerMapping，解析到对应的Handler。HandlerAdapter根据Handler调用controller，返回ModelAndView，包括数据对象Model和逻辑View。ViewResolver根据逻辑View查找实际的View。DispatcherServlet把Model传给View渲染，并返回给浏览器。**
  
- Spring 框架中用到了哪些设计模式？

  - **工厂设计模式** : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。
  - **代理设计模式** : Spring AOP 功能的实现。
  - **单例设计模式** : Spring 中的 Bean 默认都是单例的。
  - 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。
  - 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。
  - **观察者模式**: Spring 事件驱动模型就是观察者模式很经典的一个应用。
  - 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。
  - ......

- 事务几种实现方式

  > [https://blog.csdn.net/chinacr07/article/details/78817449](https://blog.csdn.net/chinacr07/article/details/78817449)

  （1）编程式事务管理对基于 POJO 的应用来说是唯一选择。我们需要在代码中调用beginTransaction()、commit()、rollback()等事务管理相关的方法，这就是编程式事务管理。

  （2）基于 TransactionProxyFactoryBean的声明式事务管理

  （3）基于 @Transactional 的声明式事务管理

  （4）基于Aspectj AOP配置事务

- Spring 事务

  - Spring 管理事务的方式有几种？
    1. **编程式事务，在代码中硬编码。**(不推荐使用)
    2. **声明式事务，在配置文件中配置**（推荐使用）
  
    声明式事务又分为两种：

    1. **基于XML的声明式事务**
    2. **基于注解的声明式事务**

  - Spring 事务中的隔离级别有哪几种?

    TransactionDefinition 接口中定义了五个表示隔离级别的常量：

    - TransactionDefinition.ISOLATION_DEFAULT: 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.
    - TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读
    - TransactionDefinition.ISOLATION_READ_COMMITTED: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
    - TransactionDefinition.ISOLATION_REPEATABLE_READ: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
    - TransactionDefinition.ISOLATION_SERIALIZABLE: 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

  - 事务的传播特性

  > [https://blog.csdn.net/chinacr07/article/details/78817449](https://blog.csdn.net/chinacr07/article/details/78817449)

    事务传播行为就是多个事务方法调用时，如何定义方法间事务的传播。Spring定义了7中传播行为：

    （1）propagation_requierd：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是Spring默认的选择。

    （2）propagation_supports：支持当前事务，如果没有当前事务，就以非事务方法执行。

    （3）propagation_mandatory：使用当前事务，如果没有当前事务，就抛出异常。

    （4）propagation_required_new：新建事务，如果当前存在事务，把当前事务挂起。

    （5）propagation_not_supported：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。

    （6）propagation_never：以非事务方式执行操作，如果当前事务存在则抛出异常。

    （7）propagation_nested：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作。

  - @Transactional(rollbackFor = Exception.class)注解了解吗？

    我们知道：Exception分为运行时异常RuntimeException和非运行时异常。事务管理对于企业应用来说是至关重要的，即使出现异常情况，它也可以保证数据的一致性。

    当@Transactional注解作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。如果类或者方法加了这个注解，那么这个类里面的方法抛出异常，就会回滚，数据库里面的数据也会回滚。

    **在@Transactional注解中如果不配置rollbackFor属性,那么事物只会在遇到RuntimeException的时候才会回滚,加上rollbackFor=Exception.class,可以让事物在遇到非运行时异常时也回滚。**

  - spring中声明式事务实现原理

    > [https://blog.csdn.net/qq_20597727/article/details/84868035](https://blog.csdn.net/qq_20597727/article/details/84868035)
  
    首先，对于spring中aop实现原理有了解的话，应该知道想要对一个方法进行代理的话，肯定需要定义切点。在@Transactional的实现中，同样如此，spring为我们定义了以 @Transactional 注解为植入点的切点，这样才能知道@Transactional注解标注的方法需要被代理。

    有了切面定义之后，在spring的bean的初始化过程中，就需要对实例化的bean进行代理，并且生成代理对象。

    生成代理对象的代理逻辑中，进行方法调用时，需要先获取切面逻辑，@Transactional注解的切面逻辑类似于@Around，在spring中是实现一种类似代理逻辑。

#### SpringBoot

- SpringBoot介绍

  > [https://github.com/Snailclimb/springboot-guide/blob/master/docs/start/springboot-introduction.md#%E4%B8%80-springboot%E4%BB%8B%E7%BB%8D](https://github.com/Snailclimb/springboot-guide/blob/master/docs/start/springboot-introduction.md#%E4%B8%80-springboot%E4%BB%8B%E7%BB%8D)
  
  我们知道Spring是重量级企业开发框架 Enterprise JavaBean（EJB） 的替代品，Spring为企业级Java开发提供了一种相对简单的方法，通过 依赖注入 和 面向切面编程 ，用简单的 Java对象（Plain Old Java Object，POJO） 实现了EJB的功能

  **虽然Spring的组件代码是轻量级的，但它的配置却是重量级的（需要大量XML配置）** 。Spring 2.5引入了基于注解的组件扫描，这消除了大量针对应用程序自身组件的显式XML配置。Spring 3.0引入了基于Java的配置，这是一种类型安全的可重构配置方式，可以代替XML。

  尽管如此，我们依旧没能逃脱配置的魔爪。开启某些Spring特性时，比如事务管理和Spring MVC，还是需要用XML或Java进行显式配置。启用第三方库时也需要显式配置，比如基于Thymeleaf的Web视图。配置Servlet和过滤器（比如Spring的DispatcherServlet）同样需要在web.xml或Servlet初始化代码里进行显式配置。组件扫描减少了配置量，Java配置让它看上去简洁不少，但Spring还是需要不少配置。

  光配置这些XML文件都够我们头疼的了，占用了我们大部分时间和精力。除此之外，相关库的依赖非常让人头疼，不同库之间的版本冲突也非常常见。

  从本质上来说，Spring Boot就是Spring，它做了那些没有它你自己也会去做的Spring Bean配置。

- Spring Boot 项目结构分析

  [https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/sringboot-restful-web-service.md](https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/sringboot-restful-web-service.md)

  1. Application.java是项目的启动类
  2. **domain目录主要用于实体（Entity）与数据访问层（Repository）**
  3. **service 层主要是业务类代码**
  4. **controller 负责页面访问控制**
  5. config 目录主要放一些配置类

- 开发 RestFul Web 服务

  > [https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/sringboot-restful-web-service.md](https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/sringboot-restful-web-service.md)

  **RESTful Web 服务介绍**

  RESTful Web 服务与传统的 MVC 开发一个关键区别是返回给客户端的内容的创建方式：传统的 MVC 模式开发会直接返回给客户端一个视图，但是 RESTful Web 服务一般会将返回的数据以 JSON 的形式返回，这也就是现在所推崇的前后端分离开发。

  1. `@RestController` **将返回的对象数据直接以 JSON 或 XML 形式写入 HTTP 响应(Response)中。** 绝大部分情况下都是直接以 JSON 形式返回给客户端，很少的情况下才会以 XML 形式返回。转换成 XML 形式还需要额为的工作，上面代码中演示的直接就是将对象数据直接以 JSON 形式写入 HTTP 响应(Response)中。关于@Controller和@RestController 的对比，我会在下一篇文章中单独介绍到（**@Controller +@ResponseBody= @RestController**）。
  2. `@RequestMapping` :上面的示例中没有指定 GET 与 PUT、POST 等，因为**@RequestMapping默认映射所有HTTP Action**，你可以使用@RequestMapping(method=ActionType)来缩小这个映射。
  3. `@PostMapping`实际上就等价于 @RequestMapping(method = RequestMethod.POST)，同样的 @DeleteMapping ,@GetMapping也都一样，常用的 HTTP Action 都有一个这种形式的注解所对应。
  4. `@PathVariable` :取url地址中的参数。@RequestParam url的查询参数值。
  5. `@RequestBody`:可以将 HttpRequest body 中的 JSON 类型数据反序列化为合适的 Java 类型。
  6. ResponseEntity: 表示整个HTTP Response：状态码，标头和正文内容。我们可以使用它来自定义HTTP Response 的内容。

  > `@RestController` = `@Controller` + `@ResponseBody`
  >
  > `@RequestMapping`, `@PostMapping`, `@GetMapping`
  >
  > `@RequestBody`, `@RequestParam`

- 面试题

  **什么是 Spring Boot?**

  首先，重要的是要理解 Spring Boot 并不是一个框架，它是一种创建独立应用程序的更简单方法，只需要很少或没有配置（相比于 Spring 来说）。Spring Boot最好的特性之一是它利用现有的 Spring 项目和第三方项目来开发适合生产的应用程序。

  **说出使用Spring Boot的主要优点**

  1. 开发基于 Spring 的应用程序很容易。
  2. Spring Boot 项目所需的开发或工程时间明显减少，通常会提高整体生产力。
  3. **Spring Boot不需要编写大量样板代码、XML配置和注释。**
  4. Spring引导应用程序可以很容易地与Spring生态系统集成，如Spring JDBC、Spring ORM、Spring Data、Spring Security等。
  5. Spring Boot遵循“固执己见的默认配置”，以减少开发工作（默认配置可以修改）。
  6. **Spring Boot 应用程序提供嵌入式HTTP服务器，如Tomcat和Jetty，可以轻松地开发和测试web应用程序。**（这点很赞！普通运行Java程序的方式就能运行基于Spring Boot web 项目，省事很多）
  7. Spring Boot提供命令行接口(CLI)工具，用于开发和测试Spring Boot应用程序，如Java或Groovy。
  8. Spring Boot提供了多种插件，可以使用内置工具(如Maven和Gradle)开发和测试Spring Boot应用程序。

  **什么是 Spring Boot Starters?**

  Spring Boot Starters 是一系列依赖关系的集合，因为它的存在，项目的依赖之间的关系对我们来说变的更加简单了。举个例子：在没有Spring Boot Starters之前，我们开发REST服务或Web应用程序时; 我们需要使用像Spring MVC，Tomcat和Jackson这样的库，这些依赖我们需要手动一个一个添加。但是，有了 Spring Boot Starters 我们只需要一个只需添加一个spring-boot-starter-web一个依赖就可以了，这个依赖包含的字依赖中包含了我们开发REST 服务需要的所有依赖。

  ```xml
  <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-web</artifactId>
  </dependency>
  ```

  **如何在Spring Boot应用程序中使用Jetty而不是Tomcat?**

  Spring Boot Web starter使用Tomcat作为默认的嵌入式servlet容器, 如果你想使用 Jetty 的话只需要修改pom.xml(Maven)或者build.gradle(Gradle)就可以了。

  **介绍一下@SpringBootApplication注解**

  大概可以把 `@SpringBootApplication `看作是 `@Configuration`、`@EnableAutoConfiguration`、`@ComponentScan ` 注解的集合。根据 SpringBoot官网，这三个注解的作用分别是：

  - `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制
  - `@ComponentScan`： **扫描被`@Component` (`@Service`,`@Controller`)注解的bean**，注解默认会扫描该类所在的包下所有的类。
  - `@Configuration`：允许在上下文中注册额外的bean或**导入其他配置类**

  **(重要)Spring Boot 的自动配置是如何实现的?**

  **这个是因为@SpringBootApplication 注解的原因。**

  **Spring Boot支持哪些嵌入式web容器？**

  Spring Boot支持以下嵌入式servlet容器:

  | **Name**     | **Servlet Version** |
  | ------------ | ------------------- |
  | Tomcat 9.0   | 4.0                 |
  | Jetty 9.4    | 3.1                 |
  | Undertow 2.0 | 4.0                 |

  您还可以将Spring引导应用程序部署到任何Servlet 3.1+兼容的 Web 容器中。

  这就是你为什么可以通过直接像运行 普通 Java 项目一样运行 SpringBoot 项目。这样的确省事了很多，方便了我们进行开发，降低了学习难度。

  **什么是Spring Security ?**

  Spring Security 应该属于 Spring 全家桶中学习曲线比较陡峭的几个模块之一，下面我将从起源和定义这两个方面来简单介绍一下它。

  - **起源：** Spring Security 实际上起源于 Acegi Security，这个框架能为基于 Spring 的企业应用提供强大而灵活安全访问控制解决方案，并且框架这个充分利用 Spring 的 IoC 和 AOP 功能，提供声明式安全访问控制的功能。后面，随着这个项目发展， Acegi Security 成为了Spring官方子项目，后来被命名为 “Spring Security”。
  - **定义：**Spring Security 是一个功能强大且高度可以定制的框架，侧重于为Java 应用程序提供身份验证和授权。——[官方介绍](https://spring.io/projects/spring-security)。

- SpringBoot 配置文件详解（告别XML）

  > [https://www.jianshu.com/p/60b34464ca58](https://www.jianshu.com/p/60b34464ca58)

  application.yml: 运行端口、数据库连接池、shiro（cookie记住登录信息时间、Session会话超时时间、无需认证(登录)可访问的请求资源路径）

#### SpringDataJPA

- JPA和MyBatis的区别

  > [https://blog.csdn.net/yunzhonmghe/article/details/78069449](https://blog.csdn.net/yunzhonmghe/article/details/78069449)

  **对于数据的操作，hibernate是面向对象的，而MyBatis是面向关系的。**

  > [https://blog.csdn.net/chehec2010/article/details/91195770](https://blog.csdn.net/chehec2010/article/details/91195770)

  Mybatis可以进行更细致的SQL优化,查询必要的字段,但是需要维护SQL和查询结果集的映射。数据库的移植性较差,针对不同的数据库编写不同的SQL。

  **Hibernate对数据库提供了较为完整的封装,封装了基本的DAO层操作,有较好的数据库移植性。**但是学习周期长，开发难度大于Mybatis。

  > [https://blog.csdn.net/u013905744/article/details/90812229](https://blog.csdn.net/u013905744/article/details/90812229)

  1. spring data jpa实现了jpa（java persistence api）功能，即可以实现pojo转换为关系型数据库记录的功能，通俗来讲就是可以不写任何的建表sql语句了。jpa是spring data jpa功能的一个子集。而mybatis并没有jpa功能，建表语句还是要自己写的。

  2. **spring data jpa是全自动框架，不需要写任何sql。**而mybatis是半自动框架，需要自己写sql，mybatis-plus为mybatis赋能，使其也可以基本上不需要写任何模板sql。

- MyBatis与Hibernate有哪些不同？

  > [https://mp.weixin.qq.com/s?__biz=MzI4Njc5NjM1NQ==&mid=2247483810&idx=2&sn=ecf3d5f70b2973a85b4bb3329a9c8524&chksm=ebd63e8edca1b798fa1be1cd673642855927c2313ea6a7a1a102d30f31ca106eb9765dfac7e1&scene=21#wechat_redirect](https://mp.weixin.qq.com/s?__biz=MzI4Njc5NjM1NQ==&mid=2247483810&idx=2&sn=ecf3d5f70b2973a85b4bb3329a9c8524&chksm=ebd63e8edca1b798fa1be1cd673642855927c2313ea6a7a1a102d30f31ca106eb9765dfac7e1&scene=21#wechat_redirect)

  1、Mybatis和hibernate不同，它不完全是一个ORM框架，因为MyBatis需要程序员自己编写Sql语句，不过mybatis可以通过XML或注解方式灵活配置要运行的sql语句，并将java对象和sql语句映射生成最终执行的sql，最后将sql执行的结果再映射生成java对象。  

  2、Mybatis学习门槛低，简单易学，**程序员直接编写原生态sql，可严格控制sql执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发**，例如互联网软件、企业运营类软件等，因为这类软件需求变化频繁，一但需求变化要求成果输出迅速。但是灵活的前提是mybatis无法做到数据库无关性，如果需要实现支持多种数据库的软件则需要自定义多套sql映射文件，工作量大。                
  
  3、**Hibernate对象/关系映射能力强，数据库无关性好**，**对于关系模型要求高的软件（例如需求固定的定制化软件）如果用hibernate开发可以节省很多代码，提高效率**。但是Hibernate的缺点是学习门槛高，要精通门槛更高，而且怎么设计O/R映射，在性能和对象模型之间如何权衡，以及怎样用好Hibernate需要具有很强的经验和能力才行。  

  总之，按照用户的需求在有限的资源环境下只要能做出维护性、扩展性良好的软件架构都是好架构，所以框架只有适合才是最好。

- 多表联查

  关系映射@OneToOne, @OneToMany, @ManyToOne

  > [https://blog.wuwii.com/jpa-query-muti.html](https://blog.wuwii.com/jpa-query-muti.html)

  > [https://blog.csdn.net/johnf_nash/article/details/80642581](https://blog.csdn.net/johnf_nash/article/details/80642581)

- Spring Boot JPA 基础：常见操作解析

  > [https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/springboot-jpa.md](https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/springboot-jpa.md)

  实体类：为这个类添加了 @Entity 注解代表它是数据库持久化类

  创建操作数据库的 Repository 接口：首先这个接口加了 @Repository 注解，代表它和数据库操作有关。另外，它继承了 JpaRepository<Person, Long>接口

- JPA 中非常重要的连表查询就是这么简单

  > [https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/springboot-jpa-lianbiao.md](https://github.com/Snailclimb/springboot-guide/blob/master/docs/basis/springboot-jpa-lianbiao.md)

  **连表查询**
  
  我们需要创建一个包含我们需要的 Person 信息的 DTO 对象,我们简单第将其命名为 UserDTO，用于保存和传输我们想要的信息。

  sql 语句和我们平时写的没啥区别，差别比较大的就是里面有一个 new 对象的操作。

  **分页操作**

  为了实现分页，我们在@Query注解中还添加了 countQuery 属性。

  传入Pageable pageable，返回Page<UserDTO>

#### Shiro

> [https://www.cnblogs.com/wmyskxz/p/10229148.html](https://www.cnblogs.com/wmyskxz/p/10229148.html)

> [https://blog.csdn.net/qq_26648623/article/details/84062666](https://blog.csdn.net/qq_26648623/article/details/84062666)

- 应用安全的四大基石

  认证：用户身份识别，通常被称为用户“登录”。

  授权：访问控制。比如某个用户是否具有某个操作的使用权限。

  会话管理：特定于用户的会话管理,甚至在非web 或 EJB 应用程序。

  加密：在对数据源使用加密算法加密的同时，保证易于使用。

- 三个主要的理念

  Subject：当前用户，Subject 可以是一个人，但也可以是第三方服务、守护进程帐户、时钟守护任务或者其它–当前和软件交互的任何事件。

  SecurityManager：管理所有Subject，SecurityManager 是 Shiro 架构的核心，配合内部安全组件共同组成安全伞。
  
  Realms：用于进行权限信息的验证，我们自己实现。Realm 本质上是一个特定的安全 DAO：它封装与数据源连接的细节，得到Shiro 所需的相关的数据。在配置 Shiro 的时候，你必须指定至少一个Realm 来实现认证（authentication）和/或授权（authorization）。

- Shiro 加密

  在之前的学习中，我们在数据库中保存的密码都是明文的，一旦数据库数据泄露，那就会造成不可估算的损失，所以我们通常都会使用非对称加密，简单理解也就是不可逆的加密，而 md5 加密算法就是符合这样的一种算法。

  如上面的 123456 用 Md5 加密后，得到的字符串：e10adc3949ba59abbe56e057f20f883e，就无法通过计算还原回 123456，我们把这个加密的字符串保存在数据库中，等下次用户登录时我们把密码通过同样的算法加密后再从数据库中取出这个字符串进行比较，就能够知道密码是否正确了，这样既保留了密码验证的功能又大大增加了安全性，但是问题是：虽然无法直接通过计算反推回密码，但是我们仍然可以通过计算一些简单的密码加密后的 Md5 值进行比较，推算出原来的密码

  比如我的密码是 123456，你的密码也是，通过 md5 加密之后的字符串一致，所以你也就能知道我的密码了，如果我们把常用的一些密码都做 md5 加密得到一本字典，那么就可以得到相当一部分的人密码，这也就相当于“破解”了一样，所以其实也没有我们想象中的那么“安全”。

  既然相同的密码 md5 一样，那么我们就让我们的原始密码再加一个随机数，然后再进行 md5 加密，这个随机数就是我们说的盐(salt)，这样处理下来就能得到不同的 Md5 值，当然我们需要把这个随机数盐也保存进数据库中，以便我们进行验证。

  另外我们可以通过多次加密的方法，即使黑客通过一定的技术手段拿到了我们的密码 md5 值，但它并不知道我们到底加密了多少次，所以这也使得破解工作变得艰难。

> [https://blog.csdn.net/romantic_PK/article/details/81510003](https://blog.csdn.net/romantic_PK/article/details/81510003)

- Shiro认证流程

  - **subject(主体)请求认证，调用subject.login(token)**
  - SecurityManager (安全管理器)执行认证
  - **SecurityManager通过ModularRealmAuthenticator进行认证。**
  - **ModularRealmAuthenticator将token传给realm，realm根据token中用户信息从数据库查询用户信息（包括身份和凭证）**
  - realm如果查询不到用户给ModularRealmAuthenticator返回null，ModularRealmAuthenticator抛出异常（用户不存在）
  - **realm如果查询到用户给ModularRealmAuthenticator返回AuthenticationInfo(认证信息)**
  - **ModularRealmAuthenticator拿着AuthenticationInfo(认证信息)去进行凭证（密码）比对。**如果一致则认证通过，如果不致抛出异常（凭证错误）。

- Shiro授权流程

  - **对subject进行授权，调用方法isPermitted("*")或者hasRole("*")**
  - **SecurityManager执行授权，通过ModularRealmAuthorizer执行授权**
  - ModularRealmAuthorizer执行realm（自定义的CustomRealm）从数据库查询权限数据调用realm的授权方法：doGetAuthorizationInfo
  - **realm从数据库查询权限数据，返回ModularRealmAuthorizer**
  - **ModularRealmAuthorizer调用PermissionResolver进行权限串比对**
  - 如果比对后，isPermitted中"permission串"在realm查询到权限数据中，说明用户访问permission串有权限，否则没有权限，抛出异常。

> 慕课网

  **什么是Shiro？**

  - Apache的强大灵活的开源安全框架
  - 认证、授权、企业会话管理、缓存管理、安全加密

  **Shiro与Spring Security比较**

  - Apache Shiro：简单、灵活，可脱离Spring，粒度较粗
  - Spring Security：复杂、笨重，不可脱离Spring，粒度更细

  **Shiro整体架构**

  - SecurityManager是Shiro的核心，Shiro通过Security Manager提供安全服务。
  - 认证器(Authenticator)管理登入登出，授权器(Authorizer)赋予主体有哪些权限。Realm是Shiro和数据库之间的桥梁，Shiro获取认证数据、权限数据都是通过Realm。主体提交请求到Security Manager，SecurityManager调用认证器去认证，认证器获取认证数据的时候是通过Realm来获取，从数据库中来获取信息和主题提交过来的认证数据去比对。
  - session管理器，shiro自己实现了一套session管理机制，可以不借助任何web容器的情况下使用session。Session Dao提供了Session的操作，主要是由增删改查。
  - Cache Manager是缓存管理器，可以缓存角色数据和权限数据。
  - Cryptography是用来做数据加密的。

#### Maven

  > [https://blog.csdn.net/weixin_37766296/article/details/79594837](https://blog.csdn.net/weixin_37766296/article/details/79594837)

  **优点**

  1. Maven是一个项目管理和综合工具。Maven提供了开发人员构建一个完整的生命周期框架。
  2. 在多个开发团队环境时，Maven可以设置按标准在非常短的时间里完成配置工作，使开发人员的工作更加轻松。
  3. Maven增加可重用性并负责建立相关的任务。

  > [https://www.cnblogs.com/sgh1023/p/10900130.html](https://www.cnblogs.com/sgh1023/p/10900130.html)

  **Maven常用命令**

  clean：删除项目中已经编译好的信息，删除target目录

  compile：Maven工程的编译命令，用于编译项目的源代码，将src/main/java下的文件编译成class文件输出到target目录下。

  test：使用合适的单元测试框架运行测试。

  package：将编译好的代码打包成可分发的格式，如JAR，WAR。

  install：安装包至本地仓库，以备本地的其它项目作为依赖使用。

  deploy：复制最终的包至远程仓库，共享给其它开发人员和项目（通常和一次正式的发布相关）。

  每一个构建项目的命令都对应了maven底层一个插件。

  **Maven命令package、install、deploy的联系与区别**

  mvn clean package依次执行了clean、resources、compile、testResources、testCompile、test、jar(打包)等7个阶段。

  mvn clean install依次执行了clean、resources、compile、testResources、testCompile、test、jar(打包)、install等8个阶段。

  mvn clean deploy依次执行了clean、resources、compile、testResources、testCompile、test、jar(打包)、install、deploy等9个阶段。

  主要区别：

  package命令完成了项目编译、单元测试、打包功能，但没有把打好的可执行jar包（war包或其它形式的包）布署到本地maven仓库和远程maven私服仓库。

  install命令完成了项目编译、单元测试、打包功能，同时把打好的可执行jar包（war包或其它形式的包）布署到本地maven仓库，但没有布署到远程maven私服仓库。

  deploy命令完成了项目编译、单元测试、打包功能，同时把打好的可执行jar包（war包或其它形式的包）布署到本地maven仓库和远程maven私服仓库。　

  **Maven生命周期**

  清理生命周期：运行mvn clean将调用清理生命周期 。

  默认生命周期：是一个软件应用程序构建过程的总体模型 。

  compile，test，package，install，deploy

  站点生命周期：为一个或者一组项目生成项目文档和报告，使用较少。

  > [https://blog.csdn.net/noaman_wgs/article/details/81137893](https://blog.csdn.net/noaman_wgs/article/details/81137893)

  Maven中 jar包冲突原理与解决办法

  > [https://github.com/Tiakon/maven-learning-notes](https://github.com/Tiakon/maven-learning-notes)

  慕课网Maven学习笔记

  **maven生命周期**

  完整的项目构建过程包括： 清理、编译、测试、打包、集成测试、验证、部署

  maven三套独立的生命周期

    clean 	清理项目
        1.pre-clean	执行清理前的工作
        2.clean		清理上一次构建生成的所有文件
        3.post-clean 	执行清理后的文件

    default 构建项目（最核心）
        compile test package install

    site 	生成项目站点
        1. pre-site 	在生成项目站点前要完成的工作
        2. site 	生成项目的站点文档
        3. post-site	在生成项目站点后要完成的工作
        4. site-deploy	发布生成的站点到服务器上

  **maven提供了6种可选依赖范围:**

  1. compile:	默认范围，编译测试运行都有效。
  2. provided:	在编译和测试时有效。（比如说在做 web 时，你在本地运行的 servlet ，
  是需要调用已添加到项目中的 servlet-api.jar 这个 jar 包的。这个过程就包含了编译【就是
  把 Java 文件编译成 class 文件的过程中也要调用】和测试【测试就是在本地运行】，那么他说
  的运行是指，整个项目已开发完成，编译、测试通过后，将 class 文件或包含有 class 文件的 war 包
  发布到服务器上的 Tomcat 中运行，这时启动项目，就可以直接调 Tomcat 中的 servlet-api.jar ，
  不必再将自己的 jar 包添加到项目中去。也就是说当你选择 provided 时，项目发布时 Maven 不会将
  你添加的 jar 包，加入到项目中。）
  3. runtime:	在测试和运行时有效。(典型例子：JDBC驱动的实现。)
  4. test:	只在测试是有效。
  5. system:	类似 provided，与本机系统相关联，可移植性差。
  6. import:	导入范围，他只是用在 dependencyManagement 中，表示从其他的 pom 中导
  入dependecy的配置。（以下引用官网案例并不难理解。）

  **依赖冲突**

  1.短路优先:

    C->B->A->X1(jar)
    C->B->X2(jar)

  【C依赖B,B依赖A,A和B都包含同一个不同版本的Jar,则取B的依赖版本。（c的pom.xml中不必注明jar坐标）】

  2.先声明先优先

    如果路径相同长度相同，则谁先声明，先解析谁。

  【C依赖A和B,A和B都包含同一个不同版本的Jar,谁依赖在前取谁的依赖版本。】

#### Tomcat & Servlet

  > [https://blog.csdn.net/qq_22638399/article/details/81506448](https://blog.csdn.net/qq_22638399/article/details/81506448)

  spring boot 项目部署到服务器 两种方式

  > [https://zhuanlan.zhihu.com/p/33612564](https://zhuanlan.zhihu.com/p/33612564)

  Tomcat+Servlet面试题

  Servlet生命周期可分为5个步骤

  - 加载Servlet。当Tomcat第一次访问Servlet的时候，Tomcat会负责创建Servlet的实例
  - 初始化。当Servlet被实例化后，Tomcat会调用init()方法初始化这个对象
  - 处理服务。当浏览器访问Servlet的时候，Servlet 会调用service()方法处理请求
  - 销毁。当Tomcat关闭时或者检测到Servlet要从Tomcat删除的时候会自动调用destroy()方法，让该实例释放掉所占的资源。一个Servlet如果长时间不被使用的话，也会被Tomcat自动销毁
  - 卸载。当Servlet调用完destroy()方法后，等待垃圾回收。如果有需要再次使用这个Servlet，会重新调用init()方法进行初始化操作。

  > [https://www.zhihu.com/question/32212996](https://www.zhihu.com/question/32212996)

  tomcat 与 nginx，apache的区别是什么？

#### ElasticSearch & Solr

  - 常见问题

    - lucena引擎，一次查询的过程
    - 近实时刷新的原理
    - 分页怎么使用的，各个查询的原理，为什么有不同
  
  - 目录

    - ES和MySQL的区别
    - ES的原理，lucene原理
    - 分布式架构的原理
    - 写入（近实时刷新）、查询、搜索的过程（搜索类型和原理）
    - 如何优化提高搜索性能

  - ES和MySQL的区别

    1. 一个ES集群可以包含多个**索引（数据库）**，每个索引又包含了很多**类型（表）**，类型中包含了很多**文档（行）**，每个文档使用 JSON 格式存储数据，包含了很多**字段（列）**。

    2. ES**分布式搜索（一个索引包含多个分片，分片包括主分片和副本分片；选举master结点）**，传统数据库遍历式搜索

    3. ES采用**倒排索引（单词到文档）**，传统数据库采用B+树索引

    4. ES**没有用户验证和权限控制**

    5. ES**没有事务**的概念，不支持回滚，误删不能恢复
  
  - elasticsearch的倒排索引是什么

    传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。有了倒排索引，就能实现o（1）时间复杂度 的效率检索文章了，极大的提高了检索效率。

    倒排索引的底层实现是基于：**FST（Finite State Transducer）数据结构**。lucene从4+版本后开始大量使用的数据结构是FST。FST有两个优点：

    1）**空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；**

    2）**查询速度快。O(len(str))的查询时间复杂度。**

    > 列式存储DocValues：分组统计
  
  - elasticsearch是如何实现master选举的

    选举流程大致描述如下：

    第一步：确认候选主节点数达标，elasticsearch.yml设置的值discovery.zen.minimum_master_nodes；

    第二步：比较：先判定是否具备master资格，具备候选主节点资格的优先返回；若两节点都为候选主节点，则id小的值会主节点。注意这里的id为string类型。
  
  - Elasticsearch的分布式架构原理是什么?

    Elasticsearch是分布式的, 在多台机器上启动ES进程实例, 组成一个ES集群. **ES集群中的节点会选举出一个master节点来管理集群, 比如负责索引的创建与删除, 负责主分片与副本分片的身份切换等等.** ES集群的master节点选举算法如下:

    - 查找当前活跃的Master节点.
    - 如果存在活跃的Master节点, 选择其中nodeId最小的那个作为Master节点. (脑裂问题可能导致多个Master节点)
    - 如果不存在活跃的Master节点, 则获取集群中活跃的Master Eligible Nodes, 进行投票选举.
    - 如果集群中活跃的候选节点数超过一半(正常情况下候选节点数的一半), 则选择clusterStateVersion(集群状态版本)最新的那个作为Master节点. 如果clusterStateVersion相同, 则选择nodeId最小的那个作为Master节点.
    - 如果如果集群中活跃的候选节点数没有超过一半, 则无法选举.
    
    **ES存储数据的基本单位是索引, 每个索引都会被拆分为多个分片, 每个分片分布在不同节点上. 同时为了保证可用性, 每个分片都会设置副本, 主分片提供读写服务, 副本分片提供读服务.** 当主分片所在的节点宕机后, master节点会从副本分片中选出一个作为主分片, 然后当宕机的节点修复后, master节点会将缺失的副本分片分配过去, 同步数据后, 集群恢复正常.
  
  - 详细描述一下Elasticsearch索引文档的过程

    这里的索引文档应该理解为文档写入ES，创建索引的过程。
    
    第一步：客户写集群某节点写入数据，发送请求。（如果没有指定路由/协调节点，请求的节点扮演路由节点 的角色。）

    第二步：节点1接受到请求后，使用文档_id来确定文档属于分片0。请求会被转到另外的节点，假定节点3。因此分片0的主分片分配到节点3上。

    第三步：节点3在主分片上执行写操作，如果成功，则将请求并行转发到节点1和节点2的副本分片上，等待结果返回。所有的副本分片都报告成功，节点3将向协调节点（节点1）报告成功，节点1向请求客户端报告写入成功。

    如果面试官再问：第二步中的文档获取分片的过程？回答：借助路由算法获取，路由算法就是根据路由和文档id计算目标的分片id的过程。

    `1shard = hash(_routing) % (num_of_primary_shards)`
  
  - 详细描述一下Elasticsearch搜索的过程？

    **搜索拆解为“query then fetch” 两个阶段。query阶段的目的：定位到位置，但不取。**步骤拆解如下：

    1）假设一个索引数据有5主+1副本 共10分片，一次请求会命中（主或者副本分片中）的一个。

    2）每个分片在本地进行查询，结果返回到本地有序的优先队列中。

    3）第2）步骤的结果发送到协调节点，协调节点产生一个全局的排序列表。

    **fetch阶段的目的：取数据。路由节点获取所有文档，返回给客户端。**

  - Elasticsearch写入数据的工作原理, 查询数据的工作原理, 搜索数据的工作原理分别是什么?

    **Elasticsearch写入数据的工作原理**

    - **客户端发送请求到任意一个协调节点(Coordinating Node), 然后协调节点将请求转发给master节点.**
    - **master节点对document进行路由, 将document写入主分片.**
    - **document写入主分片后, 将数据同步到副本分片.**
    - 主分片和副本分片都写入成功后, 返回响应结果给客户端.
    
    (1) document写入主分片的详细过程

    - **Document写入Index Buffer(ES进程缓冲), 同时将写命令记录到Transaction Log.**
    - **每隔1秒或Index Buffer空间被占满后, Index Buffer中的数据被写入新的Segment中, 并进入OS Cache, 这个过程叫Refresh.** (此时倒排索引已创建, 存在OS Cache中, 数据可被搜索)
    - 重复前面两个步骤.
    - 每隔30分钟或Transaction Log占满后, 先进行Refresh操作, 然后将OS Cache中的Segment刷入磁盘, 这个过程叫Flush.
    - 删除旧Transaction Log, 创建一个新的Transaction Log.
    - ES定期合并磁盘中的Segment File, 同时清除那些被标记为delete的文档.
    
    (2) **ES被称为近实时(Near Realtime)的原因**

    **从上文"document写入主分片的详细过程"中可以知道, Refresh操作每秒执行一次, 只有执行Refresh操作之后, 倒排索引才会被创建, 数据才能被搜索, 这就是ES被称为近实时的原因.**

    (3) ES存在数据丢失的问题

    从上文"document写入主分片的详细过程"中可以知道, document写入Index Buffer的同时会将写命令记录到Transaction Log, 目的是如果数据落盘之前机器宕机了, 可以从Transaction Log中恢复数据. 但在旧版本中Transaction Log不是默认落盘的, 它会先写入OS Cache中, 每隔5s才会被刷入磁盘, 所以如果在Transaction Log落盘前机器宕机了, 数据就完全丢失了.

    在新版本7.x中, Transaction Log是默认落盘的, 也就不会有数据丢失的问题. (index.translog.durability, index.translog.sync_interval)

    **Elasticsearch查询数据的工作原理(Get查询)**

    - **客户端发送请求到任意一个协调节点(Coordinating Node).**
    - **协调节点根据id进行路由, 找到对应的分片.**
    - **根据round-robin随机轮询算法, 在主分片和其他副本分片中随机选择一个, 进行查询.**
    - 将对应的document返回给协调节点.
    - 协调节点返回document给客户端.
    
    **Elasticsearch搜索数据的工作原理**

    - **客户端发送请求到任意一个协调节点(Coordinating Node).**
    - **协调节点将搜索请求转发给所有分片(主分片和副本分片采用随机轮询算法选一个)**
    - **每个分片将自己的搜素结果(这里只有id)返回给协调节点**
    - **协调节点对搜索结果进行合并, 排序, 分页等操作, 得出最终结果.**
    - **协调节点根据最终结果的id去各个分片上拉取document, 返回给客户端.**
  
  - Elasticsearch之四种搜索类型和搜索原理

    **Elasticsearch在搜索过程中存在以下几个问题：**

    第一、 **数量问题**。 比如， 用户需要搜索"衣服"， 要求返回符合条件的前 10 条。 但在 5个分片中， 可能都存储着衣服相关的数据。 所以 ES 会向这 5 个分片都发出查询请求， 并且要求每个分片都返回符合条件的 10 条记录。当ES得到返回的结果后，进行整体排序，然后取最符合条件的前10条返给用户。 这种情况， ES 中 5 个 shard 最多会收到 10*5=50条记录， 这样返回给用户的结果数量会多于用户请求的数量。
    
    第二、 **排名问题**。 上面说的搜索， 每个分片计算符合条件的前 10 条数据都是基于自己分片的数据进行打分计算的。计算分值使用的词频和文档频率等信息都是基于自己分片的数据进行的， 而 ES 进行整体排名是基于每个分片计算后的分值进行排序的(相当于打分依据就不一样， 最终对这些数据统一排名的时候就不准确了)， 这就可能会导致排名不准确的问题。如果我们想更精确的控制排序， 应该先将计算排序和排名相关的信息（ 词频和文档频率等打分依据） 从 5 个分片收集上来， 进行统一计算， 然后使用整体的词频和文档频率为每个分片中的数据进行打分， 这样打分依据就一样了。

    **Elasticsearch的搜索类型（SearchType类型）**

    1、 query and fetch
    
    向索引的所有分片 （ shard）都发出查询请求， 各分片返回的时候把元素文档 （ document）和计算后的排名信息一起返回。
    
    这种搜索方式是最快的。 因为相比下面的几种搜索方式， 这种查询方法只需要去 shard查询一次。 但是各个 shard 返回的结果的数量之和可能是用户要求的 size 的 n 倍。
    
    优点：这种搜索方式是最快的。因为相比后面的几种es的搜索方式，这种查询方法只需要去shard查询一次。
    
    缺点：返回的数据量不准确， 可能返回(N*分片数量)的数据并且数据排名也不准确，同时各个shard返回的结果的数量之和可能是用户要求的size的n倍。

    2、 query then fetch（ es 默认的搜索方式）

    如果你搜索时， 没有指定搜索方式， 就是使用的这种搜索方式。 这种搜索方式， 大概分两个步骤：

    第一步， 先向所有的 shard 发出请求， 各分片只返回文档 id(注意， 不包括文档 document)和排名相关的信息(也就是文档对应的分值)， 
    然后按照各分片返回的文档的分数进行重新排序和排名， 取前 size 个文档。
　　
    第二步， 根据文档 id 去相关的 shard 取 document。 这种方式返回的 document 数量与用户要求的大小是相等的。
    
    优点：返回的数据量是准确的。
　　
    缺点：性能一般，并且数据排名不准确。

    3、 DFS query and fetch
　　
    这种方式比第一种方式多了一个 DFS 步骤，有这一步，可以更精确控制搜索打分和排名。也就是在进行查询之前， 先对所有分片发送请求， 把所有分片中的词频和文档频率等打分依据全部汇总到一块， 再执行后面的操作。

    优点：数据排名准确

    缺点：性能一般；返回的数据量不准确， 可能返回(N*分片数量)的数据

    4、 DFS query then fetch
　　
    比第 2 种方式多了一个 DFS 步骤。也就是在进行查询之前， 先对所有分片发送请求， 把所有分片中的词频和文档频率等打分依据全部汇总到一块， 再执行后面的操作。

　　优点：返回的数据量是准确的，数据排名准确

　　缺点：性能最差【 这个最差只是表示在这四种查询方式中性能最慢， 也不至于不能忍受，如果对查询性能要求不是非常高， 而对查询准确度要求比较高的时候可以考虑这个】

　　DFS 是一个什么样的过程？

　　从 es 的官方网站我们可以发现， DFS 其实就是在进行真正的查询之前， 先把各个分片的词频率和文档频率收集一下， 然后进行词搜索的时候， 各分片依据全局的词频率和文档频率进行搜索和排名。 显然如果使用 DFS_QUERY_THEN_FETCH 这种查询方式， 5效率是最低的，因为一个搜索， 可能要请求 3 次分片。 但， 使用 DFS 方法， 搜索精度是最高的。

  - Elasticsearch在数据量很大的情况下（数十亿级别）如何提高搜索性能?

    (1) 善于利用OS Cache

    如果Elasticsearch的每次搜索都要落盘, 那搜索性能肯定很差, 将达到秒级. 但**如果ES集群中的数据量等于OS Cache的容量, 那每次搜索都会直接走OS Cache, 这样性能就会很高, 达到毫秒级.**

    ES集群中的数据量最好不要超过OS Cache的容量, 最低要求也不能超过OS Cache的两倍. 比如我们ES集群有3台机器, 每台机器64G内存, 为每个节点的ES JVM Heap分配32G内存, 最终集群的OS Cache为 32G * 3 = 96G内存. 我们ES集群中的数据量最优情况是不超过96G, 最低要求的情况是不超过192G.

    (2) 数据建模

    从上文"善于利用OS Cache"中我们知道, 我们要保证ES集群中的数据量不超过OS Cache的容量, 那么我们在数据建模的时候就要注意两点:

    - **不要将MySQL表中的所有字段都写入ES, 只写入一部分会被搜索的字段.**
    - **对于MySQL中具有关联关系的表, 我们直接将关联字段写入ES中或在应用端处理关联关系, 禁止在ES中处理关联关系.**

    (3) 数据预热

    如果我们无法做到让ES集群中的数据量不超过OS Cache的容量, **那我们做一个缓存预热子系统, 定时搜索"热数据", 让其进入OS Cache.**

    (4) 冷热分离

    在数据预热的基础上我们还可以进行冷热数据分离, 比如我们有6台机器, 创建两个索引, 每个索引3个分片, **一个索引放热数据, 一个索引放冷数据**. 热数据量一般只占总数据量的10%, 这样我们就能保证热数据都在OS Cache中. 而冷数据虽然占总数据的90%, 但却只有10%的用户访问, 性能差点是可以接受的.

    (5) 分页性能优化

    **深度分页的性能是很差的, 我们要防止出现深度分页的情况, 用滚动翻页来代替深度分页.**

    - search after
    - scroll

  - ES分页

    Elasticsearch分页api有三种:

    - from/size（深度分页。当我们进行一个分页查询from=990, size=10时:首先在每个分片上先都获取 1000 个文档，通过 Coordinating Node 聚合所有结果，再通过排序选取前 1000 个文档。页数越深，占用内存就越多。）
    - search after（用来实时的获取下一页文档信息, 它不支持指定页数(from), 只能往下翻.）
    - scroll（用来处理大数据量的分页搜索, 不适用于实时的分页搜索. scroll分页搜索每次都会创建一个快照, 新数据写入只能影响到后续的分页搜索.）

  - Elasticsearch生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？

    (1) ES生产集群我们部署了5台机器, 每台机器是6核64G的, 集群总内存是320G.

    (2) 我们ES集群的日增量数据大概是2000万条, 500MB左右; 每月增量数据大概是6亿条, 15G左右. 目前系统已经运行了几个月, 现在ES集群里数据总量大概是100G左右.

    (3) 目前线上有5个索引（这个结合你们自己业务来, 看看自己有哪些数据可以放ES的）, 每个索引的数据量大概是20G, 所以这个数据量之内, 我们每个索引分配的是8个shard, 比默认的5个shard多了3个shard.

  > [https://www.cnblogs.com/jajian/p/9801154.html](https://www.cnblogs.com/jajian/p/9801154.html)
  
  全文搜索引擎的索引建立都是根据**倒排索引**的方式生成索引。

  > [https://blog.csdn.net/playgrrrrr/article/details/79008124](https://blog.csdn.net/playgrrrrr/article/details/79008124)

  ES和MySQL的区别

  > [https://juejin.im/entry/5c46d7c2e51d4551df6f2338](https://juejin.im/entry/5c46d7c2e51d4551df6f2338)

  ES面试题

  > [https://developer.51cto.com/art/201904/594615.htm](https://developer.51cto.com/art/201904/594615.htm)

  ES原理

  > [https://www.cnblogs.com/sessionbest/articles/8689030.html](https://www.cnblogs.com/sessionbest/articles/8689030.html)

  Lucene原理

  > [https://blog.csdn.net/litianxiang_kaola/article/details/104147340](https://blog.csdn.net/litianxiang_kaola/article/details/104147340)

  Elasticsearch面试必知必会

  > [https://blog.csdn.net/wangyunpeng0319/article/details/78218332](https://blog.csdn.net/wangyunpeng0319/article/details/78218332)

  Elasticsearch之四种查询类型和搜索原理

  > [https://blog.csdn.net/zkyfcx/article/details/79998197](https://blog.csdn.net/zkyfcx/article/details/79998197)

  ElasticSearch底层原理浅析

  > [https://blog.csdn.net/litianxiang_kaola/article/details/103808522](https://blog.csdn.net/litianxiang_kaola/article/details/103808522)

  ES分页

  > [https://blog.csdn.net/chen_2890/article/details/83895646](https://blog.csdn.net/chen_2890/article/details/83895646)

  SpringBoot整合Elasticsearch

#### 分词算法

> [https://zhuanlan.zhihu.com/p/33261835](https://zhuanlan.zhihu.com/p/33261835)

- 基于词表的分词方法
  - 正向最大匹配法(forward maximum matching method, FMM)
  - 逆向最大匹配法(backward maximum matching method, BMM)
  - N-最短路径方法
- 基于统计模型的分词方法
  - 基于N-gram语言模型的分词方法
- 基于序列标注的分词方法
  - 基于HMM的分词方法
  - 基于CRF的分词方法
  - 基于词感知机的分词方法
  - 基于深度学习的端到端的分词方法

#### 爬虫

- 防爬

  > [https://segmentfault.com/a/1190000005840672](https://segmentfault.com/a/1190000005840672)

  - 后台对访问进行统计，如果单个IP访问超过阈值，予以封锁。
  - 后台对访问进行统计，如果单个session访问超过阈值，予以封锁。
  - 后台对访问进行统计，如果单个userAgent访问超过阈值，予以封锁。
  - 用JavaScript混淆

  > [https://www.zhihu.com/question/26221432](https://www.zhihu.com/question/26221432)

  - 模拟浏览器提交。

    简单的，使用 webkit 来提交数据，这个基本可以过大多数浏览源检测的反爬系统了。
  
    但是有的反爬系统检测浏览源的时候，会根据大众浏览器的一些特性，比如 IE，Firefox，Chrome 等的私有 js 函数来判定浏览器，这样 webkit ，以及一些封装好的 无界面浏览器 也被当成爬虫了。当然，你也可以利用调用 chromuim 来爬取数据，但是这个资源开销就更大了。

  - 控制单 ip/账号 频率。

    挂私有代理来爬的就不说了，大家都会用，但是对于一般人来说，几万 ip 差不多是极限了，所以一个 ip 还是得多次请求，账号同理。而控制了爬取速度，则意味着爬完一圈需要更多时间。时间都是成本。

  - 控制爬取策略。

    如果简单的只对目标数据进行爬取，那么如果反爬系统对访问概况和用户行为进行分析，其实很简单就能判定爬虫的那堆 ip : 你除了这堆数据什么都没访问，一看就不是正常用户。
  
    当然策略这个东西，就需要更多的博弈了。爬虫要增加迷惑度，需要去访问一些无关的东西，最后是研究正常用户的访问流程，然后模拟一遍。再者，控制速度。毕竟反爬系统的统计区间是肯定有限制的，不可能拿一个月的数据都分析一遍找出爬虫。

#### 项目介绍

我负责智能执法平台里用户授权的工作，从用户查询到他所拥有的权限，开发接口管理用户角色、角色、权限的增删改查，和它们之间的多对多关系的增删改查。另外我还负责法规的检索和推荐的工作。

#### 项目的问题

解决检索项目在服务器不能正常运行的问题

(1) 页面的搜索结果不能正常显示，但是后台并没有报错。

(2) 直接运行flask项目中的入口python文件没有问题，用uwsgi将配置文件中的3行多线程相关的内容注释掉也可以正常运行。

(3) 定位发现是调用HanLP的函数过程中线程会卡住。原因是利用python的jpype调用Hanlp的java源代码时，不能为新开启的线程分配JVM。解决方法是在每个API的开头添加两行代码，判断并为线程分配JVM。

#### 后端新的技术、项目怎么优化

  **项目怎么优化**

  > [https://tieba.baidu.com/p/6239499571?red_tag=0442800574&traceid=](https://tieba.baidu.com/p/6239499571?red_tag=0442800574&traceid=)

  redis缓存，异步，接口调优，SQL调优，调用超时

  可以说一下分布式方面的改进吧，什么集群，数据库主从分离等等

  **Docker**

  > [https://zhuanlan.zhihu.com/p/62653543](https://zhuanlan.zhihu.com/p/62653543)
  
  > [https://zhuanlan.zhihu.com/p/62653543](https://zhuanlan.zhihu.com/p/62653543)

  > [https://www.cnblogs.com/linguoguo/p/10754756.html](https://www.cnblogs.com/linguoguo/p/10754756.html)

  **Java特性：G1垃圾收集器、Java8（Lambda表达式、方法引用）**

  **Redis**

  **大数据计算：Spark，大数据存储：Hive、HBase，消息队列Kafka**

  **微服务**

  > [https://www.zhihu.com/question/65502802](https://www.zhihu.com/question/65502802)

  完全拆分后各个服务可以采用异构的技术。比如数据分析服务可以使用数据仓库作为持久化层，以便于高效地做一些统计计算；商品服务和促销服务访问频率比较大，因此加入了缓存机制等。

  微服务架构还有一个技术外的好处，它使整个系统的分工更加明确，责任更加清晰，每个人专心负责为其他人提供更好的服务。

  微服务架构整个应用分散成多个服务，定位故障点非常困难。在微服务架构中，一个服务故障可能会产生雪崩效用，导致整个系统故障。

  **云计算**

  云计算是一种商业计算模型。它将计算任务分布在大量计算机构成的资源池上，使各种应用系统能够根据需要获取计算力、存储空间和信息服务。

  云计算的三种服务模式
  
  - SaaS(Software as a Service，软件即服务)
  - PaaS(Platform as a Service，平台即服务)
  - IaaS(Infrastructure as a Service，基础架构即服务)

  云计算的基础技术

  - 虚拟化技术：系统虚拟化的目的是通过使用虚拟化管理器（Virtual Machine Monitor，简称VMM）在一台物理机上虚拟和运行一台或多台虚拟机（Virtual Machine，简称VM）。
  - 容器技术：提供应用运行的环境支持；封装系统资源，提供应用SDK；对应用进行管理、统计

#### 反问

> [https://www.zhihu.com/question/19640623?isn=1](https://www.zhihu.com/question/19640623?isn=1)

- 您详细能告诉我我如果被录用了，我会负责一些工作么？
- 我会接受什么样的培训呢？
- 您觉得胜任这个职位的人什么品质最重要？
- 您觉得贵公司未来五年的发展方向是什么？
- 您能告诉我您为什么喜欢在这工作么？
- 您能形容一下这里的工作氛围么？
- 能告诉我现在公司/所处部门面临最大机遇(或挑战)是什么吗？
- 这个职位的发展路径一般是怎么样的呢？

## 面经

- 牛客

  > [https://www.nowcoder.com/discuss/356120](https://www.nowcoder.com/discuss/356120)
  
  **集合**

  - ArrayList与LinkedList的实现和区别
  - HashMap：了解其数据结构、hash冲突如何解决（链表和红黑树）、扩容时机、扩容时避免rehash的优化
  - LinkedHashMap：了解基本原理、哪两种有序、如何用它实现LRU
  - TreeMap：了解数据结构、了解其key对象为什么必须要实现Compare接口、如何用它实现一致性哈希

  常见问题

  - hashmap如何解决hash冲突，为什么hashmap中的链表需要转成红黑树？
  - hashmap什么时候会触发扩容？
  - **jdk1.8之前并发操作hashmap时为什么会有死循环的问题？**
  - **hashmap扩容时每个entry需要再计算一次hash吗？**
  - hashmap的数组长度为什么要保证是2的幂？
  - **如何用LinkedHashMap实现LRU？**
  - **如何用TreeMap实现一致性hash？**

  **线程安全的集合**
  
  - Collections.synchronized：了解其实现原理
  - CopyOnWriteArrayList：了解写时复制机制、了解其适用场景、思考为什么没有ConcurrentArrayList
  - ConcurrentHashMap：了解实现原理、扩容时做的优化、与HashTable对比。
  - BlockingQueue：了解LinkedBlockingQueue、ArrayBlockingQueue、DelayQueue、SynchronousQueue

  常见问题

  - ConcurrentHashMap是如何在保证并发安全的同时提高性能？
  - ConcurrentHashMap是如何让多线程同时参与扩容？
  - LinkedBlockingQueue、DelayQueue是如何实现的？
  - CopyOnWriteArrayList是如何保证线程安全的？

  **I/O**

  - 了解BIO和NIO的区别、了解多路复用机制

  常见问题

  - 同步阻塞、同步非阻塞、异步的区别？
  - **select、poll、eopll的区别？**
  - java NIO与BIO的区别？
  - reactor线程模型是什么?

  **并发**

  - synchronized：了解偏向锁、轻量级锁、重量级锁的概念以及升级机制、以及和ReentrantLock的区别
  - CAS：了解AtomicInteger实现原理、CAS适用场景、如何实现乐观锁
  - AQS：了解AQS内部实现、及依靠AQS的同步类比如ReentrantLock、Semaphore、CountDownLatch、CyclicBarrier等的实现
  - ThreadLocal：了解ThreadLocal使用场景和内部实现
  - ThreadPoolExecutor：了解线程池的工作原理以及几个重要参数的设置

  常见问题

  - synchronized与ReentrantLock的区别？
  - 乐观锁和悲观锁的区别？
  - 如何实现一个乐观锁？
  - AQS是如何唤醒下一个线程的？
  - ReentrantLock如何实现公平和非公平锁是如何实现？
  - CountDownLatch和CyclicBarrier的区别？各自适用于什么场景？
  - 适用ThreadLocal时要注意什么？比如说内存泄漏?
  - 说一说往线程池里提交一个任务会发生什么？
  - 线程池的几个参数如何设置？
  - 线程池的非核心线程什么时候会被释放？
  - 如何排查死锁？

  **JVM**
  
  - GC：垃圾回收基本原理、几种常见的垃圾回收器的特性、重点了解CMS（或G1）以及一些重要的参数
  - 内存区域：能说清jvm的内存划分

  常见问题

  - CMS GC回收分为哪几个阶段？分别做了什么事情？
  - CMS有哪些重要参数？
  - Concurrent Model Failure和ParNew promotion failed什么情况下会发生？
  - CMS的优缺点？
  - 有做过哪些GC调优？
  - 为什么要划分成年轻代和老年代？
  - 年轻代为什么被划分成eden、survivor区域？
  - 年轻代为什么采用的是复制算法？
  - 老年代为什么采用的是标记清除、标记整理算法
  - 什么情况下使用堆外内存？要注意些什么？
  - 堆外内存如何被回收？
  - jvm内存区域划分是怎样的？

  **Mysql**

  - 事务隔离级别、锁、索引的数据结构、聚簇索引和非聚簇索引、最左匹配原则、查询优化（explain等命令）

  常见问题

  - Mysql(innondb 下同) 有哪几种事务隔离级别？
  - 不同事务隔离级别分别会加哪些锁？
  - mysql的行锁、表锁、间隙锁、意向锁分别是做什么的？
  - 说说什么是最左匹配？
  - 如何优化慢查询？
  - mysql索引为什么用的是b+ tree而不是b tree、红黑树
  - 分库分表如何选择分表键
  - 分库分表的情况下，查询时一般是如何做排序的？

  **Redis（或其他缓存系统）**

  - redis工作模型、redis持久化、redis过期淘汰机制、redis分布式集群的常见形式、分布式锁、缓存击穿、缓存雪崩、缓存一致性问题

  常见问题

  - redis性能为什么高?
  - 单线程的redis如何利用多核cpu机器？
  - redis的缓存淘汰策略？
  - redis如何持久化数据？
  - redis有哪几种数据结构？
  - redis集群有哪几种形式？
  - 有海量key和value都比较小的数据，在redis中如何存储才更省内存？
  - 如何保证redis和DB中的数据一致性？
  - 如何解决缓存穿透和缓存雪崩？
  - 如何用redis实现分布式锁？

  **中间件、存储、以及其他框架**

  - Spring：bean的生命周期、循环依赖问题、spring cloud（如项目中有用过）、AOP的实现、spring事务传播
  
  - java动态***和cglib动态***的区别（经常结合spring一起问所以就放这里了）
  - spring中bean的生命周期是怎样的？
  - 属性注入和构造器注入哪种会有循环依赖的问题？

  > [https://www.nowcoder.com/discuss/368408?type=2&order=4&pos=5&page=1](https://www.nowcoder.com/discuss/368408?type=2&order=4&pos=5&page=1)

  **ZooKeeper**

  - CAP定理
  - ZAB协议
  - leader选举算法和流程
  
  **Redis**

  - Redis的应用场景
  - Redis支持的数据类型（必考）
  - zset跳表的数据结构（必考）
  - Redis的数据过期策略（必考）
  - Redis的LRU过期策略的具体实现
  - 如何解决Redis缓存雪崩，缓存穿透问题
  - Redis的持久化机制（必考）
  - Redis的管道pipeline

  **Mysql**

  - 事务的基本要素
  - 事务隔离级别（必考）
  - 如何解决事务的并发问题(脏读，幻读)（必考）
  - MVCC多版本并发控制（必考）
  - binlog,redolog,undolog都是什么，起什么作用
  - InnoDB的行锁/表锁
  - myisam和innodb的区别，什么时候选择myisam
  - 为什么选择B+树作为索引结构（必考）
  - 索引B+树的叶子节点都可以存哪些东西（必考）
  - 查询在什么时候不走（预期中的）索引（必考）
  - sql如何优化
  - explain是如何解析sql的
  - order by原理
  
  **JVM**

  - 运行时数据区域（内存模型）（必考）
  - 垃圾回收机制（必考）
  - 垃圾回收算法（必考）
  - Minor GC和Full GC触发条件
  - GC中Stop the world（STW）
  - 各垃圾回收器的特点及区别
  - 双亲委派模型
  - JDBC和双亲委派模型关系
  
  **Java基础**

  - HashMap和ConcurrentHashMap区别（必考）
  - ConcurrentHashMap的数据结构（必考）
  - 高并发HashMap的环是如何产生的
  - volatile作用（必考）
  - Atomic类如何保证原子性（CAS操作）（必考）
  - synchronized和Lock的区别（必考）
  - 为什么要使用线程池（必考）
  - 核心线程池ThreadPoolExecutor的参数（必考）
  - ThreadPoolExecutor的工作流程（必考）
  - 如何控制线程池线程的优先级
  - 线程之间如何通信
  - Boolean占几个字节
  - jdk1.8/jdk1.7都分别新增了哪些特性
  - Exception和Error
  
  **Spring**

  - Spring的IOC/AOP的实现（必考）
  - 动态代理的实现方式（必考）
  - Spring如何解决循环依赖（三级缓存）（必考）
  - Spring的后置处理器
  - Spring的@Transactional如何实现的（必考）
  - Spring的事务传播级别
  - BeanFactory和ApplicationContext的联系和区别
  
  **其他**

  - 高并发系统的限流如何实现
  - 高并发秒杀系统的设计
  - 负载均衡如何设计
  
  **补充**

  另外还会考一些计算机网络，操作系统啊之类的。像消息队列，RPC框架这种考的比较少。计算机网络就是分层啊，tcp/udp啊，三次握手之类的。操作系统就是进程与线程啊，进程的数据结构以及如何通信之类的。数据结构的排序算法也比较常考，考的话一定会让你手写个快排。剩下的算法题就靠LeetCode的积累了。其实非算法岗考的算法题都蛮简单的，很多题完全就是考察你智力是否正常，稍微难点的涉及到一些算法思想的按照LeetCode题目类型的分类，每种题做一两道基本就能完全应付面试了。
  
  > [https://www.nowcoder.com/discuss/342084?type=2&order=4&pos=2&page=1](https://www.nowcoder.com/discuss/342084?type=2&order=4&pos=2&page=1)

  - **重写equals()是否需要重写hashcode()，不重写会有什么后果**
  - 自旋锁和阻塞锁的区别
  - 公平锁和非公平锁的区别
  - jdk中哪种数据结构或工具可以实现当多个线程到达某个状态时执行一段代码
  - 栅栏和闭锁的区别
  - 如何使用信号量实现上述情况
  - 新生代和年老代的GC算法分别是什么
  - 标记清除和标记整理的区别
  - 了解过CMS收集器吗
  - 解释HTTPs，HTTPs为什么要用对称加密+非对称加密，相对于只使用非对称加密有什么好处
  - 给定一个表，其中有三列（员工名称，工资，部门号），找出每个部门工资最高的员工
  - LeetCode 863 二叉树中所有距离为K的结点
  - 用过哪些Java开源框架
  - 讲一讲对Spring的理解
  - 看过IOC和AOP的源码吗
  - 它们底层是如何实现的
  - 用过其他什么框架
  - 了解过分布式或者微服务的开源框架吗
  - 讲一讲对分布式系统模型的理解
  - 分布式系统中有一个节点宕机怎么办
  - 分布式系统如何实现负载均衡
  - MySQL和Oracle数据库有哪些不同
  - 数据库有哪些锁
  - 表锁和行锁的区别
  - 哪些场景需要加表锁
  - 插入一条数据需要加什么锁
  - 分布式数据库如何保证数据可靠性
  - 了解过MySQL的主从复制吗
  
  > [https://www.nowcoder.com/discuss/372983](https://www.nowcoder.com/discuss/372983)

  - 如何实现延时任务
  - 如何实现限流
  - 线程池的参数
  - epoll和poll的区别
  - 如何自己实现内存分配和管理？不太懂，然后说了jvm的垃圾回收机制
  - Redis的key过期策略
  - 缓存穿透和缓存雪崩
  - 分布式锁
  - 如何实现全局的id生成策略
  - 悲观锁和乐观锁
  - 写个producer-consumer
  - 两线程交替打印
  - 线程模拟100分钱随机分给20个人，每个人最少分配到2分钱
  - MVCC
  - HTTPS
  - ElasticSearch的查询过程
  - Kafka如何保证高可用
  - Reids的集群和选主
  - 分布式一致性算法
  - 如何实现定时关单

  > [https://www.nowcoder.com/discuss/382503](https://www.nowcoder.com/discuss/382503)

  - 数据库的三大范式和约束类型
  - 线程生命周期

  > [https://www.nowcoder.com/discuss/382603](https://www.nowcoder.com/discuss/382603)

  - 知道MySQL插入和查询分别用的是什么锁吗？
  - 引用计数法与GC Root可达性分析法区别
  - CAS机制会出现什么问题
  - RabbitMQ了解吗？丢失消息，重复消费问题怎么处理？

  > [https://www.nowcoder.com/discuss/382329](https://www.nowcoder.com/discuss/382329)

  - 如何衡量一个哈希算法的好坏
  - 哈希解决冲突的4种方法
  - cookie和session的生命周期
  - 集群中的session会遇到什么问题，有什么解决方案呢
  - 常量过多会导致什么问题
  - JDK8用了哪种回收器，内存空间管理和以前相比有哪些提升（Parallel Scavenge + Parallel Old）
  - 构造函数的加载顺序，多个构造函数先加载哪一个
  - group by中使用的having是用来干啥的
  - 服务治理介绍一下
  - 远程调用需要从注册中心代理吗
  - 如果注册中心代理的话并发量太大不会承受不了，怎么解决

  > [https://www.nowcoder.com/discuss/382110](https://www.nowcoder.com/discuss/382110)

  - bio. nio
  - linux五种io模型
  - poll 和 epoll 的区别
  - synchronized底层原理
  - AQS
  - 聚簇索引非聚簇索引
  - timewait和closewait状态含义

  > [https://www.nowcoder.com/discuss/381858](https://www.nowcoder.com/discuss/381858)

  - synchronized用在静态和非静态方法的区别

  > [https://www.nowcoder.com/discuss/381849](https://www.nowcoder.com/discuss/381849)

  - jre和jdk的区别
  - 如何理解僵尸进程，如何解决僵尸进程

  > [https://www.nowcoder.com/discuss/381726](https://www.nowcoder.com/discuss/381726)

  - 结合数据库三大范式聊聊，项目的表设计
  - redis为什么快？在多核cpu下redis单线程浪费？
  - redis击穿
  - redis与mysql数据同步
  - redis集群
  - redis分布式锁的实现(https://www.cnblogs.com/williamjie/p/9395659.html)
  - 海量数据，找重复数量前几的数据
  - 写个死锁
  - 处理日志，获取error的日志，去重，排序（本意是让用shell写的，但我不会，就用Java写了）
  - 写个LRU
  - 泛型、通配符区别
  - 红黑树为什么插入效率高
  - MySQL执行SQL的流程
  - 选择排序原理，时间、空间复杂度
  - 访问量太大redis支撑不住怎么办
  - 爬虫用的是什么？有用框架吗？有用多线程爬虫吗？
  - 用过哪些SpringCloud组件
  - redis数据结构
  - redis zset set区别
  - redis在增删改查时为什么单线程 还那么快？io模型？
  - MYSQL日志种类 undolog redolog分别是做什么的？(https://www.jianshu.com/p/57c510f4ec28)
  - MYSQL如何实现MVCC(https://blog.csdn.net/nmjhehe/article/details/98470570)
  - MYSQL优化，Explain 有哪些信息

  > [https://www.nowcoder.com/discuss/380853](https://www.nowcoder.com/discuss/380853)

  - 线程安全的单例模式
  - 类加载时机
  - 虚拟内存，内存爆了怎么办
  - https能讲一下吗(https://www.jianshu.com/p/14cd2c9d2cd2)
  - 数据库聚集索引和非聚集索引能讲一下吗
  - read commited隔离级别解决什么问题，通过什么实现(https://blog.csdn.net/fxkcsdn/article/details/82694357)
  - 数据库行锁是互斥锁还是其他还是什么类型的锁呢，读操作会阻塞吗(https://blog.csdn.net/arkblue/article/details/53895150)

  > [https://www.nowcoder.com/discuss/164967](https://www.nowcoder.com/discuss/164967)

  - 如何判断一颗二叉树是另一颗二叉树的子树
  - tcp如果在发送数据的时候服务器宕机了会怎么样，服务器又好了又会怎么样呢
  - 用过缓存，Redis吗，用过分布式吗，比如kafka或者dubbo

  > [https://www.nowcoder.com/discuss/219099](https://www.nowcoder.com/discuss/219099)

  - 大量用户产生很多消息，消息队列怎么处理
  - 消费者消费不完怎么处理

  > [https://www.nowcoder.com/discuss/362693](https://www.nowcoder.com/discuss/362693)

  - 线程池（具体参数，拒绝策略，减少线程的机制，具体实现类及对应的阻塞队列，阻塞队列有什么特点，为什么用这个阻塞队列，线程复用的原理）(https://blog.csdn.net/testcs_dn/article/details/78083966)
  - JVM（对象是否可回收的判断条件，怎么判断，回收算法，垃圾回收器的类别及特点，担保机制）
  - JAVA内存模型
  - 线程之间的通信方式，通过volatile，synchronized，Lock的实现类那些，结合内存模型去讲。
  - MyBatis、spring、springboot相关（面试题较常见）
  - Linux常用命令
  - redis的数据结构那些，讲了skiplist、ziplist、sds等，结合使用场景说了下(https://blog.csdn.net/chenssy/article/details/89599232)

  > [https://www.nowcoder.com/discuss/370072](https://www.nowcoder.com/discuss/370072)

  - transient关键字的作用
  - synchronized关键字加的地方，有什么区别，底层实现
  - 算法：两个数值原地交换值，不能使用第三个变量(https://blog.csdn.net/qq_39411607/article/details/80989996)

  > [https://www.nowcoder.com/discuss/198399](https://www.nowcoder.com/discuss/198399)

  - 事务传播
  - 变量的初始化顺序(https://www.zhihu.com/question/49196023)

  > [https://www.nowcoder.com/discuss/370435](https://www.nowcoder.com/discuss/370435)

  - 写题：由于记账错误，给定的一个正整数序列里面，有两个数字重复了，同时缺少了一个数字。 要求写一个函数，找出序列中重复的数字和缺少的数字。（set、异或） 例如： 输入：[1, 5, 2, 2, 3] 输出：[2, 4] 附加： 如果题目为缺少x个数字，并且输入序列可能有不匹配的重复和缺少项

  - 进程线程协程(https://blog.csdn.net/fadbgfnbxb/article/details/88787361)

  > [https://www.nowcoder.com/discuss/192690](https://www.nowcoder.com/discuss/192690)

  - 逻辑题，25匹赛马🐎，5条赛道，求前三快的马(https://www.nowcoder.com/questionTerminal/e07d8e0df93b4f6b93a3fadbe72f2c7c)

  > [https://www.nowcoder.com/discuss/98120](https://www.nowcoder.com/discuss/98120)

  - 了解过其他AOP包：ASPECTJ么
  - start之后线程就会马上调用吗
  - 了解过乐观锁和悲观锁么，如何自己实现一个乐观锁 
  - hashMap高并发下的缺陷？链表为什么会成环？(https://blog.csdn.net/wthfeng/article/details/88972137)
  - 类隔离
  - 包冲突
  - 有了解过RPC么
  - 了解过一致性Hash么？
  - Java1.8做了什么优化，新特性

  > [https://www.nowcoder.com/discuss/238370](https://www.nowcoder.com/discuss/238370)

  - 反射的作用，反射相关的类(https://snailclimb.gitee.io/javaguide/#/docs/java/basic/reflection)
  - 假设一个场景，支付系统和订单系统，支付失败后订单系统怎么知道失败（感觉是分布式事务的一致性，我开始问他是两个系统吗？是分布式吗？他也不回答我，后面复述一遍问题我又问了一遍分布式事务的一致性，他才说是的）(https://www.cnblogs.com/luxiaoxun/p/8832915.html)

  > [https://www.nowcoder.com/discuss/258249](https://www.nowcoder.com/discuss/258249)

  - 反射的原理及应用
  - spring四种事务的实现方式(https://blog.csdn.net/chinacr07/article/details/78817449)
  - cap和base
  - 问了几个设计模式 工厂 策略 *** 观察者 适配器 桥接等，jdk里面用到了哪些说说
  - 分布式秒杀如果不用mq怎么做？我说直接去掉mq用异步➕分布式事务，大佬说不好，还有吗？
  - 统计用户url访问次数，我说用拦截器存redis，大佬问java有没有提供这种系统或者工具直接用？我说令牌桶也行，大佬没说话

  > [https://www.nowcoder.com/discuss/89956](https://www.nowcoder.com/discuss/89956)

  - 字符串连接的几种方法和区别(https://www.cnblogs.com/lujiahua/p/11408689.html)
  - 自己实现线程池如何实现
  - 如何防止重复买
  - String类为什么要设计为final(https://www.zhihu.com/question/31345592)
  
  > [https://www.nowcoder.com/discuss/381334](https://www.nowcoder.com/discuss/381334)

  - JDBC
  - synchronized和lock底层实现，区别

  > [https://www.nowcoder.com/discuss/87868](https://www.nowcoder.com/discuss/87868)

  - Java的线程池说一下，各个参数的作用，如何进行的。
  - Redis讲一下
  - 分布式系统的全局id如何实现。用zookeeper如何实现的呢，机器号+时间戳即可。
  - 分布式锁的方案，redis和zookeeper那个好，如果是集群部署，高并发情况下哪个性能更好。
  - kafka了解么，了解哪些消息队列。
  - 反射的作用是什么
  - 了解哪些中间件，dubbo，rocketmq，mycat等。
  - dubbo中的rpc如何实现。
  - 自己实现rpc应该怎么做
  - dubbo的服务注册与发现。

  > [https://www.nowcoder.com/discuss/244392](https://www.nowcoder.com/discuss/244392)

  - Mybatis是如何做到动态sql解析
  - Mybatis是如何实现xml文件与实体类的映射
  - java中反射获取到的属性和方法是存储在什么地方(字节码、方法区)
  - 反射如何获取方法上的注解(https://www.cnblogs.com/a591378955/p/8350499.html)
  - 注解和接口的区别(https://www.cnblogs.com/linshenghui/p/11213867.html)
  - Redis中的命令(https://www.runoob.com/redis/redis-keys.html)(https://www.php.cn/faq/417108.html)

  > [https://bbs.byr.cn/#!article/ParttimeJob/856659](https://bbs.byr.cn/#!article/ParttimeJob/856659)

  > JAVA研发工程师

  - 希望你是2021年应届毕业生（校招）
  - 扎实的java编程基础（java语法原理，java容器原理，jvm原理（jvm调优加分），java并发（越深越好）），熟悉java开发体系，如果能有一定的项目开发经验那就更好了。
  - 表达问题思路清晰，良好的沟通能力与技术学习能力 （后面项我列举了最好了解一下的知识）
  - 有过用mysql等数据库使用经验
  - 了解http，操作系统，计网等基础知识(我另一篇推荐知识的博客有这些，大概简单的勉强够用)
  - 了解一些简单的设计模式（常见的那些最好看过一些源码，实现过一些，项目中用到过并有自己的理解）
  - 了解SSM，SpringBoot 等框架加分（建议初学以spring，spring boot，mybatis框架开始，这是现在很多公司的主流架构）
  - 了解WEB开发相关技术，如HTML，CSS，JavaScript，ajax 等加分（优先度不高，安心安心）
  - 了解分布式架构加分（缓存建议学一下redis，消息队列可以学一下kafka，rocketmq，分布式事务了解一些，分布式锁可以学一下zookeeper，rpc可以看dubbo）
  - 了解高可用架构加分(比如看看Hystrix，优先级不高~ )
  - 了解微服务加分（公司项目现在设计的很轻量级，一般都是微服务架构的，了解一下有好处，这是未来所有公司架构的升级方向）

  - 热点数据请求太多，redis负载均衡全都hash到一个节点上，如何处理(https://www.cnblogs.com/rjzheng/p/10874537.html)

  > [https://www.nowcoder.com/discuss/181259](https://www.nowcoder.com/discuss/181259)

  学习历程

  18/10月: 那时候学长发布了一些日常实习的内容，这时候我才发现自己什么都不会。开始慢慢准备找实习的事。我当时很纠结，不知道自己应该从事什么样的方向。学校实验室的项目是C++，但是最后还是放弃了，因为我发现岗位太少了。于是转而走向了Java后台的路线，当时我只有一点点语法的基础。

  18/11月：开始补Java语法的基础，说实话我没有去啃《Think in Java》这类厚的书，我看的第一本是《Effective Java》,不出意料，看的第一遍并不懂，不过几个月后再看一遍是真的收获很大。学校网络原理开的晚，我便把网络原理自学了一下，看了《自顶向下》这本书，把最常考的应用层、传输层、网络层看了一遍。

  18/12月：我开始发觉缺少实践了，于是开始走了Web后台的方向，当然也走了不少弯路。建议路线是servlet规范了解后，直接上Spring Boot，然后慢慢了解Spring MVC的原理，IOC/AOP的原理，以及掌握一门ORM框架。也开始看Java的并发，《艺术》看了两遍，《实战》看了一半。《Java虚拟机》看了一遍。

  19/1月：我开始系统地学习MySQL与Redis，《MySQL技术内幕》和《高性能MySQL》各看了一小部门。重点看事务、InnoDB存储引擎、索引、热备、主从以及分片。Redis建议实践最重要，做分布式锁、做缓存，自己要试着去敲代码，然后慢慢就熟练了。当时《Redis设计与实现》也看了四分之三。然后也开始复习了HTTP的内容，《图解HTTP》看了一遍。

  19/2月：我开始跟着视频做项目。自己改编了，换了技术栈做了原创的web项目。项目需要有亮点才能打动面试官，我推荐把《大型网站技术架构》看一遍，这本书很好，一点都不难懂，就像看小说一样。将里面的部分内容复现一遍，你的项目也有闪光点了。买了极客时间的虚拟机课，看了一部分，补充下JVM的知识。

  19/3月：我开始细读源码，Java的容器、JUC的部分源码、Spring的部分实现，看别人的博客对照着读会收获很多。这时候也开始陆陆续续面试了，最重要的就是复盘，了解自己的不足，并且弥补。之前准备的过程中也再陆陆续续写博客。到3月底时，一共写了51篇。操作系统、分布式等知识我有一直对照着CyC大佬的Github以及其他大佬的博客看，收获很大。

## 面试

- 阿里

  - 红黑树
  - ARP协议
  - java如何实现多态：虚函数子类重写，然后让父类对象指针指向子类，这是调用虚函数
  - leetcode751：给你一个cidr网络段，算出所有合理的ip，比如1.2.3.4/24，输出1.2.3.1~1.2.3.254
  - leetcode 1143：求两个字符串的最长公共子串
  - 如何解决hashmap线程不安全，concurrenthashmap的原理，扩容为什么是2的幂
  - SpringBoot实现的原理、AOP的原理、注解的原理（xml配置加注入）
  - 线程池
  - 最大的优点，AOP的原理
  - java1.8类加载是在哪里发生的（方法区移到元空间，在直接内存里）

  - 项目：增量添加（时间戳），查询依赖字段，实习中的难点、负责的工作
  - like能否使用索引
  - CPU过高怎么应对
  - 三次握手，为什么要有第三次
  - 往一个网页输入URL发生了什么
  - 用过的linux命令
  - docker对项目的部署

  - 项目介绍
  - SpringBoot和Spring的区别
  - AOP原理
  - MySQL如何导入Solr及如何增量导入
  - Bean的生命周期
  - hashMap扩容
  - JVM的结构、收集算法、G1和CMS的不同（stop the world发生时间）
  - session和cookie介绍
  - mysql acid和事务隔离级别
  - mysql索引的数据结构及介绍（b+树）
  - 两个队列实现一个栈
  - 依赖注入的方式
  - A依赖于B，B依赖于A，spring如何解决
  - 多个服务器的情况，session会不会串（我回答nginx，他说可以解决，答案是redis?）

  - 自我介绍，主要说项目
  - 围绕项目，挑一个说了项目的架构，为什么用SpringCloud，和dubbo对比
  - 微服务时怎么拆分的，微服务和传统单体式相比的优缺点
  - 项目中的难点
  - 五层网络模型说一下，HTTP属于哪一层，下面又用到那些层
  - TCP协议的特点说一说
  - 拥塞避免算法说一说
  - HTTP2.0了解吗
  - HTTPS的过程说一说
  - 非对称加密算法了解吗
  - 从输入URL到得到响应，中间的过程说一说
  - 操作系统进程、线程、协程说一说
  - 进程之间是怎么通信的
  - 求最短路径的算法说一说
  - 排序算法，快排的时间复杂度，为什么是不稳定的
  - TOPK问题（用大顶堆或者小顶堆），时间复杂度
  - 用1G的数据，但是只有128M的内存，要排序怎么排
  
  - JVM的内存划分，解释各个区域的作用，JVM为什么要这么分区
  - 分布式：paxos协议的leader选举
  - 两个字符数组求交集
  - jvm分区
  - redis介绍
  - tcpip协议介绍
  - 索引优化有哪些
  
  - 单链表序列化反序列化，结点中存字符串怎么办，类比网络中组包分包
  - 数据库表怎么设计，用户登录怎么保证安全性，数据库建索引了吗，为什么要把这些列作为索引， 索引建立顺序怎么确定
  - shiro中的token保存在什么地方
  - concurrenthashmap的场景：抢票
  - hibernate多对多是怎么查询的，hibernate多对多模型介绍下，数据库表索引设计顺序设计，为啥选择shiro
  - session怎么分布式存储（cookie，redis）
  - 并发打印foobar
  - 三个瓶身可以换一瓶酒，七个瓶盖可以换一瓶酒，初始x瓶酒，一共可以喝几瓶酒（考虑借瓶子、瓶盖再还回去）
  - atomiclong atomicadder
  - 随机生成1到一亿的数，怎么保证不重复（布隆过滤器），误报怎么办
  - hashmap concurrenthashmap(1.7 1.8 多线程扩容死循环 put的位置是NULL就用CAS插入，如果是forward就参与扩容，最后加syn锁)

  - Hashmap底层结构（1.7 1.8）concurrenthashmap怎么保证高效地操作(https://blog.csdn.net/qq_36520235/article/details/82417949)
  - 线程池优点、线程池的参数在什么场景下应该怎么配置、IO密集型线程跟CPU密集型线程的线程池参数怎么配置
  - 如何自定义一个注解(https://blog.csdn.net/xsp_happyboy/article/details/80987484)
  - 有没有接触过什么新技术(Docker)(https://zhuanlan.zhihu.com/p/62653543)(https://zhuanlan.zhihu.com/p/62653543)(https://www.cnblogs.com/linguoguo/p/10754756.html)
  - 有没有知道其他的数据库、非关系型数据库、分布式数据库(Redis)
  - Redis的使用场景，按你的理解如何设计一个秒杀系统(https://www.jianshu.com/p/d789ea15d060)
    > 1. 后台使用redis分布式数据库来保存秒杀的物品的信息，整体的服务架构可以使用 集群模式+主从模式，每个服务器分担一定的请求，并在主服务器出现故障后由哨兵节点及时切换到从服务器。  
    > 2. 在此期间，不要将缓存中的数据与数据库进行同步，等时间过后再进行同步。  
    > 3. 在数据持久化过程中，使用AOF方式，并可以把AOF持久化的时间间隔调整稍微长一点，减少持久化操作的次数。 
    > 4. 在redis缓存中，设置要秒杀的物品的信息永不过期，防止出现缓存雪崩的问题，并使用布隆过滤器来过滤掉来自客户端的一些无效恶意请求
    > 5. 服务器处理请求时，使用消息队列，减轻服务器并发操作的压力
    > 6. 当整体某些下游服务出现故障时，对故障服务进行熔断，防止影响整体服务的性能； 当整体服务的负载过高时，可以适当对某些服务进行降级，减低整体服务的负载
  - 在低并发的场景下，如何保证redis与数据库的数据一致性
  - Session的持久化问题
  - 登录人数的统计问题
  - 用户关闭了网页，服务器知道，并让用户登出
  - 如果有了用户违反了一些操作，怎么禁用这些用户的任何操作和登录（禁止token）
  - AomicLong跟LongAdder的区别
  - 使用Random生成 1~1亿的数字到文件中，如何保证不重复、单线程和多线程环境下
  - Java1.8 1.9 1.10的区别 jdk源码中用到了哪些设计模式
  - Shiro的过程，如果这个人的角色权限信息修改了，session中这个人的信息应该怎么办
  - 用户登陆的过程（实质上就是一次浏览器请求页面的过程）
  - 如果项目的qps很高的话项目怎么设计（分布式）
  - Servlet知不知道 他的生命周期
  - 线程池的使用，应该注意哪些问题，原生的线程池有哪些隐患
  - Springboot为啥能提供服务（因为有tomcat） tomcat你知道有啥东西吗，或者能配置什么东西 项目怎么配置运行过程中的jvm一些信息
  - Cpu怎么排查，怎么查看进程的信息，有没有导出过dump文件，你能看到什么东西
  - 服务集群了解过没
  - Rpc是什么，java原生的rpc知不知道 rmi知不知道

- 头条

  - 100瓶药水，其中只有一瓶有毒。给你一些老鼠，老鼠吃了之后24小时内会死亡。请问这24小时内，你需要最少多少只老鼠，可以把那瓶毒药试出来？
  - 交替打印ABC

- 领英

  - 链表排序：自顶向上的归并排序

- 腾讯

  - 一个长度一亿的数组，大量有序，少量无序，把数组改成链表怎么做

- 猿辅导

  - 二叉树后序遍历

- 美团

  - 自我介绍
  - 项目介绍
  - 项目中的难点
  - java基础：java的特性，**构造方法能不能被重写**，hashmap、hashtable、concurrenthashmap对比，string和stringbuffer对比
  - JVM垃圾回收算法
  - 有没有用过mysql、redis和消息中间件
  - 怎么用的消息中间件
  - TCP/IP的流量控制实现
  - 平时怎么学习的
  - 算法题：TOP K，无序数组找最小的K个

  - 项目，技术难点，怎么攻克的
  - 微服务怎么划分的，微服务之间怎么通信的
  - 为什么不用dubbo，为什么dubbo比springcloud速度快
  - 消息序列化用的什么版本
  - **编写sql时需要注意什么**
  - stu表，有id、name、score字段，写sql找到成绩第二的
  - **where a=x,b>y,c=z会不会走联合索引c,b,a**(https://blog.csdn.net/weixin_42935902/article/details/96887763)
  - 怎么判断一个sql会不会走某个索引，explain的字段都有哪些
  - **mysql优化器的策略**(https://blog.csdn.net/hsd2012/article/details/51526733)
  - 怎么衡量一个系统设计得成不成功，负载、TPS都是什么意思
  - 平时线上服务出了问题，怎么排查
  - 平时都是用什么工具排查JVM问题
  - 编程：斜对角线打印二维数组

  1.jvm分区 
  2.redis如何处理重复请求（比如你淘宝下单，你按了很多下，你是不是收到了重复请求，但是你单只有一个，所以怎么处理呢，我说redis里有set，每个订单下单都是唯一值，查看是否存在，然后就问我redis如何设定唯一值的命令，我这个不记得了，我查了下好像最好用上redis的锁...）（我觉得是set (key value nx ex)然后value保证唯一）
  3.elasticsearch（这个是我自己简历的，你们没有就不用管）
  4.mysql锁的概念，以及Mysql什么时候出现死锁，如何解决。
  5.描述下二分查询。
  6.算法题，删除字符串中出现字符出现最少的字符。

  - spring组件，mvcc，es，solr的索引表结构

- Zoom

  > [https://www.nowcoder.com/community/comment/detail/1051?action=0&notEmpty=false&page=1](https://www.nowcoder.com/community/comment/detail/1051?action=0&notEmpty=false&page=1)

  - 进公司后，HR 拿来一道笔试题，主要是线程安全方面的知识，简单的如 StringBuffer 和 StringBuilder 的区别，一般的有死锁怎么形成的，怎么解决死锁，HashMap,ConcurrentHashMap,LinkedHashMap的区别，SpringMVC的运行原理，难的有分布式锁怎么实现，BIO 和 NIO区别，除了难的题超出了我的范围其他的对我来说都比较easy了。只要JVM，多线程方面的知识准备充分，笔试面试都没问题。下面讲讲面试情况： 技术官进来，先自我介绍，问 new 一个对象，JVM 里面都干了啥，先是加载，验证，准备，解析，初始化啥的。后面问 volatile 关键字，从原子性，可见性，指令重排三个方面说了，又问 Synchronized 关键字在 1.6 做了哪些优化，从锁消除，锁粗化，偏向锁，轻量级锁，重量级锁解锁了一遍。 再问 ReentrantLock 和 Synchronized 的区别，从可中断，是否公平锁，条件锁方面阐述，延伸到 AQS，CAS 等。后面打算问我 IO 和 MySQL 方面的知识，我没经验，就说不知道，面试官也就直接跳过了。除了这两个，我几乎百分百答完了，基本达到甚至超过了面试官的知识准备。 后面是技术经理吧，进来就说刚才的反馈，是你不熟悉 MySQL，那么你平时用什么DB，答Oracle，然后就问你在公司从事什么角色，我是技术组长，那他说你举几个例子吧，我就举了两个，他也没深问，后面就锁，问了 AQS 的原理。再就没怎么问了。然后问我面什么职位，怎么投的简历。问我有什么问题，我当时尿急，直接说要先上下厕所，囧。回来后随便聊了下他们职位的工作内容，问了他们系统的 QPS，也没怎么仔细地说，再问项目都用了哪些技术，讲了些常规的技术。 总体感觉下来，里面的技术实力都不太强，也就一般互联网公司的技术实力，不过也算是中上了，不是什么公司都有独特的环境，获取到大流量，大数据量操练。

  - 流程的话，从学校投的简历，之后做了一个在线笔试。笔试比较考察基础吧，编程题就一题，也不是很难，刷刷算法题应该都做出来。 没有电面，去公司直接面的，公司环境很好，整体体验很好。下午去早了，前台小姐姐带我去的会议室（很nice的小姐姐还给我一杯水缓解压力），说面试官还在睡觉呢，以为要等很久。结果马上就来了，还打印了我的简历（包里彩打的简历表示毫无用处）之后就是正常面试流程，主要根据简历，考了数据结构，网络协议，数据库，设计模式等。大概50分钟，hr先来聊了一下公司现状岗位情况以及人生理想。然后说主管可以再面一下，然后就被问了GC，类加载，spring源码，算法源码，hash，网络和加密算法什么的，回答了大概，spring源码还没准备过。。。但是主管人也很好，一直鼓励你。让我在凉凉边缘多次拯救。 进公司就不用多说了，导师很牛，培训很多，制度也很完善，没有加班，人文关怀也特别优秀，节假日会有礼物，日常还有零食，来zoom不吃亏！（在职舔狗，性感评价）

  > [https://www.nowcoder.com/discuss/158738](https://www.nowcoder.com/discuss/158738)

  一面

  大概面了30分钟，面试官估计是以后的同事

  - 自我介绍
  - 问了问读了什么书
  - 围绕项目问了一些实现的问题
  - Redis场景题：
    - 如果有一个for循环，不停地进行SET操作，且每次SET的key不一样，可能会循环上万次。这样的话应该怎么优化（redis管道流执行命令，不会返回每次执行的结果，主要用于批量执行命令）(https://www.jianshu.com/p/84b655a55bf5)
    - 用Redis做缓存的时候，说说详细流程，怎么防脏读
  - Spring的AOP
  - Spring怎么实现事务，事务有哪些隔离级别
  - Java基本类型的封包拆包
  - 举个线程不安全的例子
  - 关于线程的使用的场景题
  - CAS的具体实现
  - MySQL有哪些索引，有什么区别
  - SQL语句调优会吗，有哪些调优方式
  - 关于我们公司，有什么想问我的吗

  二面

  面试官开会去了，等了大概20分钟，面了50分钟左右

  - 自我介绍
  - 继续聊项目
  - 说了项目的表结构
  - 项目部分功能的具体实现
  - 提了一些项目上可能会遇到的问题，问我怎么解决
  - 感觉收获很大，很多自己以前没有考虑
  - Java8有什么新的特性
  - Java怎么具体实现的ThreadLocal
  - 线程有哪些状态
  - 讲讲线程池，都有哪些参数
  - 说说常用的线程同步的方法
  - 浏览器请求URL到返回页面的详细过程(如果是localhost呢)
  - 三次握手、四次挥手的详细过程
  - 讲讲Java都有哪些锁，他们有什么区别
  - 说说你会什么容器，然后挑了HashMap和TreeMap问
  - 说说你会什么并发容器，挑了ConcurrentHashMap的具体实现问
  - Web后台一些功能实现的场景题
  - 项目用了Spring Boot，问了问内嵌的服务器还有做了哪些配置
  - AOP有什么用？有些名词你知道吗？
  - 说说jdk动态***和CGLIB有什么区别
  - 对什么设计模式比较熟？挑了适配器、装饰器和***模式问
  - 用过Spring Cloud吗(不会，但谈了谈Dubbo和ZooKeeper)
  - 会前端吗，有了解过什么
  - 打算做后台什么方向
  - 关于我们公司有什么想问我的吗

  三面(HR)

  后来才发现，来的是人力资源的经理(哦豁)

  - 哪里人
  - 对工资有什么要求吗
  - 打算读研吗
  - 有没有女朋友
  - 每周可以保证来几天
  - 什么时候可以来上班
  - 聊完后，去和Boss打了招呼后，就送我离开公司了

## 面试

- 20/2/25 阿里云
    
  - 自我介绍太生硬
  - 一般用什么语言，用过什么Java的数据结构，List包含哪些，ArrayList和LinkedList的区别，队列应该用ArrayList还是LinkedList实现
  - Leetcode 17，提示用队列
  - hashcode相同的对象是否一定相等，有什么用
  - TCP和UDP的区别和应用场景
  - 一般用什么数据库，乐观锁悲观锁的区别和应用场景，悲观锁不上锁那别的进程修改了怎么办
  - 研究生学过的课，考研比较擅长的课
  - 三次握手，传了SYN为什么还要传ACK
  - 对Maven的理解，Maven的生命周期、命令
  - 了解什么新的技术，希望从事哪方面的工作，对于云计算有什么了解
  - 反问有什么不足可以改进：断点debug，基础，java工程化经验（Maven原理） 

- 20/2/28 钉钉

  - I am @!#$software1234engineer1234输出engineer software am I
  - 如何一次循环O(n)时间
  - 项目：项目是商业应用吗，上线了吗，你是负责什么的，shiro是做什么用的，用户角色权限目录之间的关系，用户怎么查到权限，用户角色权限的存储，多对多关系的存储，用户角色权限设置了哪些接口，shiro是怎么和持久化框架连到一起的，为什么选择shiro简化了哪些工作，法规搜索用到什么技术，部署到服务器使用什么技术
  - **http状态码，4和5的区别**
  - **服务器超时，前端怎么处理**
  - http协议的原理
  - 前端请求后端数据的技术，数据格式是什么，json的特点，json和xml的区别和好处
  - 知道哪些Java集合类，List知道哪些，ArrayList是线程安全的吗，有哪些线程安全的List，你如何实现线程安全的List
  - 为什么要有多线程并发
  - 实现线程同步的方法，volatile的特性
  - 实现多线程的方法，线程池有哪些，线程池的好处，固定长度的线程池和可变长度的线程池各有什么优缺点
  - 数据库是怎么用数据结构优化存取时间的
  - 索引有哪些，聚合索引的机制，最左前缀匹配，abc三个字段组成一个聚合索引，**查询bc可以用到这个索引吗** 
  - 反问这个岗位最重要的品质：技术和落地

- 20/3/2 钉钉二面

  - 自我介绍
  - **项目中遇到什么问题，如何解决，原理是什么**
  - **SpringBoot（跟Spring的区别）、JPA（跟MyBatis的区别）**、Shiro介绍
  - 项目怎么继续优化，**elasticsearch和solr的原理是什么**
  - JVM区域划分，Java类是怎么加载到内存的（类加载的步骤）
  - 用户如何获取到权限，如何说服甲方避免从用户直接获取到权限
  - 反问这个岗位最重要的品质：基础知识和项目

- 20/3/3 淘宝

  - 自我介绍
  - 兴趣爱好
  - 项目：shiro的作用（认证、授权），法规检索为什么是自己做的不用ES，**项目的结构框架**（一开始我说Maven，后来他说不是这个意思，是指项目的层次结构），有没有把实验室和课程中学到的知识运用到项目中，Scrapy爬虫框架的结构介绍（spider、中间件、pipeline），反爬机制有哪些（IP池、UA、减慢速度），**知不知道网站如何防爬**，为什么爬虫要用到关键词提取、命名实体识别，为什么选HanLP，有没有试过其他的自然语言处理工具
  - 项目中遇到的最大的问题，解决的原理
  - 选过什么课，成绩怎么样，分词算法知道哪些
  - 怎么学习（书、网上的博客、和同学交流），看过什么书，哪本书的哪一部分比较映像深刻，书上说的有自己动手实践过吗，觉得自己Java学得怎么样
  - 垃圾收集器的原理和算法，**FullGC的触发条件**，CMS垃圾收集器的算法
  - 类加载器的原理，类加载器怎么破坏双亲委派机制
  - Java新特征（lambda表达式、方法引用、G1垃圾收集器），G1垃圾收集器介绍
  - **Atomic的原理**
  - 悲观锁和乐观锁介绍和应用场景
  - 三次握手，**滑动窗口有什么用**
  - IO有哪几种（BIO、NIO、AIO），它们各自的特点和区别，**知道select、poll、epoll吗**
  - 数据结构本科应该学过吧，平衡二叉树介绍
  - hashmap、hashtable、concurrenthashmap的区别和原理，源码看过吗，**hashmap的key可以是可变的吗，会遇到什么问题，是在编译阶段遇到问题还是运行阶段遇到问题，concurrenthashmap为什么高效**
  - 线程池的好处，**如果内存足够，线程池里的线程是越多越好吗**
  - leetcode 181 SQL，**内连接、左外连接、右外连接、全连接的区别**
  - 文件读写、外部排序、怎么优化（多线程缓存队列）
  - 反问你认为你们团队的技术氛围怎么样

- 20/3/7 CBU

  - 介绍一下项目里用到的技术，在项目中扮演的角色，java接触多久，框架怎么学习，除了shiro还知道什么认证授权的组件，项目里的选型是谁选的
  - **shiro怎么处理分布式的情况**（可以把用户的信息密码这些放到各个主机里，然后每次用户登录都去对应的主机取数据）
  - concurrent包有哪些组件(concurrenthashmap copyonwritearraylist)，用过吗
  - 重写equals方法需要注意什么，为什么要重写hashcode方法
  - 讲一下双亲委派模型
  - 反问实习生会受到什么培训，负责什么工作：会有师兄一对一带的，阿里的培训还是很完善的

- 20/3/10 淘宝

  - 项目：是商业项目吗，IP池，公开的IP是服务器吗，为什么可以绕过封锁，命名实体识别那些是干吗的，thinphp框架的结构，thinkphp前端怎么获取后端数据，thinkphp怎么管理事务，权限管理解释一下
  - http的原理，状态是存在哪里，**session如何得到用户对应的数据**，**http协议数据格式，有什么重要的数据**
  - **java并发包**用过哪些，hashmap和concurrenthashmap的区别，hashmap的死循环问题
  - **nio举个例子**说明有什么用
  - **类型擦除**
  - **数据库的一致性举个例子说明一下**
  - 双亲委派模型，**为什么要双亲委派**
  - 项目里用到什么**设计模式**，工厂设计模式和单例设计模式不算
  - 编程题：两种方法实现二叉树层数
  - 反问实习生会受到什么培训，负责什么工作：走阿里的程序，有转正答辩，流程还是比较复杂的

- 20/3/11 飞猪

  - 自我介绍
  - 项目：智能执法平台介绍，认证授权的过程，**shiro的原理**，IP池怎么维护，法规检索怎么做的，词典保存在哪里，顺排索引和倒排索引的区别，怎么优化测试IP时的时间消耗（用一个线程专门检查IP的可用性）
  - 怎么学习
  - hashmap的原理和数据结构，hashmap可以多线程吗，会出现什么问题，concurrenthashmap加的是什么锁，JDK1.8做了什么改动
  - java内存分区，虚拟机栈和本地方法栈的区别，CMS垃圾回收器，标记-清除算法有什么缺点，怎么解决
  - 创建线程的方法，callable和runnable有什么区别，**不返回运行状态可以用callable吗**，线程池的特性（分类？），线程池的参数
  - **出现OOM异常怎么排查，怎么看哪里有问题，CPU占用过高怎么排查，用什么命令看**
  - 反问实习生会受到什么培训，负责什么工作：培训一下阿里的价值观，写业务，但是会有师兄带

- 20/3/13 CBU

  - 自我介绍，有没有实习过，单位是做什么的
  - **怎么设计线程池（用一个容器放线程，用一个变量存当前线程个数，然后用一个队列存阻塞的线程），怎么设计阻塞队列，要考虑什么问题**
  - 垃圾怎么清理（GCRoots向下追溯，分代收集），**这是第一步，然后怎么清理**
  - **设计模式**，代理设计模式
  - **spring加载的过程**
  - **怎么设计数据库表**
  - 项目：是不是分布式的，检索的原理，为什么不用倒排索引
  - 反问实习生会受到什么培训，负责什么工作：跟大学里一样有一些公开的讲座，也是要靠自己自觉去学

- 20/3/16 阿里妈妈

  - 笔试两天之前发的：日志统计出现次数并排序
  - 代码是你写的吗，解释一下思路，觉得复不复杂
  - 如果日志是海量数据怎么处理(散列成小文件)，有什么问题吗
  - 项目里会写注释吗，会分函数吗，了解过Java代码的规范吗
  - 怎么定位慢SQL，explain的字段有哪些，type字段最好到最差怎么排序
  - java怎么连数据库，MyBatis用过吗
  - 有没有做过安卓、iOS开发
  - 有没有做过线上的JVM错误排查
  - 怎么限流，有没有做过，服务依赖、服务降级
  - 网络安全：跨脚本攻击、XSS、SQL注入
  - 有没有用过阿里云、腾讯云
  - HTTP协议是有状态的协议吗，302、500什么意思
  - 项目哪个最复杂，有多人协作吗，多人管理项目的流程
  - 怎么学习，毕业以后的打算
  - 反问实习生会负责什么工作：广告的业务

- 20/3/30 美团

  - 自我介绍
  - 项目介绍：并查集，Maven怎么控制版本，Maven的生命周期
  - 跳表介绍，有什么缺点
  - OSI 7层模型，HTTP的过程，DNS的步骤，HTTP的幂等性，get请求和post请求的区别
  - TCP的三次握手、四次挥手，为什么握手三次，挥手四次
  - 双亲委派模型，三个级别的类加载器的功能
  - java.lang.String写个一模一样的可以运行吗，会报错吗
  - HashMap，100个元素要建多大的HashMap，负载因子是什么，默认是多少
  - 重写equal不重写hashcode会怎么样，会报错吗，重写hashcode要注意什么，一个学生的学号、姓名、性别、地址应该怎么计算hashcode，hash函数（除方法、乘方法）
  - Java堆（分代收集，新生代、老年代），YoungGC和FullGC的触发条件
  - 线程有哪些状态，怎么转换，死锁
  - 线程池介绍（线程池的优点，4种线程池，构造函数的参数）
  - MySQL的ACID，隔离级别，默认是什么隔离级别，解决了什么问题，脏读和幻读解释一下
  - SQL：表中有学生学号、课程、成绩，找出学生的课程总分在一个范围内的学号
  - 算法题：走台阶
  - 反问实习生负责什么业务：写Java，到店事业群，围绕一台机器的业务

- 20/4/1 Zoom

  - 自我介绍，项目介绍
  - JPA的一对一一对多多对多关系优化，全自动框架怎么优化SQL
  - AOP介绍，织入顺序怎么解决
  - 用Java定时启动一个请求怎么实现
  - InterruptException是怎么引起的
  - 主线程不能interrupt子线程，怎么退出主线程，有什么参数
  - ArrayList和LinkedList的区别和应用场景
  - ArrayList和LinkedList是线程安全的吗，JDK有什么自带的线程安全的List
  - HashMap：保证equals和hashcode相等，key的字段可以修改吗？Bean对象有多个字段，怎么重写hashcode？
  - 算法题思路：Arraylist.removeAll(Set)怎么实现
  - 算法题思路：abcoefp找包含aop的最短字符串，顺序无所谓
  - 导致线程不安全的原因，除了竞争还有什么
